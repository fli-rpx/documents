<html> <head> <title>Patent Review</title> </head> <body> Search word: <input type="text" name="patent_text" id="search_text"><input type="button" name="refresh" value="Search"  onClick="showText();"><br> <br> <input style="border:none;display: inline-block; width:50px;" type="label" name="result_count" id="result_count_i" value="699"> documents <br> <br><layer id = "layer1"><p><b>US5878391A:Device for indicating a probability that a received signal is a speech signal</b><br>A device for use in conjunction with a prayer book and sized to be inserted within the confines thereof is provided with a plurality of individual tabs, the tabs being individually extendable from the device to protrude beyond the confines of the book and is provided with indicia to visually remind the user of specific prayers, prayer segments and words applicable to the prayers of a specific day.<br><b>Independant Claims</b><br>1. An audio device for processing a received audio signal, said audio device comprising: a speech signal discrimination arrangement; and means for processing the received audio signal dependent on a probability indication signal generated by the speech signal discrimination arrangement; said speech signal discrimination arrangement comprising: an analyzing circuit for deriving an analysis signal indicative of a ratio between a signal power in a first portion of a frequency spectrum of the received audio signal and a signal power in a second portion of the frequency spectrum of the received audio signal; a first signal pattern detector for detecting first and second signal patterns in the analysis signal, said first and second signal patterns each having a probability of occurrence in a speech signal that is greater than a probability of occurrence in another signal which is not a speech signal, said first signal patterns being a plurality of briefly succeeding rapid changes in the power ratio, each occurring within a given maximum time, and said second signal patterns being a temporary decrease of the power ratio below a given lower threshold for a given period of time; and estimator means for deriving the probability indication signal based on the detection of the first and second signal patterns.<br>2. A speech signal discrimination arrangement having an input for receiving an audio signal and an output for supplying a probability indication signal which is indicative of the probability that the audio signal received via the input is a speech signal, the arrangement comprising: an analyzing circuit for deriving an analysis signal which is indicative of a ratio between a signal power in a first portion of a frequency spectrum of the received audio signal and a signal power in a second portion of the frequency spectrum of the received audio signal; a first signal pattern detector for detecting first and second signal patterns in the analysis signal, said first and second signal patterns each having a probability of occurrence in a speech signal that is greater than a probability of occurrence in another signal which is not a speech signal, said first signal patterns being a plurality of briefly succeeding rapid changes in the power ratio, each occurring within a given maximum time, and said second signal patterns being a temporary decrease of the power ratio below a given lower threshold for a given period of time; and estimator means for deriving the probability indication signal based on the detection of the first and second signal patterns.</p></layer>
<layer id = "layer2"><p><b>US5068899A:Transmission of wideband speech signals</b><br>Speech synthesis system implementable in an integrated circuit device capable of converting frames of speech data at a variable frame rate into analog signals representative of human speech. The frames of speech data comprise digital representations of values of pitch, energy, filter coefficients and coded frame rate data. The speech synthesis system includes a linear predictive coding filter as a speech synthesizer which utilizes the speech data at a varying frame rate to produce digital speech signals representative of human speech. Frames of digital speech data including coded frame rate data are received by an input, with the frame rate data being decoded to control both the rate at which the incoming variable-length frames of speech data are accepted by the speech synthesizer and the number of interpolation calculations required to define interpolated speech values between adjacent incoming frames of speech data. A frame control circuit accomplishes the foregoing utilization of speech data at a variable frame rate by the speech synthesizer by providing for a variable number of interpolation calculations between adjacent speech frames from last implemented speech data in which the number of interpolation calculations in a given instance is determined by the frame rate data. A microprocessor controls the access of selected speech data which is stored in a memory. The system also includes a digital-to-analog converter for converting the digital speech signals produced by the filter into analog signals and a speaker for generating audible sounds in the form of synthesized human speech from the analog signals provided by the digital-to-analog converter.<br><b>Independant Claims</b><br>1. A method of transmitting components of a signal in a high band of frequencies, above a predetermined frequency, on a digital transmission channel which carries components of the signal in a low band of frequencies, below the predetermined frequency, in the form of signal samples sampled at a rate of twice the predetermined frequency, comprising the steps of: deriving from the signal bits of information relating to the high band signal components; and transmitting said bits of information in place of the least significant bit of the samples.<br>14. A method of transmitting components, at frequencies above 4 kHz, of a speech signal on a digital transmission channel via which eight-bit samples of the speech signal at a sampling rate of 8 kHz are transmitted, comprising the step of replacing an eighth least significant bit of each sample with a bit of information derived from the speech signal components at frequencies above 4 kHz.<br>15. Apparatus for transmitting signal components of a speech signal in high and low bands of frequencies respectively above and below a predetermined frequency, comprising: means for producing digital samples of speech signal components in the low band at a sampling rate of twice the predetermined frequency for transmission, each sample comprising eight bits including a least significant bit; means for producing, from the speech signal, bits of information relating to speech signal components in the high band; and means for replacing the least significant bit of each sample with a bit of information relating to speech signal components in the high band.</p></layer>
<layer id = "layer3"><p><b>US7191123B1:Gain-smoothing in wideband speech and audio signal decoder</b><br>An insulating film comprising a compound having a cage structure, wherein the insulating film has a coefficient of linear expansion of 120×10<sup>−6 </sup>K<sup>−1 </sup>or less; an insulating film, which is obtained by a method comprising: irradiating a film-forming composition containing a compound having a cage structure with electron beams so as to cure the film-forming composition; and an electronic device comprising the insulating film.<br><b>Independant Claims</b><br>1) A method for producing a gain-smoothed codevector during decoding of an encoded wideband signal from a set of wideband signal encoding parameters, said method comprising: finding a codevector in relation to at least one first wideband signal encoding parameter of said set; calculating a first factor representative of voicing in the wideband signal in response to at least one second wideband signal encoding parameter of said set; calculating a second factor representative of stability of said wideband signal in response to at least one third wideband signal encoding parameter of said set; calculating a smoothing gain based on said first and second factors; and amplifying the found codevector with said smoothing gain to thereby produce said gain-smoothed codevector.<br>17) A method for producing a gain-smoothed codevector during decoding of an encoded signal from a set of signal encoding parameters, said signal containing stationary background noise and said method comprising: finding a codevector in relation to at least one first signal encoding parameter of said set; calculating at least one factor representative of stationary background noise in the signal in response to at least one second signal encoding parameter of said set; calculating a smoothing gain using a non linear operation based on said noise representative factor; and amplifying the found codevector with said smoothing gain to thereby produce said gain-smoothed codevector.<br>18) A method for producing a gain-smoothed codevector during decoding of an encoded wideband signal from a set of wideband signal encoding parameters, said method comprising: finding a codevector in relation to at least one first wideband signal encoding parameter of said set; calculating a factor representative of voicing in the wideband signal in response to at least one second wideband signal encoding parameter of said set; calculating a smoothing gain using a non linear operation based on said voicing representative factor; and amplifying the found codevector with said smoothing gain to thereby produce said gain-smoothed codevector.<br>19) A method for producing a gain-smoothed codevector during decoding of an encoded wideband signal from a set of wideband signal encoding parameters, said method comprising: finding a codevector in relation to at least one first wideband signal encoding parameter of said set; calculating a factor representative of stability of said wideband signal in response to at least one second wideband signal encoding parameter of said set; calculating a smoothing gain using a non linear operation based on said stability representative factor; and amplifying the found codevector with said smoothing gain to thereby produce said gain-smoothed codevector.<br>20) A device for producing a gain-smoothed codevector during decoding of an encoded wideband signal from a set of wideband signal encoding parameters, said device comprising: a codevector finder supplied with at least one first wideband signal encoding parameter of said set, and delivering a codevector found in relation to said at least one first wideband signal encoding parameter; a voicing factor calculator supplied with at least one second wideband signal encoding parameter of said set, and delivering a first factor representative of voicing in the wideband signal in response to said at least one second wideband signal encoding parameter; a stability factor calculator supplied with at least one third wideband signal encoding parameter of said set, and delivering a second factor representative of stability of said wideband signal in response to said at least one third wideband signal encoding parameter; a smoothing gain calculator supplied with the first and second factors, and delivering a smoothing gain based on said first and second factors; and an amplifier supplied with both the found codevector and the smoothing gain, and amplifying said found codevector with said smoothing gain to thereby produce said gain-smoothed codevector.<br>21) A device for producing a gain-smoothed codevector during decoding of an encoded wideband signal from a set of wideband signal encoding parameters, said device comprising: means for finding a codevector in relation to at least one first wideband signal encoding parameter of said set; means for calculating a first factor representative of voicing in the wideband signal in response to at least one second wideband signal encoding parameter of said set; means for calculating a second factor representative of stability of said wideband signal in response to at least one third wideband signal encoding parameter of said set; means for calculating a smoothing gain based on said first and second factors; and means for amplifying the found codevector with said smoothing gain to thereby produce said gain-smoothed codevector.<br>101) A device for producing a gain-smoothed codevector during decoding of an encoded signal from a set of signal encoding parameters, said signal containing stationary background noise and said device comprising: means for finding a codevector in relation to at least one first signal encoding parameter of said set; means for calculating at least one factor representative of stationary background noise in the signal in response to at least one second wideband signal encoding parameter of said set; means for calculating a smoothing gain using a non linear operation based on said noise representative factor; and means for amplifying the found codevector with said smoothing gain to thereby produce said gain-smoothed codevector.<br>102) A device for producing a gain-smoothed codevector during decoding of an encoded wideband signal from a set of wideband signal encoding parameters, said device comprising: means for finding a codevector in relation to at least one first wideband signal encoding parameter of said set; means for calculating a factor representative of voicing in the wideband signal in response to at least one second wideband signal encoding parameter of said set; means for calculating a smoothing gain using a non linear operation based on said voicing representative factor; and means for amplifying the found codevector with said smoothing gain to thereby produce said gain-smoothed codevector.<br>103) A device for producing a gain-smoothed codevector during decoding of an encoded wideband signal from a set of wideband signal encoding parameters, said device comprising: means for finding a codevector in relation to at least one first wideband signal encoding parameter of said set; means for calculating a factor representative of stability of said wideband signal in response to at least one second wideband signal encoding parameter of said set; means for calculating a smoothing gain using a non linear operation based on said stability representative factor; and means for amplifying the found codevector with said smoothing gain to thereby produce said gain-smoothed codevector.</p></layer>
<layer id = "layer4"><p><b>US20030063759A1:Directional audio signal processing using an oversampled filterbank</b><br>In a transfer sheet and a method of transferring a figuration to a ceramic product, an ink is provided by mixing a chromophoric pigment for expressing a desired coloration, a vitreous powder and thermoplastic resin. A sheet of paper or plastic film is prepared on which an appropriate figuration is screen printed with the use of the ink to transfer it to an outer surface of a ceramic product. A thermoplastic separable layer is provided between the mount sheet and a pigment layer. The pigment layer is coated with an adhesive layer.<br><b>Independant Claims</b><br>1. A directional signal processing system for beamforming a plurality of information signals, said directional signal processing system comprising: a plurality of microphones; an oversampled filterbank comprising at least one analysis filterbank for transforming a plurality of information signals in time domain from the microphones into a plurality of channel signals in transform domain, and one synthesis filterbank and a signal processor for processing the outputs of said analysis filterbank for beamforming said information signals, the synthesis filterbank transforming the outputs of said signal processor to a single information signal in time domain.<br>52. A method of processing a plurality of channel signals for achieving approximately linear phase response within the channel, said method comprising the step of performing filtering by applying one or more filter to at least one channel signal.<br>54. A method of processing at least one information signal in time domain for achieving approximately linear phase response, said method comprising the step of performing an oversampled transformation using at least one oversampled analysis filterbank, said oversampled analysis filterbank applying at lease one fractional delay impulse response to at least one filterbank prototype window.</p></layer>
<layer id = "layer5"><p><b>US8121833B2:Signal modification method for efficient coding of speech signals</b><br>This inventions provides techniques for estimating both temporal and spectral channel fluctuations with the duration of a data symbol. Certain pulse shaping functions are Discrete Prolate Spheroidal Sequences (DPSSs) and are used primarily because of their relatively limited Inter-Symbol Interference (ISI) properties. During reception, these properties allow one or more parameters of a joint time-frequency channel model to be more easily determined. Once the one or more parameters are determined, they can be applied to received symbols to correct the temporal fluctuations, spectral fluctuations, or both of the channel over which a communication took place. The techniques may be adapted for the Multiple-In, Multiple-Out communication situation.<br><b>Independant Claims</b><br>1) A method, comprising: dividing a sound signal into a series of successive flames; dividing each frame into a number of subframes; producing, by a device, a residual signal by filtering the sound signal through a linear prediction analysis filter; locating a last pitch pulse of the sound signal of a previous frame from the residual signal; extracting a pitch pulse prototype of given length around a position of the last pitch pulse of the previous frame using the residual signal; locating pitch pulses in a current frame using the pitch pulse prototype; predicting a position of a first pitch pulse of the current frame to occur at an instant related to the position of the previously located pitch pulse and an interpolated open-loop pitch estimate at an instant corresponding to the position of the previously located pitch pulse; and refining the predicted position of said pitch pulse by maximizing a weighted correlation between the pulse prototype and the residual signal.<br>3) An apparatus, comprising: a divider, within a device, configured to divide a sound signal into a series of successive frames; a divider of each frame into a number of subframes; a linear prediction analysis filter configured to filter the sound signal and thereby producing a residual signal; a detector configured to detect a last pitch pulse of the sound signal of a previous frame in response to the residual signal; an extractor configured to extract a pitch pulse prototype of given length around a position of the last pitch pulse of the previous frame in response to the residual signal; a detector configured to detect pitch pulses in a current frame using the pitch pulse prototype; a predictor configured to predict a position of each pitch pulse of the current frame to occur at an instant related to the position of the previous located pitch pulse and an interpolated open-loop pitch estimate at said instant corresponding to the position of the previously located pitch pulse; and a refiner configured to refine the predicted position of said pitch pulse by maximizing a weighted correlation between the pulse prototype and file residual signal.<br>5) A method, comprising: dividing, by a device, a sound signal into a series of successive frames; dividing each frame into a number of subframes; producing a weighted sound signal by processing the sound signal through a weighting filter, the weighted sound signal being indicative of signal periodicity; locating a last pitch pulse of the sound signal of the previous frame from the weighted sound signal; extracting a pitch pulse prototype of given length around a position of the last pitch pulse of a previous frame using the weighted sound signal; locating pitch pulses in a current frame using the pitch pulse prototype; predicting a position of a first pitch pulse of the current frame to occur at an instant related to the position of the previously located pitch pulse and an interpolated open-loop pitch estimate at an instant corresponding to the position of the previously located pitch pulse; and refining the predicted position of said pitch pulse by maximizing a weighted correlation between the pulse prototype and the weighted sound signal.<br>7) An apparatus, comprising: a divider, within a device, configured to divide a sound signal into a series of successive frames; a divider of each frame into a number of subframes; a weighting filter configured to process the sound signal to produce a weighted sound signal, the weighted sound signal being indicative of signal periodicity; a detector configured to detect a last pitch pulse of the sound signal of a previous frame in response to the weighted sound signal; an extractor configured to extract a pitch pulse prototype of given length around a position of the last pitch pulse of the previous frame in response to the weighted sound signal; a detector configured to detect pitch pulses in a current frame using the pitch pulse prototype; a predictor configured to predict a position of each pitch pulse of the current frame to occur at an instant related to the position of the previous located pitch pulse and an interpolated open-loop pitch estimate at said instant corresponding to the position of the previously located pitch pulse; and a refiner configured to refine the predicted position of said pitch pulse by maximizing a weighted correlation between the pulse prototype and the weighted sound signal.<br>9) A method, comprising: dividing, by a device, a sound signal into a series of successive frames; dividing each frame into a number of subframes; producing a synthesized weighted sound signal by filtering a synthesized speech signal produced during a last subframe of a previous frame of the sound signal through a weighting filter; locating a last pitch pulse of the sound signal of the previous frame from the synthesized weighted sound signal; extracting a pitch pulse prototype of given length around the position of the last pitch pulse of the previous frame using the synthesized weighted sound signal; locating pitch pulses in a current frame using the pitch pulse prototype; predicting a position of a first pitch pulse of the current frame to occur at an instant related to the position of the previously located pitch pulse and an interpolated open-loop pitch estimate at an instant corresponding to the position of the previously located pitch pulse; and refining the predicted position of said pitch pulse by maximizing a weighted correlation between the pulse prototype and the synthesized weighted sound signal.<br>11) An apparatus, comprising: a divider, within a device, configured to divide a sound signal into a series of successive frames; a divider configured to divide each frame into a number of subframes; a weighting filter configured to filter a synthesized speech signal produced during a last subframe of a previous frame of the sound signal and thereby producing a synthesized weighted sound signal; a detector configured to detect a last pitch pulse of the sound signal of the previous frame in response to the synthesized weighted sound signal; an extractor configured to extract a pitch pulse prototype of given length around the position of the last pitch pulse of the previous frame in response to the synthesized weighted sound signal; a detector configured to detect pitch pulses in a current frame using the pitch pulse prototype; a predictor configured to predict a position of each pitch pulse of the current frame to occur at an instant related to the position of the previous located pitch pulse and an interpolated open-loop pitch estimate at said instant corresponding to the position of the previously located pitch pulse; and a refiner configured to refine the predicted position of said pitch pulse by maximizing a weighted correlation between the pulse prototype and the synthesized weighted sound signal.</p></layer>
<layer id = "layer6"><p><b>US4618982A:Digital speech processing system having reduced encoding bit requirements</b><br>A magnetic bubble expander-detector circuit comprising a pattern of magnetic material, forming Chevron elements positioned over a bubble-supporting material to define a bubble expander-detector circuit. Each element of the pattern is spaced from the bubble material such that a gradient is formed in the spacing between the element and the bubble material in the direction of the expansion and detection. A rotating magnetic field of sufficient strength to magnetize the pattern is applied in the plane of the material and the gradient of the spacing causes the bubbles to move from one element to an adjacent element as the bubbles are expanded and ultimately detected by suitable detection devices. This invention is particularly characterized in that, with the combination of the pattern elements and the gradient spacing thereof, gaps between adjacent elements are eliminated.<br><b>Independant Claims</b><br>1. In a linear prediction speech processing system wherein a digital speech signal is divided in the time domain into sections and each section is analyzed to determine the parameters of a speech model filter, a volume parameter and a pitch parameter, a method for coding the determined parameters to reduce bit requirements and increase the frame rate of transmission of the parameter information for subsequent synthesis, comprising the steps of: combining the determined parameters of at least two successive speech sections into a block of information; coding the determined parameters for the first speech section in said block in complete form to represent their magnitudes; and coding at least some of the parameters in the remaining speech sections in said block in a form representation of their relative difference in magnitude from the corresponding parameters in said first speech section.<br>14. Apparatus for analyzing a speech signal using the linear prediction process and coding the results of the analysis for transmission, comprising: means for digitizing a speech signal and dividing the digitized signal into blocks containing at least two speech sections; a parameter calculator for determining the coefficients of a model speech filter based upon the energy levels of the speech signal, and a sound volume parameter for each speech section; a pitch decision stage for determining whether the speech information in a speed section is voiced or unvoiced; a pitch computation stage for determining the pitch of a voiced speech signal; and coding means for encoding the filter coefficients, sound volume parameter, and determined pitch for the first section of a block in a complete form to represent their magnitudes and for encoding at least some of the filter coefficients, sound volume parameter and determined pitch for the remaining sections of a block in a form representative of their difference from the corresponding information for the first section.</p></layer>
<layer id = "layer7"><p><b>US5056150A:Method and apparatus for real time speech recognition with and without speaker dependency</b><br>6-Fluoro-4-chromanone, a sorbinil intermediate, is regenerated from enantiomeric and mixtures of enantiomeric and racemic compounds obtained as major by-products in the synthesis of sorbinil. The regenerated intermediate is useful in the synthesis of additional sorbinil.<br><b>Independant Claims</b><br>1. A speaker dependent and independent speech recognition method, based on a comparison between speech characteristic parameter frames and a plurality of reference samples which are generated from a speaker in dependent recognition or from a plurality of persons having representative sounds in independent recognition, comprising the steps of: a) converting speech signals into a series of primitive sound spectrum parameter frames; b) determining beginning and ending points of sounds of speech according to said primitive sound parameter frames, for determination of a sound spectrum parameter frame series; c) performing non-linear time domain normalization on said sound spectrum parameter frame series into a speech characteristic parameter frame series of predefined length on the time domain, including: forming a sound stimulus series corresponding to said sound spectrum parameter frame series, selecting or deleting each sound spectrum parameter frame, respectively, according to whether a sound stimulus value of said sound spectrum parameter frame is greater or less than an average sound stimulus value, wherein said sound stimulus value represents the difference between two adjacent sound spectrum parameter frames, and wherein said average sound stimulus value is the average of all of said sound stimulus values; d) performing amplitude quantizing normalization on said speech characteristic parameter frames obtained from step c); e) comparing said speech characteristic parameter frame series of step d) with each of a plurality of reference samples, said plurality of reference samples having previously been subjected to amplitude quantizing normalization, for determining a reference sample having a closest match with said speech characteristic parameter frame series; and f) determining a result of recognition according to said reference sample having said closest match.<br>10. A speaker dependent and independent speech recognition apparatus based on a comparison between speech characteristic parameter frames and reference samples which are generated from one of a speaker in dependent recognition and from persons producing representative sounds in independent recognition, comprising: a) a speech parameter extracting means for converting speech signals into a series of primitive sound spectrum parameter frames; b) determining means for determining beginning and ending points of sounds of speech based on said series of primitive sound spectrum parameter frames, for obtaining a sound spectrum parameter frame series; c) time domain normalization means for normalizing said sound spectrum parameter frame series into a speech characteristic parameter frame series of predefined length on the time domain including: forming a sound stimulus series corresponding to said sound spectrum parameter frame series, selecting or deleting each sound spectrum parameter frame, respectively, according to whether a sound stimulus value of said sound spectrum parameter frame is greater or less than an average sound stimulus value, wherein said sound stimulus value represents the difference between two adjacent sound spectrum parameter frames, and wherein said average sound stimulus value is the average of all of said sound stimulus values; d) quantizing normalization means for performing amplitude quantizing normalization on each frame of said speech characteristic parameter frame series; e) difference evaluation means for comparing said speech characteristic parameter frame series with said plurality of reference samples, for determining a reference sample having a closest match with said speech characteristic parameter frame series of equal length on the time domain; and f) judgement means for determining a result of recognition according to said reference sample having said closest match.</p></layer>
<layer id = "layer8"><p><b>US20040153313A1:Method for enlarging the band width of a narrow-band filtered voice signal, especially a voice signal emitted by a telecommunication appliance</b><br>A latching mechanism for a closure of a motor vehicle compartment includes a housing forming a vertically extending groove for receiving a striker bar secured to the closure, first and second hollow rivets located on opposite sides of the groove, a striker spring located at the groove for upwardly biasing the striker bar out of the groove, a pawl pivotable about the first hollow rivet and defining a notch, and a ratchet pivotable about the second hollow rivet and defining a protrusion adapted to cooperate with the notch of the pawl to selectively retain the ratchet in a locked position. the ratchet also defines pocket for receiving the striker bar and retaining the striker bar in the groove when the ratchet is in the locked position. Fasteners extend though passageways in the hollow rivets to secure the latching mechanism to the motor vehicle. The striker spring is positioned to directly engage the striker bar when the striker bar is in the groove to bias the striker bar in a direction out of the groove. Adjustment means are preferably provided to adjust the position of the striker spring and therefore the force applied to the striker bar by the striker spring. The latching mechanism preferably further includes a hook pivotable about the first hollow rivet and defining a secondary catch for receiving the striker bar to retain the striker bar in the groove when exiting the ratchet pocket. A paddle is preferably provided to manually pivot the hook and release the striker bar from the secondary catch and the groove. The pawl preferably forms an internal stop which limits rotation of the ratchet when the striker is moving downward to directly transfer over slam forces to the vehicle structure through the hollow rivets and mounting fasteners.<br><b>Independant Claims</b><br>1. Method for expanding the bandwidth of a narrowband filtered speech signal, in particular a speech signal transmitted by a telecommunications device, above a cut-off frequency of the narrowband speech signal, characterized in that the narrowband speech signal is estimated in relation to frequency components above a first cut-off frequency and below a second cutoff frequency separately from each other and expanded on the basis of this respective estimation.<br>4. Method for expanding the bandwidth of a narrowband filtered speech signal, in particular a speech signal transmitted by a telecommunications device, above a first cut-off frequency of the narrowband speech signal, wherein a) the narrowband speech signal is subdivided into speech signal time segments (P0.1) and a spectral structure of the speech signal time segment is computed in each case (P1.1), b) each narrowband speech signal time segment is classified as a voiced sound or as an unvoiced sound (P2.1), characterized in that c) enhancements having a spectral structure for expanding the narrowband speech signal in relation to the sound-related classification (P3.1) performed in b), wherein in particular at least for the case of the voiced sound the enhancement is independent of the respective sound, d) the spectral structure of the narrowband speech signal time segment and the spectral structure of the generated enhancement are combined (P3.1) in time segment sequence such that an expanded spectral structure is produced in each case, e) a wideband expanded speech signal time segment is generated in each case from the expanded spectral structure (P3.1), f) a wideband expanded speech signal time segment is generated from the individual wideband expanded speech signal time segments (P6.1).<br>7. Method for expanding the bandwidth of a narrowband filtered speech signal, in particular a speech signal transmitted by a telecommunications device, above a first cut-off frequency of the narrowband speech signal, wherein a) the narrowband speech signal is subdivided into speech signal time segments (P0.2) and a spectral structure of the speech signal time segments is computed in each case (P1.2, P2.2), b) each narrowband speech signal time segment is classified as a voiced sound or as an unvoiced sound (P3.2), characterized in that c) enhancements having a spectral structure for expanding the narrowband speech signal in relation to the sound-related classification (P4.2) performed in b), wherein at least for the case of the voiced sound the enhancement is independent of the respective sound, d) the spectral structure of the narrowband speech signal time segments and the spectral structure of the generated enhancement are combined (P4.2) in time segment sequence such that an expanded spectral structure is produced in each case, e) with regard to the time segment duration, prediction error signal time segments of a wideband prediction error signal corresponding to the narrowband speech signal time segments are generated (P5.2) and a wideband expanded speech signal time segment is generated in each case from the expanded spectral structure and the respective wideband prediction error signal time segment (P6.2, P7.2), f) a wideband expanded speech signal is generated from the individual wideband expanded speech signal time segments (P10.2).<br>17. Method for expanding the bandwidth of a narrowband filtered speech signal, in particular a speech signal transmitted by a telecommunications device, above a first cut-off frequency of the narrowband speech signal, wherein a) the narrowband speech signal is subdivided into speech signal time segments (P0.3), b) each narrowband speech signal time segment is classified as a voiced sound or as an unvoiced sound (P1.3), characterized in that c) the narrowband speech signal time segments are processed non-linearly (P2.3) in such a way that in each case a modified speech signal time segment is generated which on the one hand contains the respective essentially unmodified narrowband speech signal time segment and on the other hand contains signal components generated by the non-linear signal processing above the first cut-off frequency, d) the modified speech signal time segments are filtered differently (P3.3) in relation to the sound-related classification performed in b) in such a way that wideband expanded speech signal time segments and hence a wideband expanded speech signal are produced from the modified speech signal time segments.<br>23. Method for expanding the bandwidth of a narrowband filtered speech signal, in particular a speech signal transmitted by a telecommunications device, below a second cut-off frequency of the narrowband speech signal, wherein a) a prediction error signal of the narrowband speech signal is computed (P0.4, P0.5) characterized in that b) the filter characteristic of the narrowband filtered speech signal is estimated on the basis of the prediction error signal (P1.4, P1.5), c) based on the filter characteristic, a process for processing the narrowband speech signal is controlled in such a way (P2.4, P2.5, P3.5, P4.5, P5.5) that a wideband expanded speech signal is generated.</p></layer>
<layer id = "layer9"><p><b>US5479517A:Method of estimating delay in noise-affected voice channels</b><br>The invention is concerned with novel isoquinoline derivatives of the formula ##STR1## wherein R.sup.1 is hydrogen, lower alkyl, lower alkoxy, aryl, aryloxy, aryl-lower alkyl or aryl-lower alkoxy and R.sup.2 is phenyl or substituted phenyl. These novel isoquinoline derivatives are valuable intermediates in the manufacture of morphinan derivatives.<br><b>Independant Claims</b><br>1. A method for estimating a delay between a first signal of a first noise-affected voice channel and a second signal of a second noise-affected voice channel, the first and second signals being related, the method comprising the steps of: transforming the first and second signals to frequency domain signals; cross correlating the transformed first and second signals to produce a cross power density of the first and second signals; generating a phase value representing a phase between the first and second signals based on a first predetermined number of maxima values of the cross power density of the first and second signals; and performing a phase compensation in the frequency domain based on the phase value for compensating for the delay between the first and second signals.</p></layer>
<layer id = "layer10"><p><b>US20010028713A1:Time-domain noise suppression</b><br>A device for feeding reels to a user machine, wherein a stack of reels is fitted on to the vertical guide of a slide of a lifting device; the slide defining a supporting surface for the stack and being moved along the guide by a screw-nut screw device controlled by a control system via a system of sensors, so as to successively feed the reels into a pickup station wherein the reels are fed successively, by a pickup arm, on to a conveyor for feeding the reels to the user machine.<br><b>Independant Claims</b><br>1. Process for reducing noise signals in telecommunications (Tc) systems for the transmission of acoustic useful signals, in particular human speech, with the following steps: (a) Determining by means of speech pause detection when a speech signal is contained in the mixture of useful signals and interference signals to be transmitted, or when a speech pause is present; (b) Branching the incoming TC signal from the main signal path and using a Fourier transformation on the branched TC signal to generate a frequency spectrum of the branched TC signal; (c) Storing in a buffer memory (3) the last frequency spectrum recorded during the last speech pause; (d) Using an inverse Fourier transformation on the last respective recorded frequency spectrum to generate a simulated noise signal; (e) Subtracting the simulated noise signal in the time domain from the current incoming TC signal.</p></layer>
<layer id = "layer11"><p><b>US20030050786A1:Method and apparatus for synthetic widening of the bandwidth of voice signals</b><br>There is provided a cyclic lipopeptide acylase which is capable of deacylating the acyl side chain of a cyclic lipopeptide compound, e.g. Substance FR901379 or its analog, of the general formula [I] with effectiveness as well a method of producing a cyclic peptide compound which comprises using the acylase.<br><b>Independant Claims</b><br>1. A method for synthetic widening of the bandwidth of voice signals, comprising the following steps: providing a narrowband voice signal at a predetermined sampling rate; carrying out analysis filtering on the sampled voice signal using filter coefficients which are estimated from the sampled voice signal and which result in the bandwidth of the envelope being widened; carrying out residual signal widening on the analysis-filtered voice signal; and carrying out synthesis filtering on the residual-signal-widening voice signal in order to produce a broader band voice signal with the filter coefficients estimated from the sampled voice signal.<br>10. The method as claimed in one of the preceding claims, wherein the bandwidth widening is deactivated in predetermined voice sections.<br>11. The method as claimed in one of the preceding claims, characterized in that post-filtering is carried out on the synthesis-filtered signal.<br>12. An apparatus for synthetic widening of the bandwidth of voice signals having: an input device for providing a narrowband voice signal at a predetermined sampling rate; an analysis filter (AF) for carrying out analysis filtering on the sampled voice signal using filter coefficients which are estimated from the sampled voice signal and which result in the bandwidth of the envelope being widened; a residual widening device (RE) for carrying out residual signal widening on the analysis-filtered voice signal; and a synthesis filter (SF) for carrying out synthesis filtering on the residual-signal-widening voice signal in order to produce a broader band voice signal with the filter coefficients estimated from the sampled voice signal.</p></layer>
<layer id = "layer12"><p><b>US20040076302A1:Device for the noise-dependent adjustment of sound volumes</b><br>A control system and a control method for an internal combustion engine employs an electronic control unit (ECU) in the internal combustion engine to control an output torque of the engine. The ECU anticipates that a driver will make an engine output torque change request based on an operation of an automatic transmission performed by the driver, a brake pedal operation performed by the driver, a vehicle speed detected by a vehicle speed sensor and other information, and changes in advance an amount of engine intake air, a throttle valve opening, an engine speed and other engine operating parameters that determine the engine output according to the engine output change request made by the driver. This allows even an engine operating parameter that is slow to change to be changed to a value close to that after the engine output torque has been changed. This in turn allows the engine output torque to be changed within a shorter period of time in accordance with the engine output change request made by the driver, contributing to a better response.<br><b>Independant Claims</b><br>1. A device for the noise-dependent adjustment of the sound volume of a loudspeaker (8) which is fed a useful electric signal (2, 9) from a signal source (1) in a listening area filled with noise (17), with two sound volume adjuster (3, 5) connected in series to each other and between the signal source (1) and the loudspeaker (8), one of which (3) can be controlled manually and the other (5) by a control signal (18), and a noise detector (6) to determine the level of the noise (17) and produce the control signal (18) for the other sound volume adjuster (5) in accordance with the level of the noise (17).</p></layer>
<layer id = "layer13"><p><b>US20020176589A1:Noise reduction method with self-controlling interference frequency</b><br>A method for manufacturing multi-layer molded-products, including the steps of supplying molten thermoplastic resin between an upper mold and a lower mold, and applying pressure to a forming cavity by clamping in a forming process. With this method, it is possible to easily produce a multi-layer molded-product wherein the covering material, such as a woven fabric, is entangledly fused to and integrally formed on the surface of a base plate with at least one hole that is made of thermoplastic resin.<br><b>Independant Claims</b><br>1. A noise reduction method in which a reference signal of the interference is produced for multi-channel interference compensation systems, the method comprising the steps of: reducing interference of a useful signal in a first channel via a spectral subtraction so as to define a reduced-interference signal, the useful signal also being carried in a second channel; and forming an interference reference signal by subtracting the reduced-interference signal from the useful signal in the second channel.<br>12. A noise reduction method for reducing noise in a received signal, the signal being received at a first input and a second input, the first input being connected to a first channel and the second input to a second channel, the method comprising the steps of: forming a primary signal representative of the received input as a function of the first channel and the second channel; reducing interference in a first channel via a spectral subtraction so as to define a reduced-interference signal; forming an interference reference signal by subtracting the reduced-interference signal from the second channel; and subtracting the interference reference signal from the primary signal to form an noise-reduced output.</p></layer>
<layer id = "layer14"><p><b>US20040186711A1:Method and system for reducing a voice signal noise</b><br>A single stroke fluid dispense system, including a dispense member having a dispense end defining a dispense end opening and a container well communicating with the dispense end opening for receiving a fluid to be dispensed. A closure cap is supported over the dispense end opening of the dispense member and further defines a fluid passageway therethrough in fluid communication with the container well. A compression assembly for forcing the fluid through the fluid passageway of the closure cap is also provided. A sealing piston assembly maintains the closure cap in sealing engagement with the dispense member. The closure cap may further defined a burst port at one end of the fluid passageway facing the container well which is especially useful for dispensing fluid from a flexible rupturable container. The compression assembly maintains fluid integrity between the container and the closure cap about the rupture port throughout dispensement so as to thwart fluid from leaking into the container well. The container also seals the interface between the dispense member and the closure cap during dispensement of the fluid to be dispensed through the closure cap. The compression assembly further augments the sealing force between the dispense member and the closure cap by forcing the container against the internal dispense cylinder wall to further carry the dispense cylinder against the closure cap.<br><b>Independant Claims</b><br>1. Method for voice processing, in which an incoming digital voice signal s(k) is segmented chronologically into blocks (block,m) (101), in which the blocks (block,m) are mapped in chronological order by a transformation in the frequency range to frequency components (f,i) in each case (102), the frequency components are multiplied by chronologically modifiable frequency-dependent weighting factors, where a frequency component is multiplied by the current weighting factor if this is smaller than the weighting factor last calculated for this frequency component, where a frequency component is multiplied by the weighting factor last calculated for this frequency component if this is smaller than the current weighting factor, and for which the frequency components weighted in this way are fed back after a back transformation in the time range to a low-rate voice codec.<br>3. System for noise suppression with an input (IOS) for digital voice signals and with a processor unit (PE), which is designed in such a way that an incoming digital voice signal s(k) is chronologically segmented into blocks (block,m) (101), the blocks (block,m) are mapped in chronological order by a transformation in the frequency range onto frequency components (f,i) in each case (102), the frequency components are multiplied by chronologically modifiable frequency-dependent weighting factors, where a frequency component is multiplied by the current weighting factor if this is smaller than the last weighting factor calculated for this frequency component, and where a frequency component is multiplied by the weighting factor last calculated for this frequency component if this is smaller than the current weighting factor, and for which the frequency components weighted in this way are fed back after a back transformation in the time range to a low-rate voice codec.</p></layer>
<layer id = "layer15"><p><b>US6687669B1:Method of reducing voice signal interference</b><br>A foldable intraocular lens for implantation in the eye includes an optic made of a highly pliable material and a pair of fixation members made of a material that is flexible, but more rigid than the optic. The fixation members are integral with a cantilevered arm that extends radially outward from the optic. Each fixation member includes a proximal end at the outer end of the cantilevered arm, a distal end, and a flex portion intermediate the proximal and distal ends. The flex portions of the two fixation member extend generally away from one other adjacent their respective proximal ends on diametrically-opposed sides of the optic.<br><b>Independant Claims</b><br>1) A method for reducing interferences in a voice signal, the method comprising: applying a noise reduction method to the voice signal; taking into account spectral psychoacoustic masking; determining a first spectral masking curve for an input signal of the noise reduction method; determining a second spectral masking curve for an output signal of the noise reduction method; identifying newly audible portions of the output signal by comparing signal portions of the output signal which exceed the second spectral masking curve with signal portions of the input signal that exceed the first spectral masking curve; and selectively damping the identified newly audible portions of the output signal.</p></layer>
<layer id = "layer16"><p><b>US6246979B1:Method for voice signal coding and/or decoding by means of a long term prediction and a multipulse excitation signal</b><br>At the initial diagnosis of sepsis (6-24 h before the development of ARDS), serum lactate dehydrogenase (LDH) activity level is increased in septic patients who subsequently develop ARDS compared to healthy patients and septic patients who do not develop ARDS. A method is disclosed for predicting the occurrence of ARDS in a septic patient from the patient's serum level of LDH activity, which method facilitates identification of subsets of patients destined to develop ARDS and allows prospective treatment of such septic patients.<br><b>Independant Claims</b><br>1) A method of encoding and decoding voice signals, the method comprising the steps of: a) analyzing a digital voice signal for determination of prediction parameters, b) determining an excitation signal component from an adaptive code book, the adaptive code book being formed from a delayed total excitation signal, said adaptive code book being used for LTP analysis and being constructed from entries resulting from said delayed total excitation signal which are completely searched in a first subblock of each block, whereas, in each of additional subblocks, only a defined partial range is searched, the partial range being determined by a respective preceding delay; c) minimizing an output of a weighted, filtered deviation of a signal resulting from a respective evaluated excitation signal from an input voice signal to determine a multiple pulse component of said excitation signal; d) processing digital voice signals in sequential overlapping blocks having a constant number of sampling values, each of which is divided into a defined number of subblocks having a defined number of sampling values, for determination of the excitation signal parameters; e) scalar quantizing reflection coefficients resulting from a block per block analysis of said voice signal for determination of prediction parameters using individually adjusted quantization tables; f) encoding delayed values for all subblocks together in a delay code and linearly quantizing each individual associated amplification factor; g) encoding pulse positions of a subblock together in a position code and subjecting associated amplitudes to a block-adaptive linear quantization, wherein an amplitude value maximum is quantized non-linearly and each of normalized pulse amplitudes are linearly quantized, wherein each multiple pulse excitation vector determined for one subblock contains, in addition to a defined number of pulses, only zero sampling values; h) decoding parameters for reclaiming quantized transfer values using table memories for regenerating quantized reflection coefficients; i) generating an excitation signal using a regenerated component from said adaptive code book and a regenerated multiple pulse component, wherein a regenerated voice signal is constructed by synthesis filtration using said excitation signal and regenerated prediction parameters; j) calculating, during parameter decoding, delays for components obtained from said adaptive code book from a delay code, wherein a delay for a first subblock of a block lies in a range of sampling periods and delays for three additional subblocks lie in ranges defined by a respective preceding delay; k) determining, during parameter decoding, linearly quantized amplification factors for components of said excitation signal obtained from one of said adaptive code book and a table; l) calculating, during parameter decoding, corresponding pulse positions for a multiple pulse component of said excitation vector of a subblock, wherein position values of said subblock are each extracted from a position code; and m) determining, during parameter decoding, pulse amplitudes for a multiple component of said excitation signal of a subblock, wherein each non-linearly quantized block maximum and each linearly quantized normalized pulse amplitude is extracted for multiplicative regeneration of respective quantized unnormalized pulse amplitudes of said subblock.<br>11) A device for encoding and decoding voice signals, comprising: means for analyzing a digital voice signal for determination of prediction parameters; means for determining an excitation signal component from an adaptive code book, the adaptive code book being formed from a delayed total excitation signal, said adaptive code book being used for LTP analysis and being constructed from entries resulting from said delayed total excitation signal which are completely searched in a first subblock of each block, whereas, in each of additional subblocks, only a defined partial range is searched, the partial range being determined by a respective preceding delay; means for minimizing an output of a weighted, filtered deviation of a signal resulting from a respective evaluated excitation signal from an input voice signal to determine a multiple pulse component of said excitation signal; means for processing digital voice signals in sequential overlapping blocks having a constant number of sampling values, each of which is divided into a defined number of subblocks having a defined number of sampling values, for determination of the excitation signal parameters; means for scalar quantizing reflection coefficients resulting from a block per block analysis of said voice signal for determination of prediction parameters using individually adjusted quantization tables; means for encoding delayed values for all subblocks together in a delay code and linearly quantizing each individual associated amplification factor; means for encoding pulse positions of a subblock together in a position code and subjecting associated amplitudes to a block-adaptive linear quantization, wherein an amplitude value maximum is quantized non-linearly and each of normalized pulse amplitudes are linearly quantized, wherein each multiple pulse excitation vector determined for one subblock contains, in addition to a defined number of pulses, only zero sampling values; means for decoding parameters for reclaiming quantized transfer values using table memories for regenerating quantized reflection coefficients; means for generating an excitation signal using a regenerated component from said adaptive code book and a regenerated multiple pulse component, wherein a regenerated voice signal is constructed by synthesis filtration using said excitation signal and regenerated prediction parameters; means for calculating, during parameter decoding, delays for components obtained from said adaptive code book from a delay code, wherein a delay for a first subblock of a block lies in a range of sampling periods and delays for three additional subblocks lie in ranges defined by a respective preceding delay; means for determining, during parameter decoding, linearly quantized amplification factors for components of said excitation signal obtained from one of said adaptive code book and a table; means for calculating, during parameter decoding, corresponding pulse positions for a multiple pulse component of said excitation vector of a subblock, wherein position values of said subblock are each extracted from a position code; and means for determining, during parameter decoding, pulse amplitudes for a multiple component of said excitation signal of a subblock, wherein each non- linearly quantized block maximum and each linearly quantized normalized pulse amplitude is extracted for multiplicative regeneration of respective quantized unnormalized pulse amplitudes of said subblock.</p></layer>
<layer id = "layer17"><p><b>US6643619B1:Method for reducing interference in acoustic signals using an adaptive filtering method involving spectral subtraction</b><br>A semiconductor memory device is provided which is capable of reducing the peak current of sense-amplifiers in the normal access mode operation and capable of a high speed access. The system comprises two types of sense-amplifiers 200 and 201 and a sense-amplifier control circuit for controlling activation start and finish time. Depending upon the access mode, the activation start time and the activation finish time for these sense-amplifiers and are shifted by a sense-amplifier control circuit, which can modify a one-shot-pulse signal generated by an ATD into an optional pulse width and a route for transmitting are altered for data obtained in the normal access mode operation and data obtained in the page access mode operation are transmitted by selected routes by a page-decoder, a sense-amplifier selection circuit, and a latch selector.<br><b>Independant Claims</b><br>1) A method for reducing interference in disturbed acoustic signals using an adaptive filtering process including spectral subtraction, the method comprising: filtering the signals in a plurality of respective time segments and a plurality of respective discrete frequencies i segmentwise using an adaptive filtering function; determining a respective noise-input ratio for each of the plurality of respective time segments and respective discrete frequencies so that each respective noise-input ratio has a small respective value for signals having a relatively low disturbing noise component and a high respective value for signals having a relatively high disturbing noise component; adapting the adaptive filtering function so that respective information on a respective a priori signal-to-noise ratio is used for a calculation of each of a plurality of characteristic values of the adaptive filtering function; and using at least one of the plurality of characteristic values from a respective at least one preceding time segment as the respective information on each respective a priori signal-to-noise ratio;</p></layer>
<layer id = "layer18"><p><b>US5933801A:Method for transforming a speech signal using a pitch manipulator</b><br>A switching system includes a protection switch that operates to switch a working transmission line to a protection transmission line or switch an optional transmission line to the protection transmission line. The protection switch consists of a first speed converting unit, a second speed converting unit and an add-drop unit that handles a lower order signal and is sandwiched therebetween. The optional transmission line for carrying a lower order signal is connected, via the add-drop unit and the second converting unit, to the protection transmission line carrying a higher order signal during an add-drop operation. Alternatively, the working transmission line carrying a higher order signal is connected, via the add-drop unit and the first and second converting units, to the protection transmission line under a through operation mode. The protection switch is preferably realized by using an add-drop multiplexer (ADM).<br><b>Independant Claims</b><br>1. A method of transforming a speech signal, comprising separating the speech signal into two signal parts a, b, where a represents the quasistationary part of the signal with information on the formant frequencies, and b represents a residual signal with the transient part of the signal containing information on pitch frequency and stop consonants, said signal b being produced by inverse filtration of the speech signal, characterized in that, after the inverse filtration, the signal b is supplied in parallel to a transient detector and a pitch manipulator comprising a delay circuit which is serially coupled to a multiplier to which the output signal is supplied from the transient detector.<br>7. An apparatus for transforming a speech signal comprising a circuit for splitting the signal into two signal parts a and b, a decomposition circuit, a transformation circuit and an inverse filtering circuit, the first signal part a representing the quasistationary part of the signal which is supplied to said decomposition circuit whose output is supplied to said transformation circuit, the second signal part b representing the transient part of the speech signal which is produced in said inverse filtering circuit, characterized by further comprising a transient detector and a pitch manipulator, the output from the inverse filtering circuit being supplied in parallel to said transient detector and said pitch manipulator, said pitch manipulator comprising a series connection of a delay circuit, a multiplier, and a pitch converter, the output signal from said transient detector being supplied to said multiplier.</p></layer>
<layer id = "layer19"><p><b>US20040076271A1:Audio signal quality enhancement in a digital network</b><br>A method and structure is disclosed that are advantageous for aligning a contact plug within a bit line contact corridor (BLCC) to an active area of a DRAM that utilizes a insulated sleeve structure. A lower bulk insulator layer, a capacitor dielectric layer, a cell plate conductor layer, and an upper bulk insulator layer are formed upon a semiconductor substrate. An etch removes the cell plate conductor layer, the capacitor dielectric layer, and the lower bulk insulator layer so as to form an opening terminating within the lower bulk insulator layer. A sleeve insulator layer is deposited upon the upper bulk insulator layer and within the opening. Another etch removes the sleeve insulator layer from the bottom surface within the lower bulk insulator layer. A still further etch creates a contact hole that expose a contact. The contact can be upon a transistor gate, a capacitor storage node, or an active region on the semiconductor substrate. A conductive plug is then formed in the contact hole so as to be in electrical communication with the contact. The sleeve insulator layer electrically insulates the conductive plug from the cell plate conductor layer and self aligns the BLCC so as to improve contact plug alignment tolerances between the BLCC and the capacitor components.<br><b>Independant Claims</b><br>1. Network element (1) for enhancing the quality of digitised analogue signals transmitted at least in parameterised coded form via a digital network to which the network element (1) has access, comprising a payload extraction block (20,30,40) for extracting coded digitised analogue signals from the digital network, which coded digitised analogue signals include at least in part parameterised coded digitised analogue signals; first processing means (24,34,44) for processing the extracted parameterised coded digitised analogue signals in the parameter domain with functions suitable to enhance the quality of the digitised analogue signals; second processing means (26,36,46) for processing at least part of the extracted coded digitised analogue signals in the linear domain with functions suitable to enhance the quality of the digitised analogue signals; a payload insertion block (21,31,41) for inserting processed coded digitised analogue signals to the digital network; and analysing and selecting means (23,27,33,37) for determining the quality improvement of the digitised analogue signals resulting from a processing of the extracted coded digitised analogue signals in the parameter domain and from a processing of the extracted coded digitised analogue signals in the linear domain and for causing that at least coded digitised analogue signals processed by the processing means (24,26,34,36) leading to the better improvement are inserted back to the digital network by the payload insertion block (21,31,41).<br>3. Network element (1) according to one of the preceding claims, wherein the functions for processing coded digitised analogue signals by the second processing means (26,36,46) include echo cancellation, noise reduction, level control, transcoding and/or speech mixing.<br>4. Network element (1) according to one of the preceding claims, wherein the analysing and selecting means are suited for analysing the digitised analogue signals before and after processing by the first and the second processing means for determining the better quality improvement.<br>5. Network element (1) according to one of the preceding claims, wherein the analysing and selecting means comprises a neural network for determining the better quality improvement.<br>6. Network element (1) according to one of the preceding claims, characterised by a bad frame handler (22,32,42) for detecting in the extracted coded digitised analogue signals missing frames and/or frames in disorder, and for regenerating missing frames and/or reordering frames in disorder in the extracted signals.<br>7. Network element (1) according to one of the preceding claims, characterised by analysing means (23,33) for determining whether any processing is to be applied to the extracted parameterised coded digitised analogue signals and for selecting the functions that are to be applied to the extracted coded digitised analogue signals by the first processing means (24,34) and/or the second processing means (26,36) depending on the extracted signals and/or an external control signal.<br>8. Network element (1) according to one of the preceding claims, characterised by a control block (29,39,49) for receiving an external control signal and for controlling the selection of the processing applied to the extracted coded signals directly or via analysing means (23,33,37).<br>9. Network element (1) according to one of the preceding claims, wherein the payload extraction block (20) is suitable to extract parameterised coded digitised analogue signals from the IP stack of a packet-based network and wherein the payload insertion block (21) is suitable to insert parameterised coded digitised analogue signals to the IP stack of said packet-based network.<br>15. Network element (1) according to one of the preceding claims, wherein the first processing means (24,34,44) is suited for comparing gain parameters of the extracted parameterised coded digitised analogue signals with a desired gain, for forming corresponding new gain parameters and for replacing the original gain parameters by the new gain parameters in the extracted parameterised coded digitised analogue signals.<br>18. Network element (1) according to one of the preceding claims, wherein the first processing means (24,34,44) is suited for attenuating noise portions and low level signal portions of the extracted parameterised coded digitised analogue signals in the time domain and for correspondingly replacing the gain parameters in the extracted parameterised coded digitised analogue signals.<br>19. Network element (1) according to one of the preceding claims, wherein the first processing means (24,34,44) is suited for attenuating frequency portions of noise in the extracted parameterised coded digitised analogue signals which have approximately the same energy as a noise estimate and for correspondingly replacing linear prediction parameters in the extracted parameterised coded digitised analogue signals.<br>21. Network element (1) according to one of the preceding claims, wherein the payload extraction block (20,30,40) is suited for extracting in addition further coded digitised analogue signals from the digital network transmitted in the opposite direction as compared to the extracted coded digitised analogue signals, which further coded digitised analogue signals include at least in part parameterised coded digitised analogue signals; and wherein the first processing means (24,34,44) is suited for comparing the first and the further parameterised coded digitised analogue signals in order to detect echoes in the first parameterised coded digitised analogue signals and for replacing portions of the first parameterised coded digitised analogue signal by comfort noise portions, if an echo was determined in the portion of the first parameterised coded digitised analogue signal.<br>23. Network element (1) according to one of the preceding claims, wherein the payload extraction block (20,30,40) is suited for extracting in addition further coded digitised analogue signals from the digital network transmitted in the opposite direction as compared to the extracted coded digitised analogue signals, which further coded digitised analogue signals include at least in part parameterised coded digitised analogue signals; and wherein the first processing means (24,34,44) is suited for attenuating an echo signal in the first parameterised coded digitised analogue signals making use of the further parameterised coded digitised analogue signals and for suppressing the residual echo signal.<br>26. Network element (1) according to one of the preceding claims, wherein the extracted coded digitised analogue signals are coded speech or coded video.<br>27. Method for enhancing the quality of digitised analogue signals transmitted at least in parameterised coded form via a digital network, comprising: extracting coded digitised analogue signals from the digital network, which coded digitised analogue signals include at least in part parameterised coded digitised analogue signals; determining the quality improvement of the digitised analogue signals to be expected by a processing of the extracted encoded digitised analogue signals in the parameter domain and by a processing of the extracted encoded digitised analogue signals in the linear domain; processing the extracted parameterised coded digitised analogue signals in the parameter domain at least if a greater quality improvement is expected by processing in the parameter domain, with functions suitable for enhancing the quality of digitised analogue signals; and processing at least part of the extracted coded digitised analogue signals in the linear domain at least if a greater quality improvement is expected by processing in the linear domain, with functions suitable for enhancing the quality of digitised analogue signals; and inserting at least those processed coded digitised analogue signals to the digital network that were processed in the domain, the processing in which was expected to result in a greater quality improvement.</p></layer>
<layer id = "layer20"><p><b>US20020007268A1:Sinusoidal coding</b><br>The message transmitter transmits a re-calling identification signal with a message, and a receiver identifies this signal. Thereby the message transmitter can indicate selectively the re-calling of the receiver. If the message is not confirmed, the receiver performs re-calling according to a previously set time interval with a second sound pattern different from the normal sound pattern for indicating that this message is an unconfirmed message until the message is confirmed. The receiver continues to perform the calling operation periodically until the receiver holder cancels the re-calling. Meanwhile the message is confirmed by switch operation with a third sound pattern of three short sounds which are not noisy.<br><b>Independant Claims</b><br>1. A method of encoding (2) a signal (A), the method comprising the steps of: determining (20) frequency and amplitude information of at least one sinusoidal component in the signal (A); and transmitting (22) sinusoidal parameters (f,a) representing the frequency and amplitude information; characterized in that the method (2) further comprises the step of: transmitting (22) a phase jitter parameter (p) representing an amount of phase jitter that should be added during restoring the sinusoidal component from the transmitted sinusoidal parameters (f,a).<br>5. A method of decoding (4) an encoded signal (A′), the method comprising the steps of: receiving (40) sinusoidal parameters (f,a) representing frequency and amplitude information of at least one sinusoidal component; restoring (41) the at least one sinusoidal component from the sinusoidal parameters (f,a); characterized in that the method further comprises: receiving (40) a phase jitter parameter (p); adding (41) an amount of phase jitter to the sinusoidal component, which amount of phase jitter is derived from the phase jitter parameter.<br>6. An audio coder (2) comprising: means (20) for determining frequency and amplitude information of at least one sinusoidal component in the signal (A); and means (22) for transmitting sinusoidal parameters (f,a) representing the frequency and amplitude information; characterized in that the audio coder (2) further comprises: means (22) for transmitting a phase jitter parameter (p) representing an amount of phase jitter that should be added during restoring the sinusoidal component from the transmitted sinusoidal parameters (f,a).<br>7. An audio player (4) comprising: means (40) for receiving sinusoidal parameters (f,a) representing frequency and amplitude information of at least one sinusoidal component; means (41) for restoring the at least one sinusoidal component from the sinusoidal parameters (f,a); characterized in that the audio player further comprises: means (40) for receiving a phase jitter parameter (p); means (41) for adding an amount of phase jitter to the sinusoidal component, which amount of phase jitter is derived from the phase jitter parameter.<br>9. An encoded signal (A′) comprising sinusoidal parameters (f,a) representing frequency and amplitude information of at least one sinusoidal component and further comprising a phase jitter parameter (p) representing an amount of phase jitter that should be added during restoring the sinusoidal component from the sinusoidal parameters (f,a).</p></layer>
<layer id = "layer21"><p><b>US20020072901A1:Error concealment in relation to decoding of encoded acoustic signals</b><br>A method and apparatus for determining a workpiece's surface position. One embodiment of the invention includes two conductive bodies that are insulated from each other. During a surface position determining operation, one of these bodies has a first potential, while the other body has a second potential. These bodies are then moved towards a conductive surface of the workpiece, until both of these bodies are electrically detected to contact the surface. Finally, the distance that one of these bodies traverses is used to identify the position of the surface of the workpiece.<br><b>Independant Claims</b><br>1. A method of receiving data in the form of encoded information from a transmission medium and decoding the data into an acoustic signal, the method in case of lost or received damaged data comprising: producing reconstructed data on basis of at least one parameter of previously reconstructed signal; producing a primary reconstructed signal from the reconstructed data, the primary reconstructed signal having a first spectrum; and producing a secondary reconstructed signal on basis of the primary reconstructed signal by performing a spectral adjustment of the first spectrum such that a spectrum of the secondary reconstructed signal deviates less with respect to spectral shape than the first spectrum from a spectrum of a previously reconstructed signal.<br>39. An error concealment unit for enhancing a signal decoded from received data in the form of encoded information in case of lost data or received damaged data, the unit comprising: a first transformer having an input to receive a primary reconstructed signal decoded from the received data and an output to provide a primary reconstructed frequency transform; a spectral correction unit having an input to receive the primary reconstructed frequency transform and an output to provide a secondary reconstructed spectrum; and a second transformer having an input to receive the secondary reconstructed spectrum and an output to provide a secondary reconstructed signal, wherein: the spectral correction unit produces the secondary reconstructed spectrum signal on basis of the primary reconstructed signal such that the secondary reconstructed spectrum signal deviates less with respect to spectral shape from a spectrum of a previously reconstructed signal than a spectrum based on the primary reconstructed signal.<br>41. A decoder for generating an acoustic signal from received data in the form of encoded information, comprising: a primary error concealment unit to produce at least one parameter via an output; a speech decoder having a first input to receive speech codec frames, a second input to receive the at least one parameter and an output to provide an acoustic signal in response to the at least one parameter; and an error concealment unit according to claim 37 wherein the primary reconstructed signal constitutes a decoded speech signal produced by the speech decoder and the secondary reconstructed signal constitutes an enhanced acoustic signal.<br>42. A decoder for generating an acoustic signal from received data in the form of encoded information, comprising: a primary error concealment unit to produce at least one parameter via an output; an excitation generator having a first input to receive speech codec parameters, a second input to receive the at least one parameter and an output to provide an excitation signal in response to the at least one parameter; and an error concealment unit according to claim 37 wherein the primary reconstructed signal constitutes the excitation signal produced by the excitation generator and the secondary reconstructed signal constitutes an enhanced excitation signal.</p></layer>
<layer id = "layer22"><p><b>US20030033140A1:Time-scale modification of signals</b><br>The invention concerns a torsional damper (<b>23</b>) comprising an input element and an output element coaxial and movable in rotation relative to each other counter at least to an compression spring (<b>300</b>), wherein the two adjacent transverse parts, with radial orientation, associated with the input and output elements each comprise a housing (<b>306-308, 302</b>) receiving the spring (<b>300</b>) whereof the opposite ends are capable of co-operating with the supporting end surfaces (<b>316-318, 304</b>) which define the two housings to operate between the two elements; the length (LF) of each of the two associated housings (<b>306-308, 302</b>), separating the opposite supporting end surfaces, being greater than the length (LR) of the spring (<b>300</b>) at rest.<br><b>Independant Claims</b><br>1. A method of time scale modifying a signal, the method comprising the steps of: a) defining individual frame segments within the signal, b) analysing the individual frame segments to determine a signal type in each frame segment, and c) applying a first algorithm to a determined first signal type and a second different algorithm to a determined second signal type.<br>4. The method as claimed in any preceding claim wherein the first algorithm is a SOLA algorithm.<br>5. The method as claimed in any preceding claim wherein the second algorithm comprises the steps of: a) dividing each frame of the determined second signal type into a lead in and a lead out portion, b) generating a noise signal, and c) inserting the noise signal between the lead-in and lead-out portions so as to effect an expanded segment.<br>6. The method as claimed in any preceding claim wherein the first and second algorithms are expansion algorithms and the method is used for time scale expanding a signal.<br>9. A method of time scale expanding a signal comprising the steps of: a) splitting the signal in a first portion and a second portion, and b) inserting noise in between the first portion and the second portion to obtain a time scale expanded signal.<br>10. A method as claimed in any preceding claim, wherein the signal is an audio signal and in particular unvoiced segments are time scale expanded.<br>12. A method of receiving an audio signal, the method comprising the steps of: a) decoding the audio signal, and b) time scale expanding the decoded audio signal according to a method as claimed in claim 1.<br>13. A time scale modifying device adapted to modify a signal so as to effect the formation of a time scale modified signal comprising: a) means for determining different signal types within frames of the signal, and b) means for applying a first modification algorithm to frames having a first determined signal type and a second different modification algorithm to frames having a second determined signal type.<br>15. A receiver for receiving an audio signal, the receiver comprising: a) a decoder for decoding the audio signal, and b) a device according to claim 13 or claim 14 for time scale expanding the decoded audio signal.</p></layer>
<layer id = "layer23"><p><b>US20030061055A1:Audio coding</b><br>The invention, in a preferred embodiment, is an apparatus for pulling wire and other objects between two vertical supports, such as telephone poles, connected by a cable strung above the ground. It is particularly suited for making lashers easier to use in rough terrain. The device consists of a carrier having four sides, a base, and an adjustable split top having an upper surface and a lower surface. Contained in and on the carrier is a pair of gear driven looped roller chains horizontally mounted on opposite sides of the split top. These roller chains have mounted about their outside surfaces cable-gripping clips. A pressure-regulating bar is positioned within the inside vertical surfaces of the opposed looped roller chains. Also present is a drive for adjusting the split top so that the opposed looped roller chains engage the strung cable. Within the carrier is mounted a motorized drive train for turning the opposed looped roller chains in opposite directions at a constant speed. To propel the carrier, there is a pair of vertical trolley wheels positioned above the opposed looped roller chains for moving the carrier along the string cable. A single motor drives the two looped roller chains by means of gear-connected shafts. In a preferred embodiment, the motor is a battery-driven DC motor.<br><b>Independant Claims</b><br>1. A method of coding an audio signal, the method comprising: partitioning the signal into a plurality of frequency bands; comparing amplitudes of the signal in the various frequency divided bands to respective threshold values; and coding the signal of the divided frequency bands on a priority basis such that frequency bands in which the amplitude of the signal in the particular frequency band exceeds its respective threshold value by a greatest amount are coded according to a given coding scheme, the method being characterised in that for other frequency bands a noise fill parameter is selectively allocated.<br>7. The method of any preceding claim, wherein the noise fill parameter comprises a representation of the magnitude of the noise to be inserted in the respective frequency band.<br>8. The method of any preceding claim wherein, the noise fill parameter comprises an encoded RMS value representing the average amplitude of the received audio signal across the respective frequency band.<br>9. The method of any preceding claim, wherein for frequency bands to which a noise fill parameter is allocated, the noise fill parameter is encoded and provided in a position in the output signal where encoded signal information would otherwise be present.<br>14. Audio coding apparatus (20) arranged for coding an input signal and including partitioning means (21) for partitioning the signal into a plurality of frequency bands; comparing means (22) for comparing amplitudes of the signal in the various frequency divided bands to respective threshold values; and a coder (23) for coding the signal of the divided frequency bands on a priority basis such that frequency bands in which the amplitude of the signal in the particular frequency band exceeds its respective threshold value by a greatest amount are coded according to a given coding scheme, the apparatus being characterised in that for other frequency bands a noise fill parameter is selectively allocated.<br>15. Audio decoding apparatus (30) for decoding an encoded audio signal, the decoding apparatus comprising: reception means (32) for receiving a coded audio signal; processing means (32) arranged to, for a given frequency band of the coded signal, determine whether a received signal includes encoded signal information relating to the amplitude of a transmitted signal within the given frequency band or whether it includes a noise fill parameter; first decoding means (33) for, if the received signal includes encoded signal information, decoding the information to produce an output audio signal portion for that frequency band; and second decoding means (34) for, if the received signal includes a noise fill parameter, synthesizing an output audio signal portion for that frequency band by outputting a noise signal across the frequency range of that frequency band to an amplitude indicated by the noise fill parameter.<br>17. An encoded audio signal, wherein the signal is partitioned into a number of frequency bands, a first plurality of said frequency bands including encoded signal information being coded according to a given coding scheme and a second plurality of frequency bands including a noise fill parameter.</p></layer>
<layer id = "layer24"><p><b>US20040166820A1:Wideband signal transmission system</b><br>A conditioning system for reducing an oxygen content of water carried in a subsystem of an industrial plant includes an electrolysis unit having a hydrogen side, an anode, and a cathode. The anode and cathode are connected to the subsystem to decompose water into hydrogen and oxygen. A hydrogen/oxygen recombination catalyst is connected to the subsystem. The hydrogen/oxygen recombination catalyst follows the anode and cathode on the hydrogen side. A method for reducing an oxygen content of water carried in a subsystem of an industrial plant, includes the steps of electrolytically decomposing water from a subsystem of an industrial plant into hydrogen and oxygen, and using the hydrogen generated at the same time for recombining the oxygen contained in the water.<br><b>Independant Claims</b><br>1. A transmission system (10) comprising a transmitter (12) for transmitting a narrowband audio signal to a receiver (14) via a transmission channel (16), the receiver (14) comprising a frequency domain bandwidth extender (18) for extending a bandwidth of the received narrowband audio signal by complementing the received narrowband audio signal with a highband extension thereof, the bandwidth extender (18) comprising an amplitude extender (24) for extending the bandwidth of an amplitude spectrum of the received narrowband audio signal by mapping narrowband amplitudes onto highband amplitudes, the bandwidth extender (18) further comprising a phase extender (26) for extending the bandwidth of a phase spectrum of the received narrowband signal and a combiner (28) for combining the extended amplitude spectrum and the extended phase spectrum into a bandwidth extended audio signal, characterized in that the amplitude extender (24) comprises an amplitude mapper (42) and first and second frequency scale transformers (40,44), the first frequency scale transformer (40) being arranged for transforming a linear frequency scale of the amplitude spectrum into a logarithmic frequency scale, the amplitude mapper (42) being arranged for mapping according to the logarithmic frequency scale the narrowband amplitudes onto the highband amplitudes, the second frequency scale transformer (44) being arranged for transforming the logarithmic frequency scale of the extended amplitude spectrum into the linear frequency scale.<br>6. A receiver (14) for receiving, via a transmission channel (16), a narrowband audio signal from a transmitter (12), the receiver (14) comprising a frequency domain bandwidth extender (18) for extending a bandwidth of the received narrowband audio signal by complementing the received narrowband audio signal with a highband extension thereof, the bandwidth extender (18) comprising an amplitude extender (24) for extending the bandwidth of an amplitude spectrum of the received narrowband audio signal by mapping narrowband amplitudes onto highband amplitudes, the bandwidth extender (18) further comprising a phase extender (26) for extending the bandwidth of a phase spectrum of the received narrowband signal and a combiner (28) for combining the extended amplitude spectrum and the extended phase spectrum into a bandwidth extended audio signal, characterized in that the amplitude extender (24) comprises an amplitude mapper (42) and first and second frequency scale transformers (40,44), the first frequency scale transformer (40) being arranged for transforming a linear frequency scale of the amplitude spectrum into a logarithmic frequency scale, the amplitude mapper (42) being arranged for mapping according to the logarithmic frequency scale the narrowband amplitudes onto the highband amplitudes, the second frequency scale transformer (44) being arranged for transforming the logarithmic frequency scale of the extended amplitude spectrum into the linear frequency scale.<br>9. A method of receiving, via a transmission channel (16), a narrowband audio signal, the method comprising: extending the bandwidth of an amplitude spectrum of the received narrowband audio signal by mapping narrowband amplitudes onto highband amplitudes, extending the bandwidth of a phase spectrum of the received narrowband signal, combining the extended amplitude spectrum and the extended phase spectrum into a bandwidth extended audio signal, characterized in that the method further comprises: transforming a linear frequency scale of the amplitude spectrum into a logarithmic frequency scale, mapping according to the logarithmic frequency scale the narrowband amplitudes onto the highband amplitudes, transforming the logarithmic frequency scale of the extended amplitude spectrum into the linear frequency scale.</p></layer>
<layer id = "layer25"><p><b>US5001758A:Voice coding process and device for implementing said process</b><br>An electrical penetrator for use in high pressure situations includes a metallic penetrator body having a central aperture therein which includes a conical portion and a cylindrical portion. An electrically conducting pin member fits within the aperture and has a cone portion which fits within and is displaced from the conical surface portion. An encapsulating compound maintains the pin in its proper orientation displaced from the interior walls of the aperture with the compound including a polyamide cured epoxy resin mixed with silica.<br><b>Independant Claims</b><br>1. A process for coding a voice signal comprising a block of a predetermined number of samples corresponding to a voiced segment of speech wherein said voice signal is analyzed by being split into a low frequency (LF) bandwidth and a high frequency bandwidth the signal contents of which are to be coded separately, said process being characterized in that it includes: coding said low frequency bandwidth signal; processing said high frequency-bandwidth contents to derive therefrom high frequency bandwidth energy information; processing both said low frequency bandwidth and said high frequency bandwidth contents to derive therefrom information relative to the phase shift between said high frequency signal and said low frequency signal; coding separately said high frequency bandwidth energy information and said phase shift information; grouping into a set of descriptors for transmission said coded low frequency bandwidth signal, said coded high frequency bandwidth energy information and said coded phase shift information to form the coded representation of said voice signal.<br>11. A Voice Excited Predictive Coder (VEPC) including first means sensitive to the voice signal for generating spectral descriptors representing linear prediction parameters, second means for generating a low frequency or base band signal (x(n)) and third means for generating high frequency (HF) or upper band signal descriptors of the upper band signal y(n), said third means including: base band preprocessing means connected to said second means for generating a pitch parameter M and a cleaned base band pulse train z(n); phase evaluation means connected to said base band preprocessing means and sensitive to said upper band signal to derive therefrom a phase shift descriptor K; phase shifter means sensitive to said base band pulse train z(n) and to said phase shift descriptor K to derive therefrom a shifted pulse train z(n-K); upper band analysis means sensitive to said upper band signal y(n), to said shifted pulse train z(n-K) and to said pitch parameter M, to derive therefrom noise energy information E and HF amplitude information A(i); and, coding means for coding said phase shift descriptor K, amplitude A(i), noise energy E and base band signal x (n).</p></layer>
<layer id = "layer26"><p><b>US4933957A:Low bit rate voice coding method and system</b><br><b>Independant Claims</b><br>1. A process for low bit rate block encoding a sampled voice signal s(n) based on code-excited encoding providing at least one prestored table address k and associated gain coefficient G, for each block of samples to be encoded, said process including: preemphasizing said s(n) signal into an sp(n) signal and deriving partial autocorrelation coefficients ai therefrom; filtering the voice signal s(n) using a short-term predictive filter tuned by said ai coefficients and deriving therefrom a short-term residual r(n); processing said r(n) to derive a gain factor "b" and a long-term delay M; deriving a weighted and delayed synthesized short-term residual br'(n-M) from previously subtracting br'(n-M) from r(n) to derive a long-term residual signal e(n); splitting e(n) into consecuive blocks; and, code excited encoding each block of said long-term residual e(n) into at least one TABLE address reference k and one gain coefficient G.<br>2. A low bit rate block encoding system for encoding a sampled voice originated signal s(n) into a d(n) data flow including for each block of samples a prestored TABLE address k and a gain coefficient G, said system including: means for preemphasizing said s(n) signal; partial correlation means for deriving partial autocorrelation (PARCOR) coefficients k.sub.i from said preemphasized s(n), and deriving PARCOR related coefficients a.sub.i from said preemphasized s(n) signal; short-term predictive filter means tuned with said a.sub.i coefficients and fed with s(n) to derive a short term residuals signal r(n) therefrom; means for splitting r(n) into consecutive blocks of samples; computing means connected to receive r(n) and derive a pitch related long-term delay parameter M and a gain factor b; first adding means having a(+) input fed with said r(n) signal and a(-) input, and providing a long term residual signal e(n); means for splitting e(n) into blocks of predetermined length; code excited encoding means for converting each block of samples e(n) into a TABLE reference (k) and a gain coefficient (G), said reference representing the TABLE address of the codeword best matching the considered e(n) block multiplied by gain g; a second adding means having a first (+) input fed with said selected codeword multiplied by gain G, and a second (+) input, said second adding means providing a synthesized short term residual r'(n); delay means having an input fed with said synthesized residual r'(n) and for deriving a delayed synthesized residual r'(n-M); multiplying means for multiplying sand delayed synthesized residual r'(n-M) by said gain factor b and derive b.multidot.r'(n-M) therefrom; means for feeding said b.multidot.r'(n-M) into said first adder (-) input and said second adder (+) input; and, multiplexing means for multiplexing for each block of r(n) samples said gain coefficient G, table address K, gain factor b, long-term delay M and PARCOR coefficient a.sub.i.</p></layer>
<layer id = "layer27"><p><b>US20040019492A1:Audio coding systems and methods</b><br>A nasal inhaler for introducing a substance to a nasal cavity of a user. The nasal inhaler comprises a chamber having an interior and an exterior, an outlet comprising an air exit passageway in flow communication with the interior of the chamber, a one-way air inlet valve in one-way flow communication with the interior of the chamber, and a dosage inlet passageway in flow communication with the interior of the chamber. A container includes a dispensing portion disposed in the dosage inlet passageway. In preferred embodiment, an adapter defines the dosage inlet passageway and is connected to the chamber. A mask also can be connected to the outlet. A method for dispensing a substance into the nasal cavity of the user comprises inserting the outlet into the nasal cavity, dispensing the substance into the chamber and inhaling through the outlet. A method for assembling a nasal inhaler assembly also is provided.<br><b>Independant Claims</b><br>1. An audio coding system for encoding and decoding an audio signal, said system including an encoder and a decoder, said encoder comprising: means for decomposing said audio signal into an upper and a lower sub-band signal; lower sub-band coding means for encoding said lower sub-band signal; upper sub-band coding means for encoding at least the non-periodic component of said upper sub-band signal according to a source-filter model; said decoder means comprising means for decoding said encoded lower sub-band signal and said encoded upper sub-band signal, and for reconstructing therefrom an audio output signal, wherein said decoding means comprises filter means and excitation means for generating an excitation signal for being passed by said filter means to produce a synthesised audio signal, said excitation means being operable to generate an excitation signal which includes a substantial component of synthesised noise in an upper frequency band corresponding to the upper sub-band of said audio signal.<br>5. An audio coding system according to any of the preceding claims, wherein said upper sub-band coding means comprises means for analysing and encoding said upper sub-band signal to obtain an upper sub-band energy or gain value and one or more upper sub-band spectral parameters.<br>10. An audio coding system according to any of the preceding claims, wherein said lower sub-band coding means comprises a speech coder, and includes means for providing a voicing decision.<br>13. An audio coding system according to any of the preceding claims, wherein said upper sub-band contains frequencies above 2.75 kHz and said lower sub-band contains frequencies below 2.75 kHz.<br>16. An audio encoder according to any of the preceding claims, wherein said upper sub-band coding means encodes said noise component with a bit rate of less than 800 bps and preferably of about 300 bps.<br>18. An audio coding method for encoding and decoding an audio signal, which method comprises: decomposing said audio signal into an upper and a lower sub-band signal; encoding said lower sub-band signal; encoding at least the non-periodic component of said upper sub-band signal according to a source-filter model, and decoding said encoded lower sub-band signal and said encoded upper sub-band signal to reconstruct an audio output signal; wherein said decoding step includes providing an excitation signal which includes a substantial component of synthesised noise in an upper frequency bandwidth corresponding to the upper sub-band of said audio signal, and passing said excitation signal through a filter means to produce a synthesised audio signal.<br>19. An audio encoder for encoding an audio signal, said encoder comprising: means for decomposing said audio signal into an upper and a lower sub-band signal; lower sub-band coding means for encoding said lower sub-band signal, and upper sub-band coding means for encoding at least a noise component of said upper sub-band signal according to source-filter model.<br>20. A method of encoding an audio signal which comprises decomposing said audio signal into an upper and a lower sub-band signal, encoding said lower sub-band signal and encoding at least a noise component of said upper sub-band signal according to a source-filter model.<br>23. A coder system for encoding and decoding a speech signal, said system comprising encoder means and decoder means, said encoder means including: filter means for decomposing said speech signal into lower and upper sub-bands together defining a bandwidth of at least 5.5 kHz; lower sub-band vocoder analysis means for performing a relatively high order vocoder analysis on said lower sub-band to obtain vocoder coefficients including LPC coefficients representative of said lower sub-band; upper sub-band vocoder analysis means for performing a relatively low order vocoder analysis on said upper sub-band to obtain vocoder coefficients including LPC coefficients representative of said upper sub-band; coding means for coding vocoder parameters including said lower and upper sub-band coefficients to provide an encoded signal for storage and/or transmission, and said decoder means including: decoding means for decoding said encoded signal to obtain vocoder parameters including said lower and upper sub-band vocoder coefficients; synthesising means for constructing an LPC filter from the vocoder parameters from said upper and lower sub-bands and for synthesising said speech signal from said filter and from an excitation signal.<br>31. A voice encoder apparatus for encoding a speech signal, said encoder apparatus including: filter means for decomposing said speech signal into lower and upper sub-bands; low band vocoder analysis means for performing a relatively high order vocoder analysis on said lower sub-band signal to obtain vocoder coefficients representative of said lower sub-band; upper band vocoder analysis means for performing a relatively low order vocoder analysis on said upper sub-band signal to obtain vocoder coefficients representative of said upper sub-band, and coding means for coding said low and high sub band vocoder coefficients to provide an encoded signal for storage and/or transmission.</p></layer>
<layer id = "layer28"><p><b>US6064954A:Digital audio signal coding</b><br><b>Independant Claims</b><br>1. Apparatus for digitally encoding an input audio signal, for storage or transmission, comprising: pitch detection means for determining at least a dominant time-domain periodicity in the input signal; means for generating a prediction signal based on the dominant time domain periodicity of the input signal; first discrete frequency domain transform means for generating a frequency domain representation of the input signal; second discrete frequency domain transform means for generating a frequency domain representation of the prediction signal; means to subtract at least a portion of the frequency domain representation of the prediction signal from the frequency domain representation of the input signal to generate an error signal; and means to generate an output signal from the error signal and parameters defining the prediction signal.<br>12. Apparatus for decoding a digitally encoded audio signal, the digitally encoded audio signal comprising at least parameters defining a prediction signal and an encoded error signal, the apparatus comprising: means for generating a prediction signal from the parameters; discrete frequency domain transform means for generating a frequency domain representation of the prediction signal; means to add at least a portion of the frequency domain representation of the prediction signal to the error signal to generate a frequency domain representation of the audio signal; inverse discrete frequency domain transform means for regenerating the audio signal from its frequency domain representation.<br>14. A method for digitally encoding an input audio signal, for storage or transmission, comprising: determining at least a dominant time-domain periodicity in the input signal; generating a prediction signal based on the dominant time domain periodicity of the input signal; generating a frequency domain representation of the input signal using a discrete frequency domain transform; generating a frequency domain representation of the prediction signal using a discrete frequency domain transform; subtracting at least a portion of the frequency domain representation of the prediction signal from the frequency domain representation of the input signal to generate an error signal; and generating an output signal from the error signal and parameters defining the prediction signal.<br>15. A method for decoding a digitally encoded audio signal, the digitally encoded audio signal comprising at least parameters defining a prediction signal and an encoded error signal, the method comprising: generating a prediction signal from the parameters; generating a frequency domain representation of the prediction signal using a discrete frequency domain transform; adding at least a portion of the frequency domain representation of the prediction signal to the error signal to generate a frequency domain representation of the audio signal; and regenerating the audio signal from its frequency domain representation using an discrete inverse frequency domain transform.<br>17. Apparatus for digitally encoding an input audio signal, for storage or transmission, comprising: a pitch detector to determine at least a dominant time-domain periodicity in the input signal; a first generator to generate a prediction signal based on the dominant time domain periodicity of the input signal; a first discrete frequency domain transform generator to generate a frequency domain representation of the input signal; a second discrete frequency domain transform generator to generate a frequency domain representation of the prediction signal; a subtractor to subtract at least a portion of the frequency domain representation of the prediction signal from the frequency domain representation of the input signal to generate an error signal; and a second generator to generate an output signal from the error signal and parameters defining the prediction signal.<br>28. Apparatus for decoding a digitally encoded audio signal, the digitally encoded audio signal comprising at least parameters defining a prediction signal and an encoded error signal, the apparatus comprising: a first generator to generate a prediction signal from the parameters; a discrete frequency domain transform generator to generate a frequency domain representation of the prediction signal; an adder to add at least a portion of the frequency domain representation of the prediction signal to the error signal to generate a frequency domain representation of the audio signal; an inverse discrete frequency domain transform regenerator for regenerating the audio signal from its frequency domain representation.<br>30. A computer program product for digitally encoding an input audio signal for storage or transmission, said computer program product comprising a computer usable medium having computer readable program code thereon, said computer readable program code comprising: computer readable program code means for determining at least a dominant time-domain periodicity in the input signal; computer readable program code means for generating a prediction signal based on the dominant time domain periodicity of the input signal; computer readable program code means for generating a frequency domain representation of the input signal using a discrete frequency domain transform; computer readable program code means for generating a frequency domain representation of the prediction signal using a discrete frequency domain transform; computer readable program code means for subtracting at least a portion of the frequency domain representation of the prediction signal from the frequency domain representation of the input signal to generate an error signal; and computer readable program code means for generating an output signal from the error signal and parameters defining the prediction signal.<br>31. A computer program product for decoding a digitally encoded audio signal, the digitally encoded audio signal comprising at least parameters defining a prediction signal and an encoded error signal, the computer program product comprising a computer usable medium having computer readable program code thereon, said computer readable program code comprising: computer readable program code means for generating a prediction signal from the parameters; computer readable program code means for generating a frequency domain representation of the prediction signal using a discrete frequency domain transform; computer readable program code means for adding at least a portion of the frequency domain representation of the prediction signal to the error signal to generate a frequency domain representation of the audio signal; and computer readable program code means for regenerating the audio signal from its frequency domain representation using an discrete inverse frequency domain transform.</p></layer>
<layer id = "layer29"><p><b>US20020123885A1:Transmission system with improved speech encoder</b><br>An improved optical system is disclosed for projecting light in the form of an image to a remote target. The laser light source and a holographic optical element are mounted together in optical alignment. The optical element is created using iterative discrete computer encoding for optimum efficiency. In alternate embodiments, the diffractive optical element has a collimating lens encoded into the grating levels and it also performs soft aperture circularizing using either amplitude or phase control over the coherent light. An embossed diffractive optical element laminated to an injection-molded refractive element is also disclosed.<br><b>Independant Claims</b><br>1. Transmission system comprising a transmitting arrangement having a speech encoder for deriving an encoded speech signal from an input speech signal, the transmitting arrangement comprises transmit means for transmitting the encoded speech signal to a receiving arrangement, the receiving arrangement comprising a speech decoder for decoding the encoded speech signal, characterized in that the speech encoder and/or the speech decoder comprises background noise determining means for determining a background noise property of the speech signal, in that the speech encoder and/or the speech decoder comprises at least one background noise dependent element, and in that the speech encoder and/or speech decoder comprises adaptation means for changing at least one property of the background noise dependent element in dependence on the background noise property.<br>7. Transmitting arrangement having a speech encoder for deriving an encoded speech signal from an input speech signal, the transmitting arrangement comprises transmit means for transmitting the encoded speech signal, characterized in that the speech encoder comprises background noise determination means for determining a background noise property of the speech signal, in that the speech encoder comprises at least one background noise dependent element, and in that the speech encoder comprises adaptation means for changing at least one property of the background noise dependent element in dependence on the background noise property.<br>8. Speech encoder for deriving an encoded speech signal from an input speech signal, the transmitting arrangement comprises transmit means for transmitting the encoded speech signal, characterized in that the speech encoder comprises background noise determination means for determining a background noise property of the speech signal, in that the speech encoder comprises at least one background noise dependent element, and in that the speech encoder comprises adaptation means for changing at least one property of the background noise dependent element in dependence on the background noise property.<br>9. Receiver comprising a speech decoder for decoding an encoded speech signal, characterized in that the speech decoder comprises background noise determination means for determining a background noise property of the speech signal, in that the speech decoder comprises at least one background noise dependent element, and in that the speech decoder comprises adaptation means for changing at least one property of the background noise dependent element in dependence on the background noise property.<br>10. Speech decoder for decoding an encoded speech signal, characterized in that the speech decoder comprises background noise determining means for determining a background noise property of the speech signal, in that the speech decoder comprises at least one background noise dependent element, and in that the speech decoder comprises adaptation means for changing at least one property of the background noise dependent element in dependence on the background noise property.<br>11. Transmission method comprising deriving an encoded speech signal from an input speech signal, transmitting the encoded speech signal to a destination, receiving the encoded speech signal and decoding the encoded speech signal, characterized in that the transmission method comprises determining a background noise property of the speech signal, and in that the method comprises changing the encoding and/or decoding of the speech signal in dependence on the background noise property.<br>12. Encoding method comprising deriving an encoded speech signal from an input speech signal, , characterized in that the transmission method comprises determining a background noise property of the speech signal, and in that the method comprises changing the encoding of the speech signal in dependence on the background noise property.<br>13. Decoding method comprising deriving an decoded speech signal from an encoded speech signal, characterized in that the decoding method comprises determining a background noise property of the speech signal, and in that the method comprises changing the decoding of the speech signal in dependence on the background noise property.</p></layer>
<layer id = "layer30"><p><b>US6691083B1:Wideband speech synthesis from a narrowband speech signal</b><br>An apparatus for preserving and dispensing wine or champagne. The apparatus provides a housing having a container support for holding wine or champagne bottles, a plurality of removable stoppers for insertion in the bottles, a nitrogen generator for generating a nitrogen rich gas from air, a nitrogen storage tank for storing the generated nitrogen rich gas, a cooling system for cooling certain bottles and dispensers for providing wine or champagne from the bottles to a user. The nitrogen generator draws in ambient air, adsorbs the oxygen from the air and stores nitrogen rich gas in the nitrogen storage tank. The nitrogen storage tank supplies the nitrogen rich gas to the bottles for preserving the wine or champagne. The stoppers include a nitrogen line and a supply line. The nitrogen line communicates nitrogen rich gas into the bottles and the supply line communicates wine or champagne from the bottles to the dispensers.<br><b>Independant Claims</b><br>1) An apparatus for synthesising speech from a bandlimited speech signal, the apparatus comprising means for extracting a spectral signal from the bandlimited signal; peak-picking means arranged to receive said spectral signal and to search a predetermined frequency range to provide a set of one or more peak frequency output values corresponding to the frequency of one or more peaks in said spectral signal; codebook means containing a plurality of codebook entries, each codebook entry comprising a set of one or more codebook frequency values and a set of one or more corresponding synthesis parameters; look-up means arranged to receive said peak frequency value set and arranged to access the codebook means to extract a required synthesis parameter set corresponding to a codebook frequency value set which is close to said peak frequency value set; and speech synthesis means arranged to receive the required synthesis parameter set and to generate speech using said required synthesis parameter set.<br>8) A method for synthesising speech from a bandlimited speech signal, the method comprising: extracting a spectral signal from the bandlimited signal; searching a predetermined frequency range of the spectral signal to provide a set of one or more peak frequency output values corresponding to the frequency of one or more peaks in said spectral signal; accessing a codebook containing a plurality of codebook entries, each codebook entry comprising a set of one or more codebook frequency values and a set of one or more corresponding synthesis parameters; determining a required synthesis parameter set corresponding to a codebook frequency value set which is close to said peak frequency value set; and synthesising speech using said required synthesis parameter set.</p></layer>
<layer id = "layer31"><p><b>US6681202B1:Wide band synthesis through extension matrix</b><br>A portable self-contained liquid natural gas (LNG) dispensing system is housed in a container featuring opposing side and end walls and a bottom panel. The container is divided into a ventilated portion and a covered portion. A roof is over the covered portion while the ventilated portion features an open top. A bulk tank positioned within the container contains a supply of LNG with a head space thereabove and a pump is submerged in LNG within a sump that is also positioned within the container and communicates with the bulk tank. The container is lined with stainless steel sheets to define a containment volume that is capable of holding the entire supply of LNG in the bulk tank. A vent valve communicates with the head space of the bulk tank and is positioned under the open top of the ventilated portion of the container. The electric controls are positioned on the lower portion of the end wall of the covered portion of the container so as to be located in accordance with the appropriate safety guidelines.<br><b>Independant Claims</b><br>1) Telecommunications system comprising at least a transmitter and a receiver for transmitting a speech signal with a given bandwidth, the receiver comprising means for extending the bandwidth of the received signal, wherein said receiver comprises: means for receiving a band-limited signal as input; means for segmenting said band-limited signal into a plurality of speech frames; a detector for characterizing each speech frame of said band-limited input signal; means for selecting one of a plurality of mappings in accordance with said characterization; analysis means for extracting filter coefficients of said band-limited input signal; means for creating a band-limited residual signal from a current speech frame of said input filter coefficients; means for extending the bandwidth of said band-limited residual signal; means for calculating a set of bandwidth-extended filter coefficients using said filter coefficients and said selected mapping; and a synthesis filter for outputting said extended bandwidth signal, said filter including means for filtering said bandwidth extended residual signal with said bandwidth extended filter coefficients.<br>6) A receiver for receiving speech signals with bandwidth and comprising means for extending the bandwidth of the received signal, wherein said receiver comprises: means for receiving a band-limited signal as input; means for segmenting said band-limited signal into a plurality of speech frames; a detector for characterizing each speech frame of said band-limited input signal means for selecting one of a plurality of mappings in accordance with said charactization; analysis means for extracting filter coefficients of said band-limited input signal; means for creating a band-limited residual signal from a current speech frame of said input signal and said filter coefficients; means for extending the bandwidth of said band-limited residual signal; means for calculating a set of bandwidth-extended filter coefficients using said filter coefficients and said selected mapping; and a synthesis filter for outputting said extended bandwidth signal, said filter including means for filtering said bandwidth extended residual signal with said bandwidth extended filter coefficients.<br>7) A method for extending at the receiving end, the bandwidth of a received signal, the method comprising the steps of: receiving a band-limited signal as input; segmenting said band-limited input signal into a plurality of speech frames; characterizing each speech frame of said band-limited input signal; selecting one of a plurality of mappings in accordance with said characterization; extracting filter coefficients of said band-limited input signal; creating a band-limited residual signal from a current speech frame of said band-limited input signal and said filter coefficients; extending the bandwidth of said band-limited residual signal; calculating a set of bandwidth-extended filter coefficients using said filter coefficients and said selected mapping; and filtering said bandwidth extended residual signal with said bandwidth extended filter coefficients to produce a first extended bandwidth signal.</p></layer>
<layer id = "layer32"><p><b>US6011853A:Equalization of speech signal in mobile phone</b><br>The substrate (<b>10</b>) of the present invention includes: a first electrode (<b>26</b>) and a second electrode (<b>30</b>). The second electrode (<b>30</b>) is formed on an insulation film (<b>52</b>) covering at least a part of the first electrode (<b>26</b>) and electrically connected with the first electrode (<b>26</b>) through a contact hole (<b>50</b>) formed in the insulation film (<b>52</b>). The first electrode (<b>26</b>) includes a laminated structure of a metal film (<b>42</b>) and a protective film (<b>44</b>). An etching rate of the metal film (<b>42</b>) is almost equal to an etching rate of the protective film (<b>44</b>) with respect to a first etching for forming the metal film (<b>42</b>) and the protective film (<b>44</b>). An etching rate of the protective film (<b>44</b>) is almost zero with respect to a second etching for forming the contact hole (<b>50</b>).<br><b>Independant Claims</b><br>1. A method for improving the quality and intelligibility of sound reproduced by a telephone apparatus in which the reproduced sound is handled in a digital form and equalized according to a certain frequency response, wherein there is generated control information describing operating conditions of said telephone apparatus and the frequency response of said equalization is changed on the basis of said control information to optimize the quality and intelligibility of the sound reproduced in a given situation, wherein the telephone apparatus comprises an outgoing channel with a microphone for transmitting an outgoing signal to a distant location and an incoming channel for receiving an incoming signal, the method further comprising steps of: generating the control information by sensing sound by said microphone at an input to the outgoing channel; applying said equalization to said incoming signal; adjusting said equalization in response to the control information obtained by the sensing of the sound at the input to the outgoing channel; by said microphone, recording the sound to be transmitted via said outgoing channel, measuring noise recorded through said microphone, and employing data representing noise measured by said measuring step for generation of said control information by said generating step; and by use of voice activity detection means, determining whether or not a user is speaking on the telephone during a call, and conducting said noise measuring step only during those moments when the user is not speaking according to information from said voice activity detection means.<br>10. A method for improving the quality and intelligibility of sound reproduced by a telephone apparatus in which the reproduced sound is handled in a digital form and equalized according to a certain frequency response, wherein there is generated control information describing the operating conditions of said telephone apparatus and the frequency response of said equalization is changed on the basis of said control information to optimize the quality and intelligibility of the sound reproduced in a given situation, the method further comprising recurrently the following steps: a) without any special temporal order the first information element is generated according to how the user adjusts the phone sound volume, it is monitored when the user is not speaking during a call, and the noise in the operating environment of the phone is measured during such moments and the second information element is formed on the basis of the noise measurement, the quality of the connection between the telephone and the communication networked used via it is monitored and the third information element is formed accordingly, and b) according to the information elements formed the gain of the low-frequency part of the sound reproduced is changed inversely proportionally to the sound volume set by the user, whereby value pairs representing a certain sound volume and the corresponding gain form a monotonically falling curve (A;B;C;) in a system of coordinates where the gain is represented as a function of the sound volume setting, said gain is scaled inversely proportionally to measured noise, whereby said curve shifts downwards (A->B; B->C) in said system of coordinates when the noise increases and upwards (C->B; B->A) when the noise decreases, and if the connection between the communication network and the phone is bad, said gain of the low-frequency part is set constant, whereby it does not depend on the sound volume setting.<br>12. A telephone apparatus including a loudspeaker for the reproduction of sound and a digital signal processing means for the digital processing of the sound reproduced, which signal processing means includes an equalizer which has a certain frequency response, wherein said telephone apparatus includes means for the generation of control information describing its operating conditions and a means for changing the frequency response of said equalizer on the basis of said control information, wherein the telephone apparatus comprises: an outgoing channel for transmitting an outgoing signal to a distant location and an incoming channel for receiving an incoming signal; means for generating the control information by sensing sound at an input to the outgoing channel, the reproduced sound appearing at an output of the incoming channel, said equalization being applied to said incoming signal; means for adjusting said equalization in response to the control information obtained by the sensing of the sound at the input to the outgoing channel; a control block for collecting the data describing said operating conditions and for generating said control information; a microphone for recording the sound to be transmitted via a telephone connection, noise measuring means for measuring noise recorded through said microphone, and means for conveying data representing noise measured by said measuring means to said control block for the generation of said control information; and voice activity detection means for determining whether or not a user is speaking on the phone during a call, and said noise measuring means is operative to measure noise only during those moments when the user is not speaking according to the information from said voice activity detection means.<br>22. A telephone apparatus including a loudspeaker for the reproduction of sound and a digital signal processing means for the digital processing of the sound reproduced, which signal processing means includes an equalizer which has a certain frequency response, wherein said telephone apparatus includes means for the generation of control information describing its operating conditions and a means for changing the frequency response of said equalizer on the basis of said control information; wherein said equalizer realizes the transfer function ##EQU2## wherein the Zs represent delays of a time unit and said control information comprises variable parameters K, a1 and a2, of which K represents the gain and a1 and a2 represent the center frequency and the bandwidth.<br>23. A method for improving the quality of sound reproduced by a receiver of a communications system which comprises also a transmitter, the method comprising steps of: constructing the receiver with a filter having a passband extending across the spectrum of the incoming signal; measuring ambient sonic noise level at the transmitter by use of a microphone of the transmitter to provide a measurement thereof, and employing the microphone for a transmission of speech from the system; establishing a plurality of spectral shapes for said passband wherein an individual one of said spectral shapes defines a relationship between amplitude and frequency of a signal transmission characteristic of the filter; providing a relationship between said spectral shapes and said ambient noise level for signal equalization; selecting a spectral shape for said passband corresponding to the measurement of the ambient noise level; generating control information from said measurement of the ambient noise level; and by use of voice activity detection means, determining whether or not a user is speaking on the telephone during a call, and conducting said noise measuring step only during those moments when the user is not speaking according to information from said voice activity detection means.<br>26. A receiver circuit of a communications system having an incoming signal channel and a transmission signal channel, the receiving circuit serving to improve the quality of sound of an incoming signal reproduced by the receiver circuit in response to a measurement of an ambient noise signal at the transmission channel of the system, the circuit comprising: a filter with a passband extending across the spectrum of the incoming signal, and being located in the incoming signal channel; means for measuring ambient sonic noise level at an input to the transmission channel by a microphone of the transmission channel to provide a measurement of the ambient noise level; means for establishing a plurality of spectral shapes for the passband wherein an individual one of the spectral shapes defines a relationship between amplitude and frequency of a signal transmission characteristic of the filter; means for providing a relationship between spectral shapes of the passband and said ambient noise level, wherein the passband may have any one of a plurality of said spectral shapes, an individual one of the spectral shapes defining a relationship between amplitude and frequency of a signal transmission characteristic of the filter; means responsive to the measurement of the ambient noise level for selecting one of said spectral shapes for said passband corresponding to the measurement of the ambient noise level to accomplish signal equalization of said incoming signal; and voice activity detection means for determining whether or not a user is speaking into the microphone during a call, and said noise measuring means is operative to measure noise only during those moments when the user is not speaking according to the information from said voice activity detection means.</p></layer>
<layer id = "layer33"><p><b>US5963901A:Method and device for voice activity detection and a communication device</b><br>A metal plug is formed in a connection hole such as a via hole or a contact hole to provide an interconnection between multilayer wires in a semiconductor integrated circuit. First, an adhesion layer is deposited on an insulating film, and an area of the adhesion layer is etched away isotropic etching through an opening in a resist mask, the area being larger than the opening in the resist mask. Thereafter, the insulating film is etched through the opening in the resist mask by anisotropic etching, forming a connection hole in the insulating film. Then, a metal layer such as a blanket tungsten layer is deposited on the adhesion layer and in the connection hole. The metal layer is etched back and the adhesion layer is etched away, leaving the metal layer as a metal plug in the connection hole.<br><b>Independant Claims</b><br>1. A voice activity detection devices, comprising: means for detecting voice activity in an input signal, and means for making a voice activity decision on the basis of the detection, wherein said detecting means and decision making means comprises means for dividing said input signal into subsignals each representing a specific frequency band, means for estimating noise in the subsignals, means for calculating subdecision signals on the basis of the estimated noise in the subsignals, and means for making a voice activity decision for the input signal on the basis of the calculated subdecision signals.<br>9. A mobile station for transmission and reception of speech messages, comprising: means for detecting voice activity in a speech message, and means for making a voice activity decision on the basis of the detection, wherein said detecting means and decision making means comprises means for dividing said speech message into subsignals each representing a specific frequency band, means for estimating noise in the subsignals, means for calculating subdecision signals on the basis of the estimated noise in the subsignals, and means for making a voice activity decision for the input signal on the basis of the calculated subdecision signals.<br>10. A method of detecting voice activity in a communication device, the method comprising the steps of: receiving an input signal, detecting voice activity in the input signal, and making a voice activity decision on basis of the detection, wherein the steps of detecting and making a voice activity decision comprise steps of, dividing said input signal into subsignals representing specific frequency bands, estimating noise in the subsignals, calculating subdecision signals on the basis of the estimated noise in the subsignals, and making the voice activity decision for the input signal on the basis of the calculated subdecision signals.</p></layer>
<layer id = "layer34"><p><b>US5933803A:Speech encoding at variable bit rate</b><br>An embodiment of the invention is an inflatable support member having at least one tension point to establish a bend in the inflatable support member. The inflatable support member includes a first sheet and a second sheet sealed around their respective edges. A tension point is formed by enlarging the seam area where a bend in the inflatable support member is desired. Alternate embodiments of the invention include structures including the inflatable support member. An alternate inflatable support member includes a first sheet and second sheet, the second sheet having an elasticity less than that of the first sheet by using different materials, additional materials or stretching the second sheet.<br><b>Independant Claims</b><br>1. A speech encoding method for variable-rate encoding a speech signal, comprising the steps of: a speech signal is divided into speech frames for speech encoding by frames, a first analysis is made for a divided speech frame in order to form a first product, comprising a number of first prediction parameters for modeling the divided speech frame in a first interval, a second analysis is made for the divided speech frame in order to form a second product, comprising a number of second prediction parameters for modeling the divided speech frame in a second interval, and said first and second prediction parameters are presented in digital form, wherein based upon the first and the second products obtained in the first analysis and the second analysis, the number of bits used for presenting one of the following parameters is determined: the first prediction parameters, the second prediction parameters and a combination of them, and the speech signal is encoded by a bit stream comprising a determined number of bits representing said first and said second prediction parameters.<br>6. A telecommunication system comprising communication means such as mobile stations, base stations, base station controllers, mobile communication switching centers, telecommunication networks and terminal devices for establishing a telecommunication connection and transferring information between said communication means, said communication means comprise a speech encoder operative with a variable rate of coding, which said speech encoder further comprises means for dividing a speech signal into speech frames for encoding by frames, means for performing a first analysis to a divided speech frame in order to form a first product, which first product comprises prediction parameters modeling the divided speech frame in a first interval, means for performing a second analysis to the divided speech frame in order to form a second product which second product comprises prediction parameters modeling the divided speech frame in a second interval, and means for outputting a coded speech signal by presenting the first and the second prediction parameters in a digital form, wherein said speech encoder further comprises means for analyzing the performance of the first analysis and the second analysis, based upon the first product and the second product, and that said performance analyzing means have been arranged to determine the number of bits used for presenting one of the following parameters: the first prediction parameters, the second prediction parameters, and a combination of them.<br>7. A communication device comprising means for transferring speech and a speech encoder for speech encoding, which speech encoder is operative with a variable rate of coding and comprises means for dividing a speech signal into speech frames for speech encoding by frames, means for performing a first analysis to a divided speech frame in order to form a first product, which first product comprises first prediction parameters modeling the divided speech frame in a first interval, means for performing a second analysis to the divided speech frame in order to form a second product, which second product comprises second prediction parameters modeling the divided speech frame in a second interval, and means for outputting a coded speech signal by presenting the first and the second prediction parameters in a digital form, wherein said speech encoder further comprises means for analyzing the performance of the first analysis and the second analysis of the speech encoder based upon the first product and the second product, and that said performance analyzing means have been arranged to determine the number of bits used for presenting one of the following parameters: the first prediction parameters, the second prediction parameters and a combination of them.<br>8. A speech encoder operative with a variable rate of coding, comprising: means for dividing a speech signal into speech frames for speech encoding by frames, means for performing a first analysis to a divided speech frame in order to form a first product, which first product comprises first prediction parameters modeling the divided speech frame in a first interval, means for performing a second analysis to the divided speech frame in order to form a second product, which second product comprises second prediction parameters modeling the divided speech frame in a second interval, and means for outputting a coded speech signal by presenting the first and the second prediction parameters in a digital form, wherein said speech encoder further comprises means for analyzing the performance of the first analysis and the second analysis of the speech encoder based upon the first product and the second product, and that said performance analyzing means have been arranged to determine the number of bits used for presenting one of the following parameters: the first prediction parameters, the second prediction parameters and a combination of them.<br>9. A speech encoder operative with a variable rate of coding, comprising: generating means for outputting a coded speech signal, and means for receiving speech from a telecommunication connection in form of speech parameters, which speech parameters comprise first prediction parameters for modeling speech in a first interval and second prediction parameters for modeling speech in a second interval, wherein said generating means comprise a mode selector, said speech parameters comprise information parameters, said mode selector has been arranged to select a correct speech decoding mode for the first prediction parameters and the second prediction parameters based upon said information parameters.</p></layer>
<layer id = "layer35"><p><b>US20040093208A1:Audio coding method and apparatus</b><br><b>Independant Claims</b><br>1. A method of coding an audio signal, the method comprising the steps of: receiving an audio signal x to be coded; generating a quantised audio signal {tilde over (x)} from the received audio signal x; generating a set of long-term prediction coefficients A which can be used to predict a current time frame of the received audio signal directly from at least one previous time frame of the quantised audio signal {tilde over (x)}; using the prediction coefficients A to generate a predicted audio signal ˆ; comparing the received audio signal x with the predicted audio signal ˆ and generating an error signal E(k) for each of a plurality of frequency sub-bands; quantising the error signals E(k) to generate a set of quantised error signals {tilde over (E)}(k); and combining the quantised error signals {tilde over (E)}(k) and the prediction coefficients A to generate a coded audio signal.<br>4. A method of decoding a coded audio signal, the method comprising the steps of: receiving a coded audio signal comprising a quantised error signal {tilde over (E)}(k) for each of a plurality of frequency sub-bands of the audio signal and, for each time frame of the audio signal, a set of prediction coefficients A which can be used to predict a current time frame xm of the received audio signal directly from at least one previous time frame of a reconstructed quantised audio signal {tilde over (x)}; generating said reconstructed quantised audio signal {tilde over (x)} from the quantised error signals {tilde over (E)}(k); using the prediction coefficients A and the quantised audio signal {tilde over (x)} to generate a predicted audio signal ˆ; transforming the predicted audio signal ˆ from the time domain to the frequency domain to generate a set of predicted frequency sub-band signals ˆ(k) for combining with the quantised error signals {tilde over (E)}(k) to generate a set of reconstructed frequency sub-band signals {tilde over (X)}(k); and performing a frequency to time domain transform on the reconstructed frequency sub-band signals {tilde over (X)}(k) to generate the reconstructed quantised audio signal {tilde over (x)}.<br>5. Apparatus for coding an audio signal, the apparatus comprising: an input for receiving an audio signal x to be coded; processing means coupled to said input for generating from the received audio signal x a quantised audio signal {tilde over (x)}; prediction means coupled to said processing means (3) for generating a set of long-term prediction coefficients A for predicting a current time frame xm of the received audio signal x directly from at least one previous time frame of the quantised audio signal {tilde over (x)}; generating means for generating a predicted audio signal ˆ using the prediction coefficients A and for comparing the received audio signal x with the predicted audio signal ˆ to generate an error signal E(k) for each of a plurality of frequency sub-bands; quantisation means for quantising the error signals E(k) to generate a set of quantised error signals {tilde over (E)}(k); and combining means for combining the quantised error signals {tilde over (E)}(k) with the prediction coefficients A to generate a coded audio signal.<br>8. Apparatus for decoding a coded audio signal x, where the coded audio signal comprises a quantised error signal {tilde over (E)}(k) for each of a plurality of frequency sub-bands of the audio signal and a set of prediction coefficients A for each time frame of the audio signal and wherein the prediction coefficients A can be used to predict a current time frame xm of the received audio signal directly from at least one previous time frame of a reconstructed quantised audio signal {tilde over (x)}, the apparatus comprising: an input for receiving the coded audio signal; generating means for generating said reconstructed quantised audio signal {tilde over (x)} from the quantised error signals {tilde over (E)}(k); and signal processing means for generating a predicted audio signal ˆ from the prediction coefficients A and said reconstructed audio signal {tilde over (x)}, wherein said generating means comprises first transforming means for transforming the predicted audio signal ˆ from the time domain to the frequency domain to generate a set of predicted frequency sub-band signals ˆ(k), combining means for combining said set of predicted frequency sub-band signals ˆ(k) with the quantised error signals {tilde over (E)}(k) to generate a set of reconstructed frequency sub-band signals {tilde over (X)}(k), and second transforming means for performing a frequency to time domain transform on the reconstructed frequency sub-band signals {tilde over (X)}(k) to generate the reconstructed quantised audio signal {tilde over (x)}.</p></layer>
<layer id = "layer36"><p><b>US20050027520A1:Noise suppression</b><br>A dual sprayer has an externally mounted mixing manifold for intimately commingling disparate liquids sprayed during pumping and issuing through a nozzle as a complete admixture of dual liquids.<br><b>Independant Claims</b><br>1-19. (cancelled)<br>2) 1-19. (cancelled)<br>3) 1-19. (cancelled)<br>4) 1-19. (cancelled)<br>5) 1-19. (cancelled)<br>6) 1-19. (cancelled)<br>7) 1-19. (cancelled)<br>8) 1-19. (cancelled)<br>1-19. (cancelled)<br>10) 1-19. (cancelled)<br>11) 1-19. (cancelled)<br>12) 1-19. (cancelled)<br>13) 1-19. (cancelled)<br>14) 1-19. (cancelled)<br>15) 1-19. (cancelled)<br>16) 1-19. (cancelled)<br>17) 1-19. (cancelled)<br>18) 1-19. (cancelled)<br>1-19. (cancelled)<br>20. A noise suppression stage to act on a signal, the noise suppression stage comprising: a first windowing block to weight the signal by a first window function; a transformer to transform the signal from a time domain to a frequency domain; a transformer to transform the signal from the frequency domain into the time domain and; a second windowing block to weight the signal by a second window function.<br>25. A two phase windowing method comprising: weighting a signal in the time domain by a first window function to produce a frame; transforming the frame into the frequency domain; transforming the frame back into the time domain; and weighting the frame by a second window function.<br>30. A mobile terminal comprising a noise suppression stage to act on a signal, the noise suppression stage comprising: a first windowing block to weight the signal by a first window function; a transformer to transform the signal from a time domain into a frequency domain a transformer to transform the signal from a frequency domain into the time domain and; a second windowing block to weight the signal by a second window function.<br>35. A communications system comprising a communications network having a noise suppression stage to act on a signal and a plurality of communications terminals, the noise suppression stage comprising: a first windowing block to weight the signal by a first window function; a transformer to transform the signal from a time domain into a frequency domain; a noise suppressor to suppress noise in the signal; a transformer to transform the signal from the frequency domain into the time domain; and a second windowing block to weight the signal by a second window function.<br>40. A network element comprising a noise suppression stage to act on a signal, the noise suppression stage comprising: a first windowing block to weight the signal by a first window function; a transformer to transform the signal from a time domain into a frequency domain; a transformer to transform the signal from the frequency domain into the time domain and; a second windowing block to weight the signal by a second window function.</p></layer>
<layer id = "layer37"><p><b>US20010027390A1:Speech decoder and a method for decoding speech</b><br>This invention relates generally to the remote detections of subsurface liquid contaminants using in combination a geophysical technique known as ERT and an EKS. Electrokinetic transport is used to enhance the ability of electrical resistance tomography (ERT) to detect position and movement of subsurface contaminant liquids, particles or ions. ERT images alone are difficult to interpret because of natural inhomogeneities in soil composition and electrical properties. By subtracting two or more ERT images obtained before and after field induced movement, a high contrast image of a plume of distinct electrokinetic properties can be seen. The invention is applicable to important subsurface characterization problems including, as examples, (1) detection of liquid-saturated plumes of contaminants such as those associated with leaks from underground storage tanks containing hazardous concentrated electrolytes, (2) detection and characterization of soils contaminated with organic pollutants such as droplets of gasoline; and (3) monitoring the progress of electrokinetic containment or clean up of underground contamination.<br><b>Independant Claims</b><br>1. A speech processing device, comprising: an input for receiving a linear prediction encoded speech signal representing a first frequency band, means for extracting, from the linear prediction encoded speech signal, information describing a first linear prediction filter associated with the first frequency band, a vocoder for converting an input signal into an output signal representing a second frequency band, and means for generating a second linear prediction filter, to be used by the vocoder on the second frequency band, on the basis of the information describing the first linear prediction filter.<br>8. A digital radio telephone, comprising: a speech processing device, within said speech processing device an input for receiving a linear prediction encoded speech signal representing a first frequency band, within said speech processing device means for extracting, from the linear prediction encoded speech signal, information describing a first linear prediction filter associated with the first frequency band, within said speech processing device a vocoder for converting an input signal into an output signal representing a second frequency band, and within said speech processing device means for generating a second linear prediction filter, to be used by the vocoder on the second frequency band, on the basis of the information describing the first linear prediction filter<br>9. A method for processing digitally encoded speech, comprising the steps of: extracting, from a linear prediction encoded speech signal, information describing a first linear prediction filter associated with a first frequency band, converting an input signal into an output signal representing a second frequency band, and generating a second linear prediction filter, to be used in the conversion of the input signal to the output signal on the basis of the extracted information describing a first linear prediction filter associated with a first frequency band.</p></layer>
<layer id = "layer38"><p><b>US20010044712A1:Method and arrangement for changing source signal bandwidth in a telecommunication connection with multiple bandwidth capability</b><br>The present invention provides a system and a process for removing contaminants such as CO.sub.2 and mobile cations and anions from aqueous solutions. The system and the process contemplate the use of thermally sterilizable aqueous polishing agents such as thermally sterilizable ion exchange resins and as a result, the need for chemical and/or mechanical microbial control or inhibition techniques is obviated. Therefore, the present invention will be especially useful in submarine and spacecraft applications where the need exists for reduced weight and volume water processing systems.<br><b>Independant Claims</b><br>1. A speech encoding arrangement, comprising: a speech signal input, a multiple mode speech encoder for encoding speech signals coupled to the speech signal input selectabily with a first encoding mode associated with a first bandwidth or a second encoding mode associated with a second bandwidth, and a soft bandwidth switching block with an input coupled to the speech signal input and an output coupled to the multiple mode speech encoder, said soft bandwidth switching block being arranged to gradually change the bandwidth of a speech signal coupled to the multiple mode speech encoder as a response to an instruction for changing speech signal bandwidth.<br>9. A digital radio telephone, comprising: a speech encoding arrangement, a speech signal input to the speech encoding arrangement, within the speech encoding arrangement a multiple mode speech encoder for encoding speech signals coupled to the speech signal input selectabily with a first encoding mode associated with a first bandwidth or a second encoding mode associated with a second bandwidth, and a soft bandwidth switching block with an input coupled to the speech signal input and an output coupled to the multiple mode speech encoder, said soft bandwidth switching block being arranged to gradually change the bandwidth of a speech signal coupled to the multiple mode speech encoder as a response to an instruction for changing speech signal bandwidth.<br>10. A transcoder and rate adaptor unit of a cellular radio system, comprising: a speech encoding arrangement, a speech signal input to the speech encoding arrangement, within the speech encoding arrangement a multiple mode speech encoder for encoding speech signals coupled to the speech signal input selectabily with a first encoding mode associated with a first bandwidth or a second encoding mode associated with a second bandwidth, and a soft bandwidth switching block with an input coupled to the speech signal input and an output coupled to the multiple mode speech encoder, said soft bandwidth switching block being arranged to gradually change the bandwidth of a speech signal coupled to the multiple mode speech encoder as a response to an instruction for changing speech signal bandwidth.<br>11. A speech decoding arrangement, comprising: a speech signal input, a multiple mode speech decoder for decoding speech signals coupled to the speech signal input selectabily with a first decoding rate associated with a first bandwidth or a second decoding rate associated with a second bandwidth, and a soft bandwidth switching block with an input coupled to the multiple mode speech decoder and an output, said soft bandwidth switching block being arranged to gradually change the bandwidth of a speech signal received from the multiple mode speech decoder as a response to an instruction for changing speech signal bandwidth.<br>19. A digital radio telephone, comprising: a speech decoding arrangement, a speech signal input to the speech decoding arrangement, within the speech decoding arrangement a multiple mode speech decoder for decoding speech signals coupled to the speech signal input selectabily with a first decoding rate associated with a first bandwidth or a second decoding rate associated with a second bandwidth, and a soft bandwidth switching block with an input coupled to the multiple mode speech decoder and an output, said soft bandwidth switching block being arranged to gradually change the bandwidth of a speech signal received from the multiple mode speech decoder as a response to an instruction for changing speech signal bandwidth.<br>20. A transcoder and rate adaptor unit of a cellular radio system, comprising: a speech decoding arrangement, a speech signal input to the speech decoding arrangement, within the speech decoding arrangement a multiple mode speech decoder for decoding speech signals coupled to the speech signal input selectabily with a first decoding rate associated with a first bandwidth or a second decoding rate associated with a second bandwidth, and a soft bandwidth switching block with an input coupled to the multiple mode speech decoder and an output, said soft bandwidth switching block being arranged to gradually change the bandwidth of a speech signal received from the multiple mode speech decoder as a response to an instruction for changing speech signal bandwidth.<br>21. A method for changing the bandwidth of a speech signal in association with multiple mode encoding or decoding, comprising the steps of: receiving an indication of a change in speech signal bandwidth and gradually changing the bandwidth of a speech signal processed in a multiple mode speech encoding or decoding arrangement as a response to said instruction for changing speech signal bandwidth.</p></layer>
<layer id = "layer39"><p><b>US8239192B2:Transmission error concealment in audio signal</b><br>A composite sporting implement, such as a ball bat or bat barrel, is formed with layers of continuous structural fibers embedded in a binder material having a high melting point. Such a binder does not undergo a chemical conversion process during forming of the ball bat. The layers are shaped into a preform and placed in a mold. Heat and pressure are applied to bring the binder to its melting point and to cause the binder material to flow between adjacent layers. The mold is then cooled below the binder's melting point to solidify the composite structure. A composite sporting implement formed in this manner exhibits excellent shear strength, toughness, and damping qualities.<br><b>Independant Claims</b><br>1) A method of concealing transmission error in a digital audio signal, comprising: generating, in response to detection of missing or erroneous samples in a transmitted signal, synthesized samples by means of at least one short-term prediction operator and at least, for voiced sounds, long-term prediction operators which are estimated by analyzing decoded samples of a past decoded signal, said decoded samples being stored previously when transmitted data corresponding to said past decoded signal are valid; and controlling an energy level of a synthesized signal generated from the synthesized sample by means of a gain that is computed and adapted sample by sample in accordance with a gain adaptation relationship that depends on at least one of the stored decoded samples.</p></layer>
<layer id = "layer40"><p><b>US4216354A:Process for compressing data relative to voice signals and device applying said process</b><br>A power tool includes a housing, a brushless DC motor housed inside the housing, a power supply, a control unit, and an input unit such as a trigger switch actuated by a user. The control unit controls the commutation of the motor through a series of power switches coupled to the power supply. The control unit initiates electronic braking of the motor after occurrence of a condition in the input unit, such as trigger release or reduced speed, indicative of the power tool shut-down. A mechanism is provided to power the control unit for a predetermined amount of time after the detection of the condition from the input unit in order to complete the electronic braking of the motor.<br><b>Independant Claims</b><br>1. Process for compressing a digitally encoded voice signal, said compression resulting from a transcoding operation, characterized in that it includes the following steps: on a recuring basis splitting an epoch of the frequency bandwidth of said voice signal into a low frequency and a high frequency band, digitally coding and requantizing with dynamic bit allocation for each epoch the contents of said low frequency band for each epoch to generate SIGNAL information, processing the contents of said high frequency band for each epoch to generate a set of preemphasised parcor type coefficients (COEF), processing the contents of said high frequency band for each epoch to generate energy information (ENERG), said SIGNAL, COEF and ENERG data generated for each epoch providing the digital data characterizing the compressed voice signal.<br>3. Process for transcoding a sampled and digitalized voice signal, characterized in that it includes the following steps: splitting the voice signal into blocks of samples; splitting the frequency band of said voice signal into a low frequency band and a high frequency band, coding the information of said low frequency band by splitting the band thereof into several sub-bands and by requantizing each of said sub-bands with a bit rate determined for each block of samples in accordance with the energy contained in said sub-band, said coding of the whole low frequency band supplying SIGNAL information, processing the contents of said high frequency band to generate a set of preemphasized parcor type coefficients (COEF) for each block of samples being processed, determining an energy information (ENERG) about the high frequency portion of the bandwidth of the signal to be compressed considered by blocks, and multiplexing the said SIGNAL, COEF and ENERG data on a transmission line.<br>4. A device for digitally compressing a voice signal, characterized in that it includes: an input, first means for applying to said input the samples of a telephone band of the voice signal taken by blocks of constant length, second means connected to said input for receiving and splitting the applied signal bandwidth into a high frequency band and a low frequency band, third means responsive to the information of said high frequency band and generating the preemphasized parcor type coefficients (COEF) of the signal it contains, periodic resampling means receiving the information of said low band, submitting it to a periodic resampling operation and quantizing it by splitting it into sub-bands and dynamically adapting the bit rate assigned to the quantization of each sub-band in accordance with the energy contained in said sub-band, so as to generate a SIGNAL information, means for determining the energy of the high frequency band connected to said input and to said periodic resampling means and generating information ENERG, means receiving said information COEF, SIGNAL and ENERG for multiplexing them on a transmission line.<br>11. A data compression process for compressing a voice signal extending over the telephone bandwidth, which has been sampled at a first given rate and quantized with a relatively high number of bits, said process including the following steps: splitting the frequency bandwidth of said sampled and quantized voice signal into a low frequency bandwidth and a high frequency bandwidth; periodically resampling said low frequency bandwidth at a rate lower than said first given rate; splitting the resampled low frequency bandwidth into p sub-bands; subjecting each of said p sub-bands to an adaptive sub-band block requantizing operation using a quantizing step dynamically adapted to the sub-band energy contained in said each sub-band; collecting the requantized information over the p sub-bands into a SIGNAL data information; measuring and quantizing the energy contained in said high frequency bandwidth for deriving ENERG data; processing the information contained in said telephone bandwidth for deriving COEF data representing preemphasized parcor type coefficients; and, multiplexing said SIGNAL, COEF and ENERG data.<br>12. A data compression process for compressing a voice signal extending over the telephone bandwidth, sampled at a first given rate and quantized with a relatively high number of bits, said process including the following steps: splitting the frequency bandwith of said sampled and quantized voice signal into a low frequency bandwidth and a high frequency bandwidth; periodically resampling said low frequency bandwith at a rate lower than said first given rate; splitting the resampled low frequency bandwidth into p sub-bands; subjecting each of said p sub-bands to an adaptive sub-band block requantizing operation using a quantizing step dynamically adapted to the sub-band energy contained in said each sub-band; collecting the requantized information over the p sub-bands into a SIGNAL data information; measuring and quantizing the energy contained in said high frequency bandwidth for deriving ENERG data; processing the information contained in said high frequency bandwidth for deriving COEF data representing preemphasized parcor type coefficients; and, multiplexing said SIGNAL, COEF and ENERG data.<br>15. A device for digitally compressing a voice signal extending over the telephone frequency bandwidth, said signal being sampled at a first given rate and quantized with a relatively high number of bits, said device including: filtering means for receiving said sampled and quantized voice signal and providing the high frequency components of said voice signal at an output thereof and the low frequency components of said voice signal at another output thereof; means for determining preemphasized parcor type coefficients receiving said low frequency components of said voice signal and providing preemphasized parcor type coefficients; first requantizing means for receiving said preemphasized parcor type coefficients and providing COEF data; periodic resampling means for receiving said high frequency components of said voice signal and for periodically resampling said high frequency components of said voice signal; adaptive sub-band block requentizing means for receiving the periodically resampled high frequency components of said voice signal and providing SIGNAL data; high band energy measuring means for receiving said high frequency components of said voice signal and providing information relative to the energy of said high frequency components of said voice signal; second requantizing means for receiving said information relative to the energy of said high frequency components of said voice signal and providing ENERG data; and multiplexing means for multiplexing said COEF, SIGNAL and ENERG data over a single output channel.</p></layer>
<layer id = "layer41"><p><b>US5845244A:Adapting noise masking level in analysis-by-synthesis employing perceptual weighting</b><br>A mobile communication network system (<b>1</b>) is disclosed. The network system comprises a transport network (<b>30</b>) including a plurality of routers (<b>31</b>), and a network control apparatus (<b>20</b>) for controlling mobility of a mobile node (<b>40</b>, MN<b>1</b>), characterized in that the network control apparatus (<b>20</b>) comprises a mobility managing unit (LRM<b>1</b>) for managing information (CDT) of a correspondent node (<b>41</b>, MN<b>2</b>) communicating with the mobile node (<b>40</b>, MN<b>1</b>); the mobility managing unit (LRM<b>1</b>) comprises a boundary router detecting unit for detecting that the mobile node (MN<b>1</b>) moves and reaches a boundary of a router (AR<b>2</b>) managed by the mobility managing unit (LRM<b>1</b>) itself; and a correspondent node information forwarding unit for forwarding the information (CDT) of the correspondent node (MN<b>2</b>) to a neighbor mobility managing unit (LRM<b>2</b>) having a similar structure, when it is detected that the mobile node (MN<b>1</b>) reaches a boundary of a router (AR<b>2</b>) managed by the mobility managing unit (LRM<b>1</b>) itself.<br><b>Independant Claims</b><br>1. Analysis-by-synthesis speech coding method, comprising the following steps: linear prediction analysis of order p of a speech signal digitized as successive frames in order to determine parameters defining a short-term synthesis filter ; determination of excitation parameters defining an excitation signal to be applied to the short-term synthesis filter in order to produce a synthetic signal representative of the speech signal, some at least of the excitation parameters being determined by minimizing the energy of an error signal resulting from a filtering of a difference between the speech signal and the synthetic signal by at least one perceptual weighting filter having a transfer function of the form W(z)=A(z/.sub..gamma..sub.1)/A(z/.gamma..sub.2) where ##EQU12## the coefficients a.sub.i being linear prediction coefficients obtained in the linear prediction analysis step, and .gamma..sub.1 and .gamma..sub.2 denoting spectral expansion coefficients such that 0.ltoreq..gamma..sub.2 .ltoreq..gamma..sub.1 .ltoreq.1; and production of quantization values of the parameters defining the short-term synthesis filter and of the excitation parameters, wherein the value of at least one of the spectral expansion coefficients is adapted on the basis of spectral parameters obtained in the linear prediction analysis step.</p></layer>
<layer id = "layer42"><p><b>US5812965A:Process and device for creating comfort noise in a digital speech transmission system</b><br><b>Independant Claims</b><br>1. A process for creating comfort noise in a system for the digital transmission of discontinuous speech, in which the coded speech signal is transmitted during an active period, during which active frames are transmitted, each active period being followed by an inactive period, during which at least inactive frames are transmitted, wherein said process consists, at the sending end, on detecting an inactive period, in: generating and transmitting a silence descriptor frame, consisting of a set of coded parameters describing the comfort noise, said silence descriptor frame constituting a first silence descriptor frame of said inactive period following said active period; and for every successive current inactive frame of said inactive period: analysing and storing the frequency spectrum of said current inactive frame; comparing the frequency spectrum of said current inactive frame with a reference frequency spectrum, and upon criterion of identity of the reference and current inactive frame frequency spectra: deferring any transmission, especially that of a new silence descriptor frame during said current inactive frame, and upon criterion of absence of identity of said reference and current inactive frame frequency spectra: generating and transmitting a new silence descriptor frame during said current inactive frame, thereby allowing to reduce the transmission rate of the comfort noise to that of merely the silence descriptor frames whose frequency spectrum is different from said reference spectrum estimated during the preceding silence descriptor frame.<br>4. A process for synthesizing an excitation signal used in a comfort noise generator in a system for the digital transmission of discontinuous speech comprising a speech coder of predictive type, based on a specified number of excitation samples emanating from past frames and from long-term prediction data LTP delivered by this speech coder, wherein said process consists: in subdividing each current inactive frame, including N samples, into N/L blocks each including N/L successive samples; in randomly drawing the codes of the parameters of the long-term excitation, by using said excitation samples emanating from past frames, in order to obtain L long-term prediction excitation samples e.sub.LTP (n); in randomly drawing codes of an innovation waveform, in order to obtain L samples u(n) of said waveform; in determining a gain value .beta. from the quantization index of said gain; in determining, by updating the samples of each current block, an excitation signal Exc, said excitation signal being defined for said current frame as a linear combination, based on the gain value .beta., of the long-term excitation e.sub.LTP (n) and of said innovation waveform u(n).<br>7. A device for creating comfort noise in a system for the digital transmission of discontinuous speech, in which the speech signal is transmitted during an active period, during which active frames are transmitted, each active period being followed by an inactive period, during which at least inactive frames are transmitted, said device including, at the sending end, constituting a comfort noise generator: means for creating and conditionally transmitting, upon detecting an inactive period, a silence descriptor frame, consisting of a set of coded parameters describing the comfort noise, said silence descriptor frame constituting a first silence descriptor frame of said inactive period following said active period; means for analysing and storing the frequency spectrum of every successive current inactive frame of said inactive period; means for comparing the frequency spectrum of said current inactive frame with a reference frequency spectrum delivering a specified command signal upon criterion of identity and of absence of identity of said reference and current frame frequency spectra; means for controlling the disabling and enabling respectively of the transmission of a new silence descriptor frame during said current inactive frame, receiving said specified command signal delivered by said comparing means, so as to defer any transmission especially that of a new silence descriptor frame upon the identity of said reference and current frame frequency spectra, and to carry out the transmission of a new silence descriptor frame upon the absence of identity of said reference and current frame frequency spectra, the rate of transmission of the comfort noise thus being reduced to that of merely the silence descriptor frames whose frequency spectrum is different from the reference spectrum estimated during a preceding silence descriptor frame.<br>9. A process for creating a silence descriptor frame in order to generate comfort noise in a system for the transmission of discontinuous speech in which the coded speech signal is transmitted during an active period, said transmission consisting thus of successive active periods during which coded speech signal frames are transmitted, interspersed with inactive periods during which no speech signal frame is transmitted, said inactive periods consisting thus of inactive frames, including at least one silence descriptor frame forming an initial one of said inactive frames and successive inactive frames preceding a current inactive frame, for which transmission of a new silence descriptor frame can take place, wherein, in order to create each silence descriptor frame, said process comprises the steps of: measuring local stationarity of a frequency spectrum of a plurality of said successive inactive frames preceding said current inactive frame; determining a mean frequency spectrum of said successive inactive frames in order to establish a past mean frequency spectrum and upon criterion of identity and of absence of identity of a past mean frequency spectrum and of the frequency spectrum of said current inactive frame; and selecting, in order to compute said silence descriptor frame, said past mean frequency spectrum and said spectrum of said current inactive frame respectively, thereby allowing to estimate a silence spectrum for every silence descriptor frame by taking into account the fact that said current inactive frame belongs either to a locally stationary spectral zone or to a non-stationary spectral zone.<br>10. A device generating a comfort noise in a system for the digital transmission of discontinuous speech, in which a coded speech signal is transmitting during an active period, during which active coded speech frames are transmitted, each active period being followed by an inactive period, during which at least silence descriptor frames are transmitted at the sending end, with said silence descriptor frames being transmitted on detecting an inactive period by generating and transmitting a silence descriptor frame, consisting of a set of coded parameters describing the comfort noise, said silence descriptor frame constituting a first silence descriptor frame of said inactive period following said active period, and for every successive current inactive frame of said inactive period, analyzing and storing the frequency spectrum of said current inactive frame, comparing the frequency spectrum of said current inactive frame with a reference frequency spectrum, and upon criterion of identity of the reference and current inactive frame frequency spectra, deferring any transmission, including that of a new silence descriptor frame, during said current inactive frame, and upon criterion of absence of identity of said reference and current inactive frame frequency spectra, generating a transmitting a new silence descriptor frame during said current inactive frame, so as to reduce the transmission rate of the comfort noise to that of merely the silence descriptor frames whose frequency spectrum is different from said reference spectrum estimated during the preceding silence descriptor frame, wherein said device comprises, at a receiving end, means for decoding in each successive silence descriptor frame the set of coded parameters describing the comfort noise, said means receiving a cue relating to the type of current frame processed, a coded silence descriptor frame signal and, from a speech decoder, a management signal ensuring synchronous operation with said speech decoder, in order to generate decoded parameters including a signal describing the comfort noise relating to said current frame, said decoding means being interconnected with a speech signal decoder receiving, on the one hand, said coded speech frames, and, on the other hand, said signal describing the comfort noise relating to said current frame, said speech decoder delivering by synthesis a speech signal or a synthesized comfort noise.</p></layer>
<layer id = "layer43"><p><b>US5787390A:Method for linear predictive analysis of an audiofrequency signal, and method for coding and decoding an audiofrequency signal including application thereof</b><br>A joint sintered high-temperature superconductive ceramic article is obtained by joining two sintered high-temperature superconductive ceramic masses formed of oriented crystal grains in such a manner that the directions of grain-orientation are different across the interface of union and pressing the joined ceramic masses against each other perpendicularly to the interface of union and, at the same time, heating them.<br><b>Independant Claims</b><br>1. Method for linear predictive analysis of an audiofrequency signal, in order to determine spectral parameters dependent on a short-term spectrum of the audiofrequency signal, the method comprising q successive prediction stages, q being an integer greater than 1, wherein each prediction stage p(1.ltoreq.p.ltoreq.q) includes determining parameters representing a number Mp, predefined for each stage p, of linear prediction coefficients a.sub.1.sup.p, . . . , a.sub.Mp.sup.p of an input signal of said stage, wherein the audiofrequency signal to be analysed constitutes the input signal of stage 1, and wherein, for any integer p such that 1.ltoreq.p.ltoreq.q, the input signal of stage p+1 consists of the input signal of stage p filtered by a filter with transfer function ##EQU33##<br>3. Method for coding an audiofrequency signal, comprising the following steps: linear predictive analysis of the audiofrequency signal digitized in successive frames in order to determine parameters defining a short-term synthesis filter; determination of excitation parameters defining an excitation signal to be applied to the short-term synthesis filter in order to produce a synthetic signal representing the audiofrequency signal; and production of quantization values of the parameters defining the short-term synthesis filter and of the excitation parameters, wherein the linear predictive analysis is a process with q successive stages, q being an integer greater than 1, wherein each prediction stage p(1.ltoreq.p.ltoreq.q) includes determining parameters representing a number Mp, predefined for each stage p, of linear prediction coefficients a.sub.1.sup.p, . . . , a.sub.Mp.sup.p of an input signal of said stage, wherein the audiofrequency signal to be coded constitutes the input signal of stage 1, wherein, for any integer p such that 1.ltoreq.p.ltoreq.q, the input signal of stage p+1 consists of the input signal of stage p filtered by a filter with transfer function ##EQU34## and wherein the short-term synthesis filter has a transfer function of the form 1/A(z) with ##EQU35##<br>7. Method for decoding a bit stream in order to construct an audiofrequency signal coded by said bit stream, comprising the steps of: receiving quantization values of parameters defining a short-term synthesis filter and of excitation parameters, wherein the parameters defining the synthesis filter represent a number q greater than 1 of sets of linear prediction coefficients, each set p(1.ltoreq.p.ltoreq.q) including a predefined number Mp of coefficients; producing an excitation signal on the basis of the quantization values of the excitation parameters; and producing a synthetic audiofrequency signal by filtering the excitation filter with a synthesis filter having a transfer function of the form 1/A(z) with ##EQU37## where the coefficients a.sub.1.sup.p, . . . , a.sub.Mp.sup.p correspond to the p-th set of linear prediction coefficients for 1.ltoreq.p.ltoreq.q.<br>10. Method for coding a first audiofrequency signal digitized in successive frames, comprising the following steps: linear predictive analysis of a second audiofrequency signal in order to determine parameters defining a short-term synthesis filter; determination of excitation parameters defining an excitation signal to be applied to the short-term synthesis filter in order to produce a synthetic signal representing the first audiofrequency signal, said synthetic signal constituting said second audiofrequency signal for at least one subsequent frame; and production of quantization values of the excitation parameters, wherein the linear predictive analysis is a process with q successive stages, q being an integer greater than 1, wherein each prediction stage p(1.ltoreq.p.ltoreq.q) includes determining parameters representing a number Mp, predefined for each stage p, of linear prediction coefficients a.sub.1.sup.p, . . . , a.sub.Mp.sup.p of an input signal of said stage, wherein the second audiofrequency signal constitutes the input signal of stage 1, wherein, for any integer p such that 1.ltoreq.p.ltoreq.q, the input signal of stage p+1 consists of the input signal of stage p filtered by a filter with transfer function ##EQU40## and wherein the short-term synthesis filter has a transfer function of the form 1/A(z) with ##EQU41##<br>14. Method for decoding a bit stream in order to construct in successive frames an audiofrequency signal coded by said bit stream, comprising the steps of: receiving quantization values of excitation parameters; producing an excitation signal on the basis of the quantization values of the excitation parameters; producing a synthetic audiofrequency signal by filtering the excitation signal with a short-term synthesis filter; and performing a linear predictive analysis of the synthetic signal in order to obtain coefficients of the short-term synthesis filter for at least one subsequent frame, wherein the linear predictive analysis is a process with q successive stages, q being an integer greater than 1, wherein each prediction stage p(1.ltoreq.p.ltoreq.q) includes determining parameters representing a number Mp, predefined for each stage p, of linear prediction coefficients a.sub.1.sup.p, . . . , a.sub.Mp.sup.p of an input signal of said stage, wherein the synthetic signal constitutes the input signal of stage 1, wherein, for any integer p such that 1.ltoreq.p.ltoreq.q, the input signal of stage p+1 consists of the input signal of stage p filtered by a filter with transfer function ##EQU43## and wherein the short-term synthesis filter has a transfer function of the form 1/A(z) with ##EQU44##<br>17. Method for coding a first audiofrequency signal digitized in successive frames, comprising the following steps: linear predictive analysis of the first audiofrequency signal in order to determine parameters defining a first component of a short-term synthesis filter; determination of excitation parameters defining an excitation signal to be applied to the short-term synthesis filter in order to produce a synthetic signal representing the first audiofrequency signal; production of quantization values of the parameters defining the first component of the short-term synthesis filter and of the excitation parameters; filtering of the synthetic signal with a filter with transfer function corresponding to the inverse of the transfer function of the first component of the short-term synthesis filter; and linear predictive analysis of the filtered synthetic signal in order to obtain coefficients of a second component of the short-term synthesis filter for at least one subsequent frame, wherein the linear predictive analysis of the first audiofrequency signal is a process with q.sub.F successive stages, q.sub.F being an integer at least equal to 1, wherein each prediction stage p(1.ltoreq.p.ltoreq.q.sub.F) of said process with q.sub.F stages includes determining parameters representing a number MFp, predefined for each stage p, of linear prediction coefficients A.sub.1.sup.F,p, . . . , a.sub.MFp.sup.F,p of an input signal of said stage, wherein the first audiofrequency signal constitutes the input signal of stage 1 of the process with q.sub.F stages, wherein, for any integer p such that 1.ltoreq.p<q.sub.F, the input signal of stage p+1 of the process with q.sub.F stages consists of the input signal of stage p of the process with q.sub.F stages filtered by a filter with transfer function ##EQU46## wherein the first component of the short-term synthesis filter has a transfer function of the form 1/A.sup.F (z) with ##EQU47## wherein the linear predictive analysis of the filtered synthetic signal is a process with q.sub.B successive stages, q.sub.B being an integer at least equal to 1, wherein each prediction stage p(1.ltoreq.p.ltoreq.q.sub.B) of said process with q.sub.B stages includes determining parameters representing a number MBp, predefined for each stage p, of linear prediction coefficients a.sub.1.sup.b,p, . . . , a.sub.MBp.sup.B,p of an input signal of said stage, wherein the filtered synthetic signal constitutes the input signal of stage 1 of the process with q.sub.B stages, wherein, for any integer p such that 1.ltoreq.p<q.sub.B, the input signal of stage p+1 of the process with q.sub.B stages consists of the input signal of stage p of the process with q.sub.B stages filtered by a filter with transfer function ##EQU48## wherein the second component of the short-term synthesis filter has a transfer function of the form 1/A.sup.B (z) with ##EQU49## and wherein the short-term synthesis filter has a transfer function of the form 1/A(z) with A(z)=A.sup.F (z).A.sup.B (z).<br>20. Method for decoding a bit stream in order to construct in successive frames an audiofrequency signal coded by said bit stream, comprising the steps of: receiving quantization values of parameters defining a first component of a short-term synthesis filter and of excitation parameters, wherein the parameters defining the first component of the short-term synthesis filter represent a number q.sub.F at least equal to 1 of sets of linear prediction coefficients a.sub.1.sup.F,p, . . . a.sub.MFp.sup.F,p for 1.ltoreq.p.ltoreq.q.sub.F, each set p including a predefined number MFp of coefficients, wherein the first component of the short-term synthesis filter has a transfer function of the form 1/A.sup.F (z) with ##EQU51## producing an excitation signal on the basis of the quantization values of the excitation parameters; producing a synthetic audiofrequency signal by filtering the excitation signal with a short-term synthesis filter having a transfer function 1/A(z) with A(z)=A.sup.F (z).A.sup.B (z), where 1/A.sup.B (z) represents a transfer function of a second component of the short-term synthesis filter; filtering the synthetic signal with a filter with transfer function A.sup.F (z); and performing a linear predictive analysis of the filtered synthetic signal in order to obtain coefficients of the second component of the short-term synthesis filter for at least one subsequent frame, wherein the linear predictive analysis of the filtered synthetic signal is a process with q.sub.B successive stages, q.sub.B being an integer at least equal to 1, wherein each prediction stage p(1.ltoreq.p.ltoreq.q.sub.B) includes determining parameters representing a number MBp, predefined for each stage p, of linear prediction coefficients a.sub.1.sup.B,p, . . . , a.sub.MBp.sup.B,p of an input signal of the said stage, wherein the filtered synthetic signal constitutes the input signal of stage 1, wherein, for any integer p such that 1.ltoreq.p<q.sub.B, the input signal of stage p+1 consists of the input signal of stage p filtered by a filter with transfer function ##EQU52## and wherein the second component of the short-term synthesis filter has a transfer function of the form 1/A.sup.B (z) with ##EQU53##</p></layer>
<layer id = "layer44"><p><b>US6327562B1:Method and device for coding an audio signal by “forward” and “backward” LPC analysis</b><br>A driving apparatus for a movable member of an automobile comprises a housing, a dram for driving the movable member, the dram being rotatably supported on the housing, and a clutch for selectively transmitting a driving torque to the dram, wherein the clutch is accommodated in a space of the dram.<br><b>Independant Claims</b><br>1) A method for encoding a digital audio signal by dual analysis according to a choice criterion of LPC “forward” and “backward” analysis respectively into a transmitted encoded signal consisting of LPC filtering parameters accompanied by analysis decision information, and into a residue encoding signal, not transmitted, said digital audio signal being subdivided into frames, a succession of blocks of a specified number of samples, the encoding of said digital audio signal being carried out on this signal through a “forward” LPC filtering for non-stationary zones respectively on a synthesis signal, obtained from said residue encoding signal, through a “backward” LPC filtering for stationary zones, wherein said choice criterion consists, on each current block of said succession of current blocks constituting a current frame: in defining the degree of stationarity of the digital audio signal according to a stationarity parameter, the value of which lies between a maximum stationarity value and a minimum stationarity value; in establishing, from said stationarity parameter, an analysis choice value, from a decision function; in applying said analysis choice value to the “forward” LPC filtering so as to carry out the encoding of said digital audio signal by “forward” LPC filtering for non-stationary zones on said digital audio signal, and by “backward” LPC filtering respectively for stationary zones on said synthesis signal, which makes it possible to favor the maintenance of the digital audio signal in one of the “forward” and “backward” filtering modes respectively in relation to the degree of stationarity and to limit the amount of switching from one to the other and vice versa of the filtering modes.<br>12) An encoding device for a digital audio signal by dual analysis according to a choice criterion of “forward” and “backward” LPC analysis respectively into a transmitted encoded signal, said digital signal being subdivided into frames constituted by successive blocks comprising a specified number of samples, said encoding device comprising a “forward” LPC analysis filter and a “backward” LPC filter enabling delivery of a transmitted encoded signal consisting of LPC filtering parameters accompanied by an analysis decision indication and a means of encoding an encoding residue signal, not transmitted, enabling generation of a synthesis residue signal, the encoding of said digital audio signal being carried out on this digital audio signal from the “forward” LPC filter for non-stationary zones and on this synthesis signal, from the “backward” LPC filter respectively for stationary zones, wherein said encoding device comprises in addition, for each current LPC block; calculation means of the degree of stationarity of said digital audio signal, according to a stationarity parameter the value of which is between a minimum stationarity value and a maximum stationarity value; setting means, from a stationarity parameter, of a decision function enabling an LPC analysis choice value to be set; discrimination means of LPC analysis receiving said analysis choice value and enabling delivery, for said LPC current block, of the value of the “backward” and “forward” LPC filtering parameters respectively as a function of said analysis choice value; adaptive filtering means as a function of the degree of stationarity receiving said digital audio signal and the value of the “forward” and “backward” LPC filtering parameters respectively as a function of said analysis choice value and delivering the encoding residue signal to said encoding means of the encoding residue signal, which makes it possible to encode said digital audio signal and to favor the maintenance of said digital audio signal in one of the “forward” and “backward” filtering modes respectively in relation to the degree of stationarity of said digital signal and to limit the amount of switching from one to the other and vice versa of the filtering modes.<br>14) A decoding device of a digital audio signal encoded by dual analysis according to a choice criterion of “forward” and “backward” LPC analysis respectively, into a transmitted encoded signal consisting of LPC filtering parameters accompanied by an analysis decision indication, wherein that said transmitted encoded signal, consisting for each LPC analysis block of said analysis choice value and corresponding for the LPC analysis block considered to “forward” LPC analysis in “forward” LPC filtering parameters, said decoding device comprises at least: synthesis means for the filtering residue signal receiving said encoding parameters of the LPC residue and delivering a synthesis residue signal, reverse filtering adaptive means as a function of the degree of stationarity, receiving the synthesis residue signal and enabling generation of a synthesis signal representative of the digital audio signal and constituting the decoded signal, “backward” LPC analysis means receiving said synthesis signal and enabling generation of “backward” LPC filtering parameters, discriminating means between “forward” LPC analysis and “backward” LPC analysis respectively receiving, on the one hand, for discrimination control said analysis choice value and, on the other hand, the “forward” LPC filtering parameters and the “backward” LPC filtering parameters and enabling delivery as a function of said analysis choice value, of either “forward” LPC filtering parameters, or “backward” LPC filtering parameters to said reverse filtering adaptive means as a function of the degree of stationarity.</p></layer>
<layer id = "layer45"><p><b>US5140638A:Speech coding system and a method of encoding speech</b><br><b>Independant Claims</b><br>1. A speech coding system comprising; means for filtering digitised speech samples to form perceptually weighted speech signal samples, a one-dimensional codebook, means for filtering entries read-out from the codebook, and means for comparing the filtered codebook entries with the perceptually weighted speech signals to obtain a codebook index which gives the minimum perceptually weighted error when the speech is resynthesised.<br>11. A method of encoding speech which comprises: filtering digitised speech samples to produce perceptually weighted speech samples, selecting entries from a 1-dimensional code book and filtering same to form a filtered codebook, and comparing the perceptually weighted speech samples with entries from the filtered codebook to obtain a codebook index which gives the minimum perceptually weighted error when the speech is resynthesised.<br>20. A method of deriving speech comprising: forming a filtered codebook by filtering a one dimensional codebook using a filter whose coefficients are specified in an input signal, selecting a predetermined sequence specified by a codebook index in the input signal, adjusting the amplitude of the selected predetermined sequence in response to a gain signal contained in the input signal, restoring the pitch of the selected predetermined sequence in response to pitch predictor index and gain signals contained in the input signal, and applying the pitch restored sequence to deweighting and inverse synthesis filters to produce a speech signal.<br>30. A CELP-type speech coding system comprising: means for deriving digitized speech signal samples, an analysis filter having a transfer function A(z) and coupled to an output of said speech signal deriving means, a first perceptually weighted synthesis filter having a transfer function 1/A(z/.gamma.) and coupled to an output of the analysis filter, a linear predictive coder coupled to an output of said speech signal deriving means for calculating filter coefficients a.sub.i, a one-dimensional codebook, means including a second perceptually weighted synthesis filter with a transfer function 1/A(z/.gamma.) coupled to an output of the one-dimensional codebook for filtering entries read-out of said codebook to derive filtered codebook entries, means for supplying the coefficients a.sub.i of said linear predictive coder to said analysis filter and to said first and second perceptually weighted synthesis filters, and means for comparing the filtered codebook entries with the perceptually weighted speech signals supplied by said first perceptually weighted synthesis filter thereby to derive a codebook index which gives the minimum perceptually weighted error for a resynthesized speech sequence.</p></layer>
<layer id = "layer46"><p><b>US6629068B1:Calculating a postfilter frequency response for filtering digitally processed speech</b><br>By this invention, low calorie fat compositions comprising the use of acylated glycerides are provided. Of particular interest is the use of triglyceride compositions having a at least one acylated fatty acid. Preferably, the acylated fatty acid has a melting temperature above 40° C. The acylated glyceride compositions find use as low calorie fat ingredients in food compositions. The low calorie fat compositions of the present invention demonstrate a caloric value of less than 6.5 kcal/g. Such low calorie fat compositions find use in the preparation of food compositions wherein at least a portion of the fat ingredients have been replaced with a acylated glyceride compositions of the present invention.<br><b>Independant Claims</b><br>1) A method for calculating a postfilter frequency response for filtering digitally processed speech, the method comprising identifying at least one formant of a speech spectrum of the digitally processed speech; and normalising points of the speech spectrum with respect to the magnitude of an identified formant, wherein the points of the speech spectrum are normalised according to a function of the form Rpost⁢(k)=(R⁢(k)Rform⁢(k))β where R(k) is the amplitude of the spectrum at a frequency k and Rform(k) is the amplitude of the spectrum at a frequency k which corresponds to an identified formant frequency and β controls the degree of postfiltering, and β=k-kmaxkmin-kmax⁢o⁢ ⁢γ⁢ ⁢β=kmin-kkmin-kmax⁢o⁢ ⁢γ⁢ ⁢for ⁢kmaxk≤kmin⁢ ⁢and⁢ ⁢β=kmax-kkmax-kmin⁢o⁢ ⁢γ⁢ ⁢forkmink≤kmax⁢ <br>3) A postfiltering method for enhancing a digitally processed speech signal, the method comprising obtaining a speech spectrum of the digitally processed signal; identifying at least one formant of the speech spectrum; normalising points of the speech spectrum with the magnitude of an identified formant to produce a postfilter frequency responses filtering the speech spectrum of the digitally processed signal with the postfilter frequency response, wherein the points of the speech spectrum are normalised according to a function of the form Rpost⁢(k)=(R⁢(k)Rform⁢(k))β where R(k) is the amplitude of the spectrum at a frequency k and Rform(k) is the amplitude of the spectrum at a frequency k which corresponds to an identified formant frequency and β controls the degree of postfiltering, and β=k-kmaxkmin-kmax⁢o⁢ ⁢γ⁢ ⁢β=kmin-kkmin-kmax⁢o⁢ ⁢γ⁢ ⁢for ⁢kmaxk≤kmin⁢ ⁢and⁢ ⁢β=kmax-kkmax-kmin⁢o⁢ ⁢γ⁢ ⁢forkmink≤kmax⁢  where k is a point in frequency, kmin is the frequency of a spectral valley, kmax is the frequency of a formant and γ controls the degree of postfiltering.<br>5) A postfilter comprising identifying means for identifying at least one formant of a digitally processed speech spectrum; normalising means for normalising points of the speech spectrum with respect to the magnitude of an identified formant to produce a postfilter frequency response; and means for filtering the digitally processed speech spectrum with the postfilter frequency response, wherein the normalising means normalises points of the speech spectrum according to a function of the form Rpost⁢(k)=(R⁢(k)Rform⁢(k))β where R(k) is the amplitude of the spectrum at a frequency k and Rform(k) is the amplitude of the spectrum at a frequency k which corresponds to an identified formant frequency and β controls the degree of postfiltering, and β=k-kmaxkmin-kmax⁢o⁢ ⁢γ⁢ ⁢β=kmin-kkmin-kmax⁢o⁢ ⁢γ⁢ ⁢for ⁢kmaxk≤kmin⁢ ⁢and⁢ ⁢β=kmax-kkmax-kmin⁢o⁢ ⁢γ⁢ ⁢forkmink≤kmax⁢  where k is a point in frequency, kmin is the frequency of a spectral valley, kmax is the frequency of a formant and γ controls the degree of postfiltering.<br>7) A radiotelephone comprising a postfilter, the postfilter having identifying means for identifying at least one formant of a digitally processed speech spectrum; normalising means for normalising points of the speech spectrum with respect to the magnitude of an identified formant to produce a postfilter frequency response; and means for filtering the digitally processed speech spectrum with the postfilter frequency response, wherein the normalising means normalises points of the speech spectrum according to a function of the form Rpost⁢(k)=(R⁢(k)Rform⁢(k))β where R(k) is the amplitude of the spectrum at a frequency k and Rform(k) is the amplitude of the spectrum at a frequency k which corresponds to an identified formant frequency and β controls the degree of postfiltering, and β=kmin-kkmin-kmax&CenterDot;γ⁢ ⁢for⁢ ⁢kmaxk≤kmin⁢ ⁢and⁢ ⁢β=kmin-kkmin-kmax&CenterDot;γ⁢ ⁢for⁢ ⁢kmink≤kmax where k is a point in frequency, kmin is the frequency of a spectral valley, kmax is the frequency of a formant and γ controls the degree of postfiltering.</p></layer>
<layer id = "layer47"><p><b>US6944510B1:Audio signal time scale modification</b><br>A guest operated front desk processing station is all contained in an upright stand alone housing. The housing contains a touch screen and keyboard for guest inputting information, and a signature pad in an upper portion. The housing front face contains a credit card swipe device for scanning a credit, debit or brand card, a slot for dispensing a receipt from a printer inside the housing and a key slot for dispensing a key card generated by a key making device within the housing. The housing front face also contains a slot for accepting various currency denominations and a slot for dispensing currency change. The processing station is connected by a network data cable to a Property Management System.<br><b>Independant Claims</b><br>1) A method of time-scale modification processing of frame-based digital audio signals wherein, for each frame of predetermined duration comprising: the original frame of digital audio is copied; the original and copied frames are partly overlapped to give a desired new duration to within a predetermined tolerance; the extent of overlap is adjusted within the predetermined tolerance by reference to a cross correlation determination of the best match between the overlapping portions of the original and copied frame; and a new audio frame is generated from the non-overlapping portions of the original and copied frame and by cross-fading between the overlapping portions; characterised in that a profiling procedure is applied to the overlapping portions of the original and copied frame prior to cross correlation, which profiling procedure reduces the specification of the respective audio frame portions to respective finite arrays of containing less than 128 values, and the cross correlation is then performed in relation only to the pair of finite arrays of values.<br>11) A method of time-scale modification processing of frame-based digital audio signals wherein, for each frame of predetermined duration comprising: copying an original frame of digital audio; overlapping the original and copied frames by a predetermined amount; adjusting overlapping portions of the original and copied frames in accordance with a cross correlation determination of the best match between the overlapping portions of the original and copied frame; and generating a new audio frame from the non-overlapping portions of the original and copied frame and by cross-fading between the overlapping portions; characterised in that a profiling procedure is applied to the overlapping portions of the original and copied frame prior to cross correlation, which profiling procedure reduces the specification of the respective audio frame portions to a pair of respective finite arrays of containing less than 128 values.</p></layer>
<layer id = "layer48"><p><b>US6507820B1:Speech band sampling rate expansion</b><br>A splicing tape for splicing a leading edge portion of the outer turn of a roll of sheet material to a second sheet material. A typical application is to join the outer turn of a replacement roll of paper to the end of depleted roll of paper while the paper remains in motion through some handling apparatus. The splicing tape comprises a first tape component, and second tape component, and a layer of adhesive separably joining the first and second tape components. The first tape component includes a first backing, a first layer of adhesive on a first surface of the first backing, and a first barrier layer on a second surface of the first backing. The second tape component includes a second backing, a second layer of adhesive on a first surface of the second backing, and a second barrier layer on a second surface of the second backing. Alternatively, the splicing tape may include only one barrier layer between the joining adhesive layer and one of the first and second backings. The layer of adhesive separably joins the first and second tape components at their respective barrier layers. Also disclosed are methods of manufacture and methods of use of the inventive splicing tape.<br><b>Independant Claims</b><br>1) A method to expand the bandwidth of an input speech signal, comprising the steps of converting an input speech signal sampled at a sampling rate N to a signal having a sample rate of 2N by outputting successive samples of the input signal as each alternate sample of the output signal and by outputting zero as the remaining alternate samples of the output signal; and filtering the signal output from the conversion means so as to shape the spectrum of that signal for frequencies between ¼ and ½ of its sample rate, to form a wide-band speech signal.<br>8) A digital signal processor to expand the bandwidth of an input speech signal, comprising: means to convert an input speech signal sampled at a sampling rate N to an output speech signal having a sample rate of 2N by outputting successive samples of the input signal as each alternate sample of the output signal and by outputting zero as the remaining alternate samples of the output signal; and filter means to shape the spectrum of the signal output from the conversion means for frequencies in the interval between ¼ and 2 of its sample rate, to form a wide-band speech signal.</p></layer>
<layer id = "layer49"><p><b>US5012519A:Noise reduction system</b><br>A composite material is made from a whisker body of silicon carbide whiskers containing not more than 5% by weight of non whisker particles of diameter greater than 150 microns, with a mass of matrix metal infiltrated into the interstices of the whisker body. The matrix metal is selected from the group consisting of aluminum, magnesium, tin, copper, lead, zinc, and their alloys. The bulk density of the silicon carbide whiskers is at least 0.07 gm/cm.sup.3. A method is also disclosed for making this composite material, in which first a quantity of silicon carbide whiskers containing not more than 5% by weight of non whisker particles of diameter greater than 150 microns is formed into a shaped mass with a compressive strength of at least 0.5 kg/cm.sup.2 and with a bulk density of at least 0.07 gm/cm.sup.3, and then this shaped mass is compounded with a quantity of the molten matrix metal by a pressure casting method. This formed mass of silicon carbide whiskers may be bound together by an inorganic binder, whicn may be silica, and whose volume percentage in the shaped mass of silicon carbide whiskers may desirably be less than about 25%.<br><b>Independant Claims</b><br>1. A digital processing method for reducing the noise in noisy speech signals, including the steps of: (a) generating background noise estimates from noisy speech and storing said background noise estimates; (b) generating adaptive current noise estimates from current noisy speech signals and stored background noise estimates; (c) generating current gain estimates from adaptive current noise estimates and past speech estimates; and (d) using current gain estimates and current noisy speech to obtain current speech estimates, wherein said step of using adaptive current noise estimates and past speech estimates to obtain current gain estimates includes the step of limiting the lower limit of the gain estimate to eliminate musical noise, and wherein said step of generating adaptive current noise estimates includes employing results of a speech/no speech decision from information obtained from current signal input to distinguish said noisy speech from background noise.<br>5. A digital processing method for reducing the noise in noisy speech signal, comprising the steps of: (a) generating amplitude estimates from noisy speech; (b) generating residual noise estimates from said amplitude estimates by operation of a voice operated switch; and (c) generating adaptive residual noise estimates from said amplitude estimates when speech is not present; and (d) using said adaptive residual noise estimates for smoothing speech signals.<br>6. A method for reducing the noise in noisy signals containing speech, said method comprising the steps of: (a) generating, from Fourier expansion coefficients of said noisy signals, background noise estimates, and storing said background noise estimates; (b) generating thereafter, from Fourier expansion coefficients of said signals and said stored background noise estimates, adaptive current noise estimates; (c) generating thereafter, from said adaptive current noise estimates and past speech estimates, current gain estimates; and (d) producing thereafter, from said current gain estimates and current digitized noisy signals, current speech estimates, said current speech estimates for use thereafter as past speech estimates, wherein said step (c) includes the step of limiting the lower limit of said gain estimate to eliminate musical noise, and wherein said step (b) includes applying a speech/no speech decision to said noisy signals containing speech to identify said current speech estimates with a signal segment containing speech.<br>7. A method for reducing noise in noisy signals containing speech, said noisy signals being divided into time invariant segments, said method including the steps of: (a) generating, from Fourier expansion coefficients of said segments of said noisy signals, amplitude estimates; (b) thereafter generating, from said amplitude estimates, (i) residual noise estimates from said amplitude estimates where speech is present in a current segment, and (ii) adaptive residual noise estimates where speech is not present in a current segment; and (e) smoothing said noisy signal containing speech with said adaptive residual noise estimates to suppress noise.<br>8. A digital processing method for reducing the noise in noisy speech signals, including the steps of: (a) generating, from Fourier expansion coefficients of segments of said noisy speech signals as amplitude estimates; (b) generating background noise estimates from said amplitude estimates, including employing results of a speech/no speech decision (Y/N) from information obtained from current signal input to distinguish signals containing speech from background noise; (c) generating first signal-to-noise estimates from said background noise estimates and said amplitude estimates (a posteriori SNR); (d) generating decision directed signal-to-noise estimates recursively from said background noise estimates updated on the basis of previous speech amplitude estimates (a priori SNR); (e) generating current gain estimates from said first signal-to-noise estimate and said decision directed signal-to-noise estimates; and (e) using current gain estimates and current noisy speech to obtain current speech amplitude estimates.</p></layer>
<layer id = "layer50"><p><b>US4811398A:Method of and device for speech signal coding and decoding by subband analysis and vector quantization with dynamic bit allocation</b><br>A system for mooring a buoyant case such as a marine mine or other marine vice at a preselected depth below the surface of the water in which the case was launched. After the case has been launched, and made bottom contact, the mooring system utilizes a first piston assembly in conjunction with a corrodible pin to initiate mooring line payout from a buoyant case to an attached anchor. When the preselected mooring depth is reached, a second piston assembly terminates the mooring line payout and the ascent of the case, thereby resulting in mooring of the buoyant case at the preselected depth.<br><b>Independant Claims</b><br>1. A method of speech signal coding and decoding, comprising the following steps for coding: (a) converting a speech signal into a digital form and filtering the digital form of the speech signal by pairs of cascaded digital filters having specular transfer functions with respect to their transition frequencies to split said digital form of the speech signal into the subbands; (b) subdividing the samples of a first of said subbands, at lowest frequencies of said subband into a first sequence of blocks of J samples and subjecting the blocks to a linear prediction inverse filtering operation with vector quantization techniques, and selecting for each block, from a codebook of quantized filter coefficient vectors a.sub.1h (i), a vector a.sub.1hott (i) having index h.sub.1hott (J) and forming the optimal filter thus obtaining samples of residual signal R1(m), m being the progressive sample index; (c) splitting the samples of residual signal R.sub.1 (m) into a second sequence of blocks of K samples (with K submultiple J), and computing for each block a quantized r.m.s. value .gamma..sub.1 (K) by choosing from a quantizer a level of index s.sub.1 (K); (d) extracting from said first subband samples, samples of normalized residual EN.sub.1 (m), each being quantized by choosing a level of index e.sub.1 (m) in a quantizer of a set of quantizers of the first subband having a different number of levels, said normalized residual being obtained by dividing by said quantized r.m.s. values .gamma..sub.1 (K) a residual signal obtained by subtracting from said signal of the first subband a predicted signal P.sub.1 (m-1) obtained by submitting said quantized normalized residual, previously multiplied again by said quantized r.m.s. value .gamma..sub.1 (K), to a linear prediction filtering operation by using said vector of filter coefficients a.sub.1hott (i) forming the optimal filter; (e) subjecting samples of a second subband adjacent to the first subband the operations of steps (b) to (d), thus obtaining vectors of quantized coefficients a.sub.2hott (i) having index h.sub.2ott (J), quantized r.m.s. values .gamma..sub.2 (K) having index s.sub.2 (K), and samples of quantized normalized residual having index e.sub.2 (m); (f) splitting samples of a third subband adjacent to the second subband into said second sequence of blocks and computing for each block a quantized r.m.s. value .gamma..sub.3 (K) by choosing in a quantizer a level of index s.sub.3 (K), each sample of the third subband being then divided by said quantized r.m.s. value .gamma..sub.3 (K) obtaining a normalized value EN.sub.3 (m) which is quantized by choosing a level of index e.sub.3 (m) in a quantizer out of a set of quantizers of the third subband having different number of levels; (g) computing the minimum of a mean total distortion function using each term of quantized r.m.s. values .gamma..sub.1 (K), .gamma..sub.2 (K), .gamma..sub.3 (K), said distortion being introduced with the quantization of subband samples, said function depending on the number of bits used to quantize subband signals, said minimum supplying terms of a number of levels choosing the quantizers out of said sets of subband quantizers; wherein said level indices e.sub.1 (m), e.sub.2 (m), said indices h.sub.1ott (J), h.sub.2ott (J) of linear-prediction optimal filter coefficient vectors, and said indices s.sub.1 (K), s.sub.2 (K), s.sub.3 (K) of quantized r.m.s. values form the speech signal coding; the method also comprising the following steps for decoding: (h) using level indices s.sub.1 (K), s.sub.2 (K), s.sub.3 (K) obtained during coding to identify in the corresponding quantizers the terms of quantized r.m.s. values .gamma..sub.1 (K), .gamma..sub.2 (K), .gamma..sub.3 (K) and computing the terms of numbers of levels choosing the quantizers in said sets of subband quantizers; (i) detecting with level indices e.sub.1 (m), e.sub.2 (m), e.sub.3 (m) obtained during coding, in the chosen subband quantizers, quantized normalized values EN.sub.1 (m), EN.sub.2 (m), EN.sub.3 (m); (j) multiplying quantized normalized values EN.sub.1 (m), EN.sub.2 (m) by said quantized r.m.s. values .gamma..sub.1 (K), .gamma..sub.2 (K) and subjecting the result to a linear prediction filtering operation by using quantized filter coefficient vectors a.sub.1hott (i), a.sub.2hott (i), chosen in respective codebooks by said indices h.sub.1ott (J), h.sub.2ott (J) obtained during coding, and obtaining reconstructed signal samples of the first and second subbands; (k) multiplying quantized normalized values EN.sub.3 (m) by quantized r.m.s. values .gamma..sub.3 (K) obtaining samples of the reconstructed signal of the third subband; and (l) subjecting said reconstructed signals of the first, second and third subbands to an inverse filtering operation with respect to that used during coding to obtain the reconstructed speech signal.<br>5. A speech-signal coding and decoding device comprising: a first bank of digital filters (QMF1) organized in cascaded pairs, the filters of the pairs having specular transfer functions with respect to transition frequencies, said bank splitting into subbands the digital speech signal to be coded; a first circuit (CHA1) which during coding receives the samples of a first subband, at the lowest frequencies, from said first bank (QMF) and reemits them delayed to the output, and comprises means (BF1, IND1) to subdivide samples into blocks of J samples, which form a frame time, linear prediction inverse filtering and vector quantization means (LPCF1, CXH, VOCA) to obtain, from each block, residual samples of first subband R.sub.1 (m), m being the progressive sample index, a first vector index h.sub.1ott (J) and a corresponding first vector of quantized coefficients a.sub.1hott (i) of the optimal filter during coding; said first circuit (CHA1) receiving, for each block of J samples, a first index h.sub.1ott (J) of the optimal filter during decoding and determining a corresponding first vector of quantized coefficients a.sub.1hott (i) during decoding; a second circuit (CHA2) which during coding receives from said first bank (QMF) the samples of a second subband adjacent to the first, and which for each block of J subband samples obtains samples of second subband residual R.sub.2 (m), a second vector index h.sub.2ott (J) and a second quantized coefficients vector a.sub.2hott (i) of the optical filter during coding, the second circuit (CHA2) receiving a second vector index h.sub.2ott (i) of the optimal filter and determining a corresponding second vector of quantized coefficients a.sub.2hott (i) during decoding; first memory means (BF3) to temporarily store and subdivide into blocks the samples of a third subband adjacent to the second; a third circuit (CSS1) which during coding calculates an r.m.s. value of blocks of K samples of said first subband residual R.sub.1 (m), quantizes them obtaining for each block of K samples a first quantized r.m.s. value .differential..sub.1 (K) and a corresponding first index of quantization level s.sub.1 (K) during coding, and receives a first index of quantization level s.sub.1 (K) and determines a first quantized r.m.s. value .differential..sub.1 (K) during decoding; a fourth circuit (CSS2) which obtains from said second subband residual R.sub.2 (m) a second quantized r.m.s. value .differential..sub.2 (K) and a corresponding second index of quantization level s.sub.2 (K) during coding, and receives a second index of quantization level s.sub.2 (K) and determines a second quantized r.m.s. value .differential..sub.2 (K) during decoding; a fifth circuit (CSS3), similar in structure to said third which obtains from each block of K samples received from said first memory means (BF3) a third quantized r.m.s. value .differential..sub.3 (K) and a third index of quantization level s.sub.3 (K) during coding, and receives a third index of quantization level s.sub.3 (K) and determines a third quantized r.m.s. value .differential..sub.3 (K) during decoding; first decoding means (MX9, RM1, RM2, RM3, MR4) which receive said first s.sub.1 (K), second s.sub.2 (K), third s.sub.3 (K) index of quantization level during coding and decoding and extract quantizer selecting signals (B1, B2, B3, L1, L2, L3); a sixth circuit (PRB1) carrying out an adaptive linear prediction function on samples of the first subband it receives from said first circuit (CHA1), by using at every block of samples said first quantized coefficient vector a.sub.1hott (i) during coding and decoding, and samples of a first quantized normalized residual EN.sub.1 (m) during coding and decoding, and obtaining during coding samples of a first normalized residual EN.sub.1 (m) with respect to said first quantized r.m.s. value .differential..sub.1 (K) it receives from said third circuit (CSS1), and during decoding first-subband reconstructed-signal samples (XR1); a seventh circuit (PRB2) receiving the samples of second subband and the second vector of quantized coefficients a.sub.2hott (i) from said second circuit (CHA2), said second quantized r.m.s. value .differential..sub.2 (K) from said fourth circuit (CSS2), and samples of second quantized normalized residual signal EN.sub.2 (m) during coding and decoding, and obtains during coding the samples of a second normalized residual EN.sub.2 (m) and during decoding samples of second subband reconstructed signal (XR2); an eighth circuit (QUA1) which, by using quantizers selected out of a set of first subband quantizers on the basis of said signals of selection of a quantizer it receives from said first decoding means, quantizes the samples of said first normalized residual EN.sub.1 (m) it receives from said sixth circuit (PRB1) obtaining samples of said first quantized normalized residual EN.sub.1 (m) and indices of first subband quantization levels e.sub.1 (m) during coding, and which obtains samples of said first quantized normalized residual EN.sub.1 (m) during decoding on the basis of indices of first subband quantization levels e.sub.1 (m) during decoding it receives at the input; a ninth circuit (QUA2) receiving signals for selection a quantizer out of a set of second subband quantizers from said first decoding means, samples of said second normalized residual EN.sub.2 (m) for said seventh circuit (PRB2), indices of second subband quantization levels e.sub.2 (m) during decoding, and extracts samples of said second quantized normalized residual EN.sub.2 (m) during coding and decoding supplied to said seventh circuit (PRB2), and second subband quantization-level indices e.sub.2 (m) during coding; a tenth circuit (QUA3) receiving selecting signals of a quantizer a third-subband quantizer set from said first decoding means, samples of a normalized value EN.sub.3 (m) obtained by a divider (DV3) of the samples of the third subband (XD3), received from said first memory means (BF3), by said third quantized r.m.s. value .differential..sub.3 (K) during coding, indices of third subband quantization levels e.sub.3 (m) during decoding, and extracts third subband quantization level indices e.sub.3 (m) during coding, and samples of a quantized normalized value EN.sub.3 (m) which are multiplied in a first multiplie (ML3) by said third quantized r.m.s. value .differential..sub.3 (K) during decoding obtaining samples of third subband reconstructed signal (XR3); a first multiplexer (MPX) combining in subsequent frames said first h.sub.1ott (J) and second h.sub.2ott (J) vector index during coding it receives from said first and second circuits (CHA1, CHA2), said first s.sub.1 (K), second s.sub.2 (K) and third e.sub.3 (K) quantization level indices during coding it receives from said third, fourth and fifth circuits (CSS1, CSS2, CSS3), said quantization level indices of first e.sub.1 (m), second e.sub.2 (m) and third e.sub.3 (m) subband during coding it receives from said eighth, ninth and tenth circuit (QUA1, QUA2, QUA3), relating to subsequent blocks of J subband samples, and sends each frame to the output (UT) as a coded speech signal; a first demultiplexer (DMX) which receives and splits coded speech signal frames, and generates said first h.sub.10tt (J) and second h.sub.2ott (J) vector indices during decoding for said first and second circuits (CHA1, CHA2), said first s.sub.1 (K), second s.sub.2 (K) and third s.sub.3 (K) quantization level index during decoding for said third, fourth and fifth circuits (CSS1, CSS2, CSS3), said quantization level indices of first e.sub.1 (m), second e.sub.2 (m) and third e.sub.3 (m) subband during decoding for said eigth, ninth, and tenth circuits (QUA1, QUA2, QUA3); and a second bank of digital filters (QMFD), structurally inverse to said first bank of digital filters (QMF), which receives from said sixth (PRB1), seventh (PRB2) circuits and first multiplier (ML3) said samples of reconstructed signal of first, second and third subband (XR1, XR2, XR3) and generates a digital speech signal reconstructed during decoding.</p></layer>
<layer id = "layer51"><p><b>US5321793A:Low-delay audio signal coder, using analysis-by-synthesis techniques</b><br>Porous bodies of a material which comprises SiO.sub.2 as the main constituent are heated by passing a zone of high temperature through the body. The zone of high temperature is obtained by irradiation with light of a wavelength which is absorbed by the porous part of the body but is not absorbed by the densified part of the body (.lambda.<3 .mu.m). The device preferably comprises a rotatable radiation source (2) surrounding the body (6) to be densified.<br><b>Independant Claims</b><br>1. A method of coding and decoding audio signals by means of analysis-by-synthesis techniques wherein, at a coding end, in a coding phase, an audio signal is organized into blocks of digital samples and, for each sample block, a synthesis filtering is effected for a set of innovation signals (e.sub.x) and perceptual weighting filtering of an input signal and of a synthesized signals of the analysis-by-synthesis are carried out by adapting spectral parameters of synthesis and weighting filter with backward prediction techniques, starting from a reconstructed audio signal obtained as the result of the synthesis filtering of an optimum one of the innovation signals, and, at a decoding end, the audio signal is reconstructed by submitting the optimum innovation signal (e.sub.xo), identified in the coding phase, to a synthesis filtering during which the spectral parameters of the synthesis filter (SYD) are adapted by a backward prediction technique, in a manner corresponding to the adaptation carried out in the coding phase, said method further comprising, for each sample bock to be coded and for each signal to be decoded, an adaptation is also made of the prediction order of the synthesis filters, at both the coding and the decoding ends, and of the perceptual weighting filters at the coding end, based upon spectral characteristics of the reconstructed signal.<br>9. A device for coding/decoding audio signals by means of analysis-by-synthesis techniques, in which synthesis filters in a coder and in a decoder and perceptual weighting filters in the coder are associated with spectral parameter adaptation units, which perform this adaptation for each sample block of the speech signal to code or for each coded signal to decode for reconstructing a block of samples, said adaptation units of spectral parameters also supplying parameters determined for a block of samples to be coded or respectively for a signal to be decoded to an adaptation unit of prediction order of the filters which unit updates this prediction order starting from the spectral characteristics of the reconstructed signal, with the following operations: a) calculating, in function of the prediction order and up to a predetermined maximum order, the prediction gain of the synthesis filters (SYC, SYD) which generate the reconstructed signal, and their incremental prediction gain when the prediction order is increased by one unit, said gains being given respectively by the following relations: ##EQU9## where KJ are the reflection coefficients of the acoustic tube; b) determining, in a prediction order interval between a minimum order and said maximum order, the values for which the incremental gain G(p/p-1) presents a relative maximum and is greater than a first predetermined threshold; c1) carrying out the synthesis and weighting filtering with the highest prediction order among those determined at point b), if the gain corresponding to the maximum prediction order is not less than a second predetermined threshold; and c2) carrying out the synthesis and weighting filtering using the minimum prediction order, if the gain corresponding to the maximum prediction order is less than a second predetermined threshold.</p></layer>
<layer id = "layer52"><p><b>US5548680A:Method and device for speech signal pitch period estimation and classification in digital speech coders</b><br>An apparatus for carrying a passenger on a bicycle in the form of a carrier having a first end and a second end and seat located intermediate said first and second ends. The apparatus is provided with locating means for locating the carrier on the frame of the bicycle. The locating means are provided at least two substantially mutually remote locations so that the carrier means is locatable on the bicycle frame substantially forward of the seat of the carrier of the rider of the bicycle.<br><b>Independant Claims</b><br>1. A method of speech signal coding, comprising the steps of: (a) dividing a speech signal to be coded into digital sample frames each containing the same number of samples: (b) subjecting the samples of each frame to a predictive analysis for extracting from said signal parameters representative of long-term and short-term spectral characteristics and comprising at least a long-term analysis delay d, corresponding to a pitch period, and a long-term prediction coefficient b and gain G, and to a classification which indicates whether a respective frame corresponds to an active or inactive speech signal segment and for an active signal segment, whether the segment corresponds to a voiced or an unvoiced sound, a segment being considered as voiced if a respective prediction coefficient and gain are both greater than or equal to respective thresholds; (c) providing information on said parameters to coding units for insertion into a coded signal, together with signals indicative of the classification for selecting in said coding units different coding methods according to characteristics of respective speech segments; and (d) during said long-term analysis, estimating said delay is as a maximum of covariance function, weighted with a weighting function which reduces a probability that the period computed is a multiple of an actual period, inside a window with a length not less than a maximum value admitted for the delay, said thresholds for prediction coefficient and gain being thresholds which are adapted at each frame, in order to follow a background noise but not of the speech signal, adaptation of said thresholds being enabled only in active speech signal segments.<br>9. A device for speech signal digital coding, comprising: means (TR) for dividing a sequence of speech signal digital samples into frames made up of a preset number of samples; means for speech signal predictive analysis (AS), comprising circuits (ST) for generating at each frame, parameters representative of short-term spectral characteristics and a residual signal of short-term prediction, and circuits (LT1, LT2) which obtain from the residual signal parameters representative of long-term spectral characteristics comprising a long-term analysis delay or pitch period d, and a long-term prediction coefficient b and a gain G: means for a-priori classification (CL) for recognizing whether a frame corresponds to an active speech period or to a silence period and whether an active speech period corresponds to a voiced or an unvoiced sound, the classification means (CL) comprising circuits (RA, RV) which generate a first and a second flag (A, V) for respectively signalling an active speech period and a voiced sound, and the circuits generating the second flag comprising means (CM1, CM2) for comparing the prediction coefficient and gain values with respective thresholds and emitting this flag when said values are both greater than the thresholds; and speech coding units (CV), which generate a coded signal by using at least some of the parameters generated by the predictive analysis means (AS), and are driven by said flags (A, V) in order to insert into the coded signal different information according to the nature of the speech signal in the frame, the circuits (LT1) for delay estimation computing said delay by maximizing a covariance function of a residual signal, computed inside a sample window with a length not lower than a maximum admissible value for the delay itself and weighted with a weighting function such as to reduce the probability that the maximum value computed is a multiple of the actual delay, and said comparison means (CM1, CM2) in the circuits (RV) generating the second flag (V) carrying out the comparison frame by frame with variable thresholds and being provided with means (CS1, CS2) for threshold generation, the comparison and threshold generation means being enabled only in the presence of the first flag.</p></layer>
<layer id = "layer53"><p><b>US4918729A:Voice signal encoding and decoding apparatus and method</b><br>A hydraulic control device for the pressurization of a clutch or the like for a transmission operable under load comprises a spool-type valve displaceable in one direction to pressurize the clutch and in the opposite direction to vent the same. The valve spool operates with a damping piston which receives the clutch pressure buildup and acts against a control piston which, in turn, is displaced by an operative valve. According to the invention, the pressure head is maintained substantially constant by providing a sleeve or bushing within the damping piston chamber which bears against the spool by a spring and which can be biased by a spring between the damping piston and the sleeve.<br><b>Independant Claims</b><br>1. A voice signal encoding and decoding apparatus comprising: an encoding section including: predictive filter means for computing a predicted value of an input signal to the encoding section; means for computing a difference signal by subtracting from the input signal the predicted value of the input signal computed by the predictive filter means; and means for encoding the difference signal computed by the difference signal computing means; and a decoding section including: means for decoding a received encoded difference signal; means for detecting an error in a signal; predictive synthesizing filter means for computing a predicted value of an output signal; means for computing the output signal by adding the signal decoded by the decoding means and the predicted value of the output signal computed by the predictive synthesizing filter means; and predictive synthesizing filter control means for expanding a resonant frequency band width of the predictive synthesizing filter means when an error is detected by the error detecting means.<br>7. A voice signal encoding and decoding apparatus comprising: an encoding section including: buffer means for storing a predetermined number of processed samples of an input signal; means for computing a predicted parameter from the input signal stored in the buffer means; means for computing a difference signal by subtracting a predicted value of the input signal from the output from the buffer means; means for quantizing the difference signal computed by the difference signal computing means; predictive filter means for computing the predicted value of the input signal by using the output from the quantizing means and the output from the predicted parameter computing means; first encoding means for encoding the output from the quantizing means; second encoding means for encoding the output from predicted parameter computing means; and means for multiplexing the output from the first encoding means as main information and the output from second encoding means as side information together with an error correction code and delivering the result in a predetermined frame structure; and a decoding section including: means for demultiplexing from a received signal a frame including the main data, the auxiliary data and the error correction code; first decoding means for decoding the main information output from the demultiplexing means; second decoding means for decoding the side information output from the demultiplexing means; means for computing the output signal by adding the output from the first decoding means and the predicted value of the output signal; predictive synthesizing filter means for computing the predicted value of the output signal by using the output from the output signal computing means and the output from the second decoding means; means for detecting an error in the received signal from the error correction code output from the demultiplexing means; and predictive synthesizing filter control means for expanding a resonant frequency band width of the predictive synthesizing filter means when an error is detected by the error detecting means.<br>8. A voice signal encoding and decoding method comprising the steps of: computing a difference signal by subtracting a predicted value of an input signal from the input signal; computing a predicted parameter for the input signal from the input signal; computing the predicted value of the input signal by using the difference signal and predicted parameter; encoding the difference signal; decoding the difference signal from a received signal; computing the output signal by adding the decoded difference signal and the predicted value of the output signal; computing the predicted value of the output signal by carrying out a predetermined filtering operation on the computed output signal in accordance with the predicted parameter; detecting an error in the received signal; and attenuating an erroneous influence rapidly by expanding the resonant frequency band width in the predictive synthesizing step when an error including the error component is detected by the error detecting step.</p></layer>
<layer id = "layer54"><p><b>US8412520B2:Noise reduction device and noise reduction method</b><br>A magnetic device for gripping and clamping a workpiece in a machining unit or on a machining line including a magnetic plate having a distribution of high-energy permanent-magnet modules, which can be electrically activated. An auxiliary workpiece-holder plate made of ferromagnetic material rests on a main surface of the magnetic plate and has a top surface shaped in a way complementary to a surface of the workpiece that rests thereon. The workpiece rests on the top surface of the auxiliary workpiece-holder plate only in points corresponding to some supporting pads, whilst the facing surfaces of the workpiece and auxiliary workpiece-holder plate are kept slightly set apart from one another for most of their extension.<br><b>Independant Claims</b><br>4) A noise reduction method for obtaining an output signal whose noise is reduced based on an input signal, the method comprising: obtaining a SN ratio as a function of an estimated noise spectrum, and an arithmetic product of an averaged power spectrum of the input signal and a noise likeliness signal, the SN ratio being one of two types of definitions according to values of both the averaged power spectrum of the input signal and the estimated noise spectrum, the first definition being a calculation of a value based on both the estimated noise spectrum and the arithmetic product, and the second definition being a predefined constant, the estimated noise spectrum being estimated based on the averaged power spectrum of the input signal, and the noise likeliness signal being calculated as an index indicating a likelihood that the input signal is noise, and being calculated as a variable that ranges from a plurality of values that are larger than 0 and smaller than 1; and obtaining an output signal whose noise is reduced based on the input signal and the obtained SN ratio.<br>7) A noise reduction device for reducing a noise other than a target signal contained in an input signal, the device comprising: a SN ratio obtaining unit configured to obtain a SN ratio, on a subband basis, as a function of a spectrum of a noise signal and an arithmetic product of an averaged power spectrum of the input signal, and a noise likeliness signal, the SN ratio being one of two types of definitions according to values of both the averaged power spectrum of the input signal and the spectrum of the noise signal, the first definition being a calculation of value based on both the spectrum of the noise signal and the arithmetic product, and the second definition being a predefined constant, the spectrum of the noise signal being estimated based on the averaged power spectrum of the input signal, and the noise likeliness signal being calculated as an index indicating a likelihood that the input signal is noise, and being calculated as a variable ranging from a plurality of values that are larger than 0 and smaller than 1; a spectrum reduction factor obtaining unit configured to obtain a spectrum reduction factor based on the SN ratio obtained by the SN ratio obtaining unit; and a noise reduction signal obtaining unit configured to obtain an output signal whose noise is reduced based on the input signal and the spectrum reduction factor obtained by the spectrum reduction factor obtaining unit.<br>10) A noise reduction method for reducing a noise other than a target signal contained in an input signal, the method comprising: obtaining a SN ratio, on a subband basis, as a function of a spectrum of a noise signal, and an arithmetic product of an averaged power spectrum of the input signal and a noise likeliness signal, the SN ratio being one of two types of definitions according to values of both the averaged power spectrum of the input signal and the spectrum of a noise signal, the first definition being a calculation of value based on both the spectrum of a noise signal and the arithmetic product, the second definition being a predefined constant, and the spectrum of the noise signal being estimated based on the averaged power spectrum of the input signal, the noise likeliness signal being calculated as an index indicating a likelihood that the input signal is noise, and being calculated as a variable ranging from a plurality of values that are larger than 0 and are smaller than 1; obtaining a spectrum reduction factor based on the SN ratio; and obtaining an output signal whose noise is reduced based on the input signal and the spectrum reduction factor.<br>1) A noise reduction device for obtaining an output signal whose noise is reduced based on an input signal, the device comprising: a SN ratio obtaining unit configured to obtain a SN ratio as a function of an estimated noise spectrum, and an arithmetic product of an averaged power spectrum of the input signal and a noise likeliness signal, the SN ratio being one of two types of definitions according to values of both the averaged power spectrum of the input signal and the estimated noise spectrum, the first definition being a calculation of a value based on both the estimated noise spectrum and the arithmetic product, and the second definition being a predefined constant, the estimated noise spectrum being estimated based on the averaged power spectrum of the input signal, and the noise likeliness signal being calculated as an index indicating a likelihood that the input signal is noise, and being calculated as a variable ranging from a plurality of values that are larger than 0 and smaller than 1; and an output signal obtaining unit configured to obtain an output signal whose noise is reduced based on the input signal and the SN ratio obtained by the SN ratio obtaining unit.</p></layer>
<layer id = "layer55"><p><b>US5978824A:Noise canceler</b><br>The invention relates to a wing shooting target made up of an internally empty body, subdivided into two half-portions (1, 2) integrally coupled to each other at the time of shooting, endowed with at least two radial vanes (3) and realized in a light material.<br><b>Independant Claims</b><br>1. A noise canceler comprising: first delaying means for delaying a main signal containing a desired signal and a noise signal by a preselected period of time to thereby output a delayed main signal; second delaying means for receiving the noise signal as a reference signal and delaying the reference singal by the preselected period of time to thereby output a delayed reference signal; first subtracting means for subtracting a first estimated noise signal from said delayed main signal to thereby generate a first desired signal output; second subtracting means for subtracting a first estimated desired signal from said delayed reference signal to thereby generate a first noise signal output; a first adaptive filter for receiving said first noise signal output and adaptively estimating a noise signal contained in said delayed main signal to thereby output said first estimated noise signal; a second adaptive filter for receiving said first desired signal output and adaptively estimating a desired signal contained in said delayed reference singal to thereby output said first estimated desired signal; signal-to-noise power ratio estimating means for receiving said main signal and said reference signal and calculating desired signal power and noise signal power of the main signal and desired signal power and noise signal power of the reference signal to thereby output an estimated value of a power ratio of the main signal to the noise signal and an estimated value of a power ratio of the reference signal to the noise signal; and step size outputting means for receiving said estimated values from said signal-to-noise power ratio estimating means to thereby output a first and a second step size representative of an amount of correction of a filter coefficient of said first adaptive filter and an amount of correction of a filter coefficient of said second adaptive filter, respectively.</p></layer>
<layer id = "layer56"><p><b>US5313555A:Lombard voice recognition method and apparatus for recognizing voices in noisy circumstance</b><br>A high-frequency incision tool has a flexible sheath which is adapted to be inserted into the body cavity along with an endoscope. A suction port is formed at the distal end of the sheath. A wire is inserted into the sheath and a part of the wire is exposed from the sheath to form an incision section. The wire is pushed and pulled by an operating section which is provided at the proximal end of the sheath. A suction mouthpiece is formed at the operating section to communicate with the suction port through the inside passage of the sheath. A reinforcing wire is disposed in the distal end portion of the sheath to reinforce the portion.<br><b>Independant Claims</b><br>1. A Lombard voice recognition method for recognizing an input voice under a noisy background comprising the steps of: warping a frequency spectrum of a lower frequency than a predetermined frequency in a frequency spectrum of a feature pattern with a predetermined warping width toward a lower frequency side in a frequency axis, said warping being at a time when a noisy level of an input voice is higher than a predetermined noisy level, said frequency spectrum of said feature pattern being derived from said input voice; and matching a frequency spectrum of a standard pattern with said warped frequency spectrum of said feature pattern to calculate similarity between said standard pattern and said feature pattern and outputting a recognized result based on the calculated similarity, said predetermined warping width being changeable in accordance with a nose level of said input voice at a time when said lower frequency spectrum of said feature pattern than said predetermined frequency is warped by said predetermined warping width toward said lower frequency side with respect to said frequency axis.<br>6. A Lombard voice recognition apparatus which is capable of recognizing a voice input in a noisy background, said apparatus having a control means for controlling said apparatus in a proper manner, said apparatus comprising: means connected to said control means for extracting a power spectrum from a voice of a particular speaker; means connected to said extracting means for cutting said power spectrum at proper syllabic intervals and for outputting a feature pattern; means connected to said cutting means for calculating similarity between said feature pattern and a standard pattern, and for outputting recognized result based on the calculated similarity; means connected to said extracting means for detecting a noise level of said noisy background; means connected to said detecting means and said similarity calculating means for warping said power spectrum located in a lower frequency region than a predetermined value toward a lower frequency side; and means connected to said similarity calculating means for storing said standard pattern.</p></layer>
<layer id = "layer57"><p><b>US6366881B1:Voice encoding method</b><br>An electric power steering control system reducing steering torque without making a driver feel uncomfortable torque oscillation, including a rotation speed observer for estimating the rotation speed of a motor based on the output of a torque sensor high pass filter (HPF) and the output of a drive current HPF obtained by removing a steering frequency component from a drive current detection value.<br><b>Independant Claims</b><br>1) A voice coding method comprising: the first step of adding, when a first prediction error signal dn which is a difference between an input signal xn and a predicted value yn corresponding to the input signal xn is not less than zero, one-half of a quantization step size Tn to the first prediction error signal dn to produce a second prediction error signal en, while subtracting, when the first prediction error signal dn is less than zero, one-half of the quantization step size Tn from the first prediction error signal dn to produce a second prediction error signal en; the second step of finding a code Ln on the basis of the second prediction error signal en found in the first step and the quantization step size Tn; the third step of finding a reversely quantized value qn on the basis of the code Ln found in the second step; the fourth step of finding a quantization step size Tn+1 corresponding to the subsequent input signal xn+1 on the basis of the code Ln found in the second step; and the fifth step of finding a predicted value yn+1 corresponding to the subsequent input signal xn+1 on the basis of the reversely quantized value qn found in the third step and the predicted value yn.<br>6) A voice coding method comprising: the first step of adding, when a first prediction error signal dn which is a difference between an input signal xn and a predicted value yn corresponding to the input signal xn is not less than zero, one-half of a quantization step size Tn to the first prediction error signal dn to produce a second prediction error signal en, while subtracting, when the first prediction error signal dn is less than zero, one-half of the quantization step size Tn from the first prediction error signal dn to produce a second prediction error signal en; the second step of finding, on the basis of the second prediction error signal en found in the first step and a table previously storing the relationship between the second prediction error signal en and a code Ln, the code Ln; the third step of finding, on the basis of the code Ln found in the second step and a table previously storing the relationship between the code Ln and a reversely quantized value qn, the reversely quantized value qn; the fourth step of finding, on the basis of the code Ln found in the second step and a table previously storing the relationship between the code Ln and a quantization step size Tn+1 corresponding to the subsequent input signal xn+1, the quantization step size Tn+1 corresponding to the subsequent input signal xn+1; and the fifth step of finding a predicted value yn+1 corresponding to the subsequent input signal xn+1 on the basis of the reversely quantized value qn found in the third step and the predicted value yn, wherein each of the tables being produced so as to satisfy the following conditions (a), (b) and (c): (a) The quantization step size Tn is so changed as to be increased when the absolute value of the difference dn is so changed as to be increased, (b) The reversely quantized value qn of the code Ln corresponding to a section where the absolute value of the difference dn is small is approximately zero, and (c) A substantial quantization step size corresponding to a section where the absolute value of the difference dn is large is larger, as compared with that corresponding to the section where the absolute value of the difference dn is small.</p></layer>
<layer id = "layer58"><p><b>US6463409B1:METHOD OF AND APPARATUS FOR DESIGNING CODE BOOK OF LINEAR PREDICTIVE PARAMETERS, METHOD OF AND APPARATUS FOR CODING LINEAR PREDICTIVE PARAMETERS, AND PROGRAM STORAGE DEVICE READABLE BY THE DESIGNING APPARATUS</b><br>A vehicle seat adjuster has a first track member attached to a vehicle frame and a second track member attached to a vehicle seat and is movable relative to the first track. The adjuster includes a drive mechanism, having a threaded shaft connected with the second track member, a drive block attached to the first track member, and means for moving the threaded shaft within the drive block, for moving the track members. The drive block is made of a base, an isolator made of a urethane material, and a nut. The isolator fits within an opening on the base, and the nut fits within an opening within the isolator. Each of the components has a bore formed therethrough such that the threaded shaft can pass through the drive block. The isolator and the nut are pivotable within the base component in order to maintain alignment between the shaft and the drive block.<br><b>Independant Claims</b><br>1) A method of designing a code book which is a set of code vectors to be selected when linear predictive parameters are vector-quantized as for an input audio which is divided into frames, each of which is further divided into sub frames, the method comprising the processes of: calculating the linear predictive parameters of the input audio for the sub frames respectively; calculating a plurality of quantization candidates which are candidates for the code vectors with respect to the linear predictive parameters of the input audio as for the sub frames positioned at a predetermined interval set in advance; calculating interpolation values for the linear predictive parameters on the basis of the calculated quantization candidates as for the sub frames other than the sub frames positioned at the predetermined interval; and determining the code vectors of the code book by selecting the code vectors from among the calculated quantization candidates on the basis of the calculated quantization candidates, the calculated interpolation values and the calculated linear predictive parameters, within a range of continuous sub frames in a predetermined number set in advance.<br>3) An apparatus for designing a code book which is a set of code vectors to be selected when linear predictive parameters are vector-quantized as for an input audio which is divided into frames, each of which is further divided into sub frames, the apparatus comprising: a calculating device for calculating the linear predictive parameters of the input audio for the sub frames respectively; a quantizing device for calculating a plurality of quantization candidates which are candidates for the code vectors with respect to the linear predictive parameters of the input audio as for the sub frames positioned at a predetermined interval set in advance; an interpolating device for calculating interpolation values for the linear predictive parameters on the basis of the calculated quantization candidates as for the sub frames other than the sub frames positioned at the predetermined interval; and a determining device for determining the code vectors of the code book by selecting the code vectors from among the calculated quantization candidates on the basis of the calculated quantization candidates, the calculated interpolation values and the calculated linear predictive parameters, within a range of continuous sub frames in a predetermined number set in advance.<br>5) A method of coding linear predictive parameters, by use of a code book which is a set of code vectors to be selected when the linear predictive parameters are vector-quantized as for an input audio which is divided into frames, each of which is further divided into sub frames, the method comprising the processes of: calculating the linear predictive parameters of the input audio for the sub frames respectively; calculating a plurality of quantization candidates which are candidates for the code vectors with respect to the linear predictive parameters of the input audio as for the sub frames positioned at a predetermined interval set in advance; calculating interpolation values for the linear predictive parameters on the basis of the calculated quantization candidates as for the sub frames other than the sub frames positioned at the predetermined interval; and selecting the code vectors from among the calculated quantization candidates on the basis of the calculated quantization candidates, the calculated interpolation values and the calculated linear predictive parameters, within a range of continuous sub frames in a predetermined number set in advance, and outputting the selected code vectors.<br>8) An apparatus for coding linear predictive parameters, by use of a code book which is a set of code vectors to be selected when the linear predictive parameters are vector-quantized as for an input audio which is divided into frames, each of which is further divided into sub frames, the apparatus comprising: a calculating device for calculating the linear predictive parameters of the input audio for the sub frames respectively; a quantizing device for calculating a plurality of quantization candidates which are candidates for the code vectors with respect to the linear predictive parameters of the input audio as for the sub frames positioned at a predetermined interval set in advance; an interpolating device for calculating interpolation values for the linear predictive parameters on the basis of the calculated quantization candidates as for the sub frames other than the sub frames positioned at the predetermined interval; and a selecting device for selecting the code vectors from among the calculated quantization candidates on the basis of the calculated quantization candidates, the calculated interpolation values and the calculated linear predictive parameters, within a range of continuous sub frames in a predetermined number set in advance, and outputting the selected code vectors.<br>11) A program storage device readable by a computer for designing a code book, tangibly embodying a program of instructions executable by the computer to perform method processes for designing the code book which is a set of code vectors to be selected when linear predictive parameters are vector-quantized as for an input audio which is divided into frames, each of which is further divided into sub frames, the method processes comprise: calculating the linear predictive parameters of the input audio for the sub frames respectively; calculating a plurality of quantization candidates which are candidates for the code vectors with respect to the linear predictive parameters of the input audio as for the sub frames positioned at a predetermined interval set in advance; calculating interpolation values for the linear predictive parameters on the basis of the calculated quantization candidates as for the sub frames other than the sub frames positioned at the predetermined interval; and determining the code vectors of the code book by selecting the code vectors from among the calculated quantization candidates on the basis of the calculated quantization candidates, the calculated interpolation values and the calculated linear predictive parameters, within a range of continuous sub frames in a predetermined number set in advance.</p></layer>
<layer id = "layer59"><p><b>US6292777B1:Phase quantization method and apparatus</b><br><b>Independant Claims</b><br>1) A phase quantization apparatus comprising: assignment bit number calculating means for calculating an optimum number of quantization bits assigned to respective harmonics of input speech signals; and quantization means for quantizing a phase of the respective harmonics of signals derived from the input speech signals in accordance with the assigned number of bits calculated by the assignment bit number calculating means.<br>7) A phase quantization method comprising: an assignment bit number calculating step of calculating an optimum number of quantization bits assigned to respective harmonics of input speech signals; and a quantization step of quantizing a phase of the respective harmonics of signals derived from the input speech signals in accordance with the assigned number of bits calculated by the assignment bit number calculating step.<br>10) A phase quantization apparatus comprising: assignment bit number calculating means for calculating an optimum number of quantization bits assigned to respective harmonics of input speech signals; and quantization means for quantizing a difference between an approximated phase of respective harmonics components as found from an approximation line of unwrapped phase characteristics for a phase of the respective harmonics components of signals derived from the input speech signals and the phase of the respective harmonics components of the signals derived from the input speech signals depending on the optimum number of assigned bits calculated by the assignment bit number calculating means.<br>18) A phase quantization method comprising: an assignment bit number calculating step of calculating an optimum number of quantization bits assigned to respective harmonics of input speech signals; and a quantization step of quantizing a difference between an approximated phase of respective harmonics components as found from an approximation line of unwrapped phase characteristics for a phase of respective harmonics components of signals derived from the input speech signals and the phase of the respective harmonics components of the signals derived from the input speech signals depending on the optimum number of assigned bits calculated by the assignment bit number calculating step.</p></layer>
<layer id = "layer60"><p><b>US5268991A:Apparatus for encoding voice spectrum parameters using restricted time-direction deformation</b><br>A bicycle headset structure is provided to aid in concealment of wiring from components mounted in the handlebar area to components mounted on the rest of the bicycle. The bicycle headset structure basically comprises a handlebar attachment member and a tubular spacer member. The handlebar attachment member has wiring passage extends between the handlebar mounting portion and the steerer tube attachment portion. The tubular spacer member has a wiring channel extending between first and second ends of the tubular spacer member and an axial passageway extending axially between the upper and lower end openings of the tubular spacer member. The axial passageway is dimensioned to receive the bicycle steerer tube. The wiring channel is arranged to communicate with the wiring passage of handlebar attachment member when the handlebar attachment member and the tubular spacer member are attached to the bicycle steerer tube.<br><b>Independant Claims</b><br>1. An apparatus for encoding voice spectrum parameters comprising: means for combining in time direction a fixed number of phoneme vectors composed of spectrum parameters representing information on the spectrum of an input voice signal, to provide an input phoneme matrix; means for performing a first finite number of deformations in time-direction of the input phoneme matrix, to output the first number of deformed phoneme matrices; a code book for storing a second finite number of phoneme matrix code words; distance calculation means for calculating the distances between each of the deformed phoneme matrices output from said means for performing deformations and each of the phoneme matrix code words; and optimum code word selection means for comparing the distances calculated by said distance calculation means, and for selecting for the input phoneme matrix one of the phoneme matrix code words having the smallest distance to the deformed phoneme matrices formed for the input phoneme matrix as an optimum phoneme matrix code word.<br>11. A method for encoding voice spectrum parameters comprising the steps of: obtaining an input phoneme matrix from a fixed number of input phoneme vectors composed of spectrum parameters representing information on the spectrum of an input voice signal; performing a first number of deformations in time-direction of the input phoneme matrix, to obtain the first number of deformed phoneme matrices, providing a code book which stores a second finite number of phoneme matrix code words; calculating distances between each of the obtained deformed phoneme matrices and each of the phoneme matrix code words; and comparing the distances calculated and selecting for the input phoneme matrix one of the phoneme matrix code words having the smallest distance to the deformed phoneme matrices formed for the input phoneme matrix as an optimum phoneme matrix code.</p></layer>
<layer id = "layer61"><p><b>US5027405A:Communication system capable of improving a speech quality by a pair of pulse producing units</b><br>A metrology instrument and method is offered which is capable of measuring the deviations between elements of an actual pattern at their joint without making any sample pattern for inspection in measuring and inspecting deviations produced at the joint portion when the pattern is drawn or transferred. The deviation ΔX parallel to the joint portion is found from an image obtained for inspection. On the other hand, the dose distribution diagrams of both elements of the pattern on the opposite sides of the joint portion are calculated. These dose distribution diagrams are shifted by ΔX along the joint portion and by a desired amount ΔY vertical to the joint portion. Then, the diagrams are superimposed together. The resulting image is compared with the image for the inspection and the correlation between them is found. The value of ΔY which minimizes the correlation (i.e., maximizes the degree of similarity) is found.<br><b>Independant Claims</b><br>1. In an encoder device supplied with a sequence of digital speech signals at every frame to produce a sequence of output signals, said encoder device comprising parameter calculation means responsive to said digital speech signals for calculating first and second primary parameters which specify a spectrum envelope and pitch parameters of the digital speech signals at every frame to produce first and second parameter signals representative of said spectrum envelope and said pitch parameters, respectively, calculation means coupled to said parameter calculation means for calculating a set of calculation result signals representative of said digital speech signals, and output signal producing means for producing said set of the calculation result signals as said output signal sequence, the improvement wherein said calculation means comprises: primary pulse producing means responsive to said digital speech signals and said first and said second parameter signals for calculating a first set of prediction excitation multipulses with respect to a preselected one of subframes which result from dividing every frames and each of which is shorter than said frame, said primary pulse producing means producing said first set of prediction excitation multipulses, as a primary sound source signal, and a sequence of primary synthesized signals specified by said first set of prediction excitation multipulses and said spectrum envelope and said pitch parameters; subtraction means coupled to said primary pulse producing means for subtracting said primary synthesized signals from said digital speech signals to produce a sequence of difference signals representative of differences between said primary synthesized signals and said digital speech signals; secondary pulse producing means coupled to said subtraction means and responsive to said difference signals and said first and said second parameter signals for producing a second set of secondary excitation multipulses, as a secondary sound source signal, as said set of calculation result signals; and means for supplying a combination of said first set of prediction excitation multipulses, said second set of secondary excitation multipulses, and said first and said second parameter signals to said output signal producing means as said output signal sequence.</p></layer>
<layer id = "layer62"><p><b>US6101464A:Coding and decoding system for speech and musical sound</b><br>The present invention provides an isolated mammalian leukotriene receptor, isolated or recombinant nucleic acids and recombinant vectors encoding the same, host cells comprising the nucleic acids and vectors, and methods of making the receptor using the host cells. This invention further provides antibodies and antigen binding fragments thereof which specifically bind to the receptor and are useful for treating medical conditions caused or mediated by leukotriene. Also provided are screening methods for identifying specific agonists and antagonists of the mammalian leukotriene receptor.<br><b>Independant Claims</b><br>1. A coding and decoding system for a speech sound signal and a musical sound signal, comprising: a first filter for representing an input signal with first linear prediction coefficients indicative of a coarse spectral distribution of the input signal; a second filter for representing the input signal with second linear prediction coefficients indicative of a fine spectral distribution of the input signal; and a third filter connected in series with or parallel to said second filter for representing the input signal with third linear prediction coefficients indicative of a periodic component of the input signal, wherein the second linear prediction filter coefficients are calculated using a residual signal between the input signal and a reproduced signal obtained through said first, second and third filters.<br>5. A coder for coding a speech and musical sound signal, comprising: first filter means for producing a reproduced speech and musical sound excitation signal with first linear prediction coefficients indicative of a coarse spectral distribution of the speech and musical sound signal; second filter means for producing the reproduced excitation signal of the speech and musical sound signal with second linear prediction coefficients indicative of a fine spectral distribution of the speech and musical sound signal; third filter means for producing the reproduced excitation signal corresponding to the speech and musical sound signal by using only third linear prediction coefficients indicative of a periodic component of the speech and musical sound signal or using the third linear prediction coefficients and the second linear prediction coefficients; and means for producing parameters of the speech and musical sound signal produced on the basis of a residual signal between the speech and musical sound signal and the reproduced signal obtained through said first, second and third filter means, wherein the second linear prediction coefficients are calculated using the residual signal between the input signal and the reproduced signal obtained through said first, second and third filter means.<br>9. A decoder for decoding a speech and musical sound signal, comprising: first filter means for producing a reproduced speech and musical sound signal corresponding to an input speech and musical sound signal by using only first linear prediction coefficients indicative of a periodic component of the speech and musical sound signal or using second linear prediction coefficients indicative of a fine spectral distribution of the speech and musical sound signal and the first linear prediction coefficients, on the basis of parameters of the input speech and musical sound signal; second filter means for producing the reproduced excitation signal of the speech and musical sound signal by using the second linear prediction coefficients; and third filter means for producing the reproduced speech and musical sound signal by using third linear prediction coefficients indicative of coarse spectral distribution of the input speech and musical sound signal, wherein the second linear prediction coefficients are calculated using the residual signal between the input signal and the reproduced signal obtained through said first, second and third filter means.<br>13. A coding and decoding system for coding and decoding a speech and musical sound signal, comprising: a coder comprising: first filter means for producing a reproduced speech and musical sound signal with first linear prediction coefficients indicative of a coarse spectral distribution of the speech and musical sound signal; second filter means for producing the reproduced excitation signal of the speech and musical sound signal with second linear prediction coefficients indicative of a fine spectral distribution of the speech and musical sound signal; third filter means for producing the reproduced excitation signal corresponding to the speech and musical sound signal by using only third linear prediction coefficients indicative of a periodic component of the speech and musical sound signal or using the third linear prediction coefficients and the second linear prediction coefficients; and means for producing parameters of the speech and musical sound signal produced on the basis of a residual signal between the speech and musical sound signal and a reproduced signal obtained through said first, second and third filter means, wherein the second linear prediction coefficients are calculated using the residual signal between the input signal and the reproduced signal obtained through said first, second and third filter means; and a decoder comprising: fourth filter means for producing the reproduced excitation signal corresponding to the speech and musical sound signal by using only the third linear prediction coefficients or using the second linear prediction coefficients and the third linear prediction coefficients, on the basis of parameters of the input speech and musical sound signal; fifth filter means for producing the reproduced excitation signal of the speech and musical sound signal by using the second linear prediction coefficients; and sixth filter means for producing the reproduced speech and musical sound signal of the speech and musical sound signal by using the first linear prediction coefficients.</p></layer>
<layer id = "layer63"><p><b>US4757517A:System for transmitting voice signal</b><br>An elongated electrical connector, elongated insulator block for holding several of the connectors and a jig or tool for assembling the block and connectors to a printed circuit board. The connectors are each provided with an intermediate mounting boss or plate with an opening that matches an opening in the side of the elongated block. The jig includes a series of movable claws which extend into the connector openings to align the connectors and drive them into matching apertures of a printed circuit board.<br><b>Independant Claims</b><br>1. A system for transmitting a voice signal comprising means having filter means for dividing an input voice signal into a low-frequency voice signal and a high-frequency voice signal, means for developing a predictive residual signal of the low-frequency voice signal, a waveform coder for coding said predictive signal, a waveform coder for coding said predictive residual signal in order to minimize the deterioration of its quality, transmission means for transmitting the coded predictive residual signal, means for developing from the high-frequency voice signal information indicative of a short-time frequency spectrum thereof, coding means for coding the indicative information for transmission by said transmission means, said waveform coder comprising an adaptive quantizer for obtaining a coded low-frequency voice signal to be transmitted, a short-time predictor for obtaining a short-time prediction value from the low-frequency voice signal, a long-time predictor for obtaining a long-time prediction value from the low-frequency voice signal, first subtraction means for substracting the short-time prediction value and the long-time prediction value from the low-frequency voice signal to obtain a residual signal, a dequantizer for dequantizing the coded low-frequency voice signal to obtain a quantized final residual signal, saecond substraction means for substracting the quantized final residual signal from an input of the adaptive quantizer to obtain quantized noise, a noise shaping filter for obatining shaped noise, and third subtraction means for subtracting the shaped noise from the residual signal to obtain a final residual signal to be employed as the input of the adaptive quantizer.</p></layer>
<layer id = "layer64"><p><b>US4975955A:Pattern matching vocoder using LSP parameters</b><br>A hoodless incubator is provided, which supplies both a good microclimate in the area of the patient surface (<b>1</b>) and guarantees good access to the patient at the same time and continuously. The incubator includes a bed (<b>1</b>) and an air jet unit (<b>6</b>) arranged above the bed (<b>1</b>) and directed toward the bed (<b>1</b>). The air jet unit (<b>6</b>) discharges a jacketed impinging jet, formed of an inner, air-conditioned core jet (<b>4</b>) and a non-air-conditioned jacket jet (<b>5</b>) surrounding the core jet (<b>4</b>). The bed (<b>1</b>) is surrounded by a channel-like edge area (<b>9</b>), which is in flow connection with the air jet unit (<b>6</b>) via a first feed channel (<b>13</b>) with a first fan (<b>11</b>) arranged therein and with a heating and humidifying device (<b>12</b>) likewise arranged therein in order to form the air-conditioned core jet (<b>4</b>).<br><b>Independant Claims</b><br>1. A speech signal processing system comprising: linear predictive coefficient (LPC) analysis means for deriving LPC parameters .alpha..sub.i (i=1,2, . . . n) from an input speech signal where i is the order of each LPC parameters; attenuation coefficient producing means for producing attenuation coefficients determined by said orders of said LPC parameters; attenuating means, coupled to said attenuation coefficient producing means and to said LPC analysis means, for attenuating said LPC parameters into attenuated LPC parameters by multiplying each LPC parameter by the attenuation coefficient corresponding to the order of the LPC parameter; line spectrum pair (LSP) analyzing means for deriving LSP parameters from said attenuated LPC parameters supplied from said attenuating means and for generating a sequence of said LSP parameters as an input pattern, said LSP parameters having frequency intervals dependent on said attenuation coefficients; a reference pattern memory for storing reference patterns, each composed of a sequence of LSP parameters obtained by LSP-analyzing a variety of a plurality of speech samples, each of said reference patterns being labeled by a label; and pattern matching means, connected to said LSP analyzing means and to said reference pattern memory, for selecting a reference pattern, most closely resembling said input pattern, from said reference pattern memory and for coding said label corresponding to said selected reference pattern.</p></layer>
<layer id = "layer65"><p><b>US5668927A:Method for reducing noise in speech signals by adaptively controlling a maximum likelihood filter for calculating speech components</b><br><b>Independant Claims</b><br>1. A method for reducing noise in an input speech signal in which noise suppression is done by adaptively controlling a maximum likelihood filter adapted for calculating speech components based on a probability of speech occurrence, wherein the improvement comprises the steps of: calculating a spectrum of said input speech signal; estimating a noise spectrum and a signal to-noise ratio of said input signal; employing a difference between said spectrum of said input speech signal and said estimated noise spectrum in calculating said probability of speech occurrence; and controlling said maximum likelihood filter using said calculated probability of speech occurrence and said signal-to-noise ratio.<br>3. A method for reducing noise in an input speech signal in which noise suppression is done by adaptively controlling a maximum likelihood filter adapted for calculating speech components based on a probability of speech occurrence, wherein the improvement comprises the steps of: estimating the noise spectrum of an input signal; calculating a difference between a spectrum of an input signal and said estimated noise spectrum; finding the larger value of said difference or a pre-set value for a current frame and for a previous frame; multiplying the value for the previous frame by a pre-set decay coefficient; and employing the larger of the value for the current frame or the value for the previous frame multiplied by the pre-set decay coefficient for calculating the probability of speech occurrence.<br>5. A method for reducing noise in an input speech signal in which noise suppression is done by adaptively controlling a maximum likelihood filter adapted for calculating speech components based on a probability of speech occurrence, wherein the improvement comprises the steps of: estimating the noise spectrum of an input signal; employing a difference between a spectrum of an input signal and said estimated noise spectrum in calculating the probability of speech occurrence, wherein the step of estimating the noise spectrum estimates the noise spectrum by comparing frame-based root-mean-square values to a threshold value Th.sub.1, a value th for finding the threshold value Th.sub.1 is found responsive to the smaller one of the root-mean-square value for the current frame or the value th of the previous frame multiplied with a coefficient a, and the coefficient a is changed over depending on the root-mean-square value for the current frame.</p></layer>
<layer id = "layer66"><p><b>US5091944A:Apparatus for linear predictive coding and decoding of speech using residual wave form time-access compression</b><br>A coin counting apparatus having a resiliently deformable frame adapted to carry a plurality of stacked coins. The apparatus includes a support for the frame and an abutment for causing resilient deformation of the frame so as to carry the coins upon relative movement of the frame and the abutment.<br><b>Independant Claims</b><br>1. A speech coding apparatus used for the linear predictive coding of an input speech signal, said apparatus comprising: a linear predictive analyzing means for calculating a linear predictive coefficient by the linear predictive analysis of the waveform of an input speech signal for every predetermined analysis frame; a linear predictive inverse filtering means for obtaining a linear predictive residual signal from said speech signal by using said linear predictive coefficient calculated by said linear predictive analyzing means; a pitch analyzing means for calculating the pitch periods of the waveform of said linear predictive residual signal and for calculating the strength of the correlativity between the pitch periods of the waveform of said linear predictive residual signal for each of a plurality blocks which constitute said analyzing frame; a residual signal partially compressing means for compressing the time axis of said linear predictive residual signal for each block correspondence with said strength of correlativity of said waveform calculated by said pitch analyzing means; and a residual signal quantizing means for quantizing said linear predictive residual signal which has been subject to time-axis compressing by said residual signal partially compressing means and for generating a quantized linear predictive residual signal.<br>7. A speech coding apparatus used for the linear predictive coding of an input speech signal, said apparatus comprising: a linear predictive analyzing means for calculating a linear predictive coefficient by the linear predictive analysis of the waveform of an input speech signal for every predetermined analyzing frame; a linear predictive inverse filtering means for obtaining a linear predictive residual signal from said speech signal by using said linear predictive coefficient calculated by said linear predictive analyzing means; a pitch analyzing means for calculating the pitch periods of the waveform of said linear predictive residual signal and for calculating the strength of the correlativity between the pitch periods of the waveforms of said linear predictive residual signal for each of a plurality of blocks which constitute said analyzing frame; a residual signal partially compressing means for compressing only the time axis of said linear predictive residual signal for every two adjacent pitch period sections for the block in which said strength of correlativity of said waveform calculated by said pitch analyzing means is not less than a predetermined threshold value and is larger than the strength of correlativity of said waveform in another block into a residual signal for one pitch period section repeatedly in accordance with the following equation: RC.sub.i =(RS.sub.i+p)/2 wherein RC.sub.i represents the linear predictive residual signal waveform in a one-pitch period section after compression, RS.sub.i the linear predictive residual signal waveform in a one-pitch period section before compression, and RS.sub.i+p the linear predictive residual signal waveform in a one-pitch period section adjacent to RS.sub.i before compression; a residual signal quantizing means for quantizing said linear predictive residual signal by allotting 1 bit from a predetermined number of bits to all samples of said linear predictive residual signal and further allotting 1 bit from the bits remaining after allotment to the samples of said linear predictive residual signal in the block which has been subjected to time-axis compression and for generating a quantized linear predictive residual signal; and a multiplexing means for multiplexing a linear predictive coefficient signal output from said linear predictive analyzing means, a pitch period signal output from said pitch analyzing means, a compression information relating to a compressing block and a compressing means and a quantized linear predictive residual signal output from said residual signal quantizing means, and outputting the thus-obtained signal to a transmission path.<br>8. A speech decoding apparatus for decoding a speech signal which is linear predictively coded with a part thereof subjected to time-axis compression by a speech coding apparatus having a residual signal partially compressing means, said apparatus comprising: a separating means for separating from an input signal a linear predictive coefficient signal, a quantized linear predictive residual signal, a pitch period signal of said linear predictive residual signal and a compressing signal relating to a time-axis compressed portion and a compressed state; a residual signal inverse quantizing means for inversely quantizing said quantized linear predictive residual signal which is separated by said separating means; a residual signal partially expanding means for partially expanding said linear predictive residual signal which is inversely quantized by said residual signal inverse quantizing means on the basis of said pitch period signal and said compression signal which are separated by said separating means; and a linear predictive synthetic filtering means for obtaining a speech signal from said linear predictive residual signal which is partially expanded by said residual signal partially expanding means on the basis of said linear predictive coefficient signal which is separated by said separating means.</p></layer>
<layer id = "layer67"><p><b>US4435832A:Speech synthesizer having speech time stretch and compression functions</b><br>Apparatus for compressing stacks of flat superposed sheet articles such as bags and enveloping the stacks in packaging film comprises a pressure chamber through an inlet aperture of which each stack is lifted by a pressure ram, together with a packaging film that initially spans the inlet aperture and comes to lie along the top and sides of the stack after the latter has been inserted in the pressure chamber. Following compression of the stack between the ram and a removable backing member at the top of the chamber, a reciprocatable push member having one end disposed adjacent the inlet aperture executes a forward stroke to cover the underside of the stack while the ram is laterally retracted, whereby the enveloped stack is supported by the push member on termination of its forward stroke. Welding means for joining the ends of the enveloping film co-operate with the push member, which comprises a frame and a plurality of parallel rollers freely rotatably mounted in said frame. Means for lowering the other end of the push member during or after its return stroke enable said push member additionally to act as a roller ramp for withdrawing the enveloped stack supported thereby.<br><b>Independant Claims</b><br>1. A speech synthesizer comprising: (a) speech parameter providing means for providing n-linear predictive coefficients sampled from segmental waveforms truncated from natural speech at a given time interval, voice/unvoice judging information, pitch information, and volume information; (b) speech reconstruction means including a speech synthesizing filter whose coefficients change at given intervals on the basis of the linear predictive coefficients to synthesize and provide speech in accordance with the speech parameters delivered from speech parameter providing means; (c) interpolating means provided between said speech reconstruction means and said speech parameter providing means, for interpolating the linear predictive coefficients inputted at given intervals, at a time interval of at least 10 ms or less and for supplying the interpolated linear predictive coefficients to said speech reconstruction means; and (d) timing control means for producing a synthesizing timing signal responsive to a signal for setting a speech reproduction speed and supplying the synthesizing timing signal to said speech parameter providing means and said interpolating means for changing the time interval of interpolation of the interpolating means; whereby the speech outputting time is stretchable and compressible without changing the pitch information provided by said speech parameter providing means while ensuring reconstruction of a smooth speech.<br>5. A speech synthesizer capable of stretching and compressing the speech time comprising: (a) speech parameter storing means for storing speech parameters including PARCOR coefficients sampled from segmental waveforms for a given frame period taken out from natural speech by a speech analysis; (b) speech synthesizing means including a multi-stage digital filter whose coefficients change every frame on the basis of the PARCOR coefficients contained in the speech parameters read out from said storing means in response to said speech parameters, and execute operations to synthesize speech together with remaining parameters; (c) interpolation means for interpolating the PARCOR coefficients for each frame read out from said storing means at a time interval of at least 10 ms or less to thereby provide the filter coefficients of said multi-stage digital filter; (d) timing control means for producing a synthesizing timing signal responsive to a signal for setting a speech reproduction speed and supplying the synthesizing timing signal to said speech parameter storing means, and said interpolating means at a time interval different from the frame period of said speech analysis; (e) reproduction speed setting means including a counter for updating the synthesizing timing signal of said timing synthesizing means in accordance with an input signal at a desired speech reproduction speed.<br>8. A speech synthesizer comprising: (a) speech parameter providing means for providing n-linear predictive coefficients sampled from segmented waveforms truncated from natural speech at a given time interval, voice/unvoice judging information, pitch information, and volume information; (b) speech reconstruction means including a speech synthesizing filter whose coefficients change at given intervals on the basis of the linear predictive coefficients to synthesize and provide speech in accordance with the speech parameters delivered from speech parameter providing means; (c) interpolating means provided between said speech reconstruction means and said speech parameter providing means, for interpolating the linear predictive coefficient inputted at given intervals, at a time interval of at least 10 ms or less and for supplying the interpolated linear predictive coefficient to said speech reconstruction means; and (d) timing control means for controlling the synthesis of speech by the speech reconstruction means at a constant rate in accordance with the speech parameters and for producing an interpolation signal of variable interval for causing the interpolation of said speech parameters from said speech parameter providing means in response to a signal for setting a speech reproduction speed.<br>12. A speech synthesizer capable of stretching and compressing the speech time comprising: (a) speech parameter storing means for storing speech parameters including PARCOR coefficients sampled from segmental waveforms for a given frame period taken out from natural speech by a speech analysis; (b) speech synthesizing means including a multi-stage digital filter, which updates the coefficients of said multi-stage digital filter every frame on the basis of the PARCOR coefficients contained in the speech parameters read out from said storing means in response to said speech parameters, and executes operations to synthesize speech together with remaining parameters; (c) interpolation means for interpolating the PARCOR coefficients for each frame read out from said storing means at a time interval of at least 10 ms or less to thereby provide the filter coefficients of said multi-stage digital filter; (d) timing control means for controlling the synthesis of speech by the speech synthesizing means at a constant rate in accordance with the speech parameters and for producing an interpolation signal of variable interval for causing the interpolation of said speech parameters from said speech parameter providing means in response to a signal for setting a speech reproduction speed; and (e) reproduction speed setting means including a counter for updating the interpolation signal of said timing control means in accordance with an input signal at a desired speech reproduction speed.</p></layer>
<layer id = "layer68"><p><b>US6829360B1:Method and apparatus for expanding band of audio signal</b><br>A method includes the steps of receiving (<highlight><bold>402</bold></highlight>), by a first receiver (<highlight><bold>102</bold></highlight>), a first received signal comprising a first signal (<highlight><bold>110</bold></highlight>) and a second signal (<highlight><bold>120</bold></highlight>), and receiving (<highlight><bold>402</bold></highlight>), by a second receiver (<highlight><bold>104</bold></highlight>), a second received signal comprising the first signal (<highlight><bold>110</bold></highlight>) and the second signal (<highlight><bold>120</bold></highlight>). A branch weight associated with the first receiver (<highlight><bold>102</bold></highlight>) and at least one other branch weight associated with the second receiver (<highlight><bold>104</bold></highlight>) are determined (<highlight><bold>406</bold></highlight>). The branch weight associated with the first receiver (<highlight><bold>102</bold></highlight>), the at least one other branch weight associated with the second receiver (<highlight><bold>102</bold></highlight>), the first received signal, and the second received signal are combined, forming a combined signal. Channel state information is determined for the combined signal, and the channel state information of the combined signal is restored (<highlight><bold>412</bold></highlight>).<br><b>Independant Claims</b><br>1) A method for expanding a band of an audio signal comprising: oversampling a digital audio signal of a first band having a predetermined maximum frequency with a sampling frequency that is two or more times the maximum frequency to produce an oversampled digital audio signal, and low-pass-filtering the oversampled digital audio signal so as to eliminate aliasing noise caused by the oversampling, and outputting the low-pass-filtered oversampled digital audio signal; calculating a spectrum intensity of a predetermined band of the low-pass-filtered oversampled digital audio signal, and outputting a signal indicating the calculated spectrum intensity; generating an expanded signal having frequency components of a second band higher than the first band; controlling a level of the expanded signal in response to the signal indicating the calculated spectrum intensity; and adding the expanded signal having the controlled level to the low-pass-filtered oversampled digital audio signal to produce an addition resultant digital audio signal, wherein said generating the expanded signal comprises: distorting the digital audio signal by performing nonlinear processing on the low-pass-filtered oversampled digital audio signal with a non-linear input and output characteristic, and generating a digital signal having higher harmonic components of the digital audio signal; and high-pass-filtering at least frequency components equal to or higher than the second band, from the digital signal having the higher harmonic components to produce a high-pass-filtered signal, and outputting the high-pass-filtered signal as the expanded signal.<br>4) A method for expanding a band of an audio signal comprising: oversampling a digital audio signal of a first band having a predetermined maximum frequency with a sampling frequency that is two or more times the maximum frequency to produce an oversampled digital audio signal, and low-pass-filtering the oversampled digital audio signal so as to eliminate aliasing noise caused by the oversampling, and outputting the low-pass-filtered oversampled digital audio signal; calculating a spectrum intensity of a predetermined band of the low-pass-filtered oversampled digital audio signal, and outputting a signal indicating the calculated spectrum intensity; generating an expanded signal having frequency components of a second band higher than the first band; controlling a level of the expanded signal in response to the signal indicating the calculated spectrum intensity; and adding the expanded signal having the controlled level to the low-pass-filtered oversampled digital audio signal to produce a first addition resultant digital audio signal, wherein said generating the expanded signal comprises: distorting the digital audio signal by performing nonlinear processing on the low-pass-filtered oversampled digital audio signal with a non-linear input and output characteristic, and generating a digital signal having higher harmonic components of the digital audio signal; high-pass-filtering at least frequency components equal to or higher than the second band, from the digital signal having the higher harmonic components to produce a first high-pass-filtered signal, and outputting the first high-pass-filtered signal; generating a dither signal having a predetermined probability distribution for an amplitude level; high-pass-filtering at least frequency components equal to or higher than the second band from the dither signal to produce a second high-pass-filtered signal, and outputting the second high-pass-filtered signal; and adding the two high-pass-filtered signals to produce a second addition resultant signal, and outputting the second addition resultant signal as the expanded signal.<br>7) A method for expanding a band of an audio signal comprising: oversampling a digital audio signal of a first band having a predetermined maximum frequency with a sampling frequency that is two or more times the maximum frequency to produce an oversampled digital audio signal, and low-pass-filtering the oversampled digital audio signal so as to eliminate aliasing noise caused by the oversampling, and outputting the low-pass-filtered oversampled digital audio signal; calculating a spectrum intensity of a predetermined band of the low-pass-filtered oversampled digital audio signal, and outputting a signal indicating the calculated spectrum intensity; generating an expanded signal having frequency components of a second band higher than the first band; controlling a level of the expanded signal in response to the signal indicating the calculated spectrum intensity; and adding the expanded signal having the controlled level to the low-pass-filtered oversampled digital audio signal to produce an addition resultant digital audio signal, wherein said generating the expanded signal comprises: generating a dither signal having a predetermined probability distribution for an amplitude level; and high-pass-filtering at least frequency components equal to or higher than the second band, from the dither signal to produce a high-pass-filtered signal, and outputting the high-pass-filtered signal as the expanded signal, wherein said generating the dither signal comprises: generating a plurality of pseudo noise sequence noise signals independent of each other, respectively; and adding the plurality of pseudo noise sequence noise signals, generating an addition resultant dither signal having a probability density of one of a Gaussian distribution and a bell-shaped distribution for an amplitude level, and outputting the dither signal as the expanded signal.<br>10) An apparatus for expanding a band of an audio signal comprising: a filter operable to oversample a digital audio signal of a first band having a predetermined maximum frequency with a sampling frequency that is two or more times the maximum frequency to produce an oversampled digital audio signal, and low-pass-filter the oversampled digital audio signal so as to eliminate aliasing noise caused by the oversampling, and output the low-pass-filtered oversampled digital audio signal; a first spectrum analyzer circuit operable to calculate a spectrum intensity of a predetermined band of the low-pass-filtered oversampled digital audio signal outputted from said filter, and output a signal indicating the calculated spectrum intensity; an expanded signal generating circuit operable to generate an expanded signal having frequency components of a second band higher than the first band; a level control circuit operable to control a level of the expanded signal in response to the signal indicating the calculated spectrum intensity outputted from said first spectrum analyzer circuit; and a first adder operable to add the expanded signal whose level is controlled by said level control circuit to the low-pass-filtered oversampled digital audio signal outputted from said filter to produce an addition resultant digital audio signal, wherein said expanded signal generating circuit comprises: a non-linear processing circuit, having a non-linear input and output characteristic, operable to distort the digital audio signal by performing non-linear processing on the low-pass-filtered oversampled digital audio signal outputted from said filter, and generate a digital signal having higher harmonic components of the digital audio signal; and a first high-pass filter operable to high-pass-filter at least frequency components equal to or higher than the second band, from the digital signal having the higher harmonic components outputted from said non-linear processing circuit to produce a high-pass-filtered signal, and output the high-pass-filtered signal as the expanded signal.<br>13) An apparatus for expanding a band of an audio signal comprising: a filter operable to oversample a digital audio signal of a first band having a predetermined maximum frequency with a sampling frequency that is two or more times the maximum frequency to produce an oversampled digital audio signal, and low-pass-filter the oversampled digital audio signal so as to eliminate aliasing noise caused by the oversampling, and output the low-pass-filtered oversampled digital audio signal; a first spectrum analyzer circuit operable to calculate a spectrum intensity of a predetermined band of the low-pass-filtered oversampled digital audio signal outputted from said filter, and output a signal indicating the calculated spectrum intensity; an expanded signal generating circuit operable to generate an expanded signal having frequency components of a second band higher than the first band; a level control circuit operable to control a level of the expanded signal in response to the signal indicating the calculated spectrum intensity outputted from said first spectrum analyzer circuit; and a first adder operable to add the expanded signal whose level is controlled by said level control circuit to the low-pass-filtered oversampled digital audio signal outputted from said filter to produce a first addition resultant digital audio signal, wherein said expanded signal generating circuit comprises: a non-linear processing circuit, having a non-linear input and output characteristic, operable to distort the digital audio signal by performing non-linear processing on the low-pass-filtered oversampled digital audio signal outputted from said filter, and generate a digital signal having higher harmonic components of the digital audio signal; a first high-pass filter operable to high-pass-filter at least frequency components equal to or higher than the second band, from the digital signal having the higher harmonic components outputted from said non-linear processing circuit to produce a first high-pass-filtered signal, and output the first high-pass-filtered signal; a dither signal generating circuit operable to generate a dither signal having a predetermined probability distribution for an amplitude level; a second high-pass filter operable to high-pass-filter at least frequency components equal to or higher than the second band, from the dither signal outputted from said dither signal generating circuit to produce a second high-pass-filtered signal, and output the second high-pass-filtered signal; and a second adder operable to add the signal outputted from the first high-pass filter to the signal outputted from the second high-pass filter to produce a second addition resultant signal, and output the second addition resultant signal as the expanded signal.<br>16) An apparatus for expanding a band of an audio signal comprising: a filter operable to oversample a digital audio signal of a first band having a predetermined maximum frequency with a sampling frequency that is two or more times the maximum frequency to produce an oversampled digital audio signal, and low-pass-filter the oversampled digital audio signal so as to eliminate aliasing noise caused by the oversampling, and output the low-pass-filtered oversampled digital audio signal; a first spectrum analyzer circuit operable to calculate a spectrum intensity of a predetermined band of the low-pass-filtered oversampled digital audio signal outputted from said filter, and output a signal indicating the calculated spectrum intensity; an expanded signal generating circuit operable to generate an expanded signal having frequency components of a second band higher than the first band; a level control circuit operable to control a level of the expanded signal in response to the signal indicating the calculated spectrum intensity outputted from said first spectrum analyzer circuit; and a first adder operable to add the expanded signal whose level is controlled by said level control circuit to the low-pass-filtered oversampled digital audio signal outputted from said filter to produce an addition resultant digital audio signal, wherein said expanded signal generating circuit comprises: a dither signal generating circuit operable to generate a dither signal having a predetermined probability distribution for an amplitude level; and a high-pass filter operable to high-pass-filter at least frequency components equal to or higher than the second band, from the dither signal outputted from said dither signal generating circuit to produce a high-pass-filtered signal, and output the high-pass-filtered signal as the expanded signal, wherein said dither signal generating circuit comprises: a plurality of noise signal generating circuits operable to generate a plurality of pseudo noise sequence noise signals independent of each other, respectively; and a second adder operable to the plurality of pseudo noise sequence noise signals generated by the noise signal generating circuits, generate an addition resultant dither signal having a probability density of one of a Gaussian distribution and a bell-shaped distribution for an amplitude level, and output the dither signal as the expanded signal.</p></layer>
<layer id = "layer69"><p><b>US6052660A:Adaptive codebook</b><br>A class of substituted imidazolo[5,1-a]phthalazine derivatives as ligands for GABA<sub>A </sub>receptors of formula I<chemistry id="CHEM-US-00001" num="00001"><img id="EMI-C00001" he="27.43mm" wi="54.10mm" file="US06949549-20050927-C00001.TIF" alt="embedded image" img-content="chem" img-format="tif"/></chemistry><br/>which are partial or full inverse agonists of an α5 receptor subunit while being relatively free of activity at α1 and/or α2 and/or α3 receptor subunit binding sites are described herein; they are therefore of benefit as a medicament for enhancing cognition but with the reduction or elimination of proconvulsant activity.<br><b>Independant Claims</b><br>1. An adaptive codebook generator in a coder of CELP for coding a speech signal or audio signal to index data, and also in a decoder for decoding the index data to the speech signal or audio signal, comprising: an index memory that provides a fixed codebook index preceding by i frames, an adaptive codebook index and gain indexes; a first fixed codebook that provides a first signal series according to the fixed codebook index preceding by i frames; an excitation signal memory that provides a second signal series according to the adaptive codebook index preceding by i frames; an excitation signal generator that generates an excitation signal of at least one frame by using the outputs of the first fixed codebook and the excitation signal memory and the gain indexes; and a first adaptive codebook that produces an adaptive codebook signal on the basis of the output of the excitation signal memory; the coder further comprising: a second adaptive codebook that produces an excitation vector signal corresponding to pitch vector including a component dependent on a periodicity of the speech signal; a second fixed codebook that produces an excitation output vector corresponding to a codevector of a non-periodic component of the speech signal; a first and a second multiplier that respectively multiply the excitation vector signal and excitation output vector by respective first and second gains; an adder that generates an excitation signal of a current frame by adding together the two product outputs of the first and second multipliers; a synthesizing filter that generates a reproduced signal based on the excitation signal of the current frame; a subtracter, responsive to the reproduced signal, that produces an error between the reproduced signal and an input signal; and an error power evaluator that controls and scans the outputs of the second adaptive and fixed codebooks and the gains of the first and second multipliers for each frame, and that produces an excitation signal corresponding to a minimum error to be the optimal excitation signal, wherein data stored in the excitation signal memory is updated according to the excitation signal.<br>2. An adaptive codebook generator in a coder of CELP for coding a speech signal or audio signal to index data, and also in a decoder for decoding the index data to the speech signal or audio signal, comprising: an index memory that provides a fixed codebook index preceding by i frames, an adaptive codebook index and gain indexes; a first fixed codebook that provides a first signal series according to the fixed codebook index preceding by i frames; an excitation signal memory that provides a second signal series according to the adaptive codebook index preceding by i frames; an excitation signal generator that generates an excitation signal of at least one frame by using the outputs of the first fixed codebook and the excitation signal memory and the gain indexes; and a first adaptive codebook that produces an adaptive codebook signal on the basis of the output of the excitation signal memory; the decoder further comprising: a second adaptive codebook that produces an excitation vector signal corresponding to pitch vector including a component dependent on a periodicity of the speech signal; a second fixed codebook that produces an excitation output vector corresponding to a codevector of a non-periodic component of the speech signal; a first and a second multiplier that respectively multiply the excitation vector signal and excitation output vector by respective first and second gains; an adder that generates an excitation signal of a current frame by adding together the two product outputs of the first and second multipliers; a synthesizing filter that generates a reproduced signal based on the excitation signal of the current frame; and a post-filter, cascade connected to the output of the synthesizing filter, that generates a reconstituted speech signal signal, wherein data stored in the excitation signal memory is updated according to the excitation signal.</p></layer>
<layer id = "layer70"><p><b>US6212495B1:Coding method, coder, and decoder processing sample values repeatedly with different predicted values</b><br>A device for reducing certain sound ranges of tire/road surface noise of a motor vehicle includes sound absorbers in the form of resonators positioned at the inner wall of a wheel well of the vehicle in the area of sound projection of the tire/road surface noise. The device has an electronic control device for receiving a signal preferably derived from an ABS system in the form of the wheel rpm. The control device adjusts the resonators according to the number of tread blocks of the tire, the sound emission characteristics, and the wheel rpm. In another embodiment the electronic control device is supplied with signals received from a sound receiver that records the course over time of the sound pressure. The control device adjusts the resonators such that the measured sound pressure signal is minimized. In another alternative the device has a data processing unit including an electronic control device. The control device is supplied with a signal from sound receiving devices that record the course over time of the sound pressure. The data processing unit together with an adjusting device adjusts the resonators such that the measured sound pressure signal for selected frequency ranges is minimized.<br><b>Independant Claims</b><br>1. A coding method comprising the steps of: (a) receiving successive sample values of an audio signal; (b) calculating a predicted value of a current sample value among the successive sample values in said audio signal; (c) calculating a difference between said current sample value and said predicted value; (d) quantizing said difference, obtaining a quantized value; (e) coding said quantized value, obtaining coded data; (f) calculating a predicted value of a next sample value among the successive sample values in said audio signal from the predicted value and the quantized value of said current sample value; and (g) repeating said steps (b) to (f) for said current sample value, using at least one different predicted value in said step (b).<br>10. A coder, comprising: an input terminal receiving an audio signal having sample values grouped into frames; a subtractor coupled to said input terminal, said subtractor taking a difference between a current sample value in said audio signal and a predicted value of said current sample value, thereby obtaining a difference value; a quantizing and coding unit coupled to said subtractor, quantizing and coding said difference value, thereby obtaining a quantized value and coded data representing said quantized value; an error calculator coupled to said quantizing and coding unit, calculating a quantization error for each frame of said sample values; a predictor coupled to said quantizing and coding unit, using said quantized value, the predicted value of said current sample value, and a coefficient to calculate a predicted value of a next sample value in said audio signal; and a coefficient selector coupled to said predictor, providing said coefficient to said predictor, causing said predictor and said quantizing and coding unit to code each said frame repeatedly using different values of said coefficient, selecting a value of said coefficient that produces a least quantization error for said frame, causing said quantizing and coding unit to output the coded data produced using the selected value of said coefficient, and appending information identifying said selected value to the coded data output for said frame.<br>18. A coder, comprising: an input terminal receiving an audio signal having sample values grouped into frames; a subtractor coupled to said input terminal, said subtractor taking a difference between a current sample value in said audio signal and a corresponding predicted value, thereby obtaining a difference value; a quantizing and coding unit coupled to said subtractor, using a step function to quantize and code said difference value, thereby obtaining a quantized value and coded data representing said quantized value; an error calculator coupled to said quantizing and coding unit, calculating a quantization error for each frame of said sample values; a predictor coupled to said quantizing and coding unit, calculating a predicted value of a next sample value in said audio signal from the quantized value and the predicted value of said current sample value; and a step-function selector coupled to said quantizing and coding unit, providing said step function to said quantizing and coding unit, causing said predictor and said quantizing and coding unit to code each said frame repeatedly using different step functions, selecting a step function that produces a least quantization error for said frame, causing said quantizing and coding unit to output the coded data produced using the selected step function, and appending information identifying said selected step function to the coded data output for said frame.<br>26. A coder, comprising: an input terminal receiving an audio signal having sample values grouped into frames; a predictor calculating a predicted value of a current sample value in said audio signal; a subtractor coupled to said input terminal and said predictor, taking a difference between aid current sample value and said predicted value, thereby obtaining a difference value; a quantizing and coding unit coupled to said subtractor, quantizing and coding said difference value, thereby obtaining a quantized value and coded data representing said quantized value; and a repetition controller coupled to said quantizing and coding unit, causing said predictor, said subtractor, and said quantizing and coding unit to process said current sample value again, using a different predicted value of said current sample value, when said coded data represent a maximum absolute quantized value.<br>33. A coding method, comprising the steps of: (a) providing a sequence of sample values derived from an analog information signal that carries information about a stimulus perceptible to a human sense organ; (b) calculating a predicted value of a current sample value among the successive sample values in said information signal; (c) calculating a difference between said current sample value and said predicted value; (d) quantizing said difference, obtaining a quantized value; (e) coding said quantized value, obtaining coded data; (f) calculating a predicted value of a next sample value among the successive sample values in said information signal from the predicted value and the quantized value of said current sample value; and (g) repeating said steps (b) to (f) for said current sample value, using at least one different predicted value in said step (b).</p></layer>
<layer id = "layer71"><p><b>US5245662A:Speech coding system</b><br><b>Independant Claims</b><br>1. A speech coding system constructed under a code-excited linear prediction (CELP) coding algorithm, including: an adaptive codebook storing therein a plurality of pitch prediction residual vectors and providing an output; a sparse-stochastic codebook storing therein, as white noise, a plurality of code vectors and providing an output; first and second gain amplifiers, respectively coupled to said adaptive codebook and said sparse-stochastic codebook, for applying a first gain and a second gain to the outputs from said adaptive and sparse-stochastic codebooks respectively; and an evaluation unit, coupled to said adaptive and sparse-stochastic codebooks, for selecting optimum vectors and optimum gains which match a perceptually weighted input speech signal, to provide the selected optimum vectors and optimum gains as coded information for each input speech signal, said sparse-stochastic codebook being formed as a hexagonal lattice code vector stochastic codebook in which particular code vectors are loaded, said code vectors being hexagonal lattice code vectors each consisting of a zero vector with one sample set to +1 and another sample set to -1.<br>10. A speech coding system, comprising: an adaptive codebook storing therein a plurality of pitch prediction residual vectors and providing an output; a sparse-stochastic codebook storing therein a plurality of code vectors formed as multi-dimensional polyhedral lattice vectors each consisting of a zero vector with one sample set to +1 and another sample set to -1, said sparse-stochastic codebook providing an output; and an evaluation unit, coupled to said adaptive and sparse-stochastic codebooks, for selecting optimum vectors and optimum gains which match a perceptually weighted input speech signal, to provide the selected optimum vectors and optimum gains as coded information for each input speech signal.</p></layer>
<layer id = "layer72"><p><b>US5937378A:Wideband speech coder and decoder that band divides an input speech signal and performs analysis on the band-divided speech signal</b><br>A detector for detecting hot wheels or bearings on a railroad car includes an infrared sensor supported within a detector by a sensor housing. Elastic balls are disposed in the housing to absorb shocks generated by a train passing the detector.<br><b>Independant Claims</b><br>1. A wideband speech coding system, comprising: an LPC analyzing unit configured to receive an input speech signal and to calculate LPC coefficients of the input speech signal based on an LPC analysis of the input speech signal; an LPC coding unit communicatively connected to the LPC analyzing unit and configured to code the LPC coefficients that have been calculated by the LPC analyzing unit; an impulse response unit communicatively connected to the LPC coding unit and configured to calculate an impulse response of the input speech signal based on the coded LPC coefficients; a first band divider communicatively connected to the impulse response unit and configured to divide the impulse response of the input speech signal into first through nth frequency bands, n being an integer greater than one; first through nth LPC analyzer units communicatively connected to receive a corresponding one of the first through nth frequency bands of the input speech signal output from the first band divider, the first through nth LPC analyzer units configured to calculate first through nth subband LPC coefficients, respectively; a second band divider configured to receive the input speech signal and to divide the input speech signal into first through nth subband signals respectively located in the first through nth frequency bands; first through nth coder units communicatively connected to the second band divider and a corresponding one of the first through nth LPC analyzer units, the first through nth coder units configured to code an excitation signal using a corresponding one of the first through nth subband signals and a corresponding one of the first through nth subband LPC coefficients; and a multiplexing unit communicatively connected to the first through nth coder units and configured to modulate the coded excitation signal to create a modulated signal, and to output the modulated signal to an output terminal.<br>2. A wideband speech decoding system, comprising: a demultiplexing unit configured to receive a modulated signal and to demodulate the modulated signal and to output a first signal as a result; an LPC decoder unit communicatively connected to the demultiplexing unit and configured to perform LPC analysis so as to obtain LPC coefficients from the first signal; an impulse response unit communicatively connected to the LPC decoder unit and configured to calculate an impulse response of the first signal based on the LPC coefficients; a band divider communicatively connected to the impulse response unit and configured to divide the impulse response of the first signal into first through nth frequency bands, n being an integer greater than one; first through nth LPC analyzer units communicatively connected to receive a corresponding one of the first through nth frequency bands of the first signal output from the band divider, the first through nth LPC analyzer units configured to calculate first through nth subband LPC coefficients, respectively; first through nth decoder units configured to receive and decode the modulated signal and to obtain first through nth excitation signals for the first through nth frequency bands, respectively; first through nth reproducing units communicatively connected to a corresponding one of the first through nth decoder units and a corresponding one of the first through nth LPC analyzer units, the first through nth reproducing units configured to reproduce a subband speech signal in the first through nth frequency bands, respectively, based on a corresponding one of the first through nth excitation signals and a corresponding one of the first through nth subband LPC coefficients; and a fullband synthesizing unit communicatively connected to the first through nth reproducing units and configured to create a fullband signal based on the corresponding subband speech signals in the first through nth frequency bands respectively output by the first through nth reproducing units.<br>3. A wideband speech coding system, comprising: an LPC analyzing unit configured to receive an input speech signal and to calculate LPC coefficients of the input speech signal based on an LPC analysis of the input speech signal; an LPC coding unit communicatively connected to the LPC analyzing unit and configured to code the LPC coefficients that have been calculated by the LPC analyzing unit; a first band divider communicatively connected to the LPC coding unit and configured to divide a frequency band of the LPC coefficients into first through nth frequency bands, n being an integer greater than one, the first band divider further configured to calculate first subband LPC coefficients for the respective first through nth frequency bands; a second band divider configured to receive the input speech signal and to divide the input speech signal into first through nth subband signals respectively located in the first through nth frequency bands, the second band divider further configured to calculate second subband LPC coefficients for the respective first through nth frequency bands; first through nth coder units communicatively connected to the first and second band dividers, the first through nth coder units configured to code an excitation signal for each of the first through nth frequency bands using the first and second subband LPC coefficients for the respective first through nth frequency bands; and a multiplexing unit communicatively connected to the first through nth coder units and configured to modulate the coded excitation signal to create a modulated signal, and to output the modulated signal to an output terminal.<br>4. A wideband speech decoding system, comprising: a demultiplexing unit configured to receive a modulated signal and to demodulate the modulated signal and to output a first signal as a result; an LPC decoder unit communicatively connected to the demultiplexing unit and configured to perform LPC analysis so as to obtain LPC coefficients from the first signal; a band divider communicatively connected to the LPC decoder unit and configured to divide the first signal into first through nth frequency bands, n being an integer greater than one, the band divider further configured to calculate first subband LPC coefficients for the respective first through nth frequency bands; first through nth decoder units configured to receive the modulated signal and to obtain first through nth excitation signals for first through nth frequency bands, respectively; first through nth reproducing units communicatively connected to receive the first subband LPC coefficients for a corresponding one of the first through nth frequency bands of the first signal output from the band divider, and communicatively connected to receive a corresponding one of the first through nth excitation signals respectively output from the first through nth decoder units, the first through nth reproducing units configured to demodulate a subband speech signal for each of the first through nth frequency bands as a result; and a fullband synthesizing unit communicatively connected to the first through nth reproducing units and configured to create a fullband signal based on the corresponding subband speech signals in the first through nth frequency bands respectively output by the first through nth reproducing units.<br>5. A wideband speech coding system, comprising: an LPC analyzing unit configured to receive an input speech signal and to calculate LPC coefficients of the input speech signal based on an LPC analysis of the input speech signal; an LPC coding unit communicatively connected to the LPC analyzing unit and configured to code the LPC coefficients that have been calculated by the LPC analyzing unit; an impulse response unit communicatively connected to the LPC coding unit and configured to calculate an impulse response of the input speech signal based on the coded LPC coefficients; a first band divider communicatively connected to the impulse response unit and configured to divide the impulse response of the input speech signal into first through nth frequency bands, n being an integer greater than one; a second band divider configured to receive the input speech signal and to divide the input speech signal into first through nth subband signals respectively located in the first through nth frequency bands, the second band divider further configured to calculate second subband LPC coefficients for the respective first through nth frequency bands; first through nth coder units communicatively connected to the first and second band dividers, the first through nth coder units configured to code an excitation signal for each of the first through nth frequency bands using the first and second subband LPC coefficients for the respective first through nth frequency bands; and a multiplexing unit communicatively connected to the first through nth coder units and configured to modulate the coded excitation signal to create a modulated signal, and to output the modulated signal to an output terminal.<br>6. A wideband speech decoding system, comprising: a demultiplexing unit configured to receive a modulated signal and to demodulate the modulated signal and to output a first signal as a result; an LPC decoder unit communicatively connected to the demultiplexing unit and configured to perform LPC analysis so as to obtain LPC coefficients from the first signal; an impulse response unit communicatively connected to the LPC decoder unit and configured to calculate an impulse response of the first signal based on the LPC coefficients; a band divider communicatively connected to the impulse response unit and configured to divide the input response of the first signal into first through nth frequency bands, n being an integer greater than one; first through nth decoder units configured to receive the modulated signal and to obtain first through nth excitation signals for first through nth frequency bands, respectively; first through nth reproducing units communicatively connected to receive the first subband LPC coefficients for a corresponding one of the first through nth frequency bands of the first signal output from the band divider, and communicatively connected to receive a corresponding one of the first through nth excitation signals respectively output from the first through nth decoder units, the first through nth reproducing units configured to demodulate a subband speech signal for each of the first through nth frequency bands as a result; and a fullband synthesizing unit communicatively connected to the first through nth reproducing units and configured to create a fullband signal based on the corresponding subband speech signals in the first through nth frequency bands respectively output by the first through nth reproducing units.<br>7. A wideband speech coding system, comprising: an LPC analyzing unit configured to receive an input speech signal and to calculate LPC coefficients of the input speech signal based on an LPC analysis of the input speech signal; an LPC coding unit communicatively connected to the LPC analyzing unit and configured to code the LPC coefficients that have been calculated by the LPC analyzing unit; an LPC-LSP converter communicatively connected to the LPC coding unit and configured to convert the LPC coefficients into LSP coefficients; an LSP band divider communicatively connected to the LPC-LSP converter and configured to divide the LSP coefficients into subband LSP coefficients for first through nth frequency bands, n being an integer greater than one; first through nth LSP-LPC converters communicatively connected to receive a corresponding one of the subband LSP coefficients for the first through nth frequency bands output from the LSP band divider, the first through nth LSP-LPC converters configured to calculate first through nth subband LPC coefficients, respectively; a band divider configured to receive the input speech signal and to divide the input speech signal into first through nth subband signals respectively located in the first through nth frequency bands; first through nth coder units communicatively connected to the band divider and a corresponding one of the first through nth LSP-LPC converters, the first through nth coder units configured to code an excitation signal using a corresponding one of the first through nth subband signals and a corresponding one of the first through nth subband LPC coefficients; and a multiplexing unit communicatively connected to the first through nth coder units and configured to modulate the coded excitation signal to create a modulated signal, and to output the modulated signal to an output terminal.<br>8. A wideband speech decoding system, comprising: a demultiplexing unit configured to receive a modulated signal and to demodulate the modulated signal and to output a first signal as a result; an LPC decoder unit communicatively connected to the demultiplexing unit and configured to perform LPC analysis so as to obtain LPC coefficients from the first signal; an LPC-LSP converter communicatively connected to the LPC decoder unit and configured to convert the LPC coefficients into LSP coefficients; an LSP band divider communicatively connected to the LPC-LSP converter and configured to divide the LSP coefficients into subband LSP coefficients for first through nth frequency bands, n being an integer greater than one; first through nth LSP-LPC converters communicatively connected to receive the subband LSP coefficients output from the band divider for a corresponding one of the first through nth frequency bands, and to calculate first through nth subband LPC coefficients, respectively; first through nth decoder units configured to receive and decode the modulated signal and to obtain first through nth excitation signals for the first through nth frequency bands, respectively; first through nth reproducing units communicatively connected to a corresponding one of the first through nth decoder units and a corresponding one of the first through nth LSP-LPC converters, the first through nth reproducing units configured to reproduce a subband speech signal in the first through nth frequency bands, respectively, based on a corresponding one of the first through nth excitation signals and a corresponding one of the first through nth subband LPC coefficients; and a fullband synthesizing unit communicatively connected to the first through nth reproducing units and configured to create a fullband signal based on the corresponding subband speech signals in the first through nth frequency bands respectively output by the first through nth reproducing units.<br>9. A wideband speech coding system, comprising: an LPC analyzing unit configured to receive an input speech signal and to calculate LPC coefficients of the input speech signal based on an LPC analysis of the input speech signal; an LPC-LSP converter communicatively connected to the LPC analyzing unit and configured to convert the LPC coefficients into LSP coefficients; an LSP coding unit communicatively connected to the LPC-LSP converter and configured to code the LSP coefficient; an LSP band divider communicatively connected to the LSP coding unit and configured to divide the LSP coefficients into subband LSP coefficients for first through nth frequency bands, n being an integer greater than one; first through nth LSP-LPC converters communicatively connected to receive a corresponding one of the subband LSP coefficients for the first through nth frequency bands output from the LSP band divider, the first through nth LSP-LPC converters configured to calculate first through nth subband LPC coefficients, respectively; a band divider configured to receive the input speech signal and to divide the input speech signal into first through nth subband signals respectively located in the first through nth frequency bands; first through nth coder units communicatively connected to the band divider and a corresponding one of the first through nth LSP-LPC converters, the first through nth coder units configured to code an excitation signal using a corresponding one of the first through nth subband signals and a corresponding one of the first through nth subband LPC coefficients; and a multiplexing unit communicatively connected to the first through nth coder units and configured to modulate the coded excitation signal to create a modulated signal, and to output the modulated signal to an output terminal.<br>10. A wideband speech decoding system, comprising: a demultiplexing unit configured to receive a modulated signal and to demodulate the modulated signal and to output a first signal as a result; an LPC decoder unit communicatively connected to the demultiplexing unit and configured to perform LPC analysis so as to obtain LPC coefficients from the first signal; an LSP band divider communicatively connected to the LPC decoder unit and configured to divide the LSP coefficients into subband LSP coefficients for first through nth frequency bands, n being an integer greater than one; first through nth LSP-LPC converters communicatively connected to receive the subband LSP coefficients output from the band divider for a corresponding one of the first through nth frequency bands, and to calculate first through nth subband LPC coefficients, respectively; first through nth decoder units configured to receive and decode the modulated signal and to obtain first through nth excitation signals for the first through nth frequency bands, respectively; first through nth reproducing units communicatively connected to a corresponding one of the first through nth decoder units and a corresponding one of the first through nth LSP-LPC converters, the first through nth reproducing units configured to reproduce a subband speech signal in the first through nth frequency bands, respectively, based on a corresponding one of the first through nth excitation signals and a corresponding one of the first through nth subband LPC coefficients; and a fullband synthesizing unit communicatively connected to the first through nth reproducing units and configured to create a fullband signal based on the corresponding subband speech signals in the first through nth frequency bands respectively output by the first through nth reproducing units.<br>11. A wideband speech coding system, comprising: a band divider configured to receive an input speech signal and to divide the input speech signal into first through nth subband signals respectively located in first through nth frequency bands, n being an integer greater than one; first through nth LPC analyzing units communicatively connected to the band divider and configured to receive a corresponding one of the first through nth subband signals and to calculate first subband LPC coefficients of the corresponding one of the first through nth subband signals based on an LPC analysis of the corresponding one of the first through nth subband signals; first through nth LPC-LSP converters communicatively connected to a corresponding one of the first through nth LPC analyzing units and configured to convert the first subband LPC coefficients into first subband LSP coefficients; an LSP synthesizer unit communicatively connected to the first through nth LPC-LSP converters and configured to combine the first subband LSP coefficients in a particular order to obtain fullband LSP coefficients; an LSP coding unit communicatively connected to the LSP synthesizer unit and configured to code the fullband LSP coefficients; an LSP band divider communicatively connected to the LSP coding unit and configured to divide the fullband LSP coefficients into second subband LSP coefficients for the first through nth frequency bands; first through nth LSP-LPC converters communicatively connected to the LPC band divider and configured to convert the second subband LSP coefficients for a corresponding one of the first through nth frequency bands into second subband LPC coefficients for the corresponding one of the first through nth frequency bands; first through nth coder units communicatively connected to the band divider and a corresponding one of the first through nth LSP-LPC converters, the first through nth coder units configured to code an excitation signal using a corresponding one of the first through nth subband signals and a corresponding one of the second subband LPC coefficients for the first through nth frequency bands; and a multiplexing unit communicatively connected to the first through nth coder units and configured to modulate the coded excitation signal to create a modulated signal, and to output the modulated signal to an output terminal.</p></layer>
<layer id = "layer73"><p><b>US5086471A:Gain-shape vector quantization apparatus</b><br>A multiplexable liquid crystal cell having two substrates 1 and 3 which are spaced from each other and form between each other a cell space filled with liquid-crystal substance. Strip electrodes 2 are arranged on one substrate 1 while picture electrodes 4 are arranged on the other substrate 3 opposite the strip electrodes 2. An insulating layer 7 is arranged on the picture electrodes 4, said layer in its turn bearing a connecting contact 6 which leads to the data line 5.<br><b>Independant Claims</b><br>1. A gain-shape vector quantization apparatus for an input speech signal, said apparatus comprising: a code book portion containing a plurality of shape vectors and selecting among the shape vectors upon receipt of an index signal; a gain circuit portion including a plurality of variable gain circuits coupled in parallel to said code book portion to impart predetermined gains to the shape vectors selected by said code book portion; a synthesis filter portion including a plurality of synthesis filters coupled in parallel to said gain circuit portion to reproduce signals from the shape vectors as output by said variable gain circuits in said gain circuit portion; a first adder portion coupled to said synthesis filter portion to add the signals reproduced by said synthesis filters in said synthesis filter portion and to produce an output; a second adder portion coupled to said first adder portion to add the output of said first adder portion and the input speech signal to determine an error; and an evaluation unit coupled to said second adder and said code book portion to determine the index signal used in the selection of the shape vectors stored in said code book portion to minimize the error between the output of said first adder portion and the input speech signal produced by said second adder portion, and supplied to said code book portion.</p></layer>
<layer id = "layer74"><p><b>US6308150B1:Dynamic bit allocation apparatus and method for audio coding</b><br>An image forming apparatus includes an input unit for inputting image data representing an image, a synthesizing unit for synthesizing a predetermined information with the image represented by the image data, a forming unit for forming an image in accordance with the image data, a detecting unit for detecting a condition relating to an image forming by the forming unit, and a controlling unit for controlling the synthesis by the synthesizing unit based on the detection result of the detecting unit. An image forming method is also disclosed.<br><b>Independant Claims</b><br>1) A dynamic bit allocation apparatus for audio coding for determining a number of bits used to quantize a plurality of decomposed samples of a digital audio signal, the plurality of samples being grouped into a plurality of units each having at least either one of different frequency intervals or time intervals, the different frequency intervals being determined based on a critical band of human audio characteristics, and the different time intervals including a first time interval and a second time interval longer than the first time interval, said apparatus comprising: (a) absolute threshold setting means for setting an ib absolute threshold for every unit based on a specified threshold characteristic in quiet representing whether or not a person is audible in quiet; (b) absolute threshold adjusting means for adjusting the absolute threshold of a unit having the first time interval by replacing the absolute threshold of the unit having the first time interval by a minimum absolute threshold among a plurality of units having the same frequency interval; (c) peak energy computing means for computing peak energies of the units based on the plurality of samples grouped into the plurality of units; (d) masking effect computing means for computing a masking effect that is a minimum audible limit with the simplified simultaneous masking effect model, based on a specified simplified simultaneous masking effect model and a peak energy of a masked unit when each of all the units has the second time interval, and updating and setting the absolute threshold of each unit with the computed masking effect; (e) signal-to-mask ratio (SMR) computation means for computing SMRs of the units based on the computed peak energy of each unit and the computed absolute threshold of each unit; (f) number-of-available-bits computing means for computing a number of bits available for bit allocation based on a frame size of the digital audio signal, assuming that all frequency bands to be quantized include all the units; (g) SMR positive-conversion means for positively converting the SMRs of all the units by adding a specified positive number to the SMRs of all the SMRs so as to make the SMRs all positive; (h) SMR-offset computing means for computing an SMR-offset which is defined as an offset for reducing the positively converted SMRs of all the units, based on the positively converted SMRs of all the units, a SMR reduction step determined based on an improvement in signal-to-noise ratio per bit of a specified linear quantizer, and the number of available bits; (i) bandwidth computing means for updating a bandwidth which covers units that need to be allocated bits based on the computed SMR-offset and the computed SMRs of the units so as to update the SMR-offset based on the computed bandwidth; (j) sample bit computing means for computing a subtracted SMR by subtracting the computed SMR-offset from the computed SMR in each unit, and then, computing a number of sample bits representing a number of bits to be allocated to each unit in quantization based on the subtracted SMR of each unit and the SMR reduction step; and (k) remaining bit allocation means for allocating a number of remaining bits resulting from subtracting a sum of the numbers of sample bits to be allocated to all the units from the computed number of available bits to at least units having an SMR larger than the SMR-offset.<br>11) A dynamic bit allocation method for audio coding for determining a number of bits used to quantize a plurality of decomposed samples of a digital audio signal, the plurality of samples being grouped into a plurality of units each having at least either one of different frequency intervals or time intervals, the different frequency intervals being determined based on a critical band of human audio characteristics and the different time intervals including a first time interval and a second time interval longer than the first time interval, said method including the following steps of: (a) an absolute threshold setting step for setting an absolute threshold for every unit based on a specified threshold characteristic in quiet representing whether or not a person is audible in quiet; (b) an absolute threshold adjusting step for adjusting the absolute threshold of a unit having the first time interval by replacing the absolute threshold of the unit having the first time interval by a minimum absolute threshold among a plurality of units having the same frequency interval; (c) a peak energy computing step for computing peak energies of the units based on the plurality of samples grouped into the plurality of units; (d) a masking effect computing step for computing a masking effect that is a minimum audible limit with the simplified simultaneous masking effect model based on a specified simplified simultaneous masking effect model and a peak energy of a masked unit when all the units have the second time interval, and updating and setting the absolute threshold of each unit with the computed masking effect; (e) a signal-to-maskratio (SMR) computation step for computing SMRs of the units based on the computed peak energy of each unit and the computed absolute threshold of each unit; (f) a number-of-available-bits computing step for computing a number of bits available for bit allocation based on a frame size of the digital audio signal, assuming that all frequency bands to be quantized include all the units; (g) an SMR positive-conversion step for positively converting the SMRs of all the units by adding a specified positive number to the SMRs of all the SMRs so as to make the SMRs all positive; (h) an SMR-offset computing step for computing an SMR-offset which is defined as an offset for reducing the positively converted SMRs of all the units, based on the positively converted SMRs of all the units, a SMR reduction step determined based on an improvement in signal-to-noise ratio per bit of a specified linear quantizer, and the number of available bits; (i) a bandwidth computing step for updating a bandwidth which covers units that need to be allocated bits based on the computed SMR-offset and the computed SMRs of the units so as to update the SMR-offset based on the computed bandwidth; (j) a sample bit computing step for computing a subtracted SMR by subtracting the computed SMR-offset from the computed SMR in each unit, and then, computing a number of sample bits representing a number of bits to be allocated to each unit in quantization based on the subtracted SMR of each unit and the SMR reduction step; and (k) a remaining bit allocation step for allocating a number of remaining bits resulting from subtracting a sum of the numbers of sample bits to be allocated to all the units from the computed number of available bits to at least units having an SMR larger than the SMR-offset.</p></layer>
<layer id = "layer75"><p><b>US5630012A:Speech efficient coding method</b><br>An improved warp knit having colored surfaces comprised of three or more colors can be made across the same wales. Threads having a color which is covered in one colored surface run as floats, and threads with a color forming the colored surface are placed in a pattern connecting the floats with one another. A fabric or twill pattern extends across at least a number of wales which is less by 1 than the number of colors. Accordingly adjacent floats consist of at least two differently colored threads.<br><b>Independant Claims</b><br>1. An efficient speech coding method comprising the steps of: dividing an input speech signal into a plurality of signal blocks in the time domain; dividing each of the signal blocks into a plurality of frequency bands in the frequency domain; determining spectrum structures of the frequency bands on the lower frequency side; and deciding that the signal components in the frequency bands on the higher frequency side are voiced sound components or unvoiced sound components in accordance with the determination in the preceding step.<br>3. An efficient speech coding method completing the steps of: (a) dividing an input digital speech signal in time to provide a plurality of signal blocks; (b) orthogonally transforming the signal blocks to provide spectral data on the frequency axis; (c) using multi-band excitation to determine from the spectral data whether each of plural bands obtained by a pitch-dependent division of the spectral data in frequency and which are lower than a first frequency in a first frequency band represents one of a voiced (V) and an unvoiced (UV) sound: and (d) if the discrimination results in step (c) for a determined number of the plural bands is voiced sound, assigning a discrimination result of voiced sound to all of the frequency bands under a second frequency higher than the first frequency to obtain an ultimate discrimination result of voiced sound.<br>8. An efficient speech coding method comprising the steps of: (a) dividing an input speech signal into block units on a time base; (b) dividing signals of each of the respective divided blocks into signals in a plurality of frequency bands; (c) discriminating whether signals of each of the respective divided frequency ban& which are lower than a first frequency are voiced sound or unvoiced sound; (d) if the discrimination results in step (c) for a predetermined number of frequency bands is voiced sound, assigning a discrimination result of voiced sound to all frequency bands lower than a second frequency which is higher than the first frequency to obtain an ultimate discrimination result of voiced sound.<br>10. An efficient speech coding method comprising the steps of: (a) dividing an input speech signal into a plurality of signal blocks in a time domain; (b) dividing each of the signal blocks into a plurality of frequency bands in a frequency domain; (c) determining whether a signal component in each of the frequency bands is a voiced sound component or an unvoiced sound component; (d) determining whether the signal components in a predetermined number of frequency bands below a first frequency are the voiced sound components, and (e) deciding that the signal components in all of the frequency bands below a second frequency higher than the first frequency are the voiced sound components or the unvoiced sound components in accordance with the determination in the preceding step (d).</p></layer>
<layer id = "layer76"><p><b>US5151968A:Vector quantization encoder and vector quantization decoder</b><br><b>Independant Claims</b><br>1. A vector quantization encoder in a vector quantization device comprising: codebook means for storing a plurality of indexed code vectors and for providing one of the indexed code vectors in response to an code vector index signal, synthesis filters for reproducing speech signals based on the indexed code vector provided by said codebook means, addition means for adding the reproduced speech signals provided by said synthesis filters together to form a reproduced speech signal, error computing means for receiving an input speech signal and for computing a minimum error power valve by determining a difference between the reproduced speech signal and the input speech signal; and evaluating means for selecting the code vector index which minimizes the minimum error power value due to the difference between the reproduced speech signal and the input speech signal to be encoded and for supplying the selected code vector index to said codebook means, wherein: said codebook means includes a plurality of separate codebooks, each stores indexed code vectors for a different frequency band; each of said separate codebooks is provided with one of said synthesis filters; said addition means forms the reproduced speech signal based on which the minimum error power value is to be found; and said evaluating means includes means for selecting indices corresponding to said respective separate codebooks as well as indices for the indexed code vectors of said respective separate codebooks based on the minimum error power value.<br>7. A vector quantization decoder in a vector quantization device, comprising: codebook means for storing a plurality of indexed code vectors, synthesis filters for processing the indexed code vectors provided by said codebook means and for reproducing a speech signal, one of the indexed code vectors stored in said codebook means being supplied to the synthesis filter, which then reproduces the speech signal based on the one of the indexed code vectors, wherein: said codebook means includes a plurality of separate codebooks, each storing a portion of the indexed code vectors for a different frequency band; each of said separate codebooks is provided with one of said synthesis filters; and addition means for adding the reproduced speech signals which are provided by said synthesis filters to each other.<br>13. A vector quantization encoder in a vector quantization device, comprising: codebook storing means for storing a plurality of indexed code vectors and for selectively providing code vectors in response to code vector indices and including a plurality of separate codebooks, each storing a portion of the indexed code vectors corresponding to a different frequency band; synthesis filters connected to provide respective signal wave shapes based on corresponding one of the code vectors; addition means for providing a reproduced signal wave shape responsive to signal wave shapes provided by said synthesis filters; error computing means for receiving an input speech signal and for providing an error vector responsive to adding the reproduced signal wave shape to the input speech signal; error evaluating means for selecting the code vector indices responsive to minimizing a squared norm of the error vector; and controlling means for selecting combinations of the code vector indices.<br>16. A vector quantization decoder in a vector quantization device, connectable to receive code vector indices, comprising: codebook storing means for storing a plurality of indexed code vectors and for providing code vectors selected from the indexed code vectors based on the code vector indices and including a plurality of separate codebooks, each storing a portion of the indexed code vectors corresponding to a different frequency band; gain means for providing gain code vectors responsive to multiplying a gain and the code vectors; synthesis filters, each connected to receive one of corresponding gain code vectors to reproduce a signal wave shape; and addition means for providing a reproduced speech signal responsive to adding signal wave shape reproduced by said synthesis filters.</p></layer>
<layer id = "layer77"><p><b>US5915234A:Method and apparatus for CELP coding an audio signal while distinguishing speech periods and non-speech periods</b><br>A method of providing certificate issuance and revocation checks involving mobile devices in a mobile ad hoc network (MANET). The wireless devices communicate with each other via Bluetooth wireless technology in the MANET with an access point (AP) to provide connectivity to the Internet. A Certificate authority (CA) distributes certificates and certification revocation lists (CRLs) to the devices via the access point (AP). Each group of devices has the name of the group associated with the certificate and signed by the CA. A device that is out of the radio range of the access point may still connect to the CA to validate a certificate or download the appropriate CRL by having all the devices participate in the MANET.<br><b>Independant Claims</b><br>1. A method of CELP coding an input audio signal, comprising the steps of: (a) classifying the input audio signal into a speech period and a noise period frame by frame on the basis of a result from LPC analysis; (b) computing a new autocorrelation matrix based on a combination of an autocorrelation matrix of a current noise period frame and an autocorrelation matrix of a previous noise period frame; (c) performing the LPC analysis with said new autocorrelation matrix; (d) determining a synthesis filter coefficient based on a result of the LPC analysis, quantizing said synthesis filter coefficient and producing a resulting quantized synthesis filter coefficient, which further includes (i) transforming a synthesis filter coefficient of a noise period to an LSP coefficient; (ii) determining a spectrum characteristic of a synthesis filter, and comparing said spectrum characteristic with a past spectrum characteristic of said synthesis filter that occurred in a past noise period to thereby produce a new LSP coefficient having reduced spectrum fluctuation; and (iii) transforming said new LSP coefficient to said synthesis filter coefficient; and (e) searching for an optimal codebook vector based on said quantized synthesis filter coefficient.<br>2. An apparatus for CELP coding an input signal comprising: autocorrelation analyzing means for producing autocorrelation information from the input audio signal; vocal tract prediction coefficient analyzing means for computing a vocal tract prediction coefficient from a result of analysis output from said autocorrelation analyzing means; prediction gain coefficient analyzing means for computing a prediction gain coefficient from said vocal tract prediction coefficient; autocorrelation adjusting means for detecting a non-speech signal period on the basis of the input audio signal, said vocal tract prediction coefficient and said prediction gain coefficient, and adjusting said autocorrelation information in the non-speech signal period; vocal tract prediction coefficient correcting means for producing from adjusted autocorrelation information a corrected vocal tract prediction coefficient having said vocal tract prediction coefficient of the non-speech signal period corrected; and coding means for CELP coding the input audio signal by using said corrected vocal tract prediction coefficient and an adaptive excitation signal.<br>6. An apparatus for CELP coding an input audio signal, comprising: autocorrelation analyzing means for producing autocorrelation information from the input audio signal; vocal tract prediction coefficient analyzing means for computing a vocal tract prediction coefficient from a result of analysis output from said autocorrelation analyzing means; prediction gain coefficient analyzing means for computing a prediction gain coefficient from said vocal tract prediction coefficient; LSP coefficient adjusting means for computing an LSP coefficient from said vocal tract prediction coefficient, detecting a non-speech signal period of the input audio signal from the input audio signal, said vocal tract prediction coefficient and said prediction gain coefficient, and adjusting said LSP coefficient of the non-speech signal period; vocal tract prediction coefficient correcting means for producing from adjusted LSP coefficient a corrected vocal tract prediction coefficient having said vocal tract prediction coefficient of the non-speech signal period corrected; and coding means for CELP coding the input audio signal by using said corrected vocal tract coefficient and an adaptive excitation signal.<br>10. An apparatus for CELP coding an input audio signal, comprising: autocorrelation analyzing means for producing autocorrelation information from the input audio signal; vocal tract prediction coefficient analyzing means for computing a vocal tract prediction coefficient from a result of analysis output from said autocorrelation analyzing means; prediction gain coefficient analyzing means for computing a prediction gain coefficient from said vocal tract prediction coefficient; vocal tract coefficient adjusting means for detecting a non-speech signal period on the basis of the input audio signal, said vocal tract prediction coefficient and said prediction gain coefficient, and adjusting said vocal tract prediction coefficient to thereby output an adjusted vocal tract prediction coefficient; coding means for CELP coding the input audio signal by using said adjusted vocal tract prediction coefficient and an adaptive excitation signal.<br>14. An apparatus for CELP coding an input audio signal, comprising: autocorrelation analyzing means for producing autocorrelation information from the input audio signal; vocal tract prediction coefficient analyzing means for computing a vocal tract prediction coefficient from a result of analysis output from said autocorrelation analyzing means; prediction gain coefficient analyzing means for computing a prediction gain coefficient from said vocal tract prediction coefficient; noise cancelling means for detecting a non-speech signal period on the basis of bandpass signals produced by bandpass filtering the input audio signal and said prediction gain coefficient, performing signal analysis on the non-speech signal period to thereby generate a filter coefficient for noise cancellation, and performing noise cancellation with the input audio signal by using said, filter coefficient to thereby generate a target signal for the generation of a synthetic speech signal; synthetic speech generating means for generating the synthetic speech signal by using said vocal tract prediction coefficient; and coding means for CELP coding the input audio signal by using said vocal tract prediction coefficient and said target signal.<br>20. A method of CELP coding an input audio signal, comprising the steps of: (a) classifying the input audio signal into a speech period and a noise period frame by frame on the basis of a result from LPC analysis, which further includes (a1) converting a parameter for analysis for the input acoustic signal to a first reflection coefficient rÂi!, wherein i=1, . . . , Np, where Np represents a degree of filtering; (a2) calculating an inclination of a spectrum of the input acoustic signal to obtain a second reflection coefficient rÂo!; (a3) applying the first reflection coefficient rÂi! to a first expression RS=.PI.(1.0-rÂi!.sup.2) to obtain an prediction gain RS; (a4) applying the second reflection coefficient rÂo!, the prediction gain RS and a prediction gain coefficient Pow to a second expression D=Pow*.vertline.rÂo!.vertline./RS to obtain a value D, where the asterisk * represents a multiplication; and (a5) determining the input acoustic signal as the noise period if the value D is smaller than a predetermined value Dth; (b) computing a new autocorrelation matrix based on a combination of an autocorrelation matrix of a current noise period frame and an autocorrelation matrix of a previous noise period frame; (c) performing the LPC analysis with said new autocorrelation matrix; (d) determining a synthesis filter coefficient based on a result of the LPC analysis, quantizing said synthesis filter coefficient and producing a resulting quantized synthesis filter coefficient; (e) searching for an optimal codebook vector based on said quantized synthesis filter coefficient; and (f) coding the input audio signal by using the optimal codebook vector.<br>21. A method of CELP coding an input audio signal, comprising the steps of: (a) determining whether the input audio signal is speech or noise subframe by subframe on the basis of a result from LPC analysis, which further includes (a1) converting a vocal tract prediction coefficient of the input audio signal to a first reflection coefficient rÂi!, where i=1, . . . , Np, where NP represents a degree of filtering; (a2) calculating an inclination of a spectrum of the input audio signal to obtain a second reflection coefficient rÂo!; (a3) applying the first reflection coefficient rÂi! to a first expression RS=.PI.(1.0-rÂi!.sup.2) to obtain a prediction gain RS; (a4) applying the second reflection coefficient rÂo!, the prediction gain RS and a prediction gain coefficient Pow to a second expression D=Pow*.vertline.rÂo!.vertline./RS to obtain a value D, where the asterisk * represents a multiplication; and (a5) determining the input audio signal as the noise subframe if the value D is smaller than a predetermined value Dth; (b) computing an autocorrelation m atrix of a noise period; (c) performing the LPC analysis with said autocorrelation matrix; (d) determining a synthesis filter coefficient based on a result of the LPC analysis, quantizing said synthesis filter coefficient, and producing a resulting quantized synthesis filter coefficient; (e) selecting an amount of noise reduction and a noise reducing method on the basis of the speech/noise determining performed in step (a); (f) computing a target signal vector with the noise reducing method selected; (g) searching for an optimal codebook vector by using said target signal vector; and (h) coding the input audio signal by using the optimal codebook vector.<br>22. In a CELP coder, an arrangement comprising: an autocorrelation matrix calculator which receives an audio input signal and produces an autocorrelation matrix; an LPC analyzer which receives the autocorrelation matrix from the autocorrelation matrix calculator and produces a first vocal tract prediction coefficient; a speech/noise decision circuit which receives the first vocal tract prediction coefficient from the LPC analyzer and produces a speech/noise decision signal; an autocorrelation matrix adjuster which receives the speech/noise decision signal from the speech/noise decision circuit, and provides an adjustment matrix to the LPC analyzer when the decision signal indicates noise; wherein the LPC analyzer produces a corrected vocal tract prediction coefficient in response to the adjustment matrix; and a synthesis filter which receives the corrected vocal tract prediction coefficient from the LPC analyzer and produces a synthetic speech signal.<br>46. In a CELP coder, an arrangement comprising: an autocorrelation matrix calculator which receives an audio input signal and produces an autocorrelation matrix; an LPC analyzer which receives the autocorrelation matrix from the autocorrelation matrix calculator and produces a vocal tract prediction coefficient; a prediction gain computation circuit which receives the vocal tract prediction coefficient from the LPC analyzer and provides a prediction gain signal; a bank of filters, each of which has a particular passband, receives the audio input signal, and produces a plurality of passband signals; and a speech/noise decision circuit which receives the prediction gain signal from the prediction gain computation circuit and the plurality of passband signals from the bank of filters, and produces a plurality of speech/noise decision signals on the basis of the prediction gain signal and the plurality of passband signals.<br>55. In a CELP coder, an arrangement comprising: an autocorrelation matrix calculator which receives an audio input signal and produces an autocorrelation matrix; an LPC analyzer which receives the autocorrelation matrix from the autocorrelation matrix calculator and produces a vocal tract prediction coefficient; a prediction gain computation circuit which receives the vocal tract prediction coefficient from the LPC analyzer and provides a prediction gain signal; a bandpass filter which receives the audio input signal, and produces a passband signal; a speech/noise decision circuit which receives the prediction gain signal from the prediction gain computation circuit and the passband signal from the bandpass filter, and produces a speech/noise decision signal on the basis of the prediction gain signal and the passband signal; a filter controller which receives the speech/noise decision signal from the speech/noise decision circuit and produces an adjusted noise filter coefficient; and a noise canceling filter which receives the adjusted noise filter coefficient from the filter controller and the audio input signal, and produces a minimum noise target signal.</p></layer>
<layer id = "layer78"><p><b>US5956672A:Wide-band speech spectral quantizer</b><br>A corrosion protection covering method for spliced regions of reinforcing steel is disclosed. The covering may include an outer, heat shrinkable layer and a flowable inner layer. The covering is applied to the spliced region, and then heated, causing the outer layer to constrict and thereby seal the taped area. The heat also causes the inner layer to liquify and fill any voids.<br><b>Independant Claims</b><br>1. A wide-band speech spectral quantizer comprising: a first means for splitting a frame speech signal into a plurality of split signals; a second means for developing developed coefficients representing a frequency characteristic of each split signal; a third means for obtaining subtraction results by subtracting predicted coefficients from the developed coefficients; a fourth means for quantizing the subtraction results concerning the plurality of split signals and developing a quantization result of each split signal and a quantized synthesis resulting concerning the plurality of split signals; a fifth means for developing quantized coefficients concerning each split signal on the basis of the quantization result and the predicted coefficients; a sixth means for outputting the quantized coefficients; a seventh means for developing synthesized coefficients concerning the plurality of split signals by synthesizing the developed coefficients; an eights means for developing predicted synthesis coefficients concerning the synthesized coefficients on the basis of the quantized synthesis result and the synthesized coefficients; and a ninth means for developing the predicted coefficients concerning each split signal on the basis of the predicted synthesis coefficients.<br>5. A wide-band speech spectral quantizer comprising: a first means for splitting a frame speech signal into a plurality of split signals; a second means for developing developed coefficients representing a frequency characteristic of each split signal; a third means for obtaining subtraction results by subtracting predicted coefficients from the developed coefficients; a fourth means for quantizing the subtraction results concerning the plurality of split signals and developing a quantization result of each split signal and a quantized synthesis result concerning the plurality of split signals; a fifth means for developing quantized coefficients concerning each split signal on the basis of the quantization result and the predicted coefficients; a sixth means for outputting the quantized coefficients; a seventh means for developing predicted synthesis coefficients concerning the synthesized coefficients on the basis of the quantized synthesis result; and an eighth means for developing the predicted coefficients concerning each split signal on the basis of the predicted synthesis coefficients.<br>9. A spectral quantizer for wide-band speech comprising: a frame circuit for cutting out frames with a predetermined window length from a speech signal; a band splitter for making predetermined frequency band splitting and computing each sub-band spectral coefficients; an analyzer for computing a spectral coefficient vector of each sub-band; an adder for obtaining a result of subtraction of each sub-band predicted spectral coefficient vector computed in the band splitter from the spectral coefficient vector; a quantizer for quantizing a result of subtraction for the full band, thus outputting a quantized prediction error vector; means for generating a full-band quantized vector by combining the quantized prediction error vectors of all the sub-bands; a synthesizer for outputting a full-band spectral coefficient vector by combining the spectral coefficient vectors of all the sub-bands received from the analyzer; an optimum prediction circuit for computing a full-band predicted spectral coefficient vector from the full-band quantized vector received from the quantizer and the full-band predicted spectral coefficient vector; and a band splitter for band splitting the full-band predicted spectral coefficient vector, and computing each sub-band predicted spectral coefficient vector.</p></layer>
<layer id = "layer79"><p><b>US5001759A:Method and apparatus for speech coding</b><br>A leaf spring is provided in which the major component is a leaf made up of continuous strands of fibers distributed in a matrix of polymerized plastic resin. The spring has a theoretical constant cross-sectional area and uniform width throughout its length and at the same time is thickest at its midportion and tapers to the opposite ends. The spring results in an arrangement having a cavity intermediate opposite ends and opposite sides which is capable of receiving locating pins or bolts of the type used with conventional metal leaf springs without the requirement for drilling of holes or otherwise weakening the structure. One embodiment of the invention incorporates a metallic leaf with the non-metallic components.<br><b>Independant Claims</b><br>1. A speech coding system comprising: means for applying a linear predictive analysis to an input signal; means for producing an impulse response of a linear predictive filter; means for producing an autocorrelation function of said impulse response; means for producing a crosscorrelation function between said input signal and said impulse response to use said crosscorrelation function as a criterion function; pulse search means which sets a first pulse at a location where the criterion function is maximum, and produces a first normalized autocorrelation function of an impulse response by multiplying said autocorrelation of the impulse response by an amplitude of the pulse, and which renews said criterion function by subtracting said first normalized autocorrelation function of the impulse response from said criterion function centering around a location where the pulse is set, and which iteratively determines a predetermined number of pulses in the same manner based on said criterion function, and which modifies the amplitude of the pulse set at a location, among the locations where the pulses are set, said location being an absolute value of said criterion function is maximum, and which produces a second normalized autocorrelation function of the impulse response, in accordance with only the locations where the pulses are set, by multiplying said autocorrelation of the impulse response by the modified amount of the pulse, and which renews said criterion function by subtracting said second normalized autocorrelation function of the impulse response from said criterion function, at only the locations where the pulses are set, centering around the location where the pulse amplitude is modified, and repeats pulse amplitude modification a predetermined number of times based on said criterion function; and output means for outputting the coefficients of the linear predictive filter and the locations and amplitudes of the predetermined number of pulses.</p></layer>
<layer id = "layer80"><p><b>US5909663A:Speech decoding method and apparatus for selecting random noise codevectors as excitation signals for an unvoiced speech frame</b><br>A thermoplastic resin composition comprising (a) 100 parts by weight of thermoplastic copolycarbonate comprising 0.1 to 50% by weight of structural unit of the following general formula (1) and 99.9 to 50% by weight of structural unit of the following general formula (2): ##STR1## and (b) 0.1 to 30 parts by weight of electroconductive carbon black can produce a molding product having good mechanical properties and surface smoothness with good moldability and (c) a polyester or styrenic resin.<br><b>Independant Claims</b><br>1. A speech decoding method for decoding an encoded speech signal produced by dividing an input speech signal on a time axis using a pre-set encoding unit and by waveform-encoding a resulting encoding-unit-based time-axis waveform signal, said method comprising: a waveform-decoding step for producing an encoding-unit-based time-axis waveform signal, wherein said time-axis waveform signal is an excitation signal for synthesis of an unvoiced speech signal; an error detecting step for detecting an error using an error checking code appended to said encoded speech signal; and an evading step for evading repeated use of a same waveform as a waveform used in said waveform-decoding step by using a waveform different from a directly preceding waveform when an error is detected in said error detecting step.<br>7. A speech decoding apparatus for decoding an encoded speech signal produced by dividing an input speech signal on a time axis using a pre-set encoding unit and by waveform-encoding a resulting encoding-unit-based time-axis waveform signal, said apparatus comprising: waveform-decoding means for waveform-decoding said encoded speech signal and for producing an encoding-unit-based time-axis waveform signal, wherein said time-axis waveform signal is an excitation signal for synthesis of an unvoiced speech signal; error detection means for detecting an error using an error checking code appended to said encoded speech signal; and evading means for evading repeated use of a same waveform as a waveform used by said waveform-decoding means by using a waveform different from a directly-preceding waveform when an error is detected by said error detection means.</p></layer>
<layer id = "layer81"><p><b>US6047253A:Method and apparatus for encoding/decoding voiced speech based on pitch intensity of input speech signal</b><br>A sailboat with roller furling has a first foresail rolled about a forestay by suitable rotatable gearing. A second foresail includes a flap secured along one side of the second foresail adjacent its luff and which flap extends about the furled first foresail for releasable securement to a strip sewn along the opposite side of the second foresail. In this manner, a second foresail can be deployed while the first foresail remains roller furled.<br><b>Independant Claims</b><br>1. A speech encoding method for sinusoidal analysis encoding of an input speech signal, comprising the steps of: deciding whether the input speech signal is voiced or unvoiced; detecting a pitch intensity in all bands of a voiced speech portion of the input speech signal based on the results of the step of deciding whether the input speech signal is voiced or unvoiced; and outputting pitch intensity information as a parameter corresponding to the pitch intensity detected in the step of detecting the pitch intensity, wherein the pitch intensity information is used in decoding an encoded speech signal coded from the input speech signal.<br>4. A speech encoding apparatus for sinusoidal analysis encoding of an input speech signal, comprising: means for deciding whether the input speech signal is voiced or unvoiced; means for detecting a pitch intensity in all bands of a voiced speech portion of the input speech signal based on an output of the means for deciding; and means for outputting pitch intensity information as a parameter corresponding to the pitch intensity detected by the means for detecting, wherein the pitch intensity information is used in decoding an encoded speech signal coded from the input speech signal.<br>5. A method for decoding an encoded speech signal obtained by sinusoidal analytic encoding of an input speech signal, comprising the steps of: deciding whether the input speech signal is voiced or unvoiced; and adding a noise component to a sinusoidal synthesis waveform based on pitch intensity information as a parameter of pitch intensity detected in all bands of a voiced speech portion of the input speech signal on the basis of results of the step of deciding whether the input speech signal is voiced or unvoiced.<br>12. A speech decoding apparatus for decoding encoded speech signals obtained by sinusoidal synthesis encoding of an input speech signal, the apparatus comprising: means for controlling a level and a bandwidth of a noise component added to an encoded sinusoidal synthesis waveform based on pitch intensity information provided thereto as a parameter of pitch intensity detected in all bands of a voiced speech portion of the input speech signal; means for performing sinusoidal synthesis decoding on a portion of the input speech signal found to be voiced based on voiced/unvoiced information provided thereto; and means for performing coded excitation linear predictive decoding on a portion of the input speech signal judged to be unvoiced.</p></layer>
<layer id = "layer82"><p><b>US6029134A:Method and apparatus for synthesizing speech</b><br>An aqueous polymer dispersion containing a predominant amount of first polymer particles and a smaller amount of second polymer particles is provided. The first polymer particles have a glass transition temperature in the range of from −20° C. to 25° C. The second polymer particles include multiethylenically unsaturated monomer as polymerized units, and have a glass transition temperature of less than 0° C. The aqueous polymer dispersion is useful for providing dry coatings having improved dirt pickup resistance and an acceptable level of scrub resistance. Also provided is an aqueous coating composition including the aqueous polymer dispersion and a method for preparing a dry coating from the aqueous coating composition.<br><b>Independant Claims</b><br>1. A speech synthesizing method including the steps of sectioning an input signal derived from a speech signal into frames and deriving a pitch for each sectioned frame, said method comprising the steps of: determining whether data for synthesizing speech of each frame contains a voiced sound or an unvoiced sound; synthesizing a voiced sound with a fundamental wave of said pitch and its harmonic when the data of a frame is determined to contain a voiced sound; and constantly initializing phases of said fundamental wave and its harmonic into a given value when the data of a frame is determined to contain an unvoiced sound.<br>6. A speech synthesizing apparatus arranged to section an input signal derived from a speech signal into frames and to derive a pitch for each frame, comprising: means for determining whether data of each frame contains a voiced sound or an unvoiced sound; means for synthesizing a voiced sound with a fundamental wave of the pitch and its harmonic when the data of a frame is determined to contain a voiced sound; and means for initializing the phase of said fundamental wave and its harmonic to a given value when the data of the frame is determined to contain an unvoiced sound.</p></layer>
<layer id = "layer83"><p><b>US4776015A:Speech analysis-synthesis apparatus and method</b><br>A steam and air mixing chamber having a downwardly open housing is mounted on top of a steam generator located in a housing containing a water reservoir. A steam nozzle directs a jet of steam against a baffle mounted in the mixing chamber entraining air and forming a mist. Compressed air is directed into the mixing chamber by a venturi sucking the mist and causing the mixture to flow into a T joint having one arm connected to a breathing element. A port in the T joint receives a carrier for volatile medicament. A vertical arm of the T is connected to a tube which returns condensate to the water in the reservoir.<br><b>Independant Claims</b><br>1. A speech analysis apparatus comprising: means to input speech; analyzing means for analyzing the speech input to obtain spectral envelope information; means for determining an impulse response from said spectral envelope information; means for determining a factor for effecting perceptual weighting in a manner to correspond to a sound source pulse number; means for determining a cross-correlation between the input speech and said impulse response, wherein both are perceptually weighted on the basis of said factor; means for determining an auto-correlation from the impulse response which is perceptually weighted on the basis of said factor; and means for generating sound source information necessary for the speech analysis from said cross-correlation, said auto-correlation and said sound source pulse number.<br>7. A speech analysis-synthesis method by a multipulse excitation using a plurality of pulses generated in a modelled manner as a synthetic sound source if an input is to be analyzed so that speech may be synthesized on the basis of the analyzed result, comprising the steps of: providing a variable factor for effecting in a perceptually weighting factor in a manner to correspond to a sound source pulse number; perceptually weighting said input speech and an impulse response which is determined from spectral envelope information obtained as a result of the analysis of said input speech; determining a cross-correlation between said input speech and said impulse response, wherein both of which are perceptually weighted; determining an auto-correlation from said impulse response which is perceptually weighted; and generating an amplitude and location of said sound source pulses from said cross-correlation and said auto-correlation.<br>8. A speech analysis apparatus for generating a sound source to be used in speech synthesizing, comprising: means to input speech; analyzing means for analyzing inputted speech to obtain spectral envelope information; means for determining an impulse response from said spectral envelope information; means for determining a factor for effecting perceptual weighting in a manner to correspond to a sound source pulse number; means for determining a cross-correlation between the input speech and said impulse response, wherein both are perceptually weighted on the basis of said factor; means for determining an auto-correlation from the impulse response which is perceptually weighted on the basis of said factor; and means for generating sound source information necessary for the speech analysis in response to said cross-correlation and said auto-correlation.<br>12. A speech analysis apparatus comprising: means to input speech; analyzing means for analyzing inputted speech to obtain spectral envelope information; means for determining an impulse response from said spectral envelope information; means for determining a factor for effecting perceptual weighting in a manner to correspond to a sound source pulse number; means for determining a cross-correlation between the input speech and said impulse response, wherein both are perceptually weighted on the basis of said factor; means for determining an auto-correlation from the impulse response which is perceptually weighted on the basis of said factor; and means for generating sound source information necessary for the speech analysis in response to said cross-correlation and said auto-correlation.</p></layer>
<layer id = "layer84"><p><b>US5867815A:Method and device for controlling the levels of voiced speech, unvoiced speech, and noise for transmission and reproduction</b><br>A static RAM cell in which the load devices are moved from the state nodes to outer nodes of a cross-coupled pair of transistors in first and second driver elements (33 and 35). Each driver element has a first (T1A or T3A) and a second (T1 or T3) transistor and a resistive device (42 or 44). Each transistor has first, second and third terminals, with the second terminals being the input terminals. A first terminal of the first transistor (T1A) of the first driver element (33) is connected to the resistive element (42) at a first node. A first terminal of the first transistor (T3A) of the second driver element is connected to the resistive element (44) at a second node. A first terminal of the second transistor (T1) of the first driver element (33) is connected to the resistive device (42) at a third node. A first terminal of the second transistor (T3) of the second driver element is connected to the resistive device (44 ) at a fourth node. The input terminals of the first and second transistors (T1A and T1) of the first driver element (33) are connected to the second node and the input terminals of the first and second transistors (T3A and T3) of the second driver element (35) are connected to the first node. The third terminals of the first and second transistors of the first and second driver elements are connected to a first source of common potential. A first load device (26) is connected to a second source of common potential on one end and is connected to the third node on a second end. Likewise, a second load device (28) is connected to the second source of common potential on one end and to the fourth node on the second end.<br><b>Independant Claims</b><br>1. A speech transmission/reception system for transmitting and receiving signals including speech signals between a transmission side and a reception side, the system comprising: a discrimination device at the transmission side that discriminates among a voice band component, a nonvoice band component and a noise component in an inputted speech signal; an encoder at the transmission side for encoding the voice band and nonvoice band components; a decoder at the reception side for decoding the encoded voice band and nonvoice band components; a signal level control device at the reception side that controls respective signal levels among the decoded voice band component, the decoded nonvoice band component and the noise component as discriminated by the discrimination device according to a level ratio; and a reproducing device at the reception side that generates a reproduced speech signal by combining the voice band component, the nonvoice band component and the noise component as controlled by the level ratio control device.<br>3. A speech transmission/reception system for transmitting and receiving signals including speech signals, the system comprising: a transmission side including: a first discrimination device that extracts a voice band component from an inputted speech signal; a second discrimination device that extracts a nonvoice band component and a noise component from the inputted speech signal; a nonvoice band detector coupled to the second discrimination device, the nonvoice band detector receiving the nonvoice band component and the noise component extracted by the second discrimination device and detecting the presence or absence of the nonvoice band component; an adder having a first input terminal for receiving the voice band component from the first discrimination device and a second input terminal; a switch device coupling the nonvoice band detector and the second terminal of the adder and responsive to the nonvoice band detector; a noise encoder coupled to the second discrimination device through the switch device for encoding the noise component to generate a noise code; a speech signal encoder coupled to the adder for encoding synthesized speech output to generate a speech code output; and a multiplexer that multiplexes the speech code output and the noise code output to provide a multiplexed signal for transmission; wherein the switch device provides the nonvoice band component to the second input terminal of the adder when the presence of the nonvoice band is detected by the nonvoice band detector, and provides the noise component to the noise encoder when the absence of the nonvoice band component is, detected by the nonvoice band detecter, and the adder combines the voice band component and the nonvoice band component to generate the synthesized speech output a reception side including: a voice band amplifier for amplifying a decided voice band component by a first gain; a nonvoice band amplifier for amplifying a decoded nonvoice band component by a second gain; a signal level control device for controlling the first gain and the second gain such that the respective signal levels of the decoded voice and nonvoice components are maintained at a set level ratio.<br>6. A method of transmitting and receiving signals, including speech signals, between a transmission side and a reception side, the method comprising the steps of: discriminating among a voice band component, a nonvoice band component and a noise component of an inputted speech signal at the transmission side; controlling respective signal levels among the voice band component, the nonvoice band component and the noise component according to a level ratio at the reception side; and reproducing a reproduced signal by combining the voice band component, the nonvoice band component and the noise component based upon the level ratio.<br>9. A method for transmitting and receiving signals including speech signals between a transmission system and a reception system, the method comprising the steps of: extracting a voice band component from an inputted speech signal; extracting a nonvoice band component and a noise component from the inputted speech signal; extracting the nonvoice band component from the noise component; adding the extracted voice band component and the extracted nonvoice band component to produce a speech component; encoding the speech component to generate a speech code output at the transmission system; encoding the noise component to generate a noise code output at the transmission system; multiplexing the speech code output and the noise code output to generate a multiplexed signal for transmission; amplifying a decoded speech component at the reception system at a first gain; amplifying a decoded noise component at the reception system at a second gain; and controlling the first gain and the second gain at the reception system to maintain the respective signal levels of the decoded speech and noise components at a set level ratio.<br>15. A speech transmission/reception system for transmitting and receiving a signal between a transmission side and a reception side, the signal including a speech signal component and a noise component, the speech signal component including a voice band component and a nonvoice band component, the system comprising: a transmission side including: a first filter that extracts a voice band component from an inputted signal; a second filter that extracts a nonvoice band component and a noise component from the inputted signal; a nonvoice band detecter that extracts the nonvoice band component from the noise component; an adder that adds the voice band component and the nonvoice band component to generate a speech component; a speech signal encoder that encodes the speech component to generate a speech code output; a noise encoder that encodes the noise component to generate a noise code output; and a multiplexer that multiplexes the speech code output and the noise code output to generate a multiplexed signal; and a reception side including: a speech signal amplifier for amplifying a decoded speech component at a first gain; a noise component amplifier for amplifying a decoded noise component at a second gain; and a level controller for controlling the first and second gain to maintain the respective levels of the decoded speech component and noise component at a set level ratio.</p></layer>
<layer id = "layer85"><p><b>US5581652A:Reconstruction of wideband speech from narrowband speech using codebooks</b><br><b>Independant Claims</b><br>1. A wideband speech signal reconstruction method comprising: a first step wherein an input narrowband speech signal is spectrum-analyzed; a second step wherein the spectrum-analyzed results obtained in said first step are vector-quantized using a narrowband speech signal codebook; a third step wherein the quantized values obtained in said second step are decoded to codevectors using a wideband speech signal codebook; and a fourth step wherein said codevectors obtained in said third step are spectrum-synthesized to obtain a wideband speech signal.<br>4. A wideband speech signal reconstruction method comprising: a first step wherein an input narrowband speech signal is spectrum-analyzed; a second step wherein the spectrum-analyzed results obtained in said first step are vector-quantized using a narrowband speech signal codebook; and a third step wherein the quantized values obtained by said vector quantization in said second step are reconstructed to obtain a wideband speech signal through use of a representative waveform codebook.<br>7. A wideband speech signal reconstruction method comprising: a first step wherein an input narrowband speech signal is spectrum-analyzed; a second step wherein the spectrum-analyzed results in said first step are vector-quantized using a narrowband speech signal codebook; a third step wherein the quantized values obtained in said second step are decoded to codevectors, using a wideband speech signal codebook; a fourth step wherein the codevectors decoded in said third step are spectrum-synthesized to a wideband speech signal; a fifth step wherein frequency components lower than the band of said input narrowband speech signal are extracted from said wideband speech signal obtained in said fourth step; a sixth step wherein said quantized values obtained in said second step are decoded to obtain a high-frequency speech signal, using a representative waveform codebook of a high-frequency speech signal higher than the band of said input narrowband speech signal; a seventh step wherein said input narrowband speech signal is up-sampled to compute sample values; and an eighth step wherein said lower-frequency components obtained in said fifth step, said high-frequency speech signal obtained in said sixth step and said sample values computed in said seventh step are added together to obtain a wideband speech signal.<br>11. A wideband speech signal reconstructing apparatus comprising: means for spectrum-analyzing an input narrowband speech signal; means for vector-quantizing the results, obtained by said spectrum-analyzing means, by use of a narrowband speech signal codebook; means for decoding the vector-quantized values, obtained by said vector-quantizing means, to codevectors through use of a wideband speech signal codebook; and means for spectrum-synthesizing said codevectors, obtained by said decoding means, to obtain a synthesized wideband speech signal.<br>13. A wideband speech signal reconstructing apparatus comprising: means for spectrum-analyzing an input narrowband speech signal; means for vector-quantizing the results, obtained by said spectrum-analyzing means, by use of a narrowband speech signal codebook; and speech synthesizing means utilizing a representative waveform codebook for reconstructing the vector-quantized values, obtained by said vector-quantizing means, to obtain a synthesized wideband speech signal.<br>15. A wideband speech signal reconstructing apparatus comprising: means for spectrum-analyzing an input narrowband speech signal; means for vector-quantizing the results, obtained by said spectrum-analyzing means, by use of a narrowband speech signal codebook; means for decoding the quantized values, obtained by said vector-quantizing means, to codevectors through use of a wideband speech signal codebook; first speech synthesizing means for spectrum-synthesizing said codevectors, obtained by said decoding means, to obtain a wideband speech signal; filter means for extracting, from said wideband speech signal obtained by said first speech synthesizing means, frequency components lower than the band of said input narrowband speech signal; second speech synthesizing means for decoding said quantized values, obtained by said vector-quantizing means, to obtain a high-frequency speech signal through use of a representative waveform codebook of a high-frequency speech signal higher than the band of said input narrowband speech signal; means for up-sampling said input narrowband speech signal to compute sample values; and means for adding together said lower-frequency components obtained by said filter means, said high-frequency speech signal obtained by said second speech synthesizing means, and said sample values obtained by said up-sampling means, to obtain a wideband speech signal.</p></layer>
<layer id = "layer86"><p><b>US5950153A:Audio band width extending system and method</b><br>A snap hinge closure has a lid which pivots about a main axis of rotation with film hinges aligned therewith. When the lid is closed, no parts of the hinge project beyond the surfaces of the closure.<br><b>Independant Claims</b><br>1. An audio bandwidth extending system comprising: analyzing means for obtaining autocorrelation coefficients and linear predictive coding residuals of a time region from a narrow band audio input signal; exciting source signal forming means for forming an exciting source signal from said linear predictive coding residuals obtained by said analyzing means from the input narrow band audio signal; affricate detecting means for detecting an affricate sound in said autocorrelation coefficients from said analyzing means and producing an output control signal; boosting means for boosting a level of said exciting source signal in response to said output control signal from said affricate detecting means and producing a boosted exciting source signal; a narrow band code book storing therein autocorrelation coefficients of the time region of the narrow band audio signal obtained from patterns of a plurality of audio signals and including matching means for comparing the autocorrelation coefficients of the time region of the narrow band audio input signal from said analyzing means with the autocorrelation coefficients of the time region of the narrow band audio signal stored in said narrow band code book and for retrieving optimum autocorrelation coefficients; a wide band code book storing therein autocorrelation coefficients of a time region of a wide band audio signal obtained from patterns of said plurality of audio signals stored in correspondence to said narrow band code book and being addressed by said optimum autocorrelation coefficients from said narrow band code book; converting means for converting corresponding autocorrelation coefficients from said wide band codebook to linear predictive coefficients; and synthesizing means for receiving the linear predictive coefficients from said converting means and for synthesizing an output wide band audio signal using the boosted exciting source signal from said boosting means and said linear predictive coefficients from said converting means as code vectors.<br>7. An audio bandwidth extending method comprising the steps of: providing a narrow band code book in which autocorrelation coefficients of a time region of a narrow band audio signal obtained from patterns of a plurality of audio signals have previously been stored; providing a wide band code book in which autocorrelation coefficients of a time region of a wide band audio signal obtained from the patterns of said plurality of audio signals have previously been stored in correspondence to said narrow band code book; obtaining autocorrelation coefficients and linear predictive coding residuals of a time region from an input narrow band audio signal; forming an exciting source signal from said linear predictive coding residuals obtained from said input narrow band audio signal; detecting an affricate sound in said autocorrelation coefficients from said step of obtaining and producing an output control signal; boosting a level of said exciting source signal in response to said output control signal from said step of detecting and producing a boosted exciting source signal; matching the autocorrelation coefficients of the time region of said audio signal of the input narrow band audio signal and the autocorrelation coefficients of the time region of the input narrow band audio signal stored in said narrow band code book and retrieving optimum autocorrelation coefficients by said matching; reading out corresponding autocorrelation coefficients from the autocorrelation coefficients of the time region of the wide band audio signal stored in said wide band code book on the basis of the optimum autocorrelation coefficients retrieved by said matching; converting corresponding autocorrelation coefficients from said wide band code book to linear predictive coefficients; and synthesizing an output wide band audio signal on the basis of said boosted exciting source signal from said step of boosting and said linear predictive coefficients acting as code vectors obtained in said step of reading out.<br>13. An audio bandwidth extending system for use in a digital cellular telephone system having a modulation system producing linear predictive coefficients and an exciting source signal from a narrow band audio signal, said bandwidth extending system comprising: means for upsampling the exciting source signal and producing an upsampled exciting source signal; first converting means for converting the linear prediction coefficients to autocorrelation coefficients; a narrow band code book for storing therein autocorrelation coefficients of a time region of the narrow band audio signal obtained from patterns of a plurality of audio signals, wherein the stored autocorrelation coefficients are compared with the converted autocorrelation coefficients from the first converting means for producing a matching index; a wide band code book for storing therein autocorrelation coefficients of a time region of a wide band audio signal obtained from patterns of said plurality of audio signals stored in correspondence to said narrow band code book and for receiving the matching index from said narrow band code book and reading out wide band autocorrelation coefficients in response thereto; second converting means for converting said wide band autocorrelation coefficients read out from said wide band code book into autocorrelation coefficients for use as code vectors; affricate detecting means for detecting an affricate sound in the autocorrelation coefficients converted to by said first converting means and producing an output control signal; boosting means for boosting a level of said upsampled exciting source signal in response to said output control signal and producing a boosted exciting source signal; and a linear predictive coding synthesizing filter receiving the linear predictive coefficients from said second converting means and said boosted exciting source signal for synthesizing an output wide band audio signal from said boosted exciting source signal and said linear predictive coefficients as code vectors.</p></layer>
<layer id = "layer87"><p><b>US5054073A:Voice analysis and synthesis dependent upon a silence decision</b><br>Alcohols and related oxygenates are converted in a riser reactor and dense fluid catalyst bed comprising ZSM-5 type catalyst circulated through a plurality of satellite stripping-cooling zones for temperature control. Catalyst utilized comprises from 5 to 30 weight percent coke for activity and selectivity control promoting the formation of olefins and aromatics at temperatures below about 427.degree. C. (800.degree. F.).<br><b>Independant Claims</b><br>1. A band-subdivision-type apparatus having analysis and synthesis sides for the analysis and synthesis of voice signals, in which the frequency band of the voice signals is divided into a plurality of subdivided channels and the voice signals are divided into subdivided channel signals which fall within the respective subdivided channels, said apparatus comprising: coding means provided on said analysis side for each subdivided channel for separately coding the subdivided channels signal by the use of a quantization step size signal determined for each of a plurality of frames, a frame being defined as a predetermined time interval of said subdivided channel signal; decoding means provided on said synthesis side for each subdivided channel for receiving said coded subdivided channel signal from said analysis side and decoding said coded subdivided channel signal; an analysis side amplitude level detector for detecting the amplitude level of said subdivided channel signal in each frame and providing an output corresponding thereto; an analysis side quantization level conversion coding circuit coupled to the output of said amplitude level detector for quantizing said amplitude level for each frame to determine a quantization level, said quantization level conversion coding circuit converting said quantization level into a coded quantization level signal; an analysis side silence signal decision circuit coupled to said quantization level conversion coding circuit for receiving said coded quantization level signal and making a decision as to whether the quantization level signal exceeds a predetermined level, said decision circuit outputting a decision signal to said coding means to indicate whether the quantization level exceeds a reference level; and an analysis side quantization step size decoding conversion circuit interposed between said quantization level conversion coding circuit and said coding means for receiving and decoding said coded quantization level signal into said quantization step size signal, said coding means receiving said quantization step size signal and using it for the coding of said subdivided channel signal of each frame; whereby said coding means effects the coding of the subdivided channel signal within each frame when the decision signal for that frame received from said analysis side silence signal decision circuit indicates that the amplitude level of said frame exceeds said reference level, and does not effect the coding of the subdivided channel signal within each frame when the decision signal for said frame indicates that the amplitude level of said frame does not exceed said reference level.</p></layer>
<layer id = "layer88"><p><b>US6289311B1:Sound synthesizing method and apparatus, and sound band expanding method and apparatus</b><br>A pair of goggles that are worn by an active sports participant which enhances the person's ability to see and protect his eyes during active sport activities. The goggles have a double lens assembly that is removably received in the front wall frame of the goggles. One or more metal heat sinks are secured to the goggle structure to dissipate the heat within the chamber between the goggles and the face of the person wearing the goggles.<br><b>Independant Claims</b><br>1) A sound synthesizing method for synthesizing a sound from a plurality of coded parameters using a wide-band voiced sound code book and a wide-band unvoiced sound code book pre-formed from voiced and unvoiced sound characteristic parameters, respectively, extracted from wide-band voiced and unvoiced sounds separated at every predetermined time unit, and using a narrow-band voiced sound code book and a narrow-band unvoiced sound code book pre-formed from voiced and unvoiced sound characteristic parameters extracted from a narrow-band sound obtained by limiting a frequency band of the separated wide-band voiced and unvoiced sounds, the sound synthesizing method comprising the steps of: decoding the plurality of coded parameters to form a plurality of decoded parameters; forming an innovation-related parameter from a first one of the plurality of decoded parameters; converting a second one of the plurality of decoded parameters to a sound synthesis characteristic parameter; discriminating between the voiced and unvoiced sounds discriminable with reference to a third one of the plurality of decoded parameters; quantizing the sound synthesis characteristic parameter based on a result of the step of discriminating by using the narrow-band voiced and unvoiced sound code books to form narrow-band voiced and unvoiced sound data; dequantizing, by using the wide-band voiced and unvoiced sound code books, the narrow-band voiced and unvoiced sound data having been quantized using the narrow-band voiced and unvoiced sound code books and producing dequantized sound data; and synthesizing a sound based on the dequantized sound data and the innovation-related parameter.<br>9) A sound synthesizing apparatus for synthesizing a sound from a plurality of coded parameters, uses a wide-band voiced sound code book and wide-band unvoiced sound code book pre-formed from voiced and unvoiced sound characteristic parameters, respectively, extracted from wide-band voiced and unvoiced sounds separated at every predetermined time unit, and uses a narrow-band voiced sound code book and a narrow-band unvoiced sound code book pre-formed from voiced and unvoiced sound characteristic parameters extracted from a narrow-band sound obtained by limiting a frequency band of the separated wide-band voiced and unvoiced sounds, the apparatus comprising: decoding means for decoding the plurality of coded parameters to form a plurality of decoded parameters, means for forming an innovation-related parameter from a first one of the plurality of decoded parameters decoded by the decoding means; means for obtaining a sound synthesis characteristic parameter from a second one of the plurality of decoded parameters decoded by the decoding means; means for discriminating between the voiced and unvoiced sounds with reference to a third one of the plurality of decoded parameters decoded by the decoding means; sound quantizing means for quantizing the sound synthesis characteristic parameter based on a result of the discrimination by the means for discriminating of the voiced and unvoiced sounds by using the narrow-band voiced and unvoiced sound code books to form narrow-band voiced and unvoiced sound data; sound dequantizing means for dequantizing the quantized voiced and unvoiced sound data from the sound quantizing means by using the wide-band voiced and unvoiced sound code books and producing dequantized data; and means for synthesizing a sound based on the dequantized data from the sound dequantizing means and the innovation-related parameter.<br>10) A sound synthesizing method for synthesizing sound from a plurality of coded parameters using a wide-band sound code book pre-formed from a characteristic parameter extracted from wide-band sounds at every predetermined time unit, comprising the steps of: decoding the plurality of coded parameters and forming a plurality of decoded parameters; forming an innovation-related parameter from a first one of the plurality of decoded parameters; converting a second one of the plurality of decoded parameters to a sound synthesis characteristic parameter; calculating a narrow-band characteristic parameter from each code vector in the wide-band sound code books; quantizing the sound synthesis characteristic parameter by comparison with the narrow-band characteristic parameter calculated by the step of calculating and producing quantized data; dequantizing the quantized data by using the wide-band sound code book and producing dequantized data; and synthesizing a sound based on the dequantized data and the innovation-related parameter.<br>18) A sound synthesizing apparatus for synthesizing sound from a plurality of coded parameters, a wide-band sound code book pre-formed from a characteristic parameter extracted from wide-band sounds at every predetermined time unit, comprising: means for decoding the plurality of coded parameters to form a plurality of decoded parameters; means for forming an innovation-related parameter from a first one of the plural kinds of parameters decoded by the decoding means; means for converting a second one of the plurality decoded parameters of the plural kinds of decoded parameters decoded by the means for decoding to a sound synthesis characteristic parameter; means for calculating a narrow-band characteristic parameter from each code vector in the wide-band sound code book; means for quantizing the sound synthesis characteristic parameter from the means for converting by using the narrow-band characteristic parameter from the means for calculating and producing quantized data; means for dequantizing the quantized data from the means for quantizing by using the wide-band sound code book; and means for synthesizing a source based on the dequantized data from the means for dequantizing and the innovation-related parameter from the means for forming.<br>19) A sound synthesizing method for synthesizing a sound from a plurality of coded parameters, using a wide-band sound code book pre-formed from a characteristic parameter extracted from wide-band sounds at every predetermined time unit, the method comprising the steps of: decoding the plurality of coded parameters and forming decoded parameters; forming an innovation-related parameter from a first one of the decoded parameters; converting a second one of the decoded parameters to a sound synthesis characteristic parameter; calculating a narrow-band characteristic parameter, by partial extraction, from each code vector in the wide-band sound code book; quantizing the sound synthesis characteristic parameter by comparison with the narrow-band characteristic parameter calculated in the step of calculating and producing quantized data; dequantizing the quantized data by using the wide-band sound code book and producing dequantized data; and synthesizing a sound based on the dequantized data and the innovation-related parameter.<br>25) A sound synthesizing method for synthesizing a sound from a plurality of input coded parameters, using a wide-band sound code book pre-formed from a characteristic parameter extracted from wide-band sounds at every predetermined time unit, the method comprising the steps of: decoding the plurality of coded parameters and producing decoded parameters; forming an innovation-related parameter from a first one of the decoded parameters; converting a second one of decoded parameters to a sound synthesis characteristic parameter, calculating a narrow-band characteristic parameter, by partial extraction, from each code vector in the wide-band sound code book; quantizing the sound synthesis characteristic parameter by comparison with the narrow-band characteristic parameter extracted in the step of calculating and producing quantized data; dequantizing the quantized data by using the wide-band sound code book and producing dequantized data; and synthesizing a sound based on the dequantized data and the innovation-related parameter.<br>32) A sound synthesizing apparatus for synthesizing a sound from a plurality of coded parameters using a wide-band sound code book pre-formed from a characteristic parameter extracted from wide-band sounds at every predetermined time unit, the apparatus comprising: decoding means for decoding the plurality of coded parameters and producing a plurality of decoded parameters; means for forming an innovation-related parameter from a first one of the plurality of decoded parameters from the decoding means; parameter converting means for converting a second one of the plurality of the decoded parameters from the decoding means to a sound synthesis characteristic parameter; calculating means for calculating a narrow-band characteristic parameter, by partial extraction, from each code vector in the wide-band sound code book; quantizing means for quantizing the sound synthesis characteristic parameter from the parameter converting means by using the narrow-band characteristic parameter from the calculating means and producing quantized data; dequantizing means for dequantizing the quantized data from the quantizing means by using the wide-band sound code book and producing dequantized data; and means for synthesizing a sound based on the dequantized data from the dequantizing means and the innovation-related parameter.<br>33) A sound band expanding method for expanding a band of an input narrow-band sound using a wide-band voiced sound code book and a wide band unvoiced sound code book pre-formed from voiced and unvoiced sound parameters, respectively, extracted from wide-band voiced and unvoiced sounds separated at every predetermined time unit, and using a narrow-band voiced sound code book and a narrow-band unvoiced sound code book pre-formed from voiced and unvoiced sound characteristic parameters extracted from a narrow-band sound obtained by limiting a frequency band of the wide-band voiced and unvoiced sounds, the method comprising the steps of: discriminating between a voiced sound and an unvoiced sound in the input narrow-band sound at every predetermined time unit; generating a voiced parameter and an unvoiced parameter from the narrow-band voiced and unvoiced sounds; quantizing the narrow-band voiced parameter and the unvoiced sound parameter of the narrow-band sound by using the narrow-band voiced and unvoiced sound code books and generating narrow-band voiced and unvoiced sound data; dequantizing, by using the wide-band voiced and unvoiced sound code books, the narrow-band voiced and unvoiced sound data having been quantized using the narrow-band voiced and unvoiced sound code books and generating dequantized data; and expanding the band of the narrow-band sound based on the dequantized data.<br>34) A sound band expanding apparatus for expanding a band of an input narrow-band sound, using a wide-band voiced sound code book and a wide-band unvoiced sound code book pre-formed from voiced and unvoiced sound parameters, respectively, extracted from wide-band voiced and unvoiced sounds separated at every predetermined time unit, and using a narrow-band voiced sound code book and a narrow-band unvoiced sound code book pre-formed from voiced and unvoiced sound characteristic parameters extracted from a narrow-band sound obtained by limiting a frequency band of the wide-band voiced and unvoiced sounds, the apparatus comprising: voiced/unvoiced sound discriminating means for discriminating between a voiced sound and an unvoiced sound in the input narrow-band sound at every predetermined time unit; means for generating a voiced parameter and an unvoiced parameter from the narrow-band voiced and unvoiced sounds discriminated by the voiced/unvoiced sound discriminating means; quantizing means for quantizing the narrow-band voiced parameter and unvoiced sound parameter from the generated narrow-band voiced parameter and unvoiced parameter by using the narrow-band voiced and unvoiced sound code books and for generating narrow-band voiced and unvoiced sound data; and dequantizing means for dequantizing, by using the wide-band voiced and unvoiced sound code books, the narrow-band voiced and unvoiced sound data from the quantizing means by using the narrow-band voiced and unvoiced sound code books and producing dequantized data, wherein the band of the narrow-band sound is expanded based on the dequantized data from the dequantizing means.<br>35) A sound band expanding method for expanding a band of an input narrow-band sound using a wide-band sound code book pre-formed from a parameter extracted from wide-band sounds at every predetermined time unit, the method comprising the steps of: generating a narrow-band parameter from the input narrow-band sound; calculating a narrow-band parameter from each code vector in the wide-band sound code book; quantizing the narrow-band parameter generated from the input narrow-band sound by comparison with the calculated narrow-band parameter; dequantizing the quantized data by using the wide-band sound code book and producing dequantized data; and expanding a band of the narrow-band sound based on the dequantized data.<br>36) A sound band expanding apparatus for expanding a band of an input narrow-band sound using a wide-band sound code book pre-formed from parameters extracted from wide-band sounds at every predetermined time unit, the apparatus comprising: generating means for generating a narrow-band parameter from the input narrow-band sound; calculating means for calculating a narrow-band parameter from each code vector in the wide-band sound code book; quantizing means for quantizing the narrow-band parameter from the generating means by comparison with the narrow-band parameter from the calculating means and producing quantized narrow-band data; and dequantizing means for dequantizing the quantized narrow-band data from the quantizing means by using the wide-band sound code book and producing dequantized data, wherein the band of the narrow-band sound being expanded is based on the dequantized data from the dequantizing means.<br>37) A sound band expanding method for expanding a band of an input narrow-band sound using a wide-band sound code book pre-formed from a parameter extracted from wide-band sounds at every predetermined time unit, the method comprising the steps of: generating a narrow-band parameter from the input narrow-band sound; calculating a narrow-band parameter, by partial extraction, from each code vector in the wide-band sound code book; quantizing the narrow-band parameter generated from the input narrow-band sound in the step of generating by comparison with the calculated narrow-band parameter from the step of calculating and forming quantized data; dequantizing the quantized data by using the wide-band sound code book and forming dequantized data; and expanding the band of the narrow-band sound based on the dequantized data.<br>38) A sound band expanding apparatus for expanding a band of an input narrow-band sound using a wide-band code book pre-formed from a parameter extracted from wide-band sounds at every predetermined time unit, the apparatus comprising: generating means for generating a narrow-band parameter from the input narrow-band sound; calculating means for calculating a narrow-band parameter, by partial extraction, from each code vector in the wide-band sound code book; quantizing means for quantizing the narrow-band parameter generating from the generating means by using the narrow-band parameter from the calculating means and producing quantized narrow-band data; and dequantizing means for dequantizing the quantized narrow-band data from the quantizing means by using the wide-band sound code book and producing dequantized data, wherein the band of the narrow-band sound being expanded is based on the dequantized data from the dequantizing means.</p></layer>
<layer id = "layer89"><p><b>US5677985A:Speech decoder capable of reproducing well background noise</b><br>A strain-relief clamp for securely engaging a multi-conductor cable between two relatively movable pieces at a position closely adjacent the connections of the conductors to the terminals of an electrical plug, receptacle, or other wiring device. A first piece includes a hollow, cylindrical shell having an integrally formed, generally semi-cylindrical portion internally of the shell at one end, the wiring device being secured in the other end. A second piece is positioned inside the shell with an arcuate surface opposing an inwardly facing, curved surface of the semi-cylindrical portion of the first piece. A pair of screws pass through openings in the shell and semi-cylindrical portion of the first piece and are threadedly engaged in the second piece. A pair of flexible tabs or wings extend integrally from the second piece to contact the curved surface of the first, being positioned between the metal screws and the conductors to form a dielectric barrier as the screws are tightened to grip the cable tightly between the curved surfaces of the first and second pieces.<br><b>Independant Claims</b><br>1. A speech decoder comprising: decoding means for decoding a binary coded input signal into a spectral parameter, an average amplitude, a pitch period and a sound source signal; speech detecting means for detecting a non-speech interval and a speech interval using at least one among the spectral parameter, the average amplitude and the pitch period; excitation signal generating means for generating an excitation signal using the sound source signal, the average amplitude, and the pitch period; first signal reproducing means for reproducing a sound signal using the excitation signal from the excitation signal generating means and the spectral parameter from said decoding means; memorizing means for memorizing a random number code book storing random number code vectors which can be used in reproducing sound signals; searching means for searching the random number code book and selecting a random number code vector which can be used to reproduce a sound signal that is closest to the output signal reproduced in the non-speech interval by said first signal reproducing means; second signal reproducing means for reproducing a sound signal using the spectral parameter from said decoding means and the random number code vector which has been searched by said searching means; and switching means for outputting the sound signal from said first signal reproducing means in the speech interval and outputting the sound signal from said second signal reproducing means in the non-speech interval.<br>6. A speech decoder comprising: decoding means for decoding a binary coded input signal into a spectral parameter, an average amplitude, a pitch period and a sound source signal; speech detecting means for detecting a non-speech interval and a speech interval using at least one among the spectral parameter, the average amplitude and the pitch period; excitation signal generating means for generating a excitation signal using the sound source signal, the average amplitude, and the pitch period; memorizing means for memorizing a random number code book storing random number code vectors which can be used in reproducing sound signals; searching means for searching the random number code book for a random number code vector which can be used in reproducing a sound signal that is closest to the excitation signal in the non-speech interval; switching means for outputting the excitation signal from said excitation signal generating means in the speech interval and outputting the random number code vector which has been searched in the non-speech interval by said searching means; and signal reproducing means for reproducing a sound signal using the spectral parameter from said decoding means and the output from the switching means.</p></layer>
<layer id = "layer90"><p><b>US6910009B1:Speech signal decoding method and apparatus, speech signal encoding/decoding method and apparatus, and program product therefor</b><br>A method of making a thin-film device including a substrate-supply station that supplies a substrate. The substrate has a first layer on the substrate. Also described is a method and device for depositing a second layer onto the first layer, wherein energy supplied to the second layer aids in layer formation without substantially heating the substrate. Some embodiments include depositing a photovoltaic cell. In some embodiments, the substrate is a flexible material supplied from a roll. Some embodiments include attaching an integrated circuit to the substrate and operatively coupling the integrated circuit to charge the battery from the photovoltaic cell.<br><b>Independant Claims</b><br>1) A speech signal decoding method for decoding information concerning at least a sound source signal, gain and linear prediction coefficients from a received signal, generating an excitation signal and linear prediction coefficients from decoded information, and driving a filter, which is constituted by the linear prediction coefficients, by the excitation signal to thereby decode a speech signal, comprising: smoothing the gain using a past value of the gain; limiting the value of the smoothed gain based upon an amount of fluctuation calculated from the gain and the smoothed gain; and decoding the speech signal using the gain that has been smoothed and limited.<br>6) A speech signal decoding method for decoding information concerning an excitation signal and linear prediction coefficients from a received signal, generating an excitation signal and linear prediction coefficients from the decoded information, and driving a filter, which is constituted by the linear prediction coefficients, by the excitation signal to thereby decode a speech signal, comprising: deriving a norm of the excitation signal at regular intervals; smoothing the norm using a past value of the norm; limiting the value of the smoothed norm based upon an amount of fluctuation calculated from the norm and the smoothed norm; changing the amplitude of the excitation signal in said intervals using said norm and the norm that has been smoothed and limited; and driving the filter by the excitation signal the amplitude of which has been changed.<br>12) A speech signal decoding method for decoding information concerning an excitation signal and linear prediction coefficients from a received signal, generating the excitation signal and the linear prediction coefficients from the decoded information, and driving a filter, which is constituted by the linear prediction coefficients, by the excitation signal to thereby decode a speech signal, comprising: identifying a speech segment and a noise segment with regard to the received signal using the decoded information; deriving a norm of the excitation signal at regular intervals in the noise segment; smoothing the norm using a past value of the norm; limiting the value of the smoothed norm based upon an amount of fluctuation derived from the norm and the smoothed norm; changing the amplitude of the excitation signal in said intervals using the norm and the norm that has been smoothed and limited; and driving the filter by the excitation signal the amplitude of which has been changed.<br>18) A speech signal decoding apparatus for decoding information concerning at least a sound source signal, gain and linear prediction coefficients from a received signal, generating an excitation signal and linear prediction coefficients from the decoded information, and driving a filter, which is constituted by the linear predictions coefficients, by the excitation signal to thereby decode a speech signal, comprising: a smoothing circuit smoothing the gain using a past value of the gain; and a smoothing-quantity limiting circuit limiting the value of the smoothed gain based upon an amount of fluctuation calculated from the gain and the smoothed gain.<br>22) A speech signal decoding apparatus for decoding information concerning an excitation signal and linear prediction coefficients from a received signal, generating the excitation signal and linear prediction coefficients from the decoded information, and driving a filter, which is constituted by the linear prediction coefficients, by the excitation signal to thereby decode a speech signal, comprising: an excitation-signal normalizing circuit deriving a norm of the excitation signal at regular intervals and dividing the excitation signal by the norm; a smoothing circuit smoothing the norm using a past value of the norm; a smoothing-quantity limiting circuit limiting the value of the smoothed norm based upon an amount of fluctuation calculated from the norm and the smoothed norm; and an excitation-signal reconstruction circuit multiplying the smoothed and limited norm by the excitation signal to thereby change the amplitude of the excitation signal in said intervals.<br>26) A speech signal decoding apparatus for decoding information concerning an excitation signal and linear prediction coefficients from a received signal, generating the excitation signal and linear prediction coefficients from the decoded information, and driving a filter, which is constituted by the linear prediction coefficients, by the excitation signal to thereby decode a speech signal, comprising: a voiced/unvoiced identification circuit identifying a speech segment and a noise segment with regard to the received signal using the decoded information; an excitation-signal normalizing circuit deriving a norm of the excitation signal at regular intervals and dividing the excitation signal by the norm; a smoothing circuit smoothing the norm using a past value of the norm; a smoothing-quantity limiting circuit limiting the value of the smoothed norm based upon an amount of fluctuation calculated from the norm and the smoothed norm; and an excitation-signal reconstruction circuit multiplying the smoothed and limited norm by the excitation signal to thereby change the amplitude of the excitation signal in said intervals.<br>30) A program product for causing a computer to execute processing (a) and (b) below, wherein the computer constitutes a speech signal decoding apparatus for decoding information concerning at least a sound source signal, gain and linear prediction coefficients from a received signal, generating an excitation signal and linear prediction coefficients from the decoded information, and driving a filter, which is constituted by the linear prediction coefficients, by the excitation signal to thereby decode a speech signal; (a) a process for performing smoothing using a past value of a gain and calculating an amount of fluctuation between the gain and a smoothed gain; and (b) a process for limiting the value of the smoothed gain in conformity with the value of the amount of fluctuation and decoding the speech signal using the smoothed, limited gain.<br>33) A program product for causing a computer to execute processing (a) to (c) below, wherein the computer constitutes a speech signal decoding apparatus for decoding information concerning an excitation signal and linear prediction coefficients from a received signal, generating an excitation signal and linear prediction coefficients from the decoded information, and driving a filter, which is constituted by the linear prediction coefficients, by the excitation signal to thereby decode a speech signal: (a) calculating a norm of an excitation signal at regular intervals and smoothing the norm using a past value of the norm; (b) limiting the value of the smoothed norm in conformity with the value of an amount of fluctuation calculated from the norm and the smoothed norm; and (c) changing the amplitude of the excitation signal in said intervals using the norm and the norm that has been smoothed and limited, and driving the filter by the excitation signal the amplitude of which has been changed.<br>37) A program product for causing a computer to execute processing (a) to (d) below, wherein the computer constitutes a speech signal decoding apparatus for decoding information concerning an excitation signal and linear prediction coefficients from a received signal, generating an excitation signal and linear prediction coefficients from the decoded information, and driving a filter, which is constituted by the linear prediction coefficients, by the excitation signal to thereby decode a speech signal: (a) identifying a speech segment and a noise segment with regard to a received signal using decoded information; (b) calculating a norm of an excitation signal at regular intervals in the noise segment and smoothing the norm using a past value of the norm; (c) limiting the value of the smoothed norm in conformity with an amount of fluctuation calculated from the norm and the smoothed norm; and (d) changing the amplitude of the excitation signal in said intervals using the norm and the norm that has been smoothed and limited, and driving the filter by the excitation signal the amplitude of which has been changed.<br>41) A speech signal decoding apparatus comprising: (a) a code input circuit splitting code of a bit sequence of an encoded input signal that enters from an input terminal, converting the code to indices that correspond to a plurality of decode parameters, outputting an index corresponding to a line spectrum pair, termed hereinafter “LSP”, which represents the frequency characteristic of the input signal, to an LSP decoding circuit, outputting an index corresponding to a delay that represents a pitch period of the input signal to a pitch signal decoding circuit, outputting an index corresponding to a sound source vector comprising a random number or a pulse train to a sound source signal decoding circuit, outputting an index corresponding to a first gain to a first gain decoding circuit, and outputting an index corresponding to a second gain to a second gain decoding circuit; (b) an LSP decoding circuit, to which the index output from said code input circuit is input, and which reads the LSP corresponding to the input index out of a table which stores LSPs corresponding to indices, obtains an LSP in a subframe of the present frame and outputs the LSP; (c) a linear prediction coefficient conversion circuit, to which the LSP output from said LSP decoding circuit is input, and which converts the LSP to linear prediction coefficients and outputs the coefficients to a synthesis filter; (d) a sound source signal decoding circuit, to which the index output from said code input circuit is input, and which reads a sound source vector corresponding to the index out of a table storing sound source vectors corresponding to indices, and outputs the sound source vector to a second gain decoding circuit; (e) a second gain decoding circuit, to which the index output from said code input circuit is input, and which reads a second gain corresponding to the input index out of a table storing second gains corresponding to indices, and outputs the second gain to a smoothing circuit; (f) a second gain circuit, to which a first sound source vector output from said sound source signal decoding circuit and the second gain are input, and which multiplies the first sound source vector by the second gain to generate a second sound source vector and outputs the generated second sound source vector to an adder; (g) a memory circuit holding an excitation vector input thereto from said adder and outputting a held excitation vector, which was input thereto in the past, to a pitch signal decoding circuit; (h) a pitch signal decoding circuit, to which the past excitation vector held by said memory circuit and the index output from said code input circuit are input, with said index specifying a delay, and which cuts out vectors of samples corresponding to a vector length from a point previous to the starting point of the present frame by an amount corresponding to the delay to thereby generate a first pitch vector, and outputs the first pitch vector to a first gain circuit; (i) a first gain decoding circuit, to which the index output from said code input circuit is input, and which reads a first gain corresponding to the input index out of a table storing first gains corresponding to indices, and outputs the first gain to a first gain circuit; (j) a first gain circuit, to which the first pitch vector output from said pitch signal decoding circuit and the first gain output from said first gain decoding circuit are input, and which multiplies the input first pitch vector by the first gain to generate a second pitch vector, and outputs the generated second pitch vector to said adder; (k) an adder, to which the second pitch vector output from said first gain circuit and the second sound source vector output from said second gain circuit are input, and which calculates the sum of these inputs, and outputs the sum to a synthesis filter as an excitation vector; (l) a smoothing coefficient calculation circuit, to which LSP output from said LSP decoding circuit is input, and which calculates average LSP in the present frame, finds the amount of fluctuation of the LSP with respect to each subframe, finds a smoothing coefficient in the subframe, and outputs the smoothing coefficient to a smoothing circuit; (m) a smoothing circuit, to which the smoothing coefficient output from said smoothing coefficient calculation circuit and the second gain output from said second gain decoding circuit are input, and which finds an average gain from the second gain in the subframe, and outputs the second gain; (n) a synthesis filter, to which the excitation vector output from said adder and the linear prediction coefficients output from said linear prediction coefficient conversion circuit are input, and which drives a synthesis filter, for that the linear prediction coefficients have been set, by the excitation vector to thereby calculate a reconstructed vector, and outputs the reconstructed vector from an output terminal; and (o) a smoothing-quantity limiting circuit, to which the second gain output from said second gain decoding circuit and the smoothed second gain output from said smoothing circuit are input, and which finds the amount of fluctuation between the smoothed second gain output from said smoothing circuit and the second gain output from said second gain decoding circuit, outputs the smoothed second gain to said second gain circuit as is when the amount of fluctuation is less than a predetermined threshold value, replaces the smoothed second gain with a smoothed second gain limited in terms of values it is capable of taking on when the amount of fluctuation is equal to or greater than the threshold value, and outputs this smoothed second gain to said second gain circuit.<br>47) A speech signal decoding method for decoding information concerning at least a sound source signal, gain and linear prediction coefficients from a received signal, generating an excitation signal and linear prediction coefficients from decoded information, and driving a filter, which is constituted by the linear prediction coefficients, by the excitation signal to thereby decode a speech signal, comprising: smoothing the gain using a past value of the gain; limiting the value of the smoothed gain based upon the gain prior to the smoothing and the smoothed gain; and decoding the speech signal using the gain that has been smoothed and limited.<br>48) A speech signal decoding method for decoding Information concerning an excitation signal and linear prediction coefficients from a received signal, generating an excitation signal and linear prediction coefficients from the decoded information, and driving a filter, which is constituted by the linear prediction coefficients, by the excitation signal to thereby decode a speech signal, comprising: deriving a norm of the excitation signal at regular intervals; smoothing the norm using a past value of the norm; limiting the value of the smoothed norm based upon the smoothed norm and the norm prior to the smoothing; changing the amplitude of the excitation signal in said intervals using said norm and the norm that has been smoothed and limited; and driving the filter by the excitation signal the amplitude of which has been changed.</p></layer>
<layer id = "layer91"><p><b>US5119424A:Speech coding system using excitation pulse train</b><br>A device for automatically presenting fasteners in a predetermined disposition comprising a container for the fasteners which presents the fasteners to a rotary drum which raises the fasteners upwardly for deposit into a chute. The fasteners are fed down the chute to a ramp which positions individual fasteners in a predesired position in a feed barrel for receipt by a fastener tool. An escapement mechanism is positioned between the chute and the ramp so that a single fastener at one time falls down the ramp into the feed barrel.<br><b>Independant Claims</b><br>1. A speech coding system which analyzes a speech signal for each frame, separates the speech signal into spectral envelope information and excitation information and judges whether the speech signal is a voiced or unvoiced signal so that a plurality of pulses per pitch period are used as excitation for a voiced frame, the system comprising: means for judging whether a current frame is a voiced frame which follows immediately after transition from an unvoiced frame, a voiced frame continuing from a voiced frame, or an unvoiced frame; first excitation pulse generation means which generates plural excitation pulses per pitch period immediately following the transition from an unvoiced frame to a voiced frame; second excitation pulse generation means which generates plural excitation pulses per pitch period in response to a continuing voiced frame; and third excitation pulse generation means which generates excitation pulses in response to an unvoiced frame; wherein said second excitation pulse generation means determines excitation pulse positions of the current voiced frame based on the pitch period with respect to the excitation pulse positions of the voiced frame immediately preceding the current voiced frame, and generates an excitation pulse train at positions relative to the immediately preceding pulse positions.<br>5. A speech coding system using excitation pulse trains, comprising: means for storing an input speech signal; means for analyzing the speech signal for each section of predetermined length thereof to extract spectral envelope information, said section corresponding to each frame; means for extracting a residual signal from the speech signal using said spectral envelope information, said residual signal including a plurality of pulses; voice/unvoice judgement means which judges whether the current frame is a voiced frame or unvoiced frame, and detects a transition from an unvoiced frame to a voiced frame; pitch extraction means for extracting the pitch period of the speech signal; means for generating excitation pulses in response to the output of said voice/unvoice judgement means, said judgement means, (i) if the current frame is a voiced frame following an unvoiced frame, extracting plural pulses per pitch period as an excitation pulse train from said residual pulses within the last pitch section of the current frame and outputting a head address of said excitation pulse train and the amplitude of each pulse, or (ii) if the current frame is a voiced frame continuing from a voiced frame, determining the last pitch section of the current frame with reference to the head address of the excitation pulse train of the previous frame, setting the head address of the excitation pulse train of the current frame to be an approximate head address of said pitch section relative to the head address of the excitation pulse train of the previous frame, and outputting amplitudes of plural pulses per pitch period starting from said approximate head address; and means for quantizing and coding said spectral envelope information, voice/unvoice information, pitch information and information provided by said excitation extraction means.<br>8. A speech coding method using excitation pulse trains comprising the steps of: analyzing a speech signal for each section of predetermined length thereof to extract spectral envelope information, said section corresponding to each frame; extracting a residual signal from the speech signal using said spectral envelope information, said residual signal including a plurality of pulses; judging whether the current frame is a voiced frame or an unvoiced frame, and detecting a transition from an unvoiced frame to a voiced frame; extracting the pitch period of the speech signal; in response to the voice/unvoice judgement, (i) if the current frame is a voiced frame following an unvoiced frame, extracting plural pulses per pitch period as an excitation pulse train from said residual pulses within the last pitch section of the current frame and outputting a head address of said excitation pulse train and the amplitude of each pulse, or (ii) if the current frame is a voiced frame continuing from a voiced frame, determining the last pitch section of the current frame with reference to the head address of the excitation pulse train of the previous frame, setting the head address of the excitation pulse train of the current frame to be an approximate head address of said pitch section relative to the head address of the excitation pulse train of the previous frame, and outputting amplitudes of plural pulses per pitch period starting from said approximate head address; and quantizing and coding said spectral envelope information, voice/unvoice information, pitch information and excitation information.<br>11. A speech coding method comprising the steps of: analyzing a speech signal for each frame thereof; separating the signal into spectral envelope information and excitation information; and generating a plurality of pulse trains for excitation; wherein a frame judged to be a voiced frame by voice/unvoice judgement means provided on a part of a coder is interpolated as to excitation to cause plural pulses per pitch period to be generated at a position relative to the previous pulse positions of the previous frame, each pitch period being extracted by pitch extraction means provided on another part of said coder.</p></layer>
<layer id = "layer92"><p><b>US6526378B1:Method and apparatus for processing sound signal</b><br>A magnetic tape cartridge having an integral key is provided for use within a magnetic tape drive having a tape cartridge guide assembly adapted for use with the integral key. The integral key is defined on the exterior of the cartridge housing and comprises a raised fixture or tab. The tape cartridge guide assembly includes at least one slit portion. During use, the tape cartridge having the integral key is inserted into the tape drive, the integral key is aligned and permitted to traverse the slit portion for enabling the cartridge to enter the subsystem.<br><b>Independant Claims</b><br>1) A method for processing a sound signal comprising: generating a first processed signal by processing an input sound signal; calculating a predetermined evaluation value by analyzing the input sound signal; operating a weighted addition of the input sound signal and the first processed signal based on the predetermined evaluation value to generate a second processed signal; and outputting the second processed signal.<br>17) A method for processing a sound signal comprising: decoding a speech code generated by a speech encoding process as an input sound signal to obtain a first decoded speech; generating a second decoded speech by postfiltering the first decoded speech; generating a first processed speech by processing the first decoded speech; calculating a predetermined evaluation value by analyzing any of the decoded speeches; operating weighted addition of the second decoded speech and the first processed speech based on the evaluation value to obtain a second processed speech; and outputting the second processed speech as an output speech.<br>18) An apparatus for processing a sound signal comprising: a first processed signal generator processing an input sound signal to generate a first processed signal; an evaluation value calculator calculating a predetermined evaluation value by analyzing the input sound signal; a second processed signal generator operating a weighted addition of the input sound signal and the first processed signal based on the evaluation value calculated by the evaluation value calculator and outputting a result of the weighted addition as a second processed signal.</p></layer>
<layer id = "layer93"><p><b>US6134523A:Coding bit rate converting method and apparatus for coded audio data</b><br>A fabric panel loader for automatically feeding a fabric panel from a stack of fabric pieces to a work station. The apparatus includes a fabric pickup assembly for removing the fabric panel from the stack of fabric pieces and transferring the panel to a smoothing table. The smoothing table receives the fabric panel and automatically moves the fabric panel from the stack of fabric pieces to a predetermined orientation. A panel loader removes the fabric panel from the table and transfers the panel to the work station.<br><b>Independant Claims</b><br>1. A method of further converting input compressed audio bitstream, already compressed at lower bit rate than that of originally digitized raw audio data, to output coded bitstream with coding bit rate lower than a target coding bit rate and different coding bit rate from that of said input compressed audio bitstream, characterized in: that a control output is taken out a control output from said input compressed audio bitstream without reconstructing said raw audio data when the frame size of said input compressed audio bitstream is larger than the frame size determined by said target coding bit rate; and that said output coded bitstream is provided as a bit rate-converted bitstream by controlling a parameter defining the frame size of said input compressed audio bitstream by the use of said control output in a predetermined procedure until the frame size of said input compressed audio bitstream data becomes smaller than the frame size determined by said target coding bit rate.<br>2. A method of further converting input compressed audio bitstream, already compressed at lower bit rate than that of originally digitized raw audio data, to output coded bitstream with coding bit rate lower than a target coding bit rate and different coding bit rate from that of said input compressed audio bitstream characterized in: that a control output is taken out a control output from said input compressed audio bitstream without reconstructing said raw audio data when the frame size of said input compressed audio bitstream is larger than the frame size determined by said target coding bit rate; that said output coded bitstream is provided as a bit rate--converted bitstream by controlling a parameter defining the frame size of said input compressed audio bitstream by the use of said control output in a predetermined procedure until the frame size of said input compressed audio bitstream data becomes smaller than the frame size determined by said target coding bit rate; and that said parameter is the number of bits assigned to each of a plurality of frequency bands extracted from said input compressed audio bitstream and that said number of bits are directly reduced from said input compressed audio bitstream.<br>3. A method of further converting input compressed audio bitstream, already compressed at lower bit rate than that of originally digitized raw audio data, to output coded bitstream with coding bit rate lower than a target coding bit rate and different coding bit rate from that of said input compressed audio bitstream, characterized in: that a control output is taken out a from said input compressed audio bitstream without reconstructing said raw audio data when the frame size of said input compressed audio bitstream is larger than the frame size determined by said target coding bit rate; that said output coded bitstream is provided as a bit rate-converted bitstream by controlling a parameter defining the frame size of said input compressed audio bitstream by the use of said control output in a predetermined procedure until the frame size of said input compressed audio bitstream data becomes smaller than the frame size determined by said target coding bit rate; and that said parameter is the number of bits assigned to each of a plurality of frequency bands extracted from said input compressed audio bitstream, and that said predetermined procedure is defined to reduce said number of bits assigned to said plurality of frequency bands in descending order of frequency bands.<br>4. A method of further converting input compressed audio bitstream, already compressed at lower bit rate than that of originally digitized raw audio data, to output coded bitstream with coding bit rate lower than a target coding bit rate and different coding bit rate from that of said input compressed audio bitstream, characterized in: that a control output is taken out from said input compressed audio bitstream without reconstructing said raw audio data when the frame size of said input compressed audio bitstream is larger than the frame size determined by said target coding bit rate; that said output coded bitstream is provided as a bit rate-converted bitstream by controlling a parameter defining the frame size of said input compressed audio bitstream by the use of said control output in a predetermined procedure until the frame size of said input compressed audio bitstream data becomes smaller than the frame size determined by said target coding bit rate; and that said parameter is the number of quantization steps in each of a plurality of frequency bands extracted from said input compressed audio bitstream, and that said predetermined procedure is defined to reduce said number of quantization steps in selected ones of a plurality of said frequency bands of said input compressed audio bitstream.<br>9. A method of further converting input compressed audio bitstream, already compressed at lower bit rate than that of originally digitized raw audio data, to output coded bitstream with coding bit rate lower than a target coding bit rate and different coding bit rate from that of said input compressed audio bitstream, characterized in: that a control output is taken out from said input compressed audio bitstream without reconstructing said raw audio data when the frame size of said input compressed audio bitstream is larger than the frame size determined by said target coding bit rate; that said output coded bitstream is provided as a bit rate--converted bitstream by controlling a parameter defining the frame size of said input compressed audio bitstream by the use of said control output in a predetermined procedure until the frame size determined by said target coding bit rate; and that said parameter is the number of quantization bits for each quantization step in a plurality of frequency bands extracted from said input compressed audio bitstream, and that said predetermined procedure is defined to reduce said number of bits allocated to said quantization step in selected ones of a plurality of said frequency bands in a predetermined order of selection.<br>12. An apparatus for further converting input compressed audio data, already compressed at lower bit rate than that of originally digitized raw audio data, to output coded bitstream, with coding bit rate lower than a target coding bit rate and different coding bit rate from that of said input compressed audio bitstream, characterized by: comparison means for taking out a control output from said input compressed audio bitstream without reconstructing said raw audio data when the frame size of said input compressed audio bitstream is larger than the frame size determined by said target coding bit rate; and converting means for providing said output coded bitstream as a bit rate-converted bitstream by controlling a parameter defining the frame size of said input compressed audio bitstream by the use of said control output in a predetermined procedure until the frame size of said input compressed audio bitstream becomes smaller than the frame size determined by said tav.about.get coding bit rate.<br>13. An apparatus for further converting input compressed audio data, already compressed at lower bit rate than that of originally digitized raw audio data, to output coded bitstream with coding bit rate lower than a target coding bit rate and different coding bit rate from that of said input compressed audio bitstream, characterized by: comparison means for taking out a control output from said input compressed audio bitstream without reconstructing said raw audio data when the frame size of said input compressed audio bitstream is larger than the frame size determined by said target coding bit rate; and converting means for providing said output coded bitstream, as a bit rate-converted bitstream by controlling a parameter defining the frame size of said input compressed audio bitstream by the use of said control output in a predetermined procedure until the frame size of said input compressed audio bitstream becomes smaller than the frame size determined by said target coding bit rate, said converting means being constructed so that said parameter is the number of bits assigned to each of a plurality of frequency bands extracted from said input compressed audio bitstream and that number of bits are directly reduced from said input compressed audio bitstream.<br>14. An apparatus for further converting input compressed audio data, already compressed at lower bit rate than that of originally digitized raw audio data, to output coded bitstream with coding bit rate lower than a target coding bit rate and different coding bit rate from that of said input compressed audio bitstream, characterized by: comparison means for taking out a control output from said input compressed audio bitstream without reconstructing said raw audio data when the frame size of said input compressed audio bitstream is larger than the frame size deterined by said target coding bit rate; and converting means for providing said output coded bitstream as a bit rate-converted bitstream by controlling a parameter defining the frame size of said input compressed audio bitstream by the use of said control output in a predetermined procedure until the frame size of said input compressed audio bitstream becomes smaller than the frame size determined by said target coding bit rate; said converting means being constructed so that said parameter is the number of bits assigned to each of a plurality of frequency bands extracted from said input compressed audio bitstream and that said predetermined procedure is defined to reduce said number of bits assigned to a plurality of said frequency bands in order of higher to lower frequency bands.<br>15. An apparatus for further converting input compressed audio data, already compressed at lower bit rate than that of originally digitized raw audio data, to output coded bitstream with coding bit rate lower than a target coding bit rate and different coding bit rate from that of said input compressed audio bitstream characterized by: comparison means for taking out a control output from said input compressed audio bitstream without reconstructing said raw audio data when the frame size of said input compressed audio bitstream is larger than the frame size determined by said target coding bit rate; and converting means for providing said output coded bitstream as a bit rate-converted bitstream by controlling a parameter defining the frame size of said input compressed audio bitstream by the use of said control output in a predetermined procedure until the frame size of said input compressed audio bitstream becomes smaller than the frame size determined by said target coding bit rate; said converting means being constructed so that said parameter is the number of quantization steps in each of a plurality of frequency bands extracted from said input compressed audio bitstream ,and that said predetermined procedure is defined to reduce said number of quantization steps in selected ones of a plurality of said frequency bands of said input compressed audio bitstream.<br>20. An apparatus for further converting input compressed audio data, already compressed at lower bit rate than that of originally digitized raw audio data, to output coded bitstream with coding bit rate lower than a target coding bit rate and different coding bit rate from that of said input compressed audio bitstream, characterized by: comparison means for taking out a control output from said input compressed audio bitstream without reconstructing said raw audio data when the frame size of said input compressed audio bitstream is larger than the frame size determined by said target coding bit rate; and converting means for providing said output coded bitstream as a bit rate-converted bitstream by controlling a parameter defining the frame size of said input compressed audio bitstream by the use of said control output in a predetermined procedure until the frame size of said input compressed audio bitstream becomes smaller than the frame size determined by said target coding bit rate; said converting means being constructed so that said parameter is the number of quantization bits for each quantization step in a plurality of frequency bands extracted from said input compressed audio bitstream, and that said predetermined procedure is defined to reduce said number of bits allocated for said quantization step in selected ones of a plurality of said frequency bands in a predetermined order of selection.</p></layer>
<layer id = "layer94"><p><b>US20010041976A1:Signal processing apparatus and mobile radio communication terminal</b><br>A semiconductor integrated circuit comprising a MOSFET having a metal wiring layer formed via an insulating film above and along the gate electrode of the MOSFET. The MOSFET is structured such that its channel length is small or channel width is large, and an input signal is applied from at least both end sides of the gate electrode thereof. Since the metal wiring layer for the input signal is formed on the gate electrode of the MOSFET, high-speed operation is possible without increasing the layout area. FIG. 1.<br><b>Independant Claims</b><br>1. A signal processing apparatus comprising: a noise suppressor having a plurality of different noise suppression characteristics, suppressing background noise contained in a speech signal; a speech encoder having a plurality of different coding algorithm, encoding the suppressed speech signal by using one of said different coding algorithm; and wherein said noise suppressor selects one noise suppression characteristic in accordance with the used coding algorithm at the speech encoder.<br>2. A signal processing apparatus comprising: a noise suppressor having a plurality of different noise suppression characteristics, suppressing background noise contained in a speech signal; a speech encoder having a plurality of different coding rates, encoding the suppressed speech signal by using one of said different coding rates; and wherein said noise suppressor selects one noise suppression characteristic in accordance with the used coding rate at the speech encoder.<br>10. A signal processing apparatus comprising: a speech decoder having a plurality of different decoding algorithm, decoding the encoded speech signal by using one of said different decoding algorithm; a noise suppressor having a plurality of different noise suppression characteristics, suppressing noise component contained in the decoded speech signal; and wherein said noise suppressor selects one noise suppression characteristics in accordance with the used decoding algorithm at the speech encoder.<br>11. A signal processing apparatus comprising: a speech decoder having a plurality of different decoding rates, decoding the encoded speech signal by using one of said different coding rates; a noise suppressor having a plurality of different noise suppression characteristics, suppressing noise component contained in the decoded speech signal; and wherein said noise suppressor selects one noise suppression characteristic in accordance with the used rate at the speech encoder.<br>19. A signal processing apparatus for use in a device in which a hands-free function is selectively usable, the apparatus comprising: a noise suppressor having at least two different noise suppression characteristics, suppressing background noise contained in a speech signal; and said noise suppressor having a switch which selects a suitable suppression characteristic from the different noise suppression characteristics in accordance with the use of the hands-free function.<br>22. A mobile radio communication terminal having a signal processing apparatus, said signal processing apparatus comprising: a noise suppressor having a plurality of different noise suppression characteristics, suppressing background noise contained in a speech signal; a speech encoder having a plurality of different coding algorithm, encoding the suppressed speech signal by using one of said different coding algorithm; and wherein said noise suppressor selects one noise suppression characteristics in accordance with the used coding algorithm at the speech encoder.<br>23. A mobile radio communication terminal having a signal processing apparatus, said signal processing apparatus comprising: a noise suppressor having a plurality of different noise suppression characteristics, suppressing background noise contained in a speech signal; a speech encoder having a plurality of different coding rates, encoding the suppressed speech signal by using one of said different coding rates; and wherein said noise suppressor selects one noise suppression characteristics in accordance with the used coding rate at the speech encoder.<br>24. A signal processing apparatus comprising: a noise suppressor having a plurality of different noise suppression characteristics, suppressing background noise contained in a speech signal, where the number of said noise suppression characteristics is Q (Q: a positive integer); a speech encoder having a plurality of different coding algorithm, encoding the suppressed speech signal by using one of said different coding algorithm, where the number of said coding algorithm is P (P: a positive integer); and wherein said noise suppressor selects one noise suppression characteristic in accordance with the used coding algorithm at the speech encoder, the following relationship is established: P≧Q>1.<br>25. A signal processing apparatus comprising: a noise suppressor having a plurality of different noise suppression characteristics, suppressing background noise contained in a speech signal, where the number of said noise suppression characteristics is Q (Q: a positive integer); a speech encoder having a plurality of different coding rates, encoding the suppressed speech signal by using one of said different coding rates, where the number of said coding rates is R (R: a positive integer); and wherein said noise suppressor selects one noise suppression characteristic in accordance with the used coding rate at the speech encoder, the following relationship is established: R≧Q>1.<br>26. A signal processing apparatus comprising: a noise suppressor having a plurality of different noise suppression characteristics, suppressing background noise contained in a speech signal, said noise suppression characteristics is varied in accordance with a parameter set by a parameter setting means; a speech encoder having a plurality of different coding algorithm, encoding the suppressed speech signal by using one of said different coding algorithm, where the number of said coding algorithm is P (P: a positive integer); and wherein said parameter setting means set a suitable parameter so as to select an optimal noise suppression characteristic in accordance with the used coding algorithm at the speech encoder, where the number of said parameter is S (S: a positive integer), the following relationship is established: R≧S>1.<br>27. A signal processing apparatus comprising: a noise suppressor having a plurality of different noise suppression characteristics, suppressing background noise contained in a speech signal, said noise suppression characteristics is varied in accordance with a parameter set by a parameter setting means; a speech encoder having a plurality of different coding rates, encoding the suppressed speech signal by using one of said different coding rates, where the number of said coding rates is R (R: a positive integer); and wherein said parameter setting means set a suitable parameter so as to select an optimal noise suppression characteristic in accordance with the used coding rate at the speech encoder, where the number of said parameter is S (S: a positive integer), the following relationship is established: R≧≧S>1. </p></layer>
<layer id = "layer95"><p><b>US20020052739A1:Voice decoder, voice decoding method and program for decoding voice signals</b><br>Preventive as well as therapeutic treatment to alleviate cosmetic conditions and symptoms of dermatologic disorders with amphoteric compositions containing alpha hydroxyacids, alpha ketoacids, related compounds or polymeric forms of hydroxyacids is disclosed. The cosmetic conditions and the dermatologic disorders in which the amphoteric compositions and the polymeric compounds may be useful include dry skin, dandruff, acne, keratoses, psoriasis, eczema, pruritus, age spots, lentigines, melasmas, wrinkles, warts, blemished skin, hyperpigmented skin, kyperkeratotic skin, inflammatory dermatoses, skin changes associated with aging, and skin requiring cleansers.<br><b>Independant Claims</b><br>1. A voice decoder comprising: a first voice decoding circuit which is specialized for decoding at least one encoded narrow band voice signal; a second voice decoding circuit which is specialized for decoding at least one encoded wide band voice signal; and a band determination circuit which determines whether a target signal to be decoded is a narrow band voice signal or a wide band voice signal, and wherein: said band determination circuit supplies said first voice decoding circuit with the target signal in a case where it is determined that the target signal is a narrow band voice signal, and supplies said second voice decoding circuit with the target signal in a case where it is determined that the target signal is a wide band voice signal; said first voice decoding circuit decodes the target signal supplied from said band determination circuit; and said second voice decoding circuit decodes the target signal supplied from said band determination circuit.<br>3. A voice decoder comprising: an LSP generation circuit which generates at least one LSP from an encoded narrow band voice signal or wide band voice signal as a target signal to be decoded; an converter which converts the at least one LSP into at least one LPC (Linear Prediction Code); an excitation signal generator which generates an excitation signal for use in linear prediction synthesis, from the target signal; and a voice signal generator which generates a narrow band voice signal or wide band voice signal by performing linear prediction synthesis using the at least one LPC and the excitation signal, and wherein: said converter comprises a first conversion circuit which converts the at least one LSP into the at least one LPC with an adequate level of calculation accuracy for decoding narrow band voice signals, a second conversion circuit which converts the at least one LSP into the at least one LPC with an adequate level of calculation accuracy for decoding wide band voice signals, and a first supply circuit which determines whether the target signal is a narrow band voice signal or wide band voice signal by determining whether number of the at least one LSP is equal to or larger than a predetermined number, supplies said first conversion circuit with the at least one LSP in a case where it is determined that the target signal is a narrow band voice signal, and supplies said second conversion circuit with the at least one LSP in a case where it is determined that the target signal is a wide band voice signal; and said voice signal generator comprises a first synthesis filter which performs linear prediction synthesis using the at least one LPC generated by said first conversion circuit and the excitation signal, with an adequate level of calculation accuracy for decoding narrow band voice signals, a second synthesis filter which performs linear prediction synthesis using the at least one LPC generated by said second conversion circuit and the excitation signal, with an adequate level of calculation accuracy for decoding wide band voice signals, and a second supply circuit which determines whether the target signal is a narrow band voice signal or wide band voice signal by determining whether number of the at least one LSP is equal to or larger than a predetermined number, supplies said first synthesis filter with the excitation signal in a case where it is determined that the target signal is a narrow band voice signal, and supplies said second synthesis filter with the excitation signal in a case where it is determined that the target signal is a wide band voice signal.<br>5. A voice decoder comprising: an LSP generation circuit which generates at least one LSP from an encoded narrow band voice signal or wide band voice signal as a target signal to be decoded; a converter which converts the at least one LSP into at least one LPC; an excitation signal generator which generates an excitation signal for use in performing linear predication synthesis from the target signal; and a voice signal generator which generates a narrow band voice signal or wide band voice signal, by performing linear prediction synthesis using the at least one LPC and the excitation signal, and wherein said voice signal generator includes a first synthesis filter which performs linear prediction synthesis using the at least one LPC and excitation signal, with an adequate level of calculation accuracy for decoding narrow band voice signals, a second synthesis filter which performs linear prediction synthesis using the at least one LPC and excitation signal, with an adequate level of calculation accuracy for decoding wide band voice signals; a first supply circuit which determines whether the target signal is a narrow band voice signal or wide band voice signal by determining whether number of the at least one LPC is equal to or larger than a predetermined number, supplies said first synthesis filter with the at least one LPC in a case where it is determined that the target signal is a narrow band voice signal, and supplies said second synthesis filter with the at least one LPC in a case where it is determined that the target signal is a wide band voice signal, and a second supply circuit which determines whether the target signal is a narrow band voice signal or wide band voice signal by determining whether number of the at least one LSP is equal to or larger than a predetermined number, supplies said first synthesis filter with the excitation signal in a case where it is determined that the target signal is a narrow band voice signal, and supplies said second filter with the excitation signal in a case where it is determined that the target signal is a wide band voice signal.<br>7. A voice decoding method comprising: determining whether a target signal to be decoded is a narrow band voice signal or wide band voice signal; decoding the target signal with an adequate level of calculation accuracy for decoding narrow band voice signals, in a case where it is determined that the target signal is a narrow band voice signal; and decoding the target signal with an adequate level of calculation accuracy for decoding wide band voice signals, in a case where it is determined that the target signal is wide band voice signal.<br>9. A program for controlling a computer to function as a voice decoder comprising: a first voice decoding circuit which is specialized for decoding at least one encoded arrow band voice signal; a second voice decoding circuit which is specialized for decoding at least one encoded wide band voice signal; and a band determination circuit which determines whether a target signal to be decoded is a narrow band voice signal or wide band voice signal, and wherein said band determination circuit supplies said first voice decoding circuit with the target signal in a case where it is determined that the target signal is a narrow band voice signal, and supplies said second voice decoding circuit with the target signal in a case where it is determined that the target signal is a wide band voice signal, said first voice decoding circuit decodes the target signal supplied from said band determination circuit, and said second voice decoding circuit decodes the target signal supplied from said band determination circuit.</p></layer>
<layer id = "layer96"><p><b>US20020087308A1:Speech decoder capable of decoding background noise signal with high quality</b><br>Resistance of given plant tissue to an inhibitor of acetolactate synthase is identified by (a) combining in an aqueous medium a sample of the plant tissue, the inhibitor of acetolactate synthase, and an inhibitor of keto acid reductoisomerase; (b) allowing time for acetolactate to accumulate; (c) rupturing the cells; (d) acidifying the mixture to convert any accumulated acetolactate to acetoin; and (e) calorimetrically detecting the presence of acetoin in the mixture.<br><b>Independant Claims</b><br>1. A speech decoder for decoding a coded speech signal into a reproduction speech signal and for reproducing a speech signal by the use of the reproduction speech signal, including: a spectral parameter calculating circuit, responsive to the reproduction speech signal, for calculating spectral parameters based on the reproduction speech signal; an excitation signal calculating circuit for calculating an excitation signal and for obtaining a level of the excitation signal, on the basis of the reproduction speech signal and the spectral parameters calculated by the spectral parameter calculating circuit; a smoothing circuit responsive to the spectral parameters and the excitation signal, for smoothing in time at least one of the spectral parameters and the level of the excitation signal, so as to output the spectral parameters and the excitation signal where at least one is subjected to smoothing; and a synthesis filter circuit having a synthesis filter constructed with the spectrum parameters output from the smoothing circuit, and for synthesizing the excitation signal by using the synthesis filter, so as to reproduce the speech signal; wherein the excitation signal calculating circuit, the smoothing circuit and the synthesis filter circuit operate in compliance with only predetermined conditions.<br>6. A speech decoder for decoding a coded speech signal into a reproduction speech signal and for reproducing a speech signal by the use of the reproduction speech signal, including: a spectral parameter calculating circuit, responsive to the reproduction speech signal, for calculating spectral parameters based on the reproduction speech signal; an excitation signal calculating circuit for calculating an excitation signal and for obtaining a level of the excitation signal, on the basis of the reproduction speech signal and the spectral parameters calculated by the spectral parameter calculating circuit; a pitch-prediction circuit which calculates a pitch period from either the reproduction speech signal or the excitation signal, carries out a pitch prediction by the use of pitch period to produce a pitch prediction signal, and calculates a residual signal by subtracting the pitch prediction signal from the excitation signal; a gain-calculating circuit for calculating a gain of at lease one of the pitch prediction signal and the residual signal both output from the pitch-prediction circuit; a smoothing circuit responsive to the spectral parameters and the gain, for smoothing in time at least one of the spectral parameters and the gain, so as to output the spectral parameters and the excitation signal where at least one is subjected to smoothing; and a synthesis filter circuit having a synthesis filter constructed with the spectrum parameters output from the smoothing circuit, and for newly producing an excitation signal as a proper excitation signal on the basis of the gain, the pitch prediction signal and the residual signal, and thereby for synthesizing the proper excitation signal by using the synthesis filter, so as to reproduce the speech signal.<br>8. A method of reproducing a speech signal, comprising: first step of decoding a coded speech signal output from a speech coder, so as to produce a reproduction speech signal; second step of calculating spectral parameters based on the reproduction speech signal; third step of calculating an excitation signal and obtaining a level of the excitation signal, on the basis of the reproduction speech signal and the spectral parameters; fourth step of smoothing in time at least one of the spectral parameters and the level of the excitation signal, so as to output the spectral parameters and the excitation signal where at least one is subjected to the smoothing; and fifth step of synthesizing the excitation signal by using the synthesis filter constructed with the spectrum parameters, so as to reproduce the speech signal; wherein the second to fifth steps are carried out in only a case where predetermined conditions are met, while the reproduction speech signal is handled as the speech signal in another case where predetermined conditions are not met.<br>13. A method of reproducing a speech signal, comprising: first step of decoding a coded speech signal output from a speech coder, so as to a reproduction speech signal; second step of calculating spectral parameters based on the reproduction speech signal; third step of calculating an excitation signal and obtaining a level of the excitation signal, on the basis of the reproduction speech signal and the spectral parameters; fourth step of calculating a pitch period from either the reproduction speech signal or the excitation signal, carrying out a pitch prediction by the use of pitch period to produce a pitch prediction signal, and subtracting the pitch prediction signal from the excitation signal to calculate a residual signal; fifth step of calculating a gain of at lease one of the pitch prediction signal and the residual signal; sixth step of smoothing in time at least one of the spectral parameters and the gain, so as to output the spectral parameters and the excitation signal where at least one is subjected to the smoothing; and seventh step of newly producing an excitation signal as a proper excitation signal on the basis of the gain, the pitch prediction signal and the residual signal, and then, synthesizing the proper excitation signal by the use of the synthesis filter constructed with the spectrum parameters, so that the speech signal is reproduced.</p></layer>
<layer id = "layer97"><p><b>US20030138057A1:Encoder and decoder</b><br>A GPS receiver is disclosed wherein GPS position measurement can be performed stably and rapidly without the necessity to wait for periodical time information from a GPS satellite and power consumption is minimized also with a minimized position measurement time through the selection of an optimum time interval between intermittent receptions of GPS signals. The GPS receiver includes a GPS block for performing position measurement based on a signal transmitted from a GPS satellite to update a navigation message and repeating standby and startup thereof, an external clock block for holding frequency information and time information of a high accuracy and outputting a start signal to the GPS block, which is in a standby state, based on the frequency information and the time information held therein, and a frequency measurement block for measuring a frequency offset which is a displacement of a frequency oscillator of the GPS block with reference to the frequency information held in the external clock block and outputting information of the measured frequency offset to the external clock block.<br><b>Independant Claims</b><br>1. An encoding apparatus characterized by comprising: division means for dividing an input time-sequential signal into predetermined-length blocks; low-frequency-component-signal generation means for applying a predetermined frequency analysis to the input time-sequential signal in the blocks and for generating a low-frequency-component signal according to predetermined waveform information based on a result of the analysis; residual-signal generation means for removing the low-frequency-component signal from the input time-sequential signal in the blocks to generate a residual signal; amplitude control process means for analyzing the amplitude of the residual signal and for applying a predetermined amplitude control process to the residual signal according to predetermined amplitude control process information based on a result of the analysis to generate a signal to be quantized; quantization means for quantizing the signal to be quantized to generate a quantized signal; and code-string generation means for encoding the waveform information, the amplitude control process information, and the quantized signal to generate a code string.<br>8. An encoding apparatus for dividing an input time-sequential signal into M band signals, for dividing the band signals into predetermined blocks, and for encoding them, characterized by comprising: low-frequency-component-signal generation means for applying a predetermined frequency analysis to a signal in a block of at least one band signal and for generating a low-frequency-component signal according to predetermined waveform information based on a result of the analysis; residual-signal generation means for removing the low-frequency-component signal from the band signal to generate a residual signal; and amplitude control process means for analyzing the amplitude of the residual signal and for applying a predetermined amplitude control process to the residual signal according to predetermined amplitude control process information based on a result of the analysis to generate a signal to be quantized.<br>9. An encoding method characterized by comprising: a division step of dividing an input time-sequential signal into predetermined-length blocks; a low-frequency-component-signal generation step of applying a predetermined frequency analysis to the input time-sequential signal in the blocks and of generating a low-frequency-component signal according to predetermined waveform information based on a result of the analysis; a residual-signal generation step of removing the low-frequency-component signal from the input time-sequential signal in the blocks to generate a residual signal; an amplitude control process step of analyzing the amplitude of the residual signal and of applying a predetermined amplitude control process to the residual signal according to predetermined amplitude control process information based on a result of the analysis to generate a signal to be quantized; a quantization step of quantizing the signal to be quantized to generate a quantized signal; and a code-string generation step of encoding the waveform information, the amplitude control process information, and the quantized signal to generate a code string.<br>10. A recording medium storing a computer-readable program, the program characterized by comprising: a division step of dividing an input time-sequential signal into predetermined-length blocks; a low-frequency-component-signal generation step of applying a predetermined frequency analysis to the input time-sequential signal in the blocks and of generating a low-frequency-component signal according to predetermined waveform information based on a result of the analysis; a residual-signal generation step of removing the low-frequency-component signal from the input time-sequential signal in the blocks to generate a residual signal; an amplitude control process step of analyzing the amplitude of the residual signal and of applying a predetermined amplitude control process to the residual signal according to predetermined amplitude control process information based on a result of the analysis to generate a signal to be quantized; a quantization step of quantizing the signal to be quantized to generate a quantized signal; and a code-string generation step of encoding the waveform information, the amplitude control process information, and the quantized signal to generate a code string.<br>11. A decoding apparatus for receiving a code string generated by encoding a time-sequential signal in each block and for decoding it, characterized by comprising: decomposition means for decomposing the code string into waveform information, amplitude control process information, and a quantized signal; means for dequantizing the quantized signal; inverse amplitude control process means for applying an amplitude control process inverse to that performed in encoding, to the dequantized signal according to the amplitude control process information to generate a signal to which the amplitude control process has been applied; low-frequency-component-signal generation means for generating a low-frequency-component signal according to the waveform information; and means for generating a time-sequential signal from the signal to which the amplitude control process has been applied, and the low-frequency-component signal.<br>14. A decoding method for receiving a code string generated by encoding a time-sequential signal in each block and for decoding it, characterized by comprising: a decomposition step of decomposing the code string into waveform information, amplitude control process information, and a quantized signal; a step of dequantizing the quantized signal; an inverse amplitude control process step of applying an amplitude control process inverse to that performed in encoding, to the dequantized signal according to the amplitude control process information to generate a signal to which the amplitude control process has been applied; a low-frequency-component-signal generation step of generating a low-frequency-component signal according to the waveform information; and a step of generating a time-sequential signal from the signal to which the amplitude control process has been applied, and the low-frequency-component signal.<br>15. A recording medium storing a computer-readable program for a decoding apparatus which receives a code string generated by encoding a time-sequential signal in each block and decodes it, the program characterized by comprising: a decomposition step of decomposing the code string into waveform information, amplitude control process information, and a quantized signal; a step of dequantizing the quantized signal; an inverse amplitude control process step of applying an amplitude control process inverse to that performed in encoding, to the dequantized signal according to the amplitude control process information to generate a signal to which the amplitude control process has been applied; a low-frequency-component-signal generation step of generating a low-frequency-component signal according to the waveform information; and a step of generating a time-sequential signal corresponding to an encoded time-sequential signal, from the signal to which the amplitude control process has been applied, and the low-frequency-component signal.</p></layer>
<layer id = "layer98"><p><b>US20040049382A1:Voice encoding system, and voice encoding method</b><br>The apparatus and methods of the present invention provide a mechanism for identifying and contacting potential friends and companions by placing a program participant identifier printed with identifying indicia in or on a motor vehicle and then correlating at least one piece of information associated with the program participant identifier to identify a specific program participant. In the most preferred embodiments of the present invention, the license plate of the vehicle displaying the program participant identifier is the medium for identifying the potential friend or partner.<br><b>Independant Claims</b><br>1. A speech encoding apparatus including an envelope information encoder for extracting spectrum envelope information of input speech and for encoding the spectrum envelope information; a sound source information encoder for selecting adaptive excitation code, fixed excitation code and gain code for generating synthesized speech that will minimize a distance between the synthesized speech and the input speech using the spectrum envelope information said envelope information encoder extracts; and a multiplexer for multiplexing the spectrum envelope information said envelope information encoder encodes, and the adaptive excitation code, fixed excitation code and gain code said sound source information encoder selects to output speech code, wherein when said sound source information encoder selects the fixed excitation code, it calculates encoding distortion of a noise-like fixed code vector and multiplies the encoding distortion by a fixed weight corresponding noise-like degree of the noise-like fixed code vector, calculates encoding distortion of a non-noise-like fixed code vector and multiplies the encoding distortion by a fixed weight corresponding to the non-noise-like fixed code vector, and selects the fixed excitation code associated with multiplication result with a smaller value.<br>9. A speech encoding apparatus including an envelope information encoder for extracting spectrum envelope information of input speech and for encoding the spectrum envelope information; a sound source information encoder for selecting adaptive excitation code, fixed excitation code and gain code for generating synthesized speech that will minimize a distance between the synthesized speech and the input speech using the spectrum envelope information said envelope information encoder extracts; and a multiplexer for multiplexing the spectrum envelope information said envelope information encoder encodes, and the adaptive excitation code, fixed excitation code and gain code said sound source information encoder selects to output speech code, wherein said sound source information encoder determines weights considering a number of fixed code vectors stored in each fixed excitation codebook.<br>10. A speech encoding method including the steps of extracting spectrum envelope information of input speech; encoding the spectrum envelope information; selecting adaptive excitation code, fixed excitation code and gain code for generating synthesized speech that will minimize a distance between the synthesized speech and the input speech using the spectrum envelope information encoded; and multiplexing the spectrum envelope information encoded, the adaptive excitation code, the fixed excitation code and the gain code to output speech code, wherein said speech encoding method, when selecting the fixed excitation code, comprises the steps of: calculating encoding distortion of a noise-like fixed code vector; multiplying the encoding distortion by a fixed weight corresponding to noise-like degree of the noise-like fixed code vector; calculating encoding distortion of non-noise-like fixed code vector; multiplying the encoding distortion by a fixed weight corresponding to the non-noise-like fixed code vector; and selecting the fixed excitation code associated with multiplication result with a smaller value.<br>18. A speech encoding method including the steps of extracting spectrum envelope information of input speech; encoding the spectrum envelope information; selecting adaptive excitation code, fixed excitation code and gain code for generating synthesized speech that will minimize a distance between the synthesized speech and the input speech using the spectrum envelope information encoded; and multiplexing the spectrum envelope information encoded, the adaptive excitation code, the fixed excitation code and the gain code to output speech code, wherein said speech encoding method comprises the step of determining weights considering a number of fixed code vectors stored in each fixed excitation codebook.</p></layer>
<layer id = "layer99"><p><b>US20020128835A1:Voice recognition system and standard pattern preparation system as well as voice recognition method and standard pattern preparation method</b><br>The invention concerns a cosmetic self-tanning agent based on dihyroxyacetone and having a sunscreen effect. The object of the invention is to prepare an agent in which the self-tanning effect occurs shortly after application and over a long period of time, and in which a plurality of color shades can be obtained without additional color components. According to the invention, the agent contains: specific portions of one or a plurality of UV filters selected from the group comprising octylsalicylate, octylmethoxycinnamate and benzophenone-3 and their mixtures; dihydroxyacetone (DHA) in a liposomal carrier system and additionally unencapsulated DHA; an antioxidant selected from the group comprising tocopherol, ascorbic acid, calendula extract and a mixture thereof; a moisturizer selected from the group comprising aloe vera, phospholipids, phospholipid mixtures, sodium hyaluronate, glycerol and mixtures thereof; and cosmetic carrier substances and additives.<br><b>Independant Claims</b><br>1. A voice recognition system for recognizing an input voice of a narrow frequency band, said voice recognition system including: a frequency band converting unit for converting said input voice of said narrow frequency band into a pseudo voice of a wide frequency band which covers an entirety of said narrow frequency band and which is wider than said narrow frequency band.<br>8. A standard pattern preparation system for preparing a standard pattern to recognize an input voice of a narrow frequency band, said standard pattern preparation system including: a frequency band converting unit for converting said input voice of said narrow frequency band into a pseudo voice of a wide frequency band which covers an entirety of said narrow frequency band and which is wider than said narrow frequency band.<br>15. A characteristic extraction system for extracting a mercepstrum characteristic quantity of an input voice of a narrow frequency band, said characteristic extraction system including: a power spectrum calculating unit for calculating power spectrums of said input voice of said narrow frequency band; a frequency band converting unit for converting said input voice of said narrow frequency band into a pseudo voice of a wide frequency band which covers an entirety of said narrow frequency band and which is wider than said narrow frequency band; and a mercepstrum calculating unit for calculating a mercepstrum characteristic quantity based on said pseudo voice of said wide frequency band.<br>17. A voice recognition method for recognizing an input voice of a narrow frequency band, said voice recognition method including the steps of: converting said input voice of said narrow frequency band into a pseudo voice of a wide frequency band which covers an entirety of said narrow frequency band and which is wider than said narrow frequency band.<br>21. A standard pattern preparation method for preparing a standard pattern to recognize an input voice of a narrow frequency band, said standard pattern preparation method including the steps of: converting said input voice of said narrow frequency band into a pseudo voice of a wide frequency band which covers an entirety of said narrow frequency band and which is wider than said narrow frequency band.<br>25. A characteristic extraction method for extracting a mercepstrum characteristic quantity of an input voice of a narrow frequency band, said characteristic extraction method including the steps of: calculating power spectrums of said input voice of said narrow frequency band; converting said input voice of said narrow frequency band into a pseudo voice of a wide frequency band which covers an entirety of said narrow frequency band and which is wider than said narrow frequency band; and calculating a mercepstrum characteristic quantity based on said pseudo voice of said wide frequency band.</p></layer>
<layer id = "layer100"><p><b>US20030128851A1:Noise suppressor</b><br>Sustained release dosage forms of high dose insoluble drugs such as ibuprofen and methods for their manufacture are disclosed.<br><b>Independant Claims</b><br>1. A noise suppressing apparatus, comprising: a time-to-frequency converting unit for performing a frequency analysis for an input signal and converting the input signal to both an amplitude spectrum and a phase spectrum; a noise-likeness analyzing unit for judging the input signal to obtain noise-likeness from the input signal, outputting a noise-likeness signal indicating the noise-likeness, and outputting a noise spectrum updating rate coefficient corresponding to the noise-likeness signal; a noise spectrum estimating unit for updating a noise spectrum according to the noise spectrum updating rate coefficient output from the noise-likeness analyzing unit, the amplitude spectrum output from the time-to-frequency converting unit and an average noise spectrum of a past time, and outputting the noise spectrum; a frequency band signal-to-noise ratio calculating unit for calculating a frequency band signal-to-noise ratio denoting a ratio of a signal to a noise from the amplitude spectrum output from the time-to-frequency converting unit and the noise spectrum output from the noise spectrum estimating unit for each frequency band; an amplitude suppression quantity calculating unit for calculating an amplitude suppression quantity denoting a noise suppression level of a current frame from the noise-likeness signal output from the noise-likeness analyzing unit and the noise spectrum output from the noise spectrum estimating unit; a perceptual weight pattern adjusting unit for determining a perceptual weight distributing pattern denoting a frequency characteristic distributing pattern of both a spectral subtraction quantity denoting a first perceptual weight and a spectral amplitude suppression quantity denoting a second perceptual weight from the amplitude suppression quantity calculated by the amplitude suppression quantity calculating unit and the noise-likeness signal output from the noise-likeness analyzing unit; a perceptual weight correcting unit for correcting the spectral subtraction quantity denoting the first perceptual weight and the spectral amplitude suppression quantity denoting the second perceptual weight output from the perceptual weight pattern adjusting unit according to the frequency band signal-to-noise ratio calculated by the frequency band signal-to-noise ratio calculating unit and outputting a corrected spectral subtraction quantity and a corrected spectral amplitude suppression quantity; a spectrum subtracting unit for subtracting a spectrum, which is obtained by multiplying the corrected spectral subtraction quantity output from the perceptual weight correcting unit by the noise spectrum output from the noise spectrum estimating unit, from the amplitude spectrum obtained by the time-to-frequency converting unit to obtain a noise subtracted spectrum; a spectrum suppressing unit for multiplying the noise subtracted spectrum obtained by the spectrum subtracting unit by the corrected spectral amplitude suppression quantity output from the perceptual weight correcting unit to obtain a noise suppressed spectrum; and a frequency-to-time converting unit for converting the noise suppressed spectrum obtained by the spectrum suppressing unit to a time signal according to the phase spectrum obtained by the time-to-frequency converting unit and outputting a noise suppressed signal.</p></layer>
<layer id = "layer101"><p><b>US20040028244A1:Audio signal decoding device and audio signal encoding device</b><br>A hurricane shutter system with accordion folding shutter assemblies is based on the mathematical relationship between the deployed length of the shutter, the stacked or folded length of the shutter and the size of an opening in a structure. The relationship results in a shutter system that will fit different sized openings with the least number of shutter assemblies and without excess assemblies.<br><b>Independant Claims</b><br>1. A decoding device that generates frequency spectral data from an inputted encoded audio data stream, the decoding device comprising: a core decoding unit operable to decode the inputted encoded data stream and generate first frequency spectral data representing an audio signal; and an extended decoding unit operable to generate, based on the first frequency spectral data, second frequency spectral data in a frequency region which is not represented by the encoded data stream, the second frequency spectral data indicating a harmonic structure which is same as an extension along a frequency axis of a harmonic structure indicated by the first frequency spectral data.<br>9. A decoding device that generates frequency spectral data from an inputted encoded audio data stream, the decoding device comprising: a core decoding unit operable to decode the inputted encoded data stream and generate first frequency spectral data representing an audio signal; an extended decoding unit operable to decode, out of the inputted encoded data stream, data on an amplitude indicated by frequency spectral data representing an audio signal in a frequency region extended along a frequency axis from the first frequency spectral data; and a harmonic generating unit operable to generate, based on the data on the amplitude, second frequency spectral data in a frequency region which is not represented by the encoded data stream, the second frequency spectral data indicating a harmonic structure which is same as an extension along the frequency axis of a harmonic structure indicated by the first frequency spectral data.<br>15. A decoding device that generates frequency spectral data from an inputted encoded audio data stream, the decoding device comprising: a core decoding unit operable to decode the inputted encoded data stream and generate first frequency spectral data, the first frequency spectral data being an audio time-frequency signal representing by every frequency bandwidth a time transition of frequency spectral data belonging to a frequency bandwidth which is outputted from a polyphase filter bank; and an extended decoding unit operable to generate, based on the time-frequency signal that is a frequency component of the first frequency spectral data, second frequency spectral data in a frequency region which is not represented by the encoded data stream, the second frequency spectral data being a time-frequency signal in the frequency region and indicating time cyclicity of the first frequency spectral data.<br>19. An encoding device that generates an encoded data stream from frequency spectral data of an audio signal, the encoding device comprising: a core encoding unit operable to encode the inputted frequency spectral data and generate an encoded audio data stream; and an extended encoding unit operable to encode, out of the inputted frequency spectral data, data on an amplitude of frequency spectral data in a frequency region which is not encoded by the core encoding unit.<br>23. A decoding method for generating frequency spectral data from an inputted encoded audio data stream, the decoding method comprising: a core decoding step for decoding the inputted encoded data stream and generating first frequency spectral data representing an audio signal; and an extended decoding step for generating, based on the first frequency spectral data, second frequency spectral data in a frequency region which is not represented by the encoded data stream, the second frequency spectral data indicating a harmonic structure which is same as an extension along a frequency axis of a harmonic structure indicated by the first frequency spectral data.<br>24. A decoding method comprising: a core decoding step for decoding the inputted encoded data stream and generating first frequency spectral data representing an audio signal; an extended decoding step for decoding, out of the inputted encoded data stream, data on an amplitude indicated by frequency spectral data representing an audio signal in a frequency region extended along a frequency axis from the first frequency spectral data; a harmonic structure analyzing step for analyzing the harmonic structure of the first frequency spectral data and outputting a parameter indicating the harmonic structure; and a harmonic generating step for generating, based on the data on the amplitude and the parameter, second frequency spectral data in a frequency region which is not represented by the encoded data stream, the second frequency spectral data indicating a harmonic structure which is same as an extension along the frequency axis of a harmonic structure indicated by the first frequency spectral data.<br>25. A decoding method for generating frequency spectral data from an inputted encoded audio data stream, the decoding method comprising: a core decoding step for decoding the inputted encoded data stream and generating first frequency spectral data, the first frequency spectral data being an audio time-frequency signal representing by every frequency bandwidth a time transition of frequency spectral data belonging to a frequency bandwidth which is outputted from a polyphase filter bank; and an extended decoding step for generating, based on the time-frequency signal that is a frequency component of the first frequency spectral data, second frequency spectral data in a frequency region which is not represented by the encoded data stream, the second frequency spectral data being a time-frequency signal in the frequency region and indicating time cyclicity of the first frequency spectral data.<br>26. An encoding method for generating an encoded data stream from frequency spectral data of an audio signal, the encoding method comprising: a core encoding step for encoding the inputted frequency spectral data and generating an encoded audio data stream; and an extended encoding step for encoding, out of the inputted frequency spectral data, data on an amplitude of frequency spectral data in a frequency region which is not encoded in the core encoding step.<br>27. A program for a decoding device that generates frequency spectral data from an inputted encoded audio data stream, the program causing a computer to execute: a core decoding step for decoding the inputted encoded data stream and generating first frequency spectral data representing an audio signal; and an extended decoding step for generating, based on the first frequency spectral data, second frequency spectral data in a frequency region which is not represented by the encoded data stream, the second frequency spectral data indicating a harmonic structure which is same as an extension along a frequency axis of a harmonic structure indicated by the first frequency spectral data.<br>28. A program for a decoding device that generates frequency spectral data from an inputted encoded audio data stream, the program causing a computer to execute: a core decoding step for decoding the inputted encoded data stream and generating first frequency spectral data, the first frequency spectral data being an audio time-frequency signal representing by every frequency bandwidth a time transition of frequency spectral data belonging to a frequency bandwidth which is outputted from a polyphase filter bank; and an extended decoding step for generating, based on the time-frequency signal that is a frequency component of the first frequency spectral data, second frequency spectral data in a frequency region which is not represented by the encoded data stream, the second frequency spectral data being a time-frequency signal in the frequency region and indicating time cyclicity of the first frequency spectral data.<br>29. A program for an encoding device that generates an encoded data stream from frequency spectral data of an audio signal, the program causing a computer to execute: a core encoding step for encoding the inputted frequency spectral data and generating an encoded audio data stream; and an extended encoding step for encoding, out of the inputted frequency spectral data, data on an amplitude of frequency spectral data in a frequency region which is not encoded in the core encoding step.<br>30. A computer readable recording medium on which a program for a decoding device that generates frequency spectral data from an inputted encoded audio data stream is recorded, the program causing the computer to execute: a core decoding step for decoding the inputted encoded data stream and generating first frequency spectral data representing an audio signal; and an extended decoding step for generating, based on the first frequency spectral data, second frequency spectral data in a frequency region which is not represented by the encoded data stream, the second frequency spectral data indicating a harmonic structure which is same as an extension along a frequency axis of a harmonic structure indicated by the first frequency spectral data.<br>31. A computer readable recording medium on which a program for an encoding device that generates an encoded data stream from frequency spectral data of an audio signal is recorded, the program causing the computer to execute: a core encoding step for encoding the inputted frequency spectral data and generating an encoded audio data stream; and an extended encoding step for encoding, out of the inputted frequency spectral data, data on an amplitude of frequency spectral data in a frequency region which is not encoded in the core encoding step.</p></layer>
<layer id = "layer102"><p><b>US20030093266A1:Speech coding apparatus, speech decoding apparatus and speech coding/decoding method</b><br>A post-processing mechanism for a printer or the like includes a curved paper path. Post-processing operations such as stapling or other binding are performed either within the curved paper path or during the withdrawal of a document from the curved paper path. The curved paper path permits such post-processing operations to be performed within a limited space, while reducing the complexity of the post-processing mechanism and reducing the complexity of operations performed by the post-processing mechanism.<br><b>Independant Claims</b><br>1. A speech coding apparatus that performs coding on speech signals in a sub-band ADPCM scheme, comprising: a generating section that quantizes a given sub-band signal according to the number of assigned bits to generate a codeword; and a determining section that determines an optimal value of the number of assigned bits used in the generating section.<br>8. A speech decoding apparatus that performs decoding on speech signals in a sub-band ADPCM scheme, comprising: a generating section that dequantizes a given codeword according to the number of assigned bits to generate a decoded sub-band signal; and a determining section that determines an optimal value of the number of assigned bits used in the generating section.<br>16. A speech coding/decoding method for performing coding and decoding on speech signals in a sub-band ADPCM scheme, comprising: a determining step of determining an optimal value of the number of assigned bits to quantize a given sub-band signal; a quantizing step of quantizing the sub-band signal according to the determined optimal value of the number of assigned bits to generate a codeword; an acquiring step of acquiring the optimal value of the number of assigned bits based on the codeword; and a dequantizing step of dequantizing the codeword according to the acquired optimal value of the number of assigned bits to generate a decoded sub-band signal.</p></layer>
<layer id = "layer103"><p><b>US6119081A:Pitch estimation method for a low delay multiband excitation vocoder allowing the removal of pitch error without using a pitch tracking method</b><br>An optically active tri-substituted methane compound having, as substituents, an aromatic ring group and a phenyl group having hydroxyl group at ortho or para position can be obtained by allowing a phenol compound unsubstituted at the ortho- or/and para-position to react with an optically active secondary carbinol compound having an aromatic ring group at the alpha-position in the presence of tri-substituted phosphine and diazodicarboxylate or diazodicarboxamide. These and other optically active tri-substituted methane compounds are useful as active ingredients for medicines or as intermediate compounds for preparing medicines.<br><b>Independant Claims</b><br>1. A pitch determining method for a low-delay multiband excitation vocoder, comprising the steps of: (a) obtaining a synthesized magnitude spectrum and a biasing value of the error amount with respect to respective pitch candidates in a predetermined pitch area from an input voice magnitude spectrum and obtaining the error amount .zeta.(T) with respect to the respective pitch candidates T; (b) obtaining a weighted function W(T) with respect to the respective pitch candidates; (c) obtaining a weighted error amount .zeta..sub.W (T) with respect to the respective pitch candidates T by multiplying the error amount .zeta.(T) obtained in the step (a) with the weighted function W(T) obtained in the step (b); (d) determining the candidate pitch having the minimum error amount in the weighted error amount .zeta..sub.W (T) with respect to the respective pitch candidates T obtained in the step (c) to be an estimated pitch; and (e) removing said minimum error amount without using a pitch tracking method.</p></layer>
<layer id = "layer104"><p><b>US6778954B1:Speech enhancement method</b><br>A planographic printing member precursor comprises a first component, for example a hydroxy group containing polymer, and a second component which may be a siloxane or a compound of general formula (I), wherein M represents a silicon or a titanium atom and each of R<highlight><superscript>1</superscript></highlight>, R<highlight><superscript>2</superscript></highlight>, R<highlight><superscript>3 </superscript></highlight>and R<highlight><superscript>4 </superscript></highlight>is independently selected from hydrogen or halogen atoms; a hydroxy group; an optionally substituted alkyl, alkenyl or alkynyl group; an optionally substituted alkoxy group; or an optionally substituted saturated or unsaturated cyclic or heterocyclic group. On exposure, the second component reacts with the first component to define an oleophobic/hydrophilic material in exposed areas and in non-exposed areas the second component is removed, on processing of the precursor.<chemistry-cwu id="CHEM-US-00001"><number>1</number><image id="EMI-C00001" he="45.36" wi="131.7708" file="US20020086235A1-20020704-C00001.TIF"/><chemistry-chemdraw-file id="CHEMCDX-00001" file="US20020086235A1-20020704-C00001.CDX"/><chemistry-mol-file id="CHEMMOL-00001" file="US20020086235A1-20020704-C00001.MOL"/></chemistry-cwu><br><b>Independant Claims</b><br>1) A speech enhancement method comprising the steps of: (a) segmenting an input speech signal into a plurality of frames and transforming each frame signal into a signal of the frequency domain; (b) computing the signal-to-noise ratio of a current frame, and computing signal-to-noise ratio of a frame immediately preceding the current frame; (c) computing the predicted signal-to-noise ratio of the current frame which is predicted based on the preceding frame and computing the speech absence probability using the signal-to-noise ratio and predicted signal-to-noise ratio of the current frame; (d) correcting the two signal-to-noise ratios obtained in the step (b) based on the speech absence probability computed in the step (c); (e) computing the gain of the current frame with the two corrected signal-to-noise ratios obtained in the step (d), and multiplying the speech spectrum of the current frame by the computed gain; (f) estimating the noise and speech power for the next frame to calculate the predicted signal-to-noise ratio for the next frame, and providing the predicted signal-to-noise ratio for the next frame as the predicted signal-to-noise ratio of the current frame for the step (c); and (g) transforming the result spectrum of the step (e) into a signal of the time domain.</p></layer>
<layer id = "layer105"><p><b>US20020052737A1:Speech coding system and method using time-separated coding algorithm</b><br>An adapter or housing for a module, such as a single in-line memory module (SIMM) or the like, and method of using the same are herein disclosed where the SIMM and attached housing fit a predetermined shape SIMM socket. The housing replaces SIMM board material that would otherwise be used to help secure the SIMM to a predetermined shape SIMM socket or connector. The configuration of the housing allows a SIMM or the like to be snapped or slid and secured into the housing. If desired, an adhesive, potting material and other bonding material can be used to secure the SIMM board to the housing and/or pot the SIMM within the housing.<br><b>Independant Claims</b><br>1. A time-separated speech coder for coding the transitional signal of voiced/unvoiced sound through harmonic speech coding, the time-separated speech coder comprises an excitation signal transitional analyzer analyzing means which comprises a transitional point detecting means for detecting transitional point to grasp the transitional analyzer of said transitional signal, a harmonic excitation signal analyzing means for extracting the harmonic model parameter of said detected transitional analyzer and a harmonic excitation signal synthesizing means for adding said harmonic model parameter.<br>10. A time-separated speech coding method for coding the transitional signal of voiced/unvoiced sound through harmonic speech coding, comprising the steps of: a transitional point detecting step for detecting the transitional point of the transitional signal; a window applying step for extracting harmonic model parameter of each block by applying TWH window to the central point of left/right block after dividing LPC residue signal out of inputted signals centering said transitional point; and a synthesis step for adding said harmonic model parameter.</p></layer>
<layer id = "layer106"><p><b>US4989247A:Method and system for determining the variation of a speech parameter, for example the pitch, in a speech signal</b><br>Novel chromium complex dyes are disclosed which have the formula ##STR1## wherein S.sub.1 represents a hydrogen or halogen atom, a nitro group, a sulpho group, an alkyl or alkoxy radical, an acylamino or arylazo group, S.sub.2 represents a hydrogen or halogen atom, a nitro group, a sulpho group, an alkyl or alkoxy radical, S.sub.3 represents a hydrogen atom, a nitro group or a halogen atom, P is 1 or 2, R represents a fluorochloropyrimidyl or fluorotriazinyl radical, a chloroacetyl, bromoacetyl, .alpha.-chloro- or .alpha.-bromoacryloyl radical or an .alpha.,.beta.-dichloro- or .alpha.,.beta.-dibromopropionyl radical, and K.sup..sym. represents a cation.<br><b>Independant Claims</b><br>1. A method for determining the variation of a speech parameter of a speech signal as a function of time comprising: (i) in a first step deriving time segments of the speech signal at a number of time instants m which regularly follow each other, and from each time segment i(1.ltoreq.i.ltoreq.m) deriving a degree of fit p(i,j) associated with the time segment and which, for a series of n possible values for the speech parameter, indicates how well a chosen value f.sub.j for the speech parameter (1.ltoreq.j.ltoreq.n) fits the speech signal of the time segment i, (ii) in a second step for the time instant i=1 and for each of the n possible values f.sub.j for the speech parameter, storing in a memory a value ms(1, j) associated with said speech parameter, which value is equal to p(1,j), (iii) in a third stp for a certain time instant i(>1) and a certain possible value f.sub.j for the speech parameter, deriving a number of summation values s.sub.h (i,j) in accordance with the formula s.sub.h (i,j)=p(i,j)+ms(i-1, h)+k(f.sub.j (i),f.sub.h.sup.x (i)) where h runs from x up to and including y and for x and y 1.ltoreq.x.ltoreq.j, j.ltoreq.y.ltoreq.n and x.noteq.y, and of all the y-x+1 summation values s.sub.h (i,j) an optimum summation value is stored in said memory as the value ms(i,j) and, in addition, a coupling vector v(i,j) which refers to the value f.sub.h (i-1) of the speech parameter at the time instant i-1, which, for the relevant index h, resulted, according to the above formula, in the optimum summation value, is stored in a memory, (iv) repeating the third step for all of the other indices j at the time instant i, (v) repeating the third step for all of the indices j at a subsequent time instant i+1, (vi) and wherein k(f.sub.j (i),f.sub.h.sup.x (i)) is a cost parameter which is a measure of the deviation of the speech parameter f.sub.j (i) at the time instant i with respect to a predicted value f.sub.h.sup.x (i) for the speech parameter at the time instant i, which predicted value is derived from at least the speech parameter value f.sub.h (i-1) at the time instant i-1, and is determined in accordance with the formula ##EQU4## where a.sub.o, a.sub.1 and a.sub.z are constants with a.sub.o being less than zero and, if r.gtoreq.2, f.sub.1 (i-z) is the value for the speech parameter at the time instant i-z, which value lies on a sub-path which, via the coupling vectors v(i,j), leads to the speech parameter f.sub.h (i-1) at the time instant i-1, and a.sub.1 .noteq.0.<br>9. A system for determining the variation of a speech parameter of a speech signal as a function of time comprising: an input terminal for receiving the speech signal, - a first unit for deriving time segments from the speech signal at m time instants regularly following each other and for deriving from each time segment i(1.ltoreq.i.ltoreq.m) a degree of fit p(i,j) associated with a time segment, and which, for a series of n possible values for the speech parameter, indicates how well a chosen value f.sub.j for the speech parameters (1.ltoreq.j.ltoreq.n) fits the speech signal of the time segment i, a second unit for deriving values ms (i,j) associated with the speech parameter, where for the time instant i=1 and for each of the n possible values f.sub.j the value ms (1, j) is equal to p(1, j), a third unit coupled to said first unit for determining summation values s.sub.h (i,j) and for determining an optimum summation value ms(i,j), for all y-x+1 summation values associated with a particular index (i,j), where i.1, where h runs from x up to and including y and for x and y 1.ltoreq.x.ltoreq.j, j.ltoreq.y.ltoreq.n and x.noteq.y, a first memory for storing the value ms(i,j) therien, means for determining coupling vectors v(i,j), a coupling vector referring to a value f.sub.h (i-1) of the speech parameter at a time instant i-1, which for the relevant index h, resulted in an otpimum summation value, a second memory for storing the coupling vectors v(i,j), a fourth unit for determining a predicted value f.sub.h.sup.x (i) for the speech parameter at a time instant i, a fifth unit for determining a cost parameter k(f.sub.j (i), f.sub.h.sup.x (i)), and means for determining an optimum value ms(m,jl) from the n values ms(m,j) and reading out the coupling vector v(m,jl) associated with the optimum value ms(m,jl), and for reading out coupling vectors v(i-1, v(i,j)) associated with the time segment i-1, and with the value v(i,j)=h of the speech parameter to which the coupling vector v(i,j) associated with the time segment i points, i running from m-1 down to and including 1, a series of subsequent values obtained for the speech parameter indicating the variation of the speech parameter as a function of time.<br>11. A system for determining the variation of a speech parameter of a speech signal as a function of time comprising: an input terminal for receiving the speech signal, a first unit coupled to said input terminal for deriving time segments i from the speech signal at m time instants regularly following each other and for deriving from each time segment a degree of fit p(i,j) associated with a time segment, where (l.ltoreq.i.ltoreq.m), j is an index indicating values of a speech parameter, f.sub.j, where (1.ltoreq.j.ltoreq.n), and there are n possible speech parameter values, a second unit for deriving values ms(i,j) for which i.gtoreq.2, a third unit coupled to said first unit for deriving coupling vectors v(i,j) for which i.gtoreq.2, for determining summation alues s.sub.h (i,j) and for determining an optimum summation value ms(i,j), for all y-x+1 summation values associated with a particular index (i,j), where i.noteq.1, h runs from x up to and including y and for x and y 1.ltoreq.x.ltoreq.j, j.ltoreq.y.ltoreq.n and x.noteq.y, a first memory device coupled to said first and second units for storing the values ms(i,j), a second memory device coupled to said third unit for storing the coupling vectors v(i,j), a fourth unit coupled to said second memory device for determining a predicted value f.sub.h.sup.x (i) for the speech parameter, a fifth unit coupled to said fourth unit for determining a cost parameter k(f.sub.j (i), f.sub.h.sup.x (i)), and means for determining an optimum value ms(m,jl) from the n values ms(m,j) and reading out the coupling vector v(m,jl) associated with the optimum value ms(m,jl), and for reading out coupling vectors v(i-1, v(i,j)) associated with the time segment i-1, and with the value v(i,j)=h of the speech parameter to which the coupling vector v(i,j) associated with the time segment i points, i running from m-1 down to and including 1, a series of subsequent values obtained for the speech parameter indicating the variation of the speech parameter as a function of time.</p></layer>
<layer id = "layer107"><p><b>US20020118845A1:Enhancing source coding systems by adaptive transposition</b><br><b>Independant Claims</b><br>1. A method for enhancement of audio source coding systems using high frequency reconstruction, characterised by: adaptively over time selecting different methods for high frequency generation, based on whether the signal being processed has a pulse-train-like character or a non-pulse-train-like character</p></layer>
<layer id = "layer108"><p><b>US20030009327A1:Bandwidth extension of acoustic signals</b><br>The present invention relates to a process for making and a method for using a corrosion inhibitor composition to reduce the corrosion rate of a metal by a fluid containing a corrosion agent. The corrosion inhibitor composition comprises at least a quaternized compound having a substituted diethylamino moiety. Examples of the quaternized compound having a substituted diethylamino moiety are quaternized diacrylamino imidazolines.<br><b>Independant Claims</b><br>1. A method of producing a wide-band acoustic signal (aWB) based on a narrow-band acoustic signal (aNB), the spectrum (AWB) of the wide-band acoustic signal (aWB) having a larger bandwidth than the spectrum (ANB) of the narrow-band acoustic signal (aNB), the method involving extraction of at least one essential attribute (zNB(r, c), ENB) from the narrow-band acoustic signal (aNB), and estimation of a parameter describing aspects of wide-band frequency components outside the spectrum (ANB) of the narrow-band acoustic signal (aNB) based on at least one essential attribute (zNB(r, c), ENB), characterised by allocating a parameter value to a particular wide-band frequency component based on a corresponding confidence level.<br>12. A method according to any one of the proceeding claims, characterised by the at least one essential attribute (zNB(r, c)) represents a degree of voicing and a spectral envelope (c).<br>24. A signal decoder for producing a wide-band acoustic signal (aWB) from a narrow-band acoustic signal (aNB), the spectrum (AWB) of the wide-band acoustic signal (aWB) having a larger bandwidth than the spectrum (ANB) of the narrow-band acoustic signal (aNB), the signal decoder comprising: a feature extraction unit (101) receiving the narrow-band acoustic signal (aNB) and on basis thereof producing at least one essential attribute (zNB(r, c), ENB) of the narrow-band acoustic signal (aWB), and at least one band extension unit (102-108) receiving the narrow-band acoustic signal (aNB), receiving the at least one essential attribute (zNB(r, c), ENB) and on basis of the received signals producing the wide-band acoustic signal (aWB), characterised in that the signal decoder is arranged to allocate a parameter with respect to a particular wide-band frequency component based a corresponding confidence level.</p></layer>
<layer id = "layer109"><p><b>US6732069B1:Linear predictive analysis-by-synthesis encoding method and encoder</b><br>The present invention relates to new peptides of IL-2, and derivatives thereof and their use as therapeutic agents.<br><b>Independant Claims</b><br>1) A linear predictive analysis-by-synthesis coding method, including the steps of determining optimum gains of a plurality of subframes; collectively vector quantizing said optimum gains; and updating internal encoder states using said collective vector quantized gains.<br>8) A linear predictive analysis-by-synthesis encoder, including a search algorithm block for determining optimum gains of a plurality of subframes; a vector quantizer for collectively vector quantizing said optimum gains; and means for updating internal encoder states using said collective vector quantized gains.</p></layer>
<layer id = "layer110"><p><b>US20060031064A1:Efficient spectral envelope coding using variable time/frequency resolution and time/frequency switching</b><br>A holographic read-only memory (ROM) mastering system includes a conical mirror for refracting a reference beam to generate conical reference beams to be incident on a storage medium in a first angle; and a reflective data mask, having a data pattern for data to be recorded in the storage medium, for modulating and reflecting some of the conical reference beams passing through the storage medium to generate modulated conical reference beams to be incident on the storage medium in a second angle. The modulated conical reference beams are interfered with the conical reference beams incident on the storage medium, to thereby record an interference pattern based on the interfering operation in the storage medium. The first and the second angles have a relationship of a complementary angle with respect to the vertical direction of the storage medium.<br><b>Independant Claims</b><br>1. A method for spectral envelope coding in a source encoder, and wherein the source encoder is operative to exclude a residual signal corresponding to certain frequency regions from transmitted or stored data, comprising the following step: performing a statistical analysis of the input signal, based on the outcome of the analysis, selecting a grid to be used in a spectral envelope representation, generating data representing the spectral envelope, by using the grid, transmitting or storing the data together with a control signal describing the grid, wherein the step of selecting is performed such that the grid includes granules of variable length, the granules selected in the step of selecting including a granule having a variable start boundary or a variable stop boundary, and wherein the control signal includes information on the variable start boundary or the variable stop boundary.<br>12. An apparatus for encoding of a spectral envelope of a signal to be decoded by a decoder, comprising: an analyzer for performing a statistical analysis of an input signal, a selector for selecting an instantaneous time or frequency resolution to be used in a spectral envelope representation of the input signal, based on the outcome of the analysis, a generator for generating of data representing the spectral envelope, using the resolution, and a transmitter or storing device for transmitting or storing the data together with a control signal describing the resolution, wherein the selector is operative to select a grid including granules of variable length, the granules selected in the step of selecting including a granule having a variable start boundary or a variable stop boundary, and wherein the control signal includes information on the variable start boundary or the variable stop boundary.<br>13. An apparatus for decoding an encoded spectral envelope of a signal, the encoded spectral envelope being encoded using a grid including granules of variable length, the granules including a granule having a variable start boundary or a variable stop boundary, the encoded spectral envelope including a control signal having information on the variable start boundary or the variable stop boundary, the apparatus comprising: an interpreter for interpreting the control signal in order to determine an instantaneous time or frequency resolution used in the spectral envelope of the signal, the interpreter being operative for determining the variable start boundary or the variable stop boundary of the granule; a decoder for decoding the encoded spectral envelope for the granules having a variable length, using the variable start boundary or the variable stop boundary of a granule; and a user for using decoded spectral envelope data obtained by the decoder in a synthesis of an output signal.<br>14. A method for decoding an encoded spectral envelope of a signal, the encoded spectral envelope being encoded using a grid including granules of variable length, the granules including a granule having a variable start boundary or a variable stop boundary, the encoded spectral envelope including a control signal having information on the variable start boundary or the variable stop boundary, the method comprising: interpreting the control signal in order to determine an instantaneous time or frequency resolution used in the spectral envelope of the signal, the interpreter being operative for determining the variable start boundary or the variable stop boundary of the granule; decoding the encoded spectral envelope for the granules having a variable length, using the variable start boundary or the variable stop boundary of a granule; and using decoded spectral envelope data obtained by the step of decoding in a synthesis of an output signal.</p></layer>
<layer id = "layer111"><p><b>US6298139B1:Apparatus and method for maintaining a constant speech envelope using variable coefficient automatic gain control</b><br>A single unit video camera-recorder operable either in camera or video mode comprises a mode switch for setting the camera or video mode of the single-unit video camera-recorder, function keys for instructing functions of the single-unit video camera-recorder, a light source for illuminating the function keys, and a controller for controlling the light to illuminate the function keys only when the single-unit video camera-recorder is set either in the camera or video mode.<br><b>Independant Claims</b><br>1) A method for maintaining a constant speech envelope using automatic gain control comprising: sampling actual audio signal amplitudes; computing a running mean on each sample by weighting a previous mean, weighting a current sample and adding the weighted previous mean and weighted current sample; using the running mean to alter the current sample; selecting the weighting by comparing the amplitude of the current sample with the value of the previous mean; if the amplitude of the current sample is larger than the value of the previous mean, weighting the previous mean and current sample more heavily towards the current sample; if the amplitude value of the current sample is smaller than the value of the previous mean, weighting the previous mean and current sample more heavily towards the previous mean; so that an indication of an increasing signal relative to previous mean results in an automatic gain control level that more rapidly follows the actual signal and an indication of decreasing signal relative to previous mean results in an automatic gain control level that more slowly follows the actual signal.<br>9) An apparatus for maintaining a constant speech envelope of an analog signal using variable coefficient automatic gain control (AGC) comprising: an input for samples of the analog signal; a component to measure the absolute value of the samples; a mean generator for calculating the mean of absolute values of samples; the mean generator including a component to compute a running mean on each sample by weighting a previous mean, weighting a current sample and adding the weighted previous mean and weighted current sample, a comparator to select the weighting by comparing the amplitude of the current sample with the value of the previous mean and generating a weighting signal; if the amplitude of the current sample is larger than the value of the previous mean, the component weighting the previous mean and current sample more heavily towards the current sample; if the amplitude value of the current sample is smaller than the value of the previous mean, the component weighting the previous mean and current sample more heavily towards the previous mean; so that an indication of an increasing signal relative to previous mean results in an automatic gain control level that more rapidly follows the actual signal and an indication of decreasing signal relative to previous mean results in an automatic gain control level that more slowly follows the actual signal; an output for adjusted samples.</p></layer>
<layer id = "layer112"><p><b>US6070137A:Integrated frequency-domain voice coding using an adaptive spectral enhancement filter</b><br>A sound collecting system and a sound reproducing apparatus by means of which an actual audio image can be reproduced. The sound collecting system includes a plurality of microphones for producing sound signals and a plurality of position detecting apparatus for detecting locations of the microphones and/or positions of sound sources to produce position signals. The sound signals and the position signals are multiplexed by a plurality of multiplexers, and the multiplexed signals are stored into respective audio channels or different channels by a signal recording apparatus. The multiplexing may be performed by a frequency multiplexing method, a time division multiplexing method or the like. Since also position information is stored into corresponding audio channels together with acoustic sound signals, at the reproducing stage, reproduction is possible taking the positions into consideration and an actual audio image can be produced. Also dimensions, directivities and so forth of the sound sources can be multiplexed in addition to the position information.<br><b>Independant Claims</b><br>1. A system for encoding voice with integrated noise suppression, comprising: a sampler which converts an analog audio signal into frames of time-domain audio samples; a voice activity detector operatively coupled to the sampler for determining presence or absence of speech in a current frame; a transformer operatively coupled to the sampler for transforming the frame of time-domain audio samples to a frequency-domain representation; a noise model adapter operatively associated with the voice activity detector and the transformer for updating a noise model using a current frame if the voice activity detector determines there is an absence of speech; a transformer and filter creator operatively coupled to the transformer and the noise model adaptor to create a noise suppression filter; and a spectral estimator operatively coupled to the transformer and the transformer and filter creator to remove noise characteristics from the frequency-domain representation of the current frame using the noise suppression filter and to develop a set of spectral magnitudes.<br>19. A system for encoding voice with integrated noise suppression, comprising: a sampler which converts an analog audio signal into frames of time-domain audio samples; a voice activity detector operatively coupled to the sampler for determining presence or absence of speech in a current frame; a transformer operatively coupled to the sampler for transforming the frame of time-domain audio samples to a frequency-domain representation; a noise model adapter operatively associated with the voice activity detector and the transformer for updating a noise model using a current frame if the voice activity detector determines there is an absence of speech; a transformer and filter creator operatively coupled to the transformer and the noise model adaptor to create a noise suppression filter; a spectral estimator operatively coupled to the transformer and the noise model adaptor to remove noise characteristics from the frequency-domain representation of the current frame and to develop a set of spectral magnitudes; and a quantizer and encoder for transforming the developed spectral magnitudes into a frame of encoded bits.<br>20. A system for encoding voice with integrated noise suppression, comprising: a sampler which converts an analog audio signal into frames of time-domain audio samples; a voice activity detector operatively coupled to the sampler for determining presence or absence of speech in a current frame; a transformer operatively coupled to the sampler for transforming the frame of time-domain audio samples to a frequency-domain representation; a noise model adapter operatively associated with the voice activity detector and the transformer for updating a noise model using a current frame if the voice activity detector determines there is an absence of speech; a transformer and filter creator operatively coupled to the transformer and the noise model adaptor to create a noise suppression filter; and a spectral estimator operatively coupled to the transformer and the noise model adaptor to remove noise characteristics from the frequency-domain representation of the current frame and to develop a set of spectral magnitudes, wherein the system comprises a multi-band excitation voice encoder.<br>21. A system for encoding voice with integrated noise suppression, comprising: a sampler which converts an analog audio signal into frames of time-domain audio samples; a voice activity detector operatively coupled to the sampler for determining presence or absence of speech in a current frame; a transformer operatively coupled to the sampler for transforming the frame of time-domain audio samples to a frequency-domain representation; a noise model adapter operatively associated with the voice activity detector and the transformer for updating a noise model using a current frame if the voice activity detector determines there is an absence of speech; a transformer and filter creator operatively coupled to the transformer and the noise model adaptor to create a noise suppression filter; and a spectral estimator operatively coupled to the transformer and the noise model adaptor to remove noise characteristics from the frequency-domain representation of the current frame using the noise suppression filter and to develop a set of spectral magnitudes, wherein the system comprises a sinusoidal transform voice encoder.<br>22. A system for encoding voice with integrated noise suppression, comprising: a sampler which converts an analog audio signal into frames of time-domain audio samples; a voice activity detector operatively coupled to the sampler for determining presence or absence of speech in a current frame; a transformer operatively coupled to the sampler for transforming the frame of time-domain audio samples to a frequency-domain representation; a noise model adapter operatively associated with the voice activity detector and the transformer for updating a noise model using a current frame if the voice activity detector determines there is an absence of speech, the noise model adapter storing a vector of noise model parameters; a transformer and filter creator operatively coupled to the transformer and the noise model adaptor to create a noise suppression filter; and a spectral estimator operatively coupled to the transformer and the noise model adaptor to remove noise characteristics from the frequency-domain representation of the current frame and to develop a set of spectral magnitudes, wherein the voice encoder comprises a multi-band excitation (MBE) voice encoder and wherein the noise model is stored in the same format as the spectral magnitudes of the MBE model.<br>23. A system for encoding voice with integrated noise suppression, comprising: a sampler which converts an analog audio signal into frames of time-domain audio samples; a detector operatively coupled to the sampler for determining presence or absence of speech in a current frame; a transformer operatively coupled to the sampler for transforming the frame of time-domain audio samples to a frequency-domain representation; a noise model adapter operatively associated with the voice activity detetor and the transformer for updating a noise model using a current frame if the voice activity detector determines there is an absence of speech; a transformer and filter creator operatively coupled to the transformer and the noise model adapter to convert between a domain of the noise model adapter and the frequency-domain representation and to create a noise suppression filter; a spectral estimator operatively coupled to the transformer and the noise model adaptor to remove noise characteristics from the frequency-domain representation of the current frame using the noise suppression filter; and an encoder transformer coupled to the spectral estimator for transforming the frequency-domain representation of the current frame, having noise characteristics removed, into a frame of encoded bits.<br>24. A method of suppressing noise in a voice encoder, comprising the steps of: converting a received analog audio signal into frames of time-domain audio samples; determining presence or absence of speech in a current frame of the time-domain audio samples; transforming the frame time-domain audio samples to a frequency-domain representation; updating a noise model using the transformed current frame if there is an absence of speech creating a noise suppression filter from the frequency-domain representation; and removing noise characteristics from the frequency-domain representation of the current frame using the noise suppression filter and developing a set of spectral magnitudes.<br>42. Method of suppressing noise in a voice encoder, comprising the steps of: converting a received analog audio signal into frames of time-domain audio samples; determining presence or absence of speech in a current frame of the time-domain audio samples; transforming the frame time-domain audio samples to a frequency-domain representation; updating a noise model using the transformed current frame if there is an absence of speech; creating a noise suppression filter from the frequency-domain representation; removing noise characteristics from the frequency-domain representation of the current frame and developing a set of spectral magnitudes; and transforming the developed spectral magnitudes into a frame of encoded bits.<br>43. A method of suppressing noise in a voice encoder, comprising the steps of: converting a received analog audio signal into frames of time-domain audio samples; determining presence or absence of speech in a current frame of the time-domain audio samples; transforming the frame time-domain audio samples to a frequency-domain representation; updating a noise model using the transformed current frame if there is an absence of speech, wherein the updating step stores a vector of noise model parameters; creating a noise suppression filter from the frequency-domain representation; and removing noise characteristics from the frequency-domain representation of the current frame and developing a set of spectral magnitudes, wherein the voice encoder comprises a multi-band excitation (MBE) voice encoder and wherein the noise model is stored in the same format as the spectral magnitudes of the MBE model.</p></layer>
<layer id = "layer113"><p><b>US6163608A:Methods and apparatus for providing comfort noise in communications systems</b><br>The invention concerns an electrical winding with a conductor layer (14) which is sealed in an insulating layer (30) of polyethylene. The polyethylene has a degree of crosslinking of at least 60% and contains an anti-oxidant. The starting material used is a not yet crosslinked polyethylene to which a foaming agent is added so that, when heated to be crosslinked, during which it also melts, the polyethylene penetrates between the individual turns (20) in the conductor layer (14). The protective insulating layer (24) round the individual turns of the winding consists of a material which is stable at the crosslinking temperature.<br><b>Independant Claims</b><br>1. An echo suppression device configured to attenuate an echo component of a communications signal, said device comprising: a noise modeling processor configured to generate at least one noise modeling parameter based upon said communications signal, said at least one noise modeling parameter defining a parametric model of a noise component of said communications signal; and a noise generation processor configured to provide modeled noise samples based upon said at least one noise modeling parameter.<br>45. An echo suppression device, comprising: an echo suppressor configured to attenuate echo and noise components of a communications signal; a sample buffer for storing frames of samples of said communications signal; and a noise generation processor configured to pseudo-randomly select single samples from said buffer in order to provide a sequence of white noise samples having a power level equal to a power level of said frame of samples.<br>47. An echo suppression device, comprising: an echo suppressor configured to attenuate echo and noise components of a communications signal; a noise modeling and generation processor configured to model the noise component of said communications signal and to provide comfort noise for said echo suppression device based on said model; a voice activity detector configured to provide an indication of whether said communications signal includes a voice component; and a noise level estimator configured to compute an estimate of a noise level of said communications signal and to provide an indication of whether an energy level of said communications signal is less than said estimate, wherein said noise modeling and generation processor is configured to update said model only when said voice activity detector indicates that there is no voice component in the communications signal and said noise level estimator indicates that said energy level is less than said estimate.<br>48. An echo suppression device, comprising: an echo suppressor configured to attenuate echo and noise components of a communications signal, wherein said echo suppressor removes a portion of said communications signal falling within an amplitude attenuation window; and a comfort noise generator configured to provide comfort noise for said echo suppression device, wherein an output of said comfort noise generator is limited to said amplitude attenuation window to provide a limited comfort noise output which is added to an audio output of said echo suppressor.<br>49. An echo suppression device, comprising: an echo suppressor configured to attenuate echo and noise components of a communications signal, wherein said echo suppressor multiplies a portion of said communications signal falling within an amplitude attenuation window by a scale factor; and a comfort noise generator configured to provide comfort noise for said echo suppression device, wherein an output of said comfort noise generator is limited to said amplitude attenuation window to provide a limited comfort noise output, and wherein said limited comfort noise output is scaled based on said scale factor to provide a limited and scaled comfort noise output which is added to an audio output of said echo suppressor.</p></layer>
<layer id = "layer114"><p><b>US5434947A:Method for generating a spectral noise weighting filter for use in a speech coder</b><br><b>Independant Claims</b><br>1. A method of speech coding comprising the steps of: receiving speech data; providing excitation vectors; generating filter coefficients for a combined short term and spectral noise weighting filter comprising the steps of: generating a Pth-order short term filter; generating an interim spectral noise weighting filter including a first F-order filter and a second Jth-order filter, each filter dependent upon said Pth-order short term filter, and generating coefficients for a Rth-order all-pole combined short term and spectral noise weighting filter using said Pth-order short term filter and said interim spectral noise weighting filter, where R<P+F+J; filtering said received speech data; filtering said excitation vectors utilizing a long term predictor filter and said combined short term and spectral noise weighting filter, forming filtered excitation vectors; comparing said filtered excitation vectors to said filtered received speech data, forming a difference vector; calculating energy of said difference vector, forming an error signal; and choosing, using the error signal, an excitation code, I, representing the received speech data.<br>2. A method of speech coding comprising the steps of: receiving speech data; providing excitation vectors in response to said step of receiving; determining short term and long term predictor coefficients for use by a long term and a Pth-order short term predictor filter; filtering said excitation vectors utilizing said long term predictor filter and said short term predictor filter, forming filtered excitation vectors; determining coefficients for a spectral noise weighting filter comprising the step of: generating an interim spectral noise weighting filter including a first F-order filter and a second Jth-order filter, dependent upon said Pth-order short term filter coefficients, and generating spectral noise weighting coefficients using a Rth-order all-pole model of said interim spectral noise weighting filter, where R<F+J; comparing said filtered excitation vectors to said received speech data, forming a difference vector; filtering said difference vector using a filter dependent upon said spectral noise weighting filter coefficients, forming a filtered difference vector; calculating energy of said filtered difference vector, forming an error signal; and choosing an excitation code, I, using the error signal, which represents the received speech data.</p></layer>
<layer id = "layer115"><p><b>US4220819A:Residual excited predictive speech coding system</b><br>Methods of tuning a receive window. A receiving device and a sending device may be in communication over a network. The receiving device may advertise a receive window to the sending device. The size of the receive window may be adjusted over time based on one or more connection parameters, application parameters and/or operating system parameters.<br><b>Independant Claims</b><br>1. A speech communication circuit comprising: a speech analyzer including means for partitioning an input speech signal into time intervals; means responsive to the speech signal of each interval for generating a set of first signals representative of the prediction parameters of said interval speech signal, a pitch representative signal and a voicing representative signal; and means jointly responsive to said interval speech signal and said interval first signals for generating a signal corresponding to the prediction error of the interval; and a speech synthesizer including an excitation generator responsive to said pitch and voicing representative signals for producing an excitation signal; and means jointly responsive to said excitation signal and said first signals for constructing a replica of said input speech signal; characterized in that said speech analyzer further includes means (124, 126) responsive to said prediction error signal for generating a set of second signals representative of the spectrum of the interval prediction error signal; and said synthesizer excitation generator (220) is jointly responsive to said pitch representative, voicing representative and second signals to produce a prediction error compensating excitation signal.<br>6. A method for processing a speech signal comprising the steps of: analyzing said speech signal including partitioning the speech signal into successive time intervals, generating a set of first signals representative of the prediction parameters of said interval speech signal, a pitch representative signal, and a voicing representative signal, responsive to the speech signal of each interval; and generating a signal corresponding to the prediction error of said speech interval jointly responsive to the interval speech signal and the first signals of the interval; and synthesizing a replica of said speech signal including producing an excitation signal responsive to said pitch and voicing representative signals and constructing a replica of said speech signal jointly responsive to said excitation signal and said first signals characterized in that said speech analyzing step further includes generating a set of second signals representative of the spectrum of the interval prediction error signal responsive to said prediction error signal; and said excitation signal producing step includes forming a prediction error compensating excitation signal jointly responsive to said pitch representative signal, said voicing representative signal and said second signals.</p></layer>
<layer id = "layer116"><p><b>US4969192A:Vector adaptive predictive coder for speech and audio</b><br>An apparatus is disclosed for intermittently feeding wire forward along a generally longitudinal axis, cutting and forming a front end of the wire at a first station into a jumper bridge for an electronic hybrid substrate and presenting the jumper bridge at a second station for removal from the apparatus. The apparatus has a housing comprising a wire guide for supporting and guiding said wire along the longitudinal axis; a first gripper for gripping and feeding the wire to the first station during a portion of a forward stroke; a second gripper for preventing rearward movement of the wire; means for delivering the jumper bridge from the first station to the second station and presenting it for removal at the second station; a cutter and former for cutting a specified length from the front end of wire and forming it into the jumper bridge; a driver for controlling the feeding of the wire to the first station, the cutting and forming of the wire into a jumper bridge, and the delivering of the jumper bridge from the first station to the second station; and an actuator for actuating the driver during the forward and reverse strokes, upon command.<br><b>Independant Claims</b><br>1. An improvement in the method for compressing digitally encoded input speech or audio vectors at a transmitter by using a scaling unit controlled by a quantized residual gain factor QG, a synthesis filter controlled by a set of quantized linear protective coefficient parameters QLPC, a pitch predictor controlled by pitch and pitch predictor parameters QP and QPP, a weighting filter controlled by a set of perceptual weighting parameters W, and a permanent indexed codebook containing a predetermined number M of codebook vectors, each having an assigned codebook index, to find an index which identifies the best match between an input speech or audio vector s.sub.n that is to be coded and a synthesized vector s.sub.n generated from a stored vector in said indexed codebook, wherein each of said digitally encoded input vectors consists of a predetermined number K of digitally coded samples, comprising the steps of buffering and grouping said input speech or audio vectors into frames of vectors with a predetermined number N of vectors in each frame, performing an initial analysis for each successive frame, said analysis including the computation of a residual gain factor G, a set of perceptual weighting parameters W, a pitch parameter P, a pitch predictor parameter PP, and a set of said linear predictive coefficient parameters LPC, and the computation of quantized values QG, QP, QPP and QLPC of parameters G, P, PP and LPC using one or more indexed quantizing tables for the computation of each quantized parameter or set of parameters for each frame transmitting indices of said quantized parameters QG, QP, QPP and QLPC determined in the initial analysis step as side information about vectors analyzed for later use in looking up in one or more identical tables said quantized parameters QG, QP QPP and QLPC while reconstructing speech and audio vectors from encoded vectors in a frame, where each index for a quantized parameter points to a location in one or more of said identical tables where said quantized parameter may be found, computing a zero-state response vector from the vector output of a zero-input response filter comprising a scaling unit, synthesis filter and weighting filter identical in operation to said scaling unit, synthesis filter and weighting filter used for encoding said input vectors, said zero-state response vector being computed for each vector in said permanent codebook by first setting to zero the initial condition of said zero-input response filter so that the response computed is not influenced by a preceding one of said codebook vectors processed by said zero-input response filter, and the using said quanitized values of said residual gain factor, set of linear predictive coefficient parameters, and said set of perceptual weighting parameters computed in said initial analysis step by processing each vector in said permanent codebook through said zero-input response filter to compute a zero-state response vector, and storing each zero-state response vector computed in a zero-state response codebook at or together with an index corresponding to the index of said vector in said permanent codebook used for this zero-state response computation step, and after thus performing an initial analysis of and computing a zero-state response codebook for each successive frame of input speech or audio vectors, encode each input vector s.sub.n of a frame in sequence by transmitting the codebook index of the vector in said permanent codebook which corresponds to the index of a zero-state response vector in said zero-state response codebook that best matches a vector v.sub.n obtained from an input vector s.sub.n by subtracting a long term pitch prediction vector s.sub.n from the input vector s.sub.n to produce a difference vector d.sub.n and filtering said difference vector d.sub.n by said perceptual weighting filter to produce a final input vector f.sub.n, where said long term pitch prediction s.sub.n is computed by taking a vector from said permanent codebook at the address specified by the preceding particular index transmitted as a compressed vector code and performing gain scaling of this vector using said quantized gain factor QG, then synthesis filtering the vector obtained from said scaling using said quantized values QLPC of said set of linear predictive coefficient parameters to obtain a vector d.sub.n and from vector d.sub.n producing a long term pitch predicted vector s.sub.n of the next input vector s.sub.n through a pitch synthesis filter using said quantized values of pitch predictor parameters QP and QPP, said long term prediction vector s.sub.n being a prediction of the next input vector s.sub.n, and producing said vector v.sub.n by subtracting from said final input vector f.sub.n the vector output of said zero-input response filter generated in response to a permanent codebook vector at the codebook address of the last transmitted index code, said vector output being generated by processing through said zero input response filter, said permanent codebook vector located at said last transmitted index code where the output of said zero input response filter is discarded while said permanent codebook vector located at said last transmitted index code is being processed sample by sample in sequence into said zero input response filter until all samples of said codebook vector have been entered, and where the input of said zero input response filter is interrupted after all samples of said codebook vector have been entered and then the desired vector output from said zero-input response filter is processed out sample by sample for subtraction from said final vector v.sub.n, and for each input vector s.sub.n in a frame, finding the vector stored in said zero-state response codebook which best matches the vector v.sub.n, thereby finding the best match of a codebook vector with an input vector, using an estimate vector s.sub.n produced from the best match codebook vector found for the preceding input vector, having found the best match of said vector v.sub.n with a zero-state response vector in said zero-state response codebook for an input speech or audio vector s.sub.n, transmit the zero-state response codebook index of the current best-match zero-state response vector as a compressed vector code of the current input vector, and also use said index of the current best-match zero-state response vector to select a vector from said permanent codebook for computing said long term pitch predicted input vector s.sub.n to be subtracted from the next input vector s.sub.n of the frame.<br>9. A postfiltering method for enhancing digitally processed speech or audio signals comprising the steps of buffering said speech or audio signals into frames of vectors, each vector having K successive samples, performing analysis of said buffered frames of speech or audio signals in predetermined blocks to compute linear predictive coefficients, pitch and pitch predictor parameters, and filtering each vector with long-delay and short-delay postfiltering in cascade, said long-delay postfiltering being controlled by said pitch and pitch predictor parameters and said short-delay postfiltering being controlled by said linear predictive coefficient parameters, wherein postfiltering is accomplished by using a transfer function for said short-delay postfilter of the form ##EQU11## where z is the inverse of the unit delay operator z.sup.-1 used in the z transform representation of transfer functions, and .alpha. and .beta. are fixed scaling factors.</p></layer>
<layer id = "layer117"><p><b>US5457769A:Method and apparatus for detecting the presence of human voice signals in audio signals</b><br>The invention discloses compounds of the general formula ##STR1## in which R represents a methyl radical or a methoxy radical when R.sup.1 is a hydrogen atom; or R represents a methyl radical when R.sup.1 is a methyl radical. The compounds of the invention are useful as fragrances.<br><b>Independant Claims</b><br>1. Apparatus for detecting human voice signals in audio signals to activate a voice operated switch, said apparatus comprising: means for sensing audio signals which may include human voice signals, said human voice signals comprising fundamental frequency components characteristic of human voice and which fundamental frequency components have an approximate characteristic frequency difference, said sensing means having means for converting said audio signals into an electrical analog voltage signal; a first bandpass filter coupled to said sensing means for frequency filtering said electrical analog voltage signal to produce a first filtered voltage signal having a limited frequency band including the frequencies of at least some of said fundamental frequency components characteristic of human voice; an electronic mixer coupled to said first bandpass filter for receiving said first filtered voltage signal for producing a mixer output voltage signal including difference frequency components representing differences of the frequency components included in said first filtered voltage signal; a second bandpass filter coupled to said electronic mixer for filtering said mixer output voltage signal, said second bandpass filter having a pass band such as to pass said difference frequency components of said mixer output voltage signal and to reject frequency components of said mixer output voltage signal having frequencies falling within said limited frequency band of said first bandpass filter so as to produce an output voltage signal from said second bandpass filter the magnitude of which second bandpass filter output signal is dependent on the magnitude of said fundamental frequency components characteristic of human voice included in said audio signals; and means coupled to said second bandpass filter for producing a signal indicating the presence of human voice signals in said audio signals when said output voltage signal from said second bandpass filter exceeds a given magnitude characteristic.<br>3. Apparatus for detecting human voice signals to control a voice operated switch, said apparatus comprising: means for inputting an input analog voltage signal representative of an audible sound which may include human voice signals; a first bandpass filter coupled to said inputting means for filtering said input analog voltage signal to produce a first filtered signal having frequency components within a first frequency band of limited width; a mixer coupled to said first bandpass filter to produce a mixer output voltage signal including the difference frequencies between at least some of the frequency components of said first filtered signal; a second bandpass filter coupled to said mixer for filtering said first filtered voltage signal to produce a second filtered voltage signal having frequency components within a second frequency band including at least some of said difference frequencies of said mixer output voltage signal and excluding the frequencies of said first frequency band; and means coupled to said second bandpass filter to generate an output voltage signal to control the condition of a voice operated switch in response to the magnitude of said second filtered voltage signal.<br>6. A method for detecting human voice signals to control a voice operated switch, said method comprising the steps of: inputting an input analog voltage signal which may include human voice signals; bandpass filtering said input analog voltage signal to produce a first filtered voltage signal having frequency components limited to a frequency band extending between approximately 700 hertz and approximately 1100 hertz; mixing said first filtered signal to generate a mixed voltage signal including difference frequencies existing between the frequency components of said first filtered voltage signal; bandpass filtering said mixed voltage signal to produce a second filtered signal limited to a frequency band extending between approximately 120 hertz and 180 hertz; and using said second filtered signal to control the condition of said voice operated switch.</p></layer>
<layer id = "layer118"><p><b>US7016507B1:Method and apparatus for noise reduction particularly in hearing aids</b><br>Apparatus suitable for use in reciprocally opening and closing a camshaft-actuated valve may include a rotating camshaft (<b>20</b>) having first and second cams (<b>16, 17, 18</b>) respectively defining first and second amounts of valve opening distance. A cam follower (<b>10, 11, 12</b>) may be defined on a mounting pin (<b>24</b>) so as to operatively engage the first and second cams in an alternating manner. At a first rotational position of the cam follower relative to the camshaft, the cam follower operatively engages the first cam and generates the first amount of valve opening distance. At a second rotational position, the cam follower operatively engages the second cam and generates the second amount of valve opening distance. A valve lever (<b>6</b>) transmits the respective generated first and second amounts of valve opening distance to the valve. A locking device (<b>50</b>) releasably locks the mounting pin and cam follower in the respective first and second rotational positions.<br><b>Independant Claims</b><br>1) A method of reducing noise in an input signal, said input signal containing speech and noise related to each other by a signal to noise ratio, the method comprising the steps: (1) detecting the presence and absence of speech; (2) in the absence of speech, determining a noise magnitude spectral estimate (|&Ncirc;(f)|); (3) in the presence of speech, comparing the magnitude spectrum of the input signal (|X(f)|) to the noise magnitude spectral estimate (|&Ncirc;(f)|); (4) calculating an attenuation function (H(f)) from the magnitude spectrum of the input signal (|X(f)|) and the noise magnitude spectral estimate (|&Ncirc;(f)|), the attenuation function (H(f)) being dependent on the signal to noise ratio; and, (5) modifying the input signal by the attenuation function (H(f)) to generate a noise reduced signal wherein there is no substantial modification to the input signal for very low and for very high signal to noise ratios.<br>23) An apparatus, for reducing noise in a single input signal, the apparatus including an input for receiving the single input signal, the apparatus comprising: (a) a compression circuit for receiving a compression control signal and generating an amplification control signal in response; (b) an amplification unit for receiving an input amplification signal and the amplification control signal and generating an output signal with compression and reduced noise under the control of the amplification control signal; (c) an auxiliary noise reduction unit connected to the input for generating an auxiliary noise reduced signal, the compression control signal being the auxiliary noise reduced signal; and, (d) a main noise reduction unit connected to the input and the amplification unit for receiving the single input signal and generating a noise reduced signal, the noise reduced signal being the input amplification signal;<br>29) A method of reducing noise in an input signal, said input signal containing speech and noise related to each other by a signal to noise ratio, the method comprising the steps: (1) detecting the presence and absence of speech; (2) in the absence of speech, determining a noise magnitude spectral estimate (|&Ncirc;(f)|); (3) in the presence of speech, comparing the magnitude spectrum of the input signal (|X(f)|) to the noise magnitude spectral estimate (|&Ncirc;(f)|); (4) calculating an attenuation function (H(f)) from the magnitude spectrum of the input signal (|X(f)|) and the noise magnitude spectral estimate (|&Ncirc;(f)|), the attenuation function (H(f)) being dependent on the signal to noise ratio; and, (5) modifying the input signal by the attenuation function (H(f)) to generate a noise reduced signal wherein there is no substantial modification to the input signal for very low and for very high signal to noise ratios and wherein the amount of attenuation provided by the attenuation function is increased as the signal to noise ratio increases above zero to a maximum value at a predetermined signal to noise ratio and for higher signal to noise ratios the amount of attenuation provided by the attenuation function decreases to zero at a second predetermined signal to noise ratio greater than the first predetermined signal to noise ratio.<br>30) An apparatus, for reducing noise in an input signal containing speech and noise related to each other by a signal to noise ratio, the apparatus including an input for receiving the input signal, the apparatus comprising: (a) a compression circuit for receiving a compression control signal and generating an amplification control signal in response; (b) an amplification unit for receiving an input amplification signal and the amplification control signal and generating an output signal with compression and reduced noise; and, (c) an auxiliary noise reduction unit connected to the input for generating an auxiliary noise reduced signal, the compression control signal being the auxiliary noise reduced signal,<br>31) An apparatus, for reducing noise in an input signal containing speech and noise related to each other by a signal to noise ratio, the apparatus including an input for receiving the input signal, the apparatus comprising: (a) a compression circuit for receiving a compression control signal and generating an amplification control signal in response; (b) an amplification unit for receiving the input signal and the amplification control signal and generating an output signal with compression and reduced noise; and, (c) an auxiliary noise reduction unit connected to the input for generating an auxiliary noise reduced signal, the compression control signal being the auxiliary noise reduced signal,<br>32) An apparatus, for reducing noise in an input signal, the apparatus including an input for receiving the input signal, the apparatus comprising: (a) a compression circuit for receiving a compression control signal and generating an amplification control signal in response; (b) an amplification unit for receiving an input amplification signal and the amplification control signal and generating an output signal with compression and reduced noise under the control of the amplification control signal; (c) an auxiliary noise reduction unit connected to the input for generating an auxiliary noise reduced signal, the compression control signal being the auxiliary noise reduced signal; and, (d) a main noise reduction unit connected to the input and the amplification unit for receiving the input signal and generating a noise reduced signal, the input amplification signal being the noise reduced signal;</p></layer>
<layer id = "layer119"><p><b>US5432859A:Noise-reduction system</b><br>The invention provides spectacles in which the distance between two lens frames (1)(2) is variable and which has holders (7)(7a) on the lens frame, a bridge (8) slidably fitted in the holder for connecting the lens frames together and holding means (9) for determining the effective length of the bridge.<br><b>Independant Claims</b><br>1. For reducing the noise content of a sampled input signal consisting of a sequence of input samples, a noise-reduction circuit comprising: A) a speech detector for determining whether the input signal includes speech and generating a speech-detector output that indicates whether speech is present or absent in the input signal; B) a sliding-discrete-Fourier-transform circuit for recursively computing, for each sample, the values of at least a plurality of the components of the discrete Fourier transform of a sample sequence that ends with that sample, each such Fourier-component value, denominated a raw Fourier-component value, thereby being associated with a respective frequency bin; C) a gain-value generator, responsive to the speech-detector output and the computed Fourier components, for generating, from the frequency components associated with each of a plurality of the frequency bins, a gain value associated with that frequency bin by comparing a function of those components computed for samples that include those taken when the speech detector indicated the presence of speech with those components computed only for samples taken when the speech detector indicated the absence of speech; D) a gain-adjustment circuit for generating an adjusted-Fourier-component value for each bin by multiplying the raw Fourier-component value associated with each bin by the gain value generated for that bin; and E) an output circuit for generating an output from the adjusted frequency-bin values.<br>9. For reducing the noise content of a sampled input signal consisting of a sequence of input samples, a noise-reduction circuit comprising: A) a speech detector for determining whether the input signal includes speech and generating a speech-detector output that indicates whether speech is present or absent in the input signal; B) a discrete-Fourier-transform circuit for computing, for each sample, at least a plurality of the components of the discrete Fourier transform of a sample sequence that ends with that sample, each such Fourier component thereby being associated with a respective frequency bin; C) a gain-value generator, responsive to the speech-detector output and the computed Fourier components, for generating, from the frequency components associated with each of a plurality of the frequency bins, a gain value associated with that frequency bin by comparing a function of those components computed for samples taken when the speech detector indicated the presence of speech with those components computed for samples taken when the speech detector indicated the absence of speech, the gains for at least a first plurality of the frequency bins above 800 Hz being the same and those for at least a second plurality of the frequency bins below 1500 Hz not in general being the same; D) a gain-adjustment circuit for generating an adjusted-Fourier-component value for each bin by multiplying the raw Fourier-component value associated with each bin by the gain value generated for that bin; and E) an output circuit for generating an output from the adjusted frequency-bin values.<br>16. In a noise-reduction circuit, adapted to receive a sampled input signal consisting of a sequence of input samples, that includes a speech detector for determining whether the input signal includes speech and generating a speech-detector output that indicates whether speech is present or absent in the input signal and circuitry responsive to the speech-detector output and the input signal for processing the input signal to generate as an output signal a noise-reduced version of the input signal, the improvement wherein the speech detector comprises means for indicating the absence of speech when .rho..sub.ave is less than a predetermined threshold, where .rho..sub.ave is the average of a plurality of factors .rho..sub.k associated with respective frequency bins, each factor .rho..sub.k associated with a given frequency bin being the result of computing a first average of the Fourier components associated with that frequency bin for samples that include those taken when the speech detector has indicated the presence of speech, computing a second average of the Fourier components associated with that frequency bin for samples taken when the speech detector has indicated the absence of speech, and taking as .rho..sub.k the ratio that the difference between the first and second averages bears to the first average.</p></layer>
<layer id = "layer120"><p><b>US20010023396A1:Method and apparatus for hybrid coding of speech at 4kbps</b><br>In a semiconductor laser device including a strained multiquantum well active layer having a plurality of well layers and a plurality of barrier layers, alternatingly laminated, each well layer includes a main region having a strain while each barrier layer includes a main region having a strain different from the strain of the well layer. Either or both of the well layers and the barrier layers has transition regions at both sides of the main region. The transition regions have a strain that gradually varies from the strain of the main region to the strain of the main regions of adjacent layers toward interfaces between the well and barrier layers. The difference in strains between adjacent layers at the interfaces is smaller than the difference in strains between the main regions of adjacent layers. Therefore, lattice defects, such as dislocations, at the interfaces of the well layer and the barrier layers are reduced, so that the strained multiquantum active layer is grown with improved surface morphology. As a result, the optical characteristics of the strained multiquantum active layer are improved, and the laser characteristics of the semiconductor laser including this active layer are improved.<br><b>Independant Claims</b><br>1. A hybrid speech encoding method, comprising the steps of: (a) classifying frames of speech signals as voiced, unvoiced, or transitory; (b) using harmonic coding to compress frames associated with at least one of said classes; and (c) coding frames classified as transitory using a coding technique selected from the group consisting of waveform coding, analysis-by-synthesis coding, codebook excited linear prediction analysis-by-synthesis coding, and multipulse analysis-by-synthesis coding.<br>3. A method for encoding speech in an encoder for communication to a decoder for reproduction thereof, said speech comprising a plurality of frames of speech, said method comprising the steps of: (a) classifying each frame of speech into three or more classes wherein one or more of said classes is transitory in character; (b) representing the speech in a frame of speech associated with at least one of said classes with a harmonic model; (c) computing parameter values of said harmonic model where said parameter values are characteristic of the frame; and (d) quantizing said parameters for communication to said decoder.<br>8. A hybrid method of encoding speech in an encoder for transmission to a decoder for reproduction thereof, comprising the steps of: (a) classifying frames of the speech signal into steady state voiced, stationary unvoiced, or transitory speech segments; (b) coding a frame with harmonic coding if the frame is classified as steady state voiced speech; (c) coding a frame with “noise-like” coding if the frame is classified as stationary unvoiced speech; and (d) coding a frame classified as transitory using a coding technique selected from the group consisting of waveform coding, analysis-by-synthesis coding, codebook excited linear prediction analysis-by-synthesis coding, and multipulse analysis-by-synthesis coding.<br>12. A method for encoding a speech signal for communication to a decoder for reproduction, comprising the steps of: (a) computing a plurality of pitch candidates using time-domain or frequency domain estimation; (b) computing a candidate synthetic signal for each pitch value; (c) modifying the original signal to match each of the synthetic signal candidates; (d) computing a weight which represents the degree of matching achieved in step (d); and (e) selecting the final pitch value by making use of the weights computed in step (d).<br>13. A hybrid speech encoder, comprising: (a) means for classifying frames of speech signals as voiced, unvoiced, or transitory; (b) means for harmonically coding frames associated with at least one of said classes; and (c) means for coding frames classified as transitory using a coding technique selected from the group consisting of waveform coding, analysis-by-synthesis coding, codebook excited linear prediction analysis-by-synthesis coding, and multipulse analysis-by-synthesis coding.<br>15. A hybrid speech encoder for communication to a decoder for reproduction of speech, said speech comprising a plurality of frames of speech, said encoder comprising: (a) means for classifying each frame of speech into three or more classes wherein one or more of said classes is transitory in character; (b) means for representing the speech in a frame of speech associated with at least one of said classes with a harmonic model; (c) means for computing parameter values of said harmonic model where said parameter values are characteristic of the frame; and (d) means for quantizing said parameters for communication to said decoder.<br>20. An apparatus for encoding speech for transmission to a decoder for reproduction thereof, comprising: (a) means for classifying frames of the speech signal as steady state voiced, stationary unvoiced, or transitory speech; (b) means for coding a frame with harmonic coding if the frame is classified as steady state voiced speech; (c) means for coding a frame with “noise-like” coding if the frame is classified as stationary unvoiced speech; and (d) means for coding a frame classified as transitory using a coding technique selected from the group consisting of waveform coding, analysis-by-synthesis coding, codebook excited linear prediction analysis-by-synthesis coding, and multipulse analysis-by-synthesis coding.<br>24. An apparatus for encoding a speech signal for communication to a decoder for reproduction, comprising: (a) means for computing a plurality of pitch candidates using time-domain or frequency domain estimation; (b) means for computing a candidate synthetic signal for each pitch value; (c) means for modifying the original signal to match each of the synthetic signal candidates; (d) means for computing a weight which represents the degree of matching achieved by said signal modifying means; and (e) means for selecting the final pitch value by making use of said weights.<br>25. A hybrid speech encoder, comprising: (a) a speech classifier, said speech classifier classifying frames of speech signals as voiced, unvoiced, or transitory; (b) a harmonic encoder, said harmonic encoder harmonically coding frames associated with at least one of said classes; and (c) a transitory encoder, said transitory encoder coding frames classified as transitory using a coding technique selected from the group consisting of waveform coding, analysis-by-synthesis coding, codebook excited linear prediction analysis-by-synthesis coding, and multipulse analysis-by-synthesis coding.<br>27. A hybrid speech encoder, comprising: (a) a speech classifier, said speech classifier classifying frames of speech signals as voiced, unvoiced, or transitory; (b) a encoder for voiced signals; (c) an encoder for unvoiced signals; and (d) an encoder for transitory signals; (e) wherein at one of said encoders comprises a harmonic encoder, and wherein at least one of said encoders comprises an encoder selected from the group consisting of a waveform encoder, an analysis-by-synthesis encoder, a codebook excited linear prediction analysis-by-synthesis encoder, and a multipulse analysis-by-synthesis encoder.<br>29. A hybrid speech decoder, comprising: (a) a harmonic decoder, said harmonic decoder harmonically decoding frames of speech associated with at least one of the classes of speech comprising voiced, unvoiced and transitory speech; and (b) a transitory decoder, said transitory decoder decoding frames of speech classified as transitory using a decoding technique selected from the group consisting of waveform decoding, analysis-by-synthesis decoding, codebook excited linear prediction analysis-by-synthesis decoding, and multipulse analysis-by-synthesis decoding.<br>30. A hybrid speech decoder, comprising: (a) a decoder for speech signals classified as voiced signals; (c) a decoder for speech signals classified as unvoiced signals; and (d) a decoder for speech signals classified as transitory signals; (e) wherein at one of said decoders comprises a harmonic decoder, and wherein at least one of said decoders comprises a decoder selected from the group consisting of a waveform decoder, an analysis-by-synthesis decoder, a codebook excited linear prediction analysis-by-synthesis decoder, and a multipulse analysis-by-synthesis decoder.<br>31. A hybrid speech compression system, comprising: (a) a speech classifier, said speech classifier classifying frames of speech signals as voiced, unvoiced, or transitory; (b) a harmonic encoder, said harmonic encoder harmonically coding frames associated with at least one of said classes; (c) a transitory encoder, said transitory encoder coding frames classified as transitory using a coding technique selected from the group consisting of waveform coding, analysis-by-synthesis coding, codebook excited linear prediction analysis-by-synthesis coding, and multipulse analysis-by-synthesis coding; (d) a harmonic decoder; and (e) a transitory decoder, said transitory decoder decoding frames of speech classified as transitory using a decoding technique selected from the group consisting of waveform decoding, analysis-by-synthesis decoding, codebook excited linear prediction analysis-by-synthesis decoding, and multipulse analysis-by-synthesis decoding.<br>33. A hybrid speech compression system, comprising: (a) a speech classifier, said speech classifier classifying frames of speech signals as voiced, unvoiced, or transitory; (b) an encoder for voiced signals; (c) an encoder for unvoiced signals; (d) an encoder for transitory signals; (e) wherein at one of said encoders comprises a harmonic encoder, and wherein at least one of said encoders comprises an encoder selected from the group consisting of a waveform encoder, an analysis-by-synthesis encoder, a codebook excited linear prediction analysis-by-synthesis encoder, and a multipulse analysis-by-synthesis encoder; (f) a decoder for speech signals classified as voiced signals; (g) a decoder for speech signals classified as unvoiced signals; and (h) a decoder for speech signals classified as transitory signals; (i) wherein at one of said decoders comprises a harmonic decoder, and wherein at least one of said decoders comprises a decoder selected from the group consisting of a waveform decoder, an analysis-by-synthesis decoder, a codebook excited linear prediction analysis-by-synthesis decoder, and a multipulse analysis-by-synthesis decoder.</p></layer>
<layer id = "layer121"><p><b>US4805193A:Protection of energy information in sub-band coding</b><br>Novel carboxylic acid esters of 6-hydroxy-2-benzothiazolesulfonamide are shown to be useful for the topical treatment of elevated intraocular pressure. Ophthalmic compositions including drops and inserts are also disclosed, as well as methods for preparing the novel compounds.<br><b>Independant Claims</b><br>1. A method of improving the quality of sub-band coded speech signals comprising at least the steps of: sampling the original speech signals; filtering the sampled speech signals into a plurality of frequency bands covering the desired spectrum; determining the energy contained in each band with respect to the other bands; providing a first code for specifying which band contains the maximum energy level; providing a second code for specifying the energy level of said maximum energy band; computing two difference codes, a delta code and an epsilon code, for each other band according to a predetermined algorithm for specifying the relative energy level of each said other band, a delta code representing the difference between the energy of a band and the protected energy of an adjacent band, and an epsilon code representing the difference between the energy of a band and the protected energy of the same band, and utilizing said delta codes for determining the bit allocation of the sample information; providing protection bits for each said delta code; and multiplexing said delta codes and said epsilon codes with other information into a frame of a data stream and transmitting said data stream.<br>5. A sub-band coding system comprising: sampling means for sampling an input signal; filter means for separating said sampled input signal into a plurality of sub-band signals; encoder means for producing an encoded data stream corresponding to at least the energy levels of said sub-band signals, said encoded data stream including delta codes and epsilon codes, a delta code representing the difference between the actual energy level of a particular sub-band signal and that of a different sub-band signal, an epsilon code representing the difference between the quantized energy level as represented by said delta code of a particular sub-band signal and the actual energy level of that sub-band signal; and transmission means for processing said encoded data stream for transmission.<br>11. A method of sub-band coding comprising steps of: filtering an input signal into a plurality of frequency bands; determining the actual energy level of the signal in each band; determining the band which has the maximum actual energy level with respect to the other bands; and computing a delta code and an epsilon code for each band other than said maximum band, a delta code representing the difference between the actual energy level of a band and a coarse quantization of the energy level of another band, and an epsilon code representing the difference between the actual energy level of a band and a coarse quantization of the energy level of that band.</p></layer>
<layer id = "layer122"><p><b>US6064955A:Low complexity MBE synthesizer for very low bit rate voice messaging</b><br>This metal gasket is formed by laminating a pair of bead plates and a pair of intermediate plates, and capable of setting the temperature distribution thereof uniform by efficiently cooling high-temperature regions which are in the vicinity of swirl chambers without causing a decrease in the rigidity and strength thereof. The portions of the bead plates which are in the vicinity of the parts thereof in which the swirl chambers are positioned are provided with coolant-contact areas surrounded by half beads formed on the bead plates, these coolant-contact areas being provided with holes. The wall surfaces of these holes directly contact the cooling water flowing in a water jacket in a cylinder head, and fulfil the function of radiating the heat transmitted from a high-temperature combustion gas thereto.<br><b>Independant Claims</b><br>1. A multi-band excitation (MBE) synthesizer for generating speech from information received by a receiver, the information received including spectral information and excitation information representing a segment of speech, said MBE synthesizer comprising: a voiced signal generator for generating voiced signal components in the time domain using a pitch wave generator and a pitch wave resampler; an unvoiced signal generator for generating unvoiced signal components in the time domain; and a voicing processor, responsive to band voicing flags within the excitation information, for controlling selection of a voiced spectral component or an unvoiced spectral component from a harmonic amplitude spectrum.<br>6. A method of decoding a voice message having voiced components and unvoiced components within a frame of the voice message, comprising the steps of: building a harmonic spectrum of a speech segment of the voice message; subdividing the harmonic spectrum into a plurality of bands, each band of the plurality of bands having a respective band voicing flag; building a voiced spectrum and an unvoiced spectrum based on a status of the band voicing flag; processing the voiced spectrum with fixed phase values to get a voiced signal in the time domain; processing the unvoiced spectrum to get an unvoiced signal in the time domain; and adding the voiced signal and the unvoiced signal to provide a synthesized signal of the speech segment.</p></layer>
<layer id = "layer123"><p><b>US4809334A:Method for detection and correction of errors in speech pitch period estimates</b><br>A color conversion circuit converts a three-primary-color signal PS<b>0 </b>to a 5-color signal PS<b>5, </b>and includes (i) a color component extraction module that generates, by performing isochromatic conversion, a 7-color signal PS<b>2 </b>made up of 7 color components equivalent in terms of color to color components d<b>1 </b>through d<b>5 </b>of the 5-color signal PS<b>5, </b>and (ii) a matrix operation module that generates color components of the 5-color signal by performing linear combination of the color components of the 7-color signal. With this, it is possible to realize a color conversion circuit by which colors represented by a signal after conversion can be adjusted using intuitively-understandable parameters.<br><b>Independant Claims</b><br>1. A method for detecting and correcting gross errors in pitch period estimates of a speech signal, comprising the steps of: determining an average of nonzero values of received pitch period estimates; accepting a current pitch period estimate if said current pitch period estimate is within a predetermined range of said average; and correcting said current pitch period estimate if said current pitch period estimate is outside said predetermined range of said average.</p></layer>
<layer id = "layer124"><p><b>US6438517B1:Multi-stage pitch and mixed voicing estimation for harmonic speech coders</b><br>A high resolution x-ray imaging device based on a storage phosphor layer. The storage phosphor layer is sandwiched between two arrays of electrodes. In one embodiment of the device, the arrays are orthogonal arrays of linear electrodes, one of the arrays being transparent to the phosphorescence emitted by the storage phosphor. To read a pixel of a latent image stored in the storage phosphor layer, a voltage difference is established between two crossed electrodes that exceeds the threshold voltage of the storage phosphor material. The emitted light is detected by a device such as a CCD array that has coarser resolution than the crossed electrode array: the resolution of the imaging device of the present invention is the electrode width. Preferably, the electrodes are addressed for activation by optical scanning of photoconductive strips adjacent and perpendicular to the electrodes. Also preferably, the electrodes are addressed in interleaved subsets, each with as many electrode intersections as there are pixels in the CCD array, to create subimages which are interleaved to provide a final image having a resolution finer than the resolution of the CCD array. In another embodiment of the device, one array is a single electrode and the other array includes several electrodes. A subimage of the latent image is read by establishing a voltage difference between the single electrode and one of the several electrodes that exceeds the threshold voltage. The emitted light is detected by a CCD array with the resolution of the CCD array. The several subimages are assembled to provide a final image having a resolution finer than the resolution of the CCD array.<br><b>Independant Claims</b><br>1) A method of modeling the voiced or unvoiced characteristics of a segment of an input signal, comprising the steps of: receiving a pitch value associated with said input speech signal; comparing a synthesized speech signal to said input speech signal on a harmonic by harmonic basis; for each harmonic, determining whether said harmonic is voiced or unvoiced; counting the number of said harmonics that are voiced; calculating a cut-off frequency of said input speech signal, using the ratio of the results of said counting step and the total number of said harmonics, such that said cut-off frequency represents a frequency below which said speech signal is assumed to be voiced and above which said speech signal is comprised of both voiced and unvoiced speech; and generating a synthesized representation of said speech signal using said pitch value such that for each harmonic that falls below the cut-off frequency the harmonics are assumed to be voiced and for each harmonic above the cut-off frequency the harmonics are assumed to be mixed using both voiced and unvoiced energies for each harmonic.</p></layer>
<layer id = "layer125"><p><b>US6175602B1:Signal noise reduction by spectral subtraction using linear convolution and casual filtering</b><br>A support system for data transmission lines and the like, comprising a rail section supported generally horizontally, a splice for connecting the rail section and another structure, and a fastener for securing the splice to the rail section. Each rail section has a hollow box beam portion having a top wall, opposite side walls and a bottom wall. Each splice has a central part and first and second end parts, the first end part being receivable in an open end of the box beam portion of the rail section and the second end part being connectable to the structure. The central part of the splice has an outside width immediately adjacent the first end part of the splice essentially the same as the outside width of the rail section immediately adjacent its open end thereby to provide smooth junctures between the central part of the splice and the rail section at opposite sides of the rail section when the first end part of the splice is received in the rail section.<br><b>Independant Claims</b><br>1) A noise reduction system, comprising: a spectral subtraction processor configured to filter a noisy input signal to provide a noise reduced output signal, wherein a gain function of the spectral subtraction processor is computed based on an estimate of a spectral density of the input signal and on an estimate of a spectral density of a noise component of the input signal, wherein a block of samples of the noise reduced output signal is computed based on a respective block of samples of the input signal and on a respective block of samples of the gain function, wherein an order of the block of computed samples of the output signal is greater than a sum of an order of the respective block of samples of the input signal and an order of the respective block of samples of the gain function, and wherein a phase is imposed on the gain function so that the spectral subtraction processor provides causal filtering.<br>14) A method for processing a noisy input signal to provide a noise reduced output signal, comprising the steps of: computing an estimate of a spectral density of the input signal and an estimate of a spectral density of a noise component of the input signal; using spectral subtraction to compute the noise reduced output signal based on the noisy input signal and based on a gain function computed using the spectral density estimates; and adding a phase to the gain function so that the step of using spectral subtraction provides causal filtering, wherein a block of samples of the noise reduced output signal is computed based on a respective block of samples of the input signal and on a respective block of samples of the gain function, and wherein an order of the block of computed samples of the output signal is greater than a sum of an order of the respective block of samples of the input signal and an order of the respective block of samples of the gain function.<br>27) A mobile telephone, comprising: a spectral subtraction processor configured to filter a noisy near-end speech signal to provide a noise reduced near-end speech signal, wherein a gain function of the spectral subtraction processor is computed based on an estimate of a spectral density of the noisy near-end speech signal and on an estimate of a spectral density of a noise component of the noisy near-end speech signal, wherein a block of samples of the noise reduced near-end speech signal is computed based on a respective block of samples of the noisy near-end speech signal and on a respective block of samples of the gain function, wherein an order of the block of computed samples of the noise reduced speech signal is greater than a sum of an order of the respective block of samples of the noisy near-end speech signal and an order of the respective block of samples of the gain function, and wherein a phase is added to the gain function so that the spectral subtraction processor provides causal filtering.</p></layer>
<layer id = "layer126"><p><b>US5550924A:Reduction of background noise for speech enhancement</b><br><b>Independant Claims</b><br>1. An apparatus for the perceived real-time suppression of background noise in an input audio signal having components of noise comprising: a framer for dividing the input audio signal into a sequence of audio signal frames; a windower for producing a current windowed audio signal frame, combining all of one audio signal frame with some of the audio signal frame immediately preceding in time the one audio signal frame; a transformer for obtaining a group of frequency spectrum components from the current windowed audio signal frame; a noise estimator using the frequency spectrum components to produce a noise estimate of an amount of noise in the frequency spectrum components; a noise suppression spectral modifier for producing current gain multiplicative factors based on the noise estimate and the frequency spectrum components; a delayer for delaying, by a fixed number of frames, the frequency spectrum components of said sequence of audio signal frames to produce delayed frequency spectrum components; a controlled attenuator for attenuating the delayed frequency spectrum components of a previous frame of said sequence based on the current gain multiplicative factors produced using said current frame to produce noise-reduced frequency components; and an inverse transformer for converting the noise-reduced frequency components to the time domain.<br>6. An apparatus for the perceived suppression of background noise in an input audio signal having components of noise comprising: a framer for dividing the input audio signal into a sequence of audio signal frames; a windower for producing a current windowed audio signal frame, combining all of one audio signal frame with some of the audio signal frame immediately preceding in time the one audio signal frame; a transformer for obtaining a group of frequency spectrum components from the windowed audio signal frame; a noise estimator using the frequency spectrum components to produce a noise estimate of an amount of noise in the frequency spectrum components; a noise suppression spectral modifier for producing current gain multiplicative factors based on the noise estimate and the frequency spectrum components; a delayer for delaying the frequency spectrum components of said sequence of audio signal frames to produce delayed frequency spectrum components; a controlled attenuator for attenuating the delayed frequency spectrum components of a previous frame of said sequence based on the current gain multiplicative factors produced using said current frame to produce noise-reduced frequency components; and an inverse transformer for converting the noise-reduced frequency components to the time domain, and wherein the noise suppression spectral modifier further comprises: means for using previously produced gain multiplicative factors for determining current gain multiplicative factors; a global decision mechanism for making, for a group of the frequency spectrum components of a frame a determination as to whether that group is noise; a local noise decision mechanism for deriving, for each frequency component of the frequency spectrum components, a confidence level for each component, whether that frequency component is a noise component; a detector for determining, based on the confidence levels, initial gain multiplicative factors for each frequency component; and a spreading mechanism for spectrally and temporally effecting adjustment of the initial gain multiplicative factors.<br>15. An apparatus for the perceived suppression of background noise in an input audio signal having components of noise comprising: a transformer for obtaining frequency spectrum components from an audio signal frame derived from the input audio signal; a detector for determining multiplicative gain factors for each frequency component; a spreading mechanism for adjusting the multiplicative gain factors for effecting temporal and spectral spreading; and a controlled attenuator for attenuating the frequency components in accordance with said adjusted multiplicative gain factors to derive a noise-modified spectral signal.<br>16. A method for reducing the perception of background noise of an input audio signal comprising the steps of: dividing the input audio signal into a sequence of audio signal frames; producing a windowed audio signal frame; combining all of one audio signal frame with some of the audio signal frame immediately preceding in time the one audio signal frame to obtain a current frame; obtaining a group of frequency spectrum components from the windowed audio signal frame; using the frequency spectrum components to produce a noise estimate of an amount of noise in the frequency spectrum components; producing current gain multiplicative factors based on the noise estimate and the frequency spectrum components; delaying, by a fixed number of frames, the frequency spectrum components of said sequence to produce delayed frequency spectrum components; attenuating the delayed frequency spectrum components of a previous frame based on the current gain multiplicative factors produced using said current frame to produce noise-reduced frequency components; and converting the noise-reduced frequency components to the time domain.<br>19. A method for reducing the perception of background noise of an input audio signal comprising the steps of: dividing the input audio signal into a sequence of audio signal frames; producing a windowed audio signal frame; combining all of one audio signal frame with some of the audio signal frame immediately preceding in time the one audio signal frame to obtain a current frame; obtaining a group frequency spectrum components from the current windowed audio signal frame; using the frequency spectrum components to produce a noise estimate of an amount of noise in the frequency spectrum components; producing current gain multiplicative factors based on the noise estimate and the frequency spectrum components; delaying the frequency spectrum components of said sequence to produce delayed frequency spectrum components; attenuating the delayed frequency spectrum components of a previous frame based on the current gain multiplicative factors produced using said current frame to produce noise-reduced frequency components; converting the noise-reduced frequency components to the time domain; and wherein the step of producing current gain multiplicative factors further comprises the steps of: using previously produced gain multiplicative factors for determining said current gain multiplicative factors; making, for a group of the frequency spectrum components of a frame, a determination as to whether that group is noise; deriving, for each frequency component of the frequency spectrum components, a confidence level for each component, whether that frequency component is a noise component; determining, based on the confidence levels, initial gain multiplicative factors for each frequency component; and spectrally and temporally effecting adjustment of the initial gain multiplicative factors.<br>21. A method for reducing the perception of background noise in an input audio signal having components of noise comprising the steps of: obtaining frequency spectrum components from an audio signal frame derived from the input audio signal; determining multiplicative gain factors for each frequency component; adjusting the multiplicative gain factors for effecting temporal and spectral spreading; and attenuating the frequency components in accordance with said adjusted multiplicative gain factors to derive a noise-modified spectral signal.</p></layer>
<layer id = "layer127"><p><b>US3706929A:COMBINED MODEM AND VOCODER PIPELINE PROCESSOR</b><br>A portable remote control device (<b>100</b>) for a radio is housed within a key fob housing (<b>102</b>). The key fob housing (<b>102</b>) camouflages a plurality of radio interface functions.<br><b>Independant Claims</b><br>5) We claim:<br>1) A digital apparatus having a first operating mode wherein said apparatus is responsive to a first input signal representative of a first speech wave in the time domain, and a second alternative operating mode wherein said apparatus is responsive to a second input signal (i) representative of the power spectrum and the pitch frequency of a second speech wave and (ii) comprising a plurality of differentially coherent phase shift keyed tones, said apparatus comprising: first means for a. computing from said first input signal the power spectrum of said first speech wave, b. generating a binary representation of a modulated carrier comprising a plurality of differentially coherent phase shift keyed tones, said modulation bearing the power spectrum and the pitch frequency of said first speech wave, and c. recovering from said second input signal the power spectrum and the pitch frequency of said second speech wave, said first means comprising: first and second memories, a first adder having an output connected to the input of said first memory, a first multiplier, means for coupling the outputs of said first multiplier to an input of said first adder, first and second read-only memories, means for coupling the output of said first read-only memory to said input of said first adder, means for coupling the output of said second read-only memory to an input of said first multiplier, means for connecting the output of said first memory to said input of said first adder and to inputs of said first multiplier and to the input of said second read-only memory and to the input of said second memory, and means for connecting the output of said second memory to the input of said second memory and to an input of said first multiplier; and second means for a. computing the pitch frequency of said first speech wave, b. supplying said pitch frequency of said first speech wave to said first means, and c. generating from the power spectrum and pitch frequency recovered by said first means a binary representation of said second speech wave in the time domain, said second means comprising: a third memory, a second adder having its output connected to the input of said third memory, a second multiplier having its output connected to an input of said second adder, means for connecting the output of said third memory to an input of said second multiplier and to an input of said second adder, means for connecting the output of said second memory to an input of said second multiplier, means, having an input coupled to the output of said third memory, for synthesizing the impulse response of a plurality of filters each responsive to pass a different one of said plurality of tones, means for connecting the output of said impulse response synthesizer means to an input of said second multiplier, means for generating a plurality of noiselike signals each having a center frequency corresponding to a different one of said plurality of tones, and means for connecting the output of said noise generator means to an input of said second adder.</p></layer>
<layer id = "layer128"><p><b>US4811404A:Noise suppression system</b><br>A heat pump air conditioning system with an active digital control of the refrigeration cycle thereof to improve the coefficient of performance. The system can incorporate solar collectors in parallel with the outdoor heat exchanger and a water storage tank in the system to maximize the utilization of solar heating and nocturnal cooling as an additional heat source or heat sink means when such are available to further improve the coefficient of performance. The system also incorporates individual temperature control mechanisms in each room to circulate an adequate amount of water from the storage tank in accordance with the heat demand of each room, thus contributing to realization of an energy efficient central air conditioning system.<br><b>Independant Claims</b><br>1. An improved noise suppression system for attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal, said noise suppression system comprising: means for separating the input signal into a plurality of pre-processed signals representative of selected frequency channels; means for generating estimates of the signal-plus-noise energy and the noise energy in each individual channel; means for producing a gain value for each individual channel in response to said channel energy estimates, said gain values having a minimum gain value for each channel, said gain value producing means including threshold means for allowing gain values above said minimum gain value to be prodeced only when said signal-plus-noise energy estimates exceed said noise energy estimates by a predetermined amount; and means for modifying the gain of each of said plurality of pre-processed signals in esponse to said gain values to provide a plurality of post-processed signals.<br>9. An improved noise suppression system for attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal, said noise suppression system comprising: means for separating the input signal into a plurality of pre-processed signals representative of selected frequency channels; means for generating and storing an estimate of the background noise power spectral density of said pre-processed signals, said background noise estimate generating means including means for modifying said background noise estimate in response to a timing parameter indicative of the time interval since the previous background noise estimate modification; means for generating an estimate of the signal-to-noise ratio (SNR) in each individual channel based upon said modified background noise estimates; means for producing a gain value for each individual channel in response to said channel SNR estimates; and means for modifying the gain of each of said plurality of pre-processed signals in response to said gain values to provide a plurality of post-procesed signals.<br>22. An improved noise suppression system for attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal, said noise suppression system comprising: means for separating the input signal into a plurality of pre-processed signals representative of a number N of selected frequency channels means for generating an estimate of the energy in each individual channel; means for monitoring said channel energy estimates and for distinguishing narrowband noise bursts from speech energy and background noise energy, thereby producing a modification signal; means for selectively modifying said channel energy estimates in response to said modification signal such that channel energy estimates representative of narrowband noise bursts are modified; means for producing a gain value for each individual channel in response to each modified channel energy estimate; and means for modifying the gain of each of said plurality of pre-processed signals in response to said gain values to provide a plurality of post-processed signals.<br>31. An improved method of attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal in a noise suppression system comprising the steps of: separating the input signal into a plurality of preprocessed signals representative of a number N of selected frequency channels; generating an estimate of the energy in each individual channel; generating and storing an estimate of the background noise power spectral density of said pre-processed signals; generating an estimate of the signal-to-noise ratio (SNR) in each individual channel based upon said background noise estimates and said channel energy estimates; producing a gain value for each individual channel in response to said channel SNR estimates, said gain values having a range of minimal values, said gain value producing step including the steps of providing a predefined SNR threshold and comparing said channel SNR estimates to said predefined SNR threshold such that channels having SNR estimates below said SNR threshold produce gain values within said minimal range; and modifying the gain of each of said plurality of preprocessed signals in response to said gain values to provide a plurality of post-processed signals.</p></layer>
<layer id = "layer129"><p><b>US4852179A:Variable frame rate, fixed bit rate vocoding method</b><br>The invention relates to a tray having two handle configurations along two opposing side walls, the configurations comprising extensions in the form of flaps extending obliquely outward and downward from the upper edge portion of the two side walls, the flaps being held in position by being secured to projections extending from the ends of the two other side walls.<br><b>Independant Claims</b><br>1. A method of operating a vocoder to compress a multiplicity of voice data samples for application to a constant rate channel, said method comprising the steps of: selecting one of a plurality of subframe rates; analyzing at lest a portion of the samples to produce a predictive code representative of the analyzed samples; quantizing the predictive code into a quantized code having a bit length defined by the selected subframe rate and a rate parameter of the constant rate channel; and said steps of selecting, analyzing and quantizing being performed at a bit rate of said constant rate channel.<br>10. A method of operating a vocoder to decompress a base frame of data which represents a multiplicity of voice data samples and which is received from a constant rate channel, said method comprising the steps of: obtaining information describing one of a plurality of subframe rates from the constant rate base frame of data; separating the base frame of data into a least one subframe of data in response to the subframe rate from said obtaining step; expanding each subframe of data from said separating step into an independent predictive code; synthesizing the multiplicity of voice data samples from the predictive code for each subframe; and said steps of obtaining, separating, expanding and synthesizing being performed at a bit rate of said constant rate channel.<br>15. A method of operating a vocoder to compress a multiplicity of voice data samples for application to a fixed rate channel, said method comprising the steps of: measuring spectral change occurring between the multiplicity of voice data samples and a prior multiplicity of voice data samples; modulating a subframe rate in response to the spectral change so that increasing spectral change causes increasing subframe rate; performing a linear predictive coding of at least a portion of the multiplicity of voice data samples to generate excitation, energy and spectrum data; making first and second vector quantization codebooks available for searching; choosing one of the first and second vector quantization codebooks in response to the subframe rate of said modulating step; searching within only the one codebook chosen in said choosing step for a nearest matching reference pattern to the spectrum data of said performing step; and retrieving a reference pattern descriptor code which uniquely describes the nearest matching reference pattern, wherein the reference pattern descriptor code contains N bits and the one codebook chosen in said choosing step contains less than 2.sup.N unique reference patterns.</p></layer>
<layer id = "layer130"><p><b>US6081776A:Speech coding system and method including adaptive finite impulse response filter</b><br>The invention relates to a method for the regeneration of a particulate filter (<b>7</b>) arranged on an exhaust line (<b>5</b>) of an engine (<b>3</b>) of a motor vehicle (<b>1</b>), wherein the charge of said filter (<b>7</b>) is evaluated by means of a model wherein P=f(Qvol, soot mass), and P=Pup−Pdown, and Qvol=K*(Qair+pfuel*Qcarb)*N*Tup/Pup, or Pup et Pdown are the pressures measured respectively upstream and downstream from said particulate filter (<b>7</b>). The inventive method is characterized in that Pdown is modelled and in that Pup is determined by means of the relation Pup=P+Pdown.<br><b>Independant Claims</b><br>1. A spectral frequency quantizer comprising: a digital signal processor adapted to operate, at least in part, as a finite impulse response filter, said finite impulse response filter comprising an input for receiving line spectral frequencies, and an output for providing smoothed quantized line spectral frequencies, said finite impulse response filter characterized by the transfer function: H(z)=0.5+.DELTA.+(0.5-.DELTA.)z.sup.-1 wherein .DELTA. is determined by the formula: .DELTA.=min(0.5,.gamma..vertline..function.(n)-.function.(n-1).vertline.) and wherein .function.(n) denotes a present input to said finite impulse response filter, and wherein .function.(n-1) denotes a previous input to said finite impulse response filter.</p></layer>
<layer id = "layer131"><p><b>US6098036A:Speech coding system and method including spectral formant enhancer</b><br>A portable, lightweight, dual-lighted clamp having two jaws for gripping a variety of objects and a pair of battery-operated flashlights assemblies integrally built into the handles, with the light bulbs and transparent illuminating areas located at each of the jaws. The spring clamp may be conveniently attached to many hard-to-reach places. The flashlights each have a switch actuator for allowing the user to easily operate each flashlight.<br><b>Independant Claims</b><br>1. A method for synthesizing speech comprising the steps of: determining spectral peaks and valleys of a synthesized speech spectrum; attenuating the amplitude values in the spectral valleys of said synthesized speech spectrum without attenuating said spectral peaks.<br>2. A speech synthesizer comprising: a linear predictive coefficient (LPC) filter adapted to provide a synthesized speech waveform including voiced portions at an output in response to voiced speech excitation at an input; a harmonic generator for providing voiced speech excitation comprising spectral peaks and valleys to said input of said LPC filter; said voiced speech excitation characterized by the relationship: ##EQU13## wherein said harmonic generator is adapted to attenuate values of amp (k) in said spectral valleys.</p></layer>
<layer id = "layer132"><p><b>US6591234B1:Method and apparatus for adaptively suppressing noise</b><br>An overmolded electronic assembly (<b>10</b>) and method for forming the assembly (<b>1</b>) that entails enclosing a circuit board (<b>12</b>) having one or more circuit devices (<b>16</b>) mounted to its surface. The assembly (<b>10</b>) includes a heat-conductive member (<b>18</b>) in thermal contact with one or more of the circuit devices (<b>16</b>) mounted to the circuit board (<b>12</b>). An overmolded body (<b>22</b>) encloses the circuit board (<b>12</b>) and the circuit devices (<b>16</b>) with the heat-conductive member (<b>18</b>), such that the overmolded body (<b>22</b>) and heat-conductive member (<b>18</b>) form a moisture-impermeable seal around the circuit board (<b>12</b>) and circuit devices (<b>16</b>). The overmolded body (<b>22</b>) also includes a connector housing (<b>28</b>) integrally-formed in its outer surface. The method for manufacturing the overmolded electronic assembly (<b>10</b>) generally entails supporting the circuit board (<b>12</b>) with the heat-conductive member (<b>18</b>) such that the heat-conductive member (<b>18</b>) thermally contacts the circuit devices (<b>16</b>). An overmolded enclosure is then formed by molding a material over the surface of the circuit board (<b>12</b>) to form the overmolded body (<b>22</b>) that, with the heat-conductive member (<b>18</b>), encases the circuit board (<b>12</b>) and its circuit devices (<b>16</b>).<br><b>Independant Claims</b><br>1) In a communications system for processing a communication signal comprising speech and noise components derived from speech and noise, apparatus for enhancing the quality of the communication signal comprising a processor arranged to: divide the communication signal into a plurality of frequency band signals including speech and noise components due to said speech and noise; generate first power signals for the frequency band signals, each first power signal being based on estimating over a first time period the power of one of said frequency band signals; generate second power signals for the frequency band signals, each second power signal being based on estimating over a second time period less than the first time period the power of one of said frequency band signals; generate condition signals representing conditions of the frequency band signals in response to predetermined relationships between at least the first power signals and second power signals; adjust the gain of the frequency band signals in response to the condition signals to generate adjusted frequency band signals; and combine the adjusted frequency band signals to generate an adjusted communication signal.<br>14) In a communications system for processing a communication signal comprising speech and noise components derived from speech and noise, a method of enhancing the quality of the communication signal comprising: dividing the communication signal into a plurality of frequency band signals including speech and noise components due to said speech and noise; generating first power signals for the frequency band signals, each first power signal being based on estimating over a first time period the power of one of said frequency band signals; generating second power signals for the frequency band signals, each second power signal being based on estimating over a second time period less than the first time period the power of one of said frequency band signals; generating condition signals representing conditions of the frequency band signals in response to predetermined relationships between at least the first power signals and second power signals; adjusting the gain of the frequency band signals in response to the condition signals to generate adjusted frequency band signals; and combining the adjusted frequency band signals to generate an adjusted communication signal.</p></layer>
<layer id = "layer133"><p><b>US6173255B1:Synchronized overlap add voice processing using windows and one bit correlators</b><br>A method of forming a resistor from semiconductive material includes, a) providing a substrate; b) providing a layer of semiconductive material over the substrate; c) providing a pair of openings into the semiconductive material layer; d) plugging the pair of openings with an electrically conductive material to define a pair of electrically conductive pillars within the semiconductive material, the pair of pillars having semiconductive material extending therebetween to provide a resistor construction; and e) providing a conductive node to each of the electrically conductive pillars. An integrated circuit incorporating a resistor construction includes, i) a layer of semiconductive material; ii) a pair of electrically conductive pillars provided within the semiconductive material layer, the pair of pillars being separated from one another and thereby having a mass of the semiconductive material extending therebetween; and iii) an electrically conductive node in electrical connection with each of the respective conductive pillars. Alternately, a resistor is provided within a semiconductive substrate using different concentration diffusion regions.<br><b>Independant Claims</b><br>1) A method for processing an audio signal, comprising the steps of: digitizing the audio signal; processing the digitized audio signal using a linear predictor to attenuate coherent noise contained in the audio signal to produce a residual output signal that is representative of the audio signal; processing the residual output signal using a synchronized overlap add processor for compressing the audio signal using one bit correlation and smooth windowing; and further compressing the audio signal using an encoder to provide a compressed digital output signal that corresponds to the audio signal.<br>10) Apparatus for compressing an audio signal, comprising: an analog to digital converter for digitizing the audio signal; and a linear predictor for processing the digitized audio signal to attenuate coherent noise and produce a residual output signal that is representative of the audio signal; and a synchronized overlap add processor comprising a one bit correlator and a smoothly-shaped window for compressing the digitized audio signal to provide a compressed audio signal.</p></layer>
<layer id = "layer134"><p><b>US6411927B1:Robust preprocessing signal equalization system and method for normalizing to a target environment</b><br>A pulse discrimination method for discriminating between pulses having a short decay period and a long decay period, may comprise: Detecting the pulse; integrating a rise portion of the pulse; integrating a decay portion of the pulse; and comparing the integrated rise portion of the pulse with the integrated decay portion of the pulse to distinguish between a pulse having a long decay period and a pulse having a short decay period.<br><b>Independant Claims</b><br>1) A signal normalizer for processing an audio source comprising: a speech signal detector receptive of said audio source for detecting when speech is present and is not present in said audio source; a first compensation factor calculation module responsive to said speech signal detector for determining a first noise quantity and adding noise to said audio source when speech is not present in said audio source, to set the background noise level in accordance with predetermined target parameters; a second compensation factor calculation module responsive to said speech signal detector for determining a second noise quantity for selectively adding noise to said audio source when speech is present in said audio source, to set a predetermined signal-to-noise ratio in accordance with said predetermined target parameters.<br>11) A speech recognition system, the system comprising: a speech recognizer of the type that is trained upon a predetermined corpus of training speech generated in a training environment and used by matching patterns in an utterance of test speech generated in a use environment; and a normalizer for processing said training speech and said test speech by adding predetermined quantities of noise to said training speech and said test speech to minimize mismatch between said training and use environments.</p></layer>
<layer id = "layer135"><p><b>US6275794B1:System for detecting voice activity and background noise/silence in a speech signal using pitch and signal to noise ratio information</b><br>A gaming device, and a method of providing a slot machine game to a user on the gaming device. Reels comprising symbols are displayed, where each symbol is a partial image of a currency object. After a wager from a user to play at least one pay line is received, symbols on the display are rearranged and then displayed. It is determined whether a whole image of a currency object is displayed within a played pay line, and if so, an award is provided to the user, where the award is associated with the currency object.<br><b>Independant Claims</b><br>1) In a speech communication system comprising: (a) a speech encoder for receiving and encoding an incoming speech signal to generate a bit stream for transmission to a speech decoder; (b) a communication channel for transmission; and (c) a speech decoder for receiving the bit stream from the speech encoder to decode the bit stream to generate a reconstructed speech signal, the incoming speech signal comprising periods of active voice and non-active voice, a method for generating a frame voicing decision comprising the steps of: i. extracting a predetermined set of parameters, including a pitch gain and a pitch lag, from the incoming speech signal for each frame; ii. estimating a signal-to-noise ratio; and iii. making a frame voicing decision according to the predetermined set of parameters and the signal-to-noise ratio.<br>9) A voice activity detector (VAD) for making a voicing decision on an incoming speech signal frame, the VAD comprising: an extractor for extracting a predetermined set of parameters, including a pitch gain and a pitch lag, from the incoming speech signal for each frame; a calculator unit for calculating a set of predetermined values, including a signal-to-noise ratio SNR, based on the extracted predetermined set of parameters and for adaptively determining threshold values according to the SNR value; and a decision unit for making a frame voicing decision according to the predetermined set of values.<br>15) A voice activity detection method for detecting voice activity in an incoming speech signal frame, the improvement comprising making a voicing decision based on a pitch lag and a pitch gain of the speech signal frame and using a signal-to-noise ratio to adaptively set threshold values.</p></layer>
<layer id = "layer136"><p><b>US6122610A:Noise suppression for low bitrate speech coder</b><br>A method, apparatus and program storage device for providing wireless storage is disclosed. At least a first wireless storage node and at least one network node are provided. A plurality of wireless channels couple the first wireless storage node and the network node. The plurality of the wireless channels for the first wireless storage node are assigned based upon loading.<br><b>Independant Claims</b><br>1. A method for suppressing noise in an input signal that carries a combination of noise and speech, comprising the steps of: dividing said input signal into signal blocks; applying a Discrete Fourier Transform (DFT) to the signal blocks over a number of DFT bins to provide a complex-valued frequency domain representation of each block; converting the frequency domain representations of the signal blocks to magnitude-only signals; and averaging the magnitude-only signals across different frequency bands to provide an estimate of a short-time perceptual band spectrum of the input signal; wherein each of the different frequency bands is correlated with an associated plurality of the DFT bins; determining, at various points in time, whether said input signal is carrying noise only, or a combination of noise and speech, and, when the input signal is carrying noise only, using the corresponding estimated short-time perceptual band spectrum of the input signal to update an estimate of a long term perceptual band spectrum of the noise; determining a noise suppression frequency response based on said estimate of the long term perceptual band spectrum of the noise and the estimated short-time perceptual band spectrum of the input signal; and providing an all-pole time-domain filter in accordance with said noise suppression frequency response for time-domain shaping of a current block of the input signal to suppress noise therein.<br>9. An apparatus for suppressing noise in an input signal that carries a combination of noise and speech, comprising: a signal preprocessor for dividing said input signal into signal blocks; a Discrete Fourier transform (DFT) processor for processing said signal blocks over a number of DFT bins to provide a complex-valued frequency domain representation of each block; means for computing a magnitude of said complex-valued frequency domain representation to provide a frequency domain magnitude spectrum; an accumulator for accumulating said frequency domain magnitude spectrum into a perceptual-band spectrum comprising frequency bands of unequal width; wherein values of the frequency domain magnitude spectrum are accumulated from different frequency bands, each of which is correlated with an associated plurality of the DFT bins; a filter for filtering the perceptual-band spectrum to generate an estimate of a short-time perceptual-band spectrum comprising a current segment of the input signal; a speech/pause detector for determining whether said input signal is currently noise only or a combination of speech and noise; a noise spectrum estimator responsive to said speech/pause detector when the input signal is noise only for updating an estimate of a long term perceptual band spectrum of the noise based on the estimated short-time perceptual band spectrum of the input signal; a spectral gain processor responsive to said noise spectrum estimator for determining a noise suppression frequency response; and a spectral shaping processor comprising an all-pole time-domain filter that is responsive to said spectral gain processor for time-domain shaping of a current block of the input signal to suppress noise therein.<br>18. A method for suppressing noise in an input signal that carries a combination of noise and audio information, comprising the steps of: computing a noise suppression frequency response for said input signal in the frequency domain; and applying said noise suppression frequency response to said input signal using an all-pole time-domain filter to suppress noise in the input signal.</p></layer>
<layer id = "layer137"><p><b>US6347297B1:Matrix quantization with vector quantization error compensation and neural network postprocessing for robust speech recognition</b><br>Disclosed is the use of a vaccine based on a tumor-associated antigen, its epitope, mimotope, specific or anti-idiotypic antibody, for preparing a medicament for the prophylactic and/or therapeutic active immunization against cancer, in combination with chemotherapy.<br><b>Independant Claims</b><br>1) A speech recognition system comprising: a vector quantizer to receive first parameters of an input signal and to generate a first quantization observation sequence; a first speech classifier to receive the first quantization observation sequence from the vector quantizer and to generate first respective speech classification output data; a matrix quantizer to receive second parameters of the input signal, and to generate a second quantization observation sequence; a second speech classifier to receive the second quantization observation sequence from the matrix quantizer and to generate second respective speech classification output data; a mixer to combine corresponding first and second respective speech classification data to generate third respective speech classification data and to generate output data from the first, second, and third speech classification data; and a neural network to receive output data from the mixer and to determine fourth respective speech classification output data.<br>17) A speech recognition system comprising: a vector quantizer to receive first parameters of an input signal and to generate a first quantization observation sequence, wherein the first parameters are grouped into S1 partition(s); a split matrix quantizer to receive second parameters of the input signal and to generate a second quantization observation sequence, wherein the second parameters are grouped into S2 partition(s); a first speech classifier to receive the first quantization observation sequence from the vector quantizer and generate first respective speech classification output data; a second speech classifier to receive the second quantization observation sequence from the split matrix quantizer and generate second respective speech classification output data; a mixer to combine corresponding first and second respective speech classification data to generate third respective speech classification data and to provide output data based on the first, second, and third classification data; and a neural network to receive the mixer output data and to generate fourth respective speech classification data based on the mixer output data.<br>20) An apparatus comprising: a first speech classifier to operate on S1 group(s) of first parameters of an input signal and to provide first output data relating the input signal to first reference data, wherein the first input signal parameters include frequency and time domain parameters, wherein S1 is a positive integer; a second speech classifier to operate on S2 group(s) of second parameters of the input signal and to provide second output data relating the second input signal to second reference data, wherein the second parameters of the input signal include the frequency domain parameters, wherein S2 is a positive integer; mixer to combine the first output data and the second output data into third output data so that the second output data compensates for errors in the first output data; and a neural network to receive selected output data from the mixer and to generate output data to classify the input signal.<br>30) A method comprising the steps of: processing first parameters of the input signal to relate the first parameters to first reference data wherein the first parameters include frequency and time domain information; generating first output data relating the first parameters to reference data; processing second parameters of the input signal to relate the second parameters to second reference data wherein the second parameters include frequency domain information; generating second output data relating the second parameters to the second reference data; combining the first output data and second output data into third output data to compensate for errors in the first output data; and providing the first, second, and third output data to a neural network to classify the input signal.<br>40) A method of recognizing speech comprising the steps of: receiving an input signal; determining parameters of the input signal; vector quantizing the parameters of the input signal to obtain first quantization output data; classifying the first quantization output data; matrix quantizing the parameters of the input signal to obtain second quantization output data; classifying the second quantization output data; combining the first and second quantization output data to generate third output data; and generating an identification of the input signal with a neural network based upon the classification of the first and second quantization output data and the third output data.<br>44) A method of recognizing speech comprising the steps of: receiving an input signal; determining D order line spectral pairs for TO frames of the input signal, wherein D and TO are integers; determining parameters related to the energy of the input signal, wherein the parameters related to the energy of the input signal include the input signal energy and a first derivative of the input signal energy; vector quantizing the D order line spectral pairs for each of the TO frames and the parameters related to the input signal energy; classifying the input signal using the vector quantization of the D order line spectral pairs; matrix quantizing the D order line spectral pairs and the parameters related to the input signal energy for T matrices of frames of the input signal, wherein T is defined as int(TO/N), and N is the number for input signal frames represented in each of the T matrices; classifying the input signal using the matrix quantization of the D order line spectral pairs and parameters related to the input signal energy; combining the classifications of the input signal and providing the individual classifications of the input signal and the combined classification of the input signal to a neural network.</p></layer>
<layer id = "layer138"><p><b>US6219642B1:Quantization using frequency and mean compensated frequency input data for robust speech recognition</b><br>A method producing a thermobonding interlining comprises the steps of depositing a non-woven layer of intermingled fibers or filaments presented in a general direction on a conveyor of wire netting, directing toward said conveyor weft yarns made of textured continuous filaments that are kept in a stretched condition and parallel with one another; depositing the weft yarns in a zone where the non-woven layer is being deposited such that the weft yarns are oriented crosswise to the general direction of and covered by the non-woven layer. Afterwards, such superposed weft yarns and non-woven layer assembly is subject to the high pressure jets of water from injectors disposed above the conveyor so that the weft yarns and the fibers or filaments of the non-woven layer are intermingled to obtain a base material of interlining. Then, the base material of interlining is dried in a thermal treatment. The dots of thermofusible polymer are deposited one face of the base material of interlining.<br><b>Independant Claims</b><br>1) An apparatus comprising: a mean compensation module to receive parameters for TO samples of an input signal and to generate mean compensated parameters from the received input signal parameters; a first quantizer to receive the input signal parameters and to quantize the input signal parameters, wherein the first quantizer is comprised of a first matrix quantizer and a first vector quantizer; a second quantizer to receive the input signal mean compensated parameters and to quantize the input signal mean compensated parameters wherein the second quantizer is comprised of a second matrix quantizer and a second vector quantizer; a backend processor to receive the quantized input signal parameters and the input signal mean compensated input signal parameters and to classify the input signal therefrom, wherein the backend processor comprises: a first group of hidden Markov models which are trained using quantized input signal parameters from the first and second matrix quantizers; a second group of hidden Markov models which are trained using quantized input signal parameters from the first and second vector quantizers; and a stochastic module to (a) receive the quantized input signal parameters from the first and second matrix quantizers, (b) determine the respective probabilities that each hidden Markov model from the first group of hidden Markov models modeled the quantized input signal parameters from the first and second matrix quantizers, (c) receive the quantized input signal parameters from the first and second vector quantizers, (d) determine the respective probabilities that each hidden Markov model from the second group of hidden Markov models to have modeled the quantized input signal parameters from the first and second vector quantizers, wherein the backend processor is capable of utilizing the probabilities to generate the input signal classification.</p></layer>
<layer id = "layer139"><p><b>US4937873A:Computationally efficient sine wave synthesis for acoustic waveform processing</b><br>A simple and rapid method by which lipids can be measured quantitatively or qualitatively. The method involves the use of a labelled lipid of which one is interested in measuring or a different lipid reacting similarly to the lipid of interest. The labelled lipid is added to an unknown specimen and to a set of standard(s) containing various amounts of the lipid of interest. The label is allowed to interact. A portion of the label is then selectively removed of which the degree of the removal of the label is dependent upon the amount of the lipid initially present. The amount of lipid originally present in the unknown specimen can therefore be ascertained by extrapolating the amount of label present in the unknown specimen to the amount present in the identically treated standard(s).<br><b>Independant Claims</b><br>1. A method of processing an acoustic waveform, the method comprising: sampling a waveform to obtain a series of discrete samples and constructing therefrom a series of frames, each frame spanning a plurality of samples; analyzing each frame of samples to extract a set of variable frequency components having individual amplitudes; tracking said components from one frame to a next frame, said tracking including matching a component from the one frame with a component in the next frame having a similar value regardless of shifts in frequency and spectral energy; and interpolating the values of the components from the one frame to the next frame by performing an overlap-and-add function utilizing Fourier analysis to generate a reconstruction of said waveforms.<br>9. A method for suppressing tonal noise artifacts during the reconstruction of an acoustic waveform from a sinusoidal parametric representation of the waveform, the method comprising; estimating a noise envelope from a set of variable frequency components having individual amplitudes which comprise a parametric representation of the waveform; reconstructing an acoustic waveform from said parametric representation; and filtering said reconstructed waveform using said noise envelope estimates to suppress tonal noise estimates.<br>10. A method of deriving phase values for frequency components during reconstruction of an acoustic waveform from a sinusoidal representation of the waveform, the method comprising: determining a phase of the fundamental frequency by integration of a pitch frequency obtained by linear interpolation of matched fundamental frequencies between successive frames; determining a pitch onset time by locating the time at which the phase function crosses the nearest multiple of the phase synchrony point; and allocating phase values to the frequency components, such that all of the frequency components come into phase every pitch onset time.<br>11. A system for processing an acoustic waveform, the system comprising sampling means for sampling a waveform to obtain a series of discrete samples and constructing therefrom a series of frames, each frame spanning a plurality of samples, analyzing means for analyzing each frame of samples to extract a set of variable frequency components having individual amplitudes, tracking means for tracking said components from one frame to a next frame, said tracking means including matching means for matching a component from the one frame with a component in the next frame having a similar value regardless of shifts in frequency and special energy, interpolating means for interpolating the values of the components from the one frame to the next frame, including means for performing an overlap-and-add function utilizing Fourier analysis to generate a reconstruction of said waveform.<br>19. A receiver for receiving a coded parametric representation of an acoustic waveform in which the representation comprises as set of variable frequency components having individual amplitudes defining sine waves which can be summed to recreate the waveform at a particular frame of time, the receiver comprising: decoding means for extracting a set of frequency components having individual amplitudes from each frame of a coded representation of an acoustic waveform; tracking means for tracking said components from one frame to a next frame, said tracking means, including matching means for matching a component from the one frame with a component in the next frame having a similar value regardless of shifts in frequency and spectral energy; and interpolation means for interpolating the values of the components from the one frame to the next frame, including means for performing an overlap-and-add function utilizing Fourier analysis, to generate a reconstruction of said waveform.</p></layer>
<layer id = "layer140"><p><b>US6314396B1:Automatic gain control in a speech recognition system</b><br>A mouth blown sports whistle includes a mouthpiece that communicates with a sound chamber and emits an audio signal when pressurized air is blown into the mouthpiece and a second chamber that communicates via a passageway with the sound chamber. A visual member is housed in the second chamber in a retracted position so as to be capable of extending through an opening therein to an extended position when pressurized air enters the second chamber from said sound chamber to thereby render a visual signal of the blowing of the whistle. The whistle may further include a check valve associated with the second chamber to temporally hold the visual member in its extended position after the extension thereof and also a release valve associated with the second chamber to permit the visual member to return to its retracted position to ready the whistle for another combined audio and visual signalling.<br><b>Independant Claims</b><br>1) A speech recognition preprocessor, comprising: an analyzer for receiving a digital speech signal generating therefrom a sequence of frames, each frame having a plurality of samples from said digital speech signal; means coupled to said analyzer means for tracking an upper energy envelope, an average energy envelope, and a lower energy envelope by a plurality of energy tracks in one or more consecutive frames of said digital speech signal, wherein said energy tracks are based on a high biased running mean, a low biased running mean and a nominally unbiased running mean; and means coupled to said tracking means for computing a normalized energy value and providing said normalized energy value to a speech recognition system.<br>5) A method of normalizing energy in a voice signal, said method comprising the steps of: dividing the voice signal into a plurality of consecutive time intervals; calculating a high energy track for tracking the upper energy envelope of said voice signal; calculating a low energy track for tracking the lower energy envelope of said voice signal; calculating a mid energy track for tracking the average energy envelope of said voice signal, wherein said high energy track, said low energy track and said mid energy track are based on a high biased running mean, a low biased running mean, and a nominally unbiased running mean, respectively; and calculating a value of normalized energy from said high energy track to be provided to a speech recognition system.<br>12) A method of normalizing energy value in a PCM voice signal, said voice signal comprising a plurality of frames, each of said plurality of frames defining a fixed interval of said voice signal, said method comprising the steps of: constructing an observation window whose width defines a current observation interval of said voice signal, said current observation interval encompassing a plurality of digital samples of said voice signal; shifting said observation window discrete shift increments along said PCM voice signal; at each discrete shift increment of the observation window; computing a feature vector from said plurality of encompassed digital samples of said voice signal contained within said observation interval; using said feature vector to compute a high biased running mean, a low biased running mean, and a nominally unbiased running mean; determining whether said current interval is one of a speech interval and a silence interval; based on the determination step, when said interval is a speech interval; computing a gated and smoothed high biased running mean from said high biased running mean; holding a gated and smoothed low bias running mean constant to a value computed at the most recent silence interval; computing an energy normalization value from said gated and smoothed high biased running; and outputting said energy normalization value to a speech recognition system holding a gated and smoothed low bias running mean constant to a value computed at the most recent silence interval; computing an energy normalization value from said gated and smoothed high biased running mean; and outputting said energy normalization value to a speech recognition system.</p></layer>
<layer id = "layer141"><p><b>US5517595A:Decomposition in noise and periodic signal waveforms in waveform interpolation</b><br>A method for determining a property of fluids in formations surrounding an earth borehole includes the following steps: producing, from measurements on a multiplicity of fluid samples, a database of stored fluid property training values related to stored fluid measurement training values; deriving, from the database, radial basis function parameters; deriving formation fluid measurement values; and determining, using radial basis function interpolation, the property of formation fluids from values in the database, the parameters, and the derived formation fluid measurement values.<br><b>Independant Claims</b><br>1. A method of coding a speech signal, the method comprising the steps of: 1. generating a time-ordered sequence of sets of parameters based on samples of the speech signal, each set of parameters corresponding to a waveform characterizing the speech signal; 2. grouping parameters of the plurality of sets based on index values for said parameters to form a first set of signals which set represents an evolution of characterizing waveform shape across the time-ordered sequence of sets; 3. filtering signals of the first set to remove low-frequency components of said signals evolving over time at low frequencies, wherein said filtering produces a second set of signals which second set represents relatively high rates of evolution of characterizing waveform shape; and 4. coding said speech signal based on the second set of signals.<br>19. A method of coding a speech signal, the method comprising the steps of: 1. generating a time-ordered sequence of sets of parameters based on samples of a speech signal, each set of parameters corresponding to a waveform characterizing the speech signal; 2. grouping parameters of the plurality of sets based on index values for said parameters to form a first set of signals which set represents an evolution of characterizing waveform shape across the time-ordered sequence of sets; 3. filtering signals of the first set to remove components of said signals evolving over time at high frequencies, wherein said filtering produces a second set of signals which second set represents relatively low rates of evolution of characterizing waveform shape; and 4. coding said speech signal based on the second set of signals.<br>20. A method of coding a speech signal using a set of fixed codebooks, the speech signal comprising sequential sets of samples of said speech signal, each set of samples specifying the value of said signals at a specific point in time, the method comprising the steps of: coding a first set of samples of the speech signal with a first codebook; and coding a different time-successive set of samples of the speech signal with a codebook other than said first codebook.</p></layer>
<layer id = "layer142"><p><b>US5784532A:Application specific integrated circuit (ASIC) for performing rapid speech compression in a mobile telephone system</b><br><b>Independant Claims</b><br>1. A vocoder comprising: digital signal processing (DSP) core means for performing a recursive convolution computation and for providing a result of said recursive convolution; and minimization processor means separate from said DSP core means for receiving said result of said recursive convolution and performing a minimization search in accordance with said result of said recursive convolution.<br>4. A vocoder comprising: a digital signal processing (DSP) core having an input for receiving a sequence of digitized audio data, the DSP core means generating a corresponding sequence of synthesized versions of the data; and a minimization processor having an input coupled to said DSP core for receiving the sequence of synthesized versions of the data, the minimization processor determining the minimum difference between the synthesized version of the data and the digitized audio data, the minimization processor undertaking its determining function in parallel with the DSP core means undertaking its generating function.<br>8. A logic device for performing method steps for undertaking recursive convolution between a first sequence representative of synthesized speech samples in a mobile telephone system and a second sequence representative of speech samples, the method comprising the steps of: performing an initial convolution; testing if a step index is even; retrieving said first sequence from a first memory element; retrieving said second sequence from a second memory element; retrieving a partial convolution result from a third memory element when said step index is even; performing partial convolution in accordance with said retrieved first sequence, said retrieved second sequence and said retrieved partial convolution result; storing the result of said partial convolution in said second memory element when said step index is odd; and processing the convolution result to minimize the difference between the sequences to render an accurate synthesis of the digitized audio data.<br>10. A device for performing recursive convolution for modeling digitized speech, comprising: a digital signal processor (DSP) core for recursively convolving a plurality of values; and a plurality of random access memories (RAMs) accessible by the DSP core, each RAM for storing a respective value such that the values can be fetched from the RAMs in parallel with each other for processing by the DSP core.<br>16. A minimization processor for receiving a first sequence of speech samples from a digital signal processor (DSP) core and a second sequence of synthesized speech samples from the DSP core for determining a minimum mean squared error (MSE) over the sequences, comprising: logic means for determining an autocorrelation of the second sequence; logic means for determining a cross-correlation between the first sequence and the second sequence; and logic means responsive to the autocorrelation and cross-correlation for determining the minimum MSE in parallel with the DSP core performing recursive convolutions.</p></layer>
<layer id = "layer143"><p><b>US20020099548A1:VARIABLE RATE SPEECH CODING</b><br>A dispensing bucket apparatus that removably connects to a loader vehicle. The apparatus is a bucket that is adapted to receive and hold a flowable material and has an exit opening in its front end that is selectively opened and closed by a gate. The position of the gate may be controlled by the user from within the loader vehicle to control the flow and flow rate of the flowable material from the bucket. The side walls of the bucket converge toward the front of the bucket and form a funnel that directs the flowable material to the exit opening. The construction of the apparatus is such that the user can view the pour at all times and, thereby, reduce spillage and waste. An alternate embodiment includes a tilting mechanism that provides for attachment of the bucket to a forklift and for tilting of the bucket. A removable chute allows the pour opening to be extended further from the front of the bucket.<br><b>Independant Claims</b><br>1. A method for the variable rate coding of a speech signal, comprising the steps of: (a) classifying the speech signal as either active or inactive; (b) classifying said active speech into one of a plurality of types of active speech; (c) selecting a coding mode based on whether the speech signal is active or inactive, and if active, based further on said type of active speech; and (d) encoding the speech signal according to said coding mode, forming an encoded speech signal.<br>19. A variable rate coding system for coding a speech signal, comprising: classification means for classifying the speech signal as active or inactive, and if active, for classifying the active speech as one of a plurality of types of active speech; and a plurality of encoding means for encoding the speech signal as an encoded speech signal, wherein said encoding means are dynamically selected to encode the speech signal based on whether the speech signal is active or inactive, and if active, based further on said type of active speech.</p></layer>
<layer id = "layer144"><p><b>US6463406B1:Fractional pitch method</b><br>In a barrel of a semi-automatic pistol, the barrel having fore and aft barrel locking grooves for locking into corresponding fore and aft slide assembly wall segments formed in a slide mounted on a receiver of the pistol when the barrel is in its lock-up position, the improvement comprising adjustment means for precision-fitting the barrel to the dimensions and tolerances of the slide and the receiver of the pistol. The barrel includes a pair of raised contact pads integrally-formed in laterally-spaced relation in the aft locking groove of the barrel to provide an initial vertical interference fit between the aft locking groove of the barrel and the aft locking wall segment of the slide. The contact pads are adapted for incremental trial-and-error removal until a just-sufficient amount material from one or both of the contact pads has been removed to cause the barrel to move into the proper lock-up position with lock-up pressure transferred onto the top of a slide stop pin on which the barrel is pivotally mounted with the barrel locking grooves intimately engaged with the aft locking wall segment of the slide assembly.<br><b>Independant Claims</b><br>1) A method of pitch period determination for digital speech, comprising the steps of: (a) providing input digital signals at a-first sampling rate having a first sampling period, and selecting a signal as a frame point; (b) determining crosscorrelations of pairs of intervals of length LI of said signals, each of said intervals including said frame point; (c) taking as an integer pitch period, P, the offset of the two intervals of the pair from step (b) with the largest crosscorrelation; (d) determining crosscorrelations of pairs of intervals of length L2 of said signals for intervals with ends adjacent the ends of said two intervals of step (c), wherein said L2 is at least P but less than L1; (e) determining a pitch period adjustment, q, by interpolating the crosscorrelations of step (d) where said q is less than said first sampling period, whereby a pitch period of P+q is determined.</p></layer>
<layer id = "layer145"><p><b>US5715365A:Estimation of excitation parameters</b><br>There is described a process for the production of an ethanol solution of an ethyl or butyl half-ester copolymer of maleic anhydride and a methyl vinyl ether which comprises: (a) copolymerizing the monomers in acetone as solvent by simultaneously feeding molten maleic anhydride, a molar excess of methyl vinyl ether, and a solution of a free radical initiator in acetone, into a reactor precharged with acetone, at about 68.degree.-85.degree. C., preferably 70.degree.-80.degree. C.; (b) esterifying the acetone solution of said copolymer with ethanol or butanol; and then (c) solvent exchanging ethanol for acetone by continuously injecting vapors of ethanol at about 85.degree.-95.degree. C. into said copolymer solution while simultaneously distilling out acetone therefrom at atmospheric pressure.<br><b>Independant Claims</b><br>1. A method of analyzing a digitized speech signal to determine excitation parameters for the digitized speech signal, comprising the steps of: dividing the digitized speech signal into at least two frequency band signals; performing a nonlinear operation on at least one of the frequency band signals to produce at least one modified frequency band signal, wherein the nonlinear operation is an operation that emphasizes a fundamental frequency of the digitized speech signal so that the modified frequency band signal includes a component corresponding to the fundamental frequency even when the at least one frequency band signal does not include such a component; and for at least one modified frequency band signal, determining whether the modified frequency band signal is voiced or unvoiced.<br>29. A method of analyzing a digitized speech signal to determine excitation parameters for the digitized speech signal, comprising the steps of: dividing the digitized speech signal into at least two frequency band signals; performing a nonlinear operation on a first one of the frequency band signals to produce a first modified frequency band signal, wherein the nonlinear operation is an operation that emphasizes a fundamental frequency of the digitized speech signal so that the first modified frequency band signal includes a component corresponding to the fundamental frequency even when the first one of the frequency band signals does not include such a component; combining the first modified frequency band signal and at least one other frequency band signal to produce a combined frequency band signal; and estimating the fundamental frequency of the combined frequency band signal.<br>30. A method of analyzing a digitized speech signal to determine excitation parameters for the digitized speech signal, comprising the steps of: dividing the digitized speech signal into at least two frequency band signals; performing a nonlinear operation on at least one of the frequency band signals to produce at least one modified band signal, wherein the nonlinear operation is an operation that emphasizes a fundamental frequency of the digitized speech signal so that the modified frequency band signal includes a component corresponding to the fundamental frequency even when the at least one of the frequency band signals does not include such a component; and estimating the fundamental frequency from at least one modified band signal.<br>31. A method of analyzing a digitized speech signal to determine the fundamental frequency for the digitized speech signal, comprising the steps of: dividing the digitized speech signal into at least two frequency band signals; performing a nonlinear operation on at least two of the frequency band signals to produce at least two modified frequency band signals, wherein the nonlinear operation is an operation that emphasizes a fundamental frequency of the digitized speech signal so that the modified frequency band signals include a component corresponding to the fundamental frequency even when the corresponding frequency band signal does not include such a component; combining the at least two modified frequency band signals to produce a combined signal; and estimating the fundamental frequency of the combined signal.<br>32. A system for encoding speech by analyzing a digitized speech signal to determine excitation parameters for the digitized speech signal, comprising: means for dividing the digitized speech signal into at least two frequency band signals; means for performing a nonlinear operation on at least one of the frequency band signals to produce at least one modified frequency band signal, wherein the nonlinear operation is an operation that emphasizes a fundamental frequency of the digitized speech signal so that the modified frequency band signal includes a component corresponding to the fundamental frequency even when the at least one frequency band signal does not include such a component; and means for determining, for at least one modified frequency band signal, whether the modified frequency band signal is voiced or unvoiced.</p></layer>
<layer id = "layer146"><p><b>US6311154B1:Adaptive windows for analysis-by-synthesis CELP-type speech coding</b><br>A wireless communication terminal (<b>10</b>) having a plurality of radio receiver branches (<b>11</b><i>a</i>-<i>c</i>) all ordinarily for use in receiving a downlink frequency from a radio access network (<b>15</b>), but configured to intermittently tune one or another of the branches (<b>11</b><i>a</i>-<i>c</i>) to a non-downlink frequency (causing reduced receiver performance in receiving the downlink frequency), but doing so only when expected by the radio access network (<b>15</b>) (or other entity of a wireless communication network with which the wireless communication terminal is in wireless communication).<br><b>Independant Claims</b><br>1) A method for coding a speech signal, comprising steps of: partitioning samples of the speech signal into frames; classifying the speech signal in each frame into one of a plurality of classes, wherein the step of classifying classifies a frame as being one of an unvoiced frame or a not unvoiced frame and classifies said not unvoiced frame as being one of a voiced frame or a transition frame; determining the location of at least one window in the frame; and encoding an excitation for the frame, whereby all or substantially all of non-zero excitation amplitudes lie within the at least one window.<br>5) A method for coding a speech signal, comprising the steps of: partitioning samples of the speech signal into frames; classifying the speech signal in each frame into one of a plurality of classes, wherein the step of classifying classifies a frame as being one of an unvoiced frame or a not unvoiced frame and classifies said not unvoiced frame as being one of a voiced frame or a transition frame; deriving a residual signal for each frame; determining a location of at least one window, whose center lies within the frame, by considering the residual signal for the frame; and encoding an excitation for the frame whereby all or substantially all of non-zero excitation amplitudes lie within the at least one window.<br>8) A method for coding a speech signal, comprising steps of: partitioning samples of the speech signal into frames; deriving a residual signal for each frame; classifying the speech signal in each frame into one of a plurality of classes, wherein the step of classifying classifies a frame as being one of an unvoiced frame or a not unvoiced frame and classifies said not unvoiced frame as being one of a voiced frame or a transition frame; identifying the location of at least one window in the frame by examining the residual signal for the frame; encoding an excitation for the frame using one of a plurality of excitation coding techniques selected according to the class of the frame; and for at least one of the classes, confining all or substantially all of non-zero excitation amplitudes to lie within the windows.<br>19) A method for coding a speech signal, comprising steps of: partitioning samples of the speech signal into frames; classifying the speech signal in each frame into one of a plurality of classes, wherein the step of classifying classifies a frame as being one of an unvoiced frame or a not unvoiced frame and classifies said not unvoiced frame as being one of a voiced frame or a transition frame; modifying the duration and boundaries of a frame or a subframe by considering the speech or residual signal for the frame; and encoding an excitation for the frame using an analysis-by-synthesis coding technique.<br>21) Apparatus for coding speech, comprising: a framing unit for partitioning samples of an input speech signal into frames; a first classifier for classifying a frame as being one of an unvoiced frame or a not unvoiced frame and a second classifier for classifying said not unvoiced frame as being one of a voiced frame or a transition frame; a windowing unit for determining the location of at least one window in a frame; and an encoder for encoding an excitation for the frame such that all or substantially all of non-zero excitation amplitudes lie within the at least one window.<br>25) A wireless voice communicator, comprising; a wireless transceiver comprising a transmitter and a receiver; an input speech transducer and an output speech transducer; and a speech processor comprising, a sampling and framing unit having an input coupled to an output of said input speech transducer for partitioning samples of an input speech signal into frames; a first classifier for classifying a frame as being one of an unvoiced frame or a not unvoiced frame and a second classifier for classifying said not unvoiced frame as being one or a voiced frame or a transition frame; a windowing unit for determining the location of at least one window in a frame; and an encoder for providing an encoded speech signal where, in an excitation for the frame, all or substantially all of non-zero excitation amplitudes lie within the at least one window; said wireless communicator further comprising a modulator for modulating a carrier with the encoded speech signal, said modulator having an output coupled to an input of said transmitter; a demodulator having an input coupled to an output of said receiver for demodulating a carrier that is encoded with a speech signal and that was transmitted from a remote transmitter; and said speech processor further comprising a decoder having an input coupled to an output of said demodulator for decoding an excitation from a frame wherein all or substantially all of non-zero excitation amolitudes lie within at least one window, said decoder having an output coupled to an input of said output speech transducer.<br>34) A speech decoder, comprising: a class decoder having an input coupled to an input node of said speech decoder for extracting from an input bit stream predetermined ones of bits encoding class information for an encoded speech signal frame and for decoding the class information, wherein there are a plurality of predetermined classes; said plurality of predetermined classes comprises a voiced class, an unvoiced class and a transition class; and wherein said input bit stream is also coupled to an input of a LSP decoder; a first multi-position switch element controlled by an output of said class decoder for directing said input bit stream to an input of one of selected one of a plurality of excitation generators, an individual one of said excitation generators corresponding to one of said plurality of predetermined classes; a second multi-position switch element controlled by said output of said class decoder for coupling an output of the selected one of said excitation generators to an input of a synthesizer filter and, via a feedback path, also to said adaptive code book; an unvoiced class excitation generator and a transition class excitation generator coupled between said first and second multi-position switch elements; wherein for said transition class, at least one window position is decoded in a window decoder having an input coupled to said input bit stream; and wherein a codebook vector is retrieved from a transition excitation fixed codebook using information concerning the at least one window location output from said window decoder and by multiplying a retrieved codebook vector; and wherein for said voiced class, the input bit stream encodes pitch information for the encoded speech signal frame which is decoded in a pitch decoder block having an output coupled to a window generator block that generates at least one window based on the decoded pitch information, said at least one window being used to retrieve, from an adaptive code book, an adaptive code book vector used for generating an excitation vector which is multiplied by a gain element and added to an adaptive codebook excitation to give a total excitation for a voiced frame.</p></layer>
<layer id = "layer147"><p><b>US6304843B1:Method and apparatus for reconstructing a linear prediction filter excitation signal</b><br>The present invention is directed to a process for preparing a catalyst which comprises combining catalyst components or precursors thereof in an aqueous medium to form a catalyst precursor mixture, feeding the mixture to a shaping apparatus, and shaping the mixture to form particles wherein just before the shaping step the mixture is destabilized. It was found that with this process catalysts can be prepared which have both a good attrition resistance and a high accessibility. The invention further relates to catalysts obtainable by this process.<br><b>Independant Claims</b><br>1) An apparatus for reconstructing a linear prediction synthesis filter excitation signal, the apparatus comprising: means for receiving parameters representative of a signal's magnitude and phase spectrum, and for producing therefrom a deterministic signal comprising a magnitude spectrum and a phase spectrum; and means for receiving the deterministic signal and a noise signal and for reconstructing therefrom the linear prediction synthesis filter excitation signal, wherein the phase spectrum is derived substantially from the formula: φE(ω)=−tan−1(αsin ω/1−αcos ω)−tan−1(γsin ω/1−γcos ω)+2 tan−1(sin ω/β−cos ω) where φE (ω) represents the phase at frequency ω, α is a predetermined constant, γ represents a desired degree of spectral tilting, and β is substantially equal to the mean average of α and γ.<br>6) A method for reconstructing a linear prediction synthesis filter excitation signal, the method comprising the steps of: receiving parameters representative of a signal's magnitude and phase spectrum, and producing therefrom a deterministic signal including a magnitude spectrum and a phase spectrum; and receiving the deterministic signal and a noise signal and reconstructing therefrom the linear prediction synthesis filter excitation signal, wherein the phase spectrum is derived substantially from the formula: φE(ω)=−tan−1(αsin ω/1−αcos ω)−tan−1(γsin ω/1−γcos ω)+2 tan−1(sin ω/β−cos ω) where φE (ω) represents the phase at frequency ω, α is a predetermined constant, γ represents a desired degree of spectral tilting, and β is substantially equal to the mean average of α and γ.</p></layer>
<layer id = "layer148"><p><b>US20040128130A1:Perceptual harmonic cepstral coefficients as the front-end for speech recognition</b><br>A hydraulic steering arrangement with a steering handwheel, which is connected with a hydraulic steering unit, and a steering motor, which is connected with a pump via a steering valve. In a steering arrangement of this kind an improvement of the steering comfort is desired. For this purpose, a supply line is located between the steering unit and the pump, and a pressure reduction valve is located in the supply line.<br><b>Independant Claims</b><br>1. A speech recognition method using a perceptual harmonic cepstral coefficient comprising: a) processing a speech frame whereby to obtain a short-term power spectrum; b) performing a robust pitch estimation; c) using a peak-picking formula whereby to obtain a pitch harmonic; d) applying class-dependent harmonic weighting whereby to obtain the harmonics weighted spectrum; e) applying a mel-scaled filter to the harmonics weighted spectrum; and f) computing the log energy output which is transformed into cepstrum by the discrete cosine transform.<br>10. A speech recognition method using a harmonic weighing function in accordance with the formula: 15wh⁡(ω)={max⁡(1,ⅇ(Ha-η)&CenterDot;γ),if⁢ ⁢ω≤ωT⁢ ⁢is⁢ ⁢pitchharmonic1,otherwise⁢  wherein 16Ha=maxτ⁢ ⁢R⁡(τ) is the harmonic confidence, μa7 is the harmonic confidence threshold, γ is the weight factor, R(τ) is the spectro-temporal autocorrelation criterion, and ωT is the cut-off frequency.<br>12. A speech recognition method using a harmonic weighing function in accordance with the formula: 17wh⁡(ω)={max⁡(1,ⅇ(Ha-η)&CenterDot;γ),if⁢ ⁢ω≤ωT⁢ ⁢is⁢ ⁢pitchharmonic1,otherwise⁢  wherein 18Ha=maxτ⁢ ⁢R⁡(τ) is the harmonic confidence, μa7 is the harmonic confidence threshold, γ is the weight factor, R(τ) is the spectro-temporal autocorrelation criterion, and ωT is the cut-off frequency.</p></layer>
<layer id = "layer149"><p><b>US6223151B1:Method and apparatus for pre-processing speech signals prior to coding by transform-based speech coders</b><br>A dressing blade for finishing and reconditioning new and used abrasive grinding and cutting tools has a slab-shaped shank with an extension protruding longitudinally from the shank. Superabrasive grains are disposed on the surface of the extension and held in place by a brazed metal composition. This composition is formed by brazing a powdered mixture of brazing metal components and active metal components. Specific extension configurations are provided which allow aligning the superabrasive grains in single layer arrangement for precise dressing and simple fabrication of the tool. The novel dressing tool exhibits excellent wear characteristics.<br><b>Independant Claims</b><br>1) A method for pre-processing speech signals comprising the steps of: computing a first pitch period track; determining cycle markers and corresponding pitch periods based on the first pitch period track; computing a first set of refined cycles; determining if a second set of refined cycles is necessary; computing a second set of refined cycles if determined to be necessary; concatenating the first set of refined cycles; concatenating the second set of refined cycles if computed, and thereafter combining the first set of concatenated refined cycles with the second set of concatenated refined cycles.<br>16) A method of pre-processing a speech signal to be input to a speech coding apparatus, comprising: receiving the speech signal; producing in response to the received speech signal a modified speech signal and a plurality of markers respectively indicative of relatively low signal energy points in the modified speech signal, including outputting the modified speech signal from a speech synthesis filter; and providing the modified speech signal and the plurality of markers to a speech coding apparatus that can produce therefrom encoded information from which a speech decoding apparatus can reconstruct the modified speech signal.<br>20) An apparatus for pre-processing speech signals comprising: a pitch period processor for computing a first pitch period track; a cycle marker processor for determining cycle markers and corresponding pitch periods based on the first pitch period track; a first refined cycle computer for computing a first set of refined cycles; a second refined cycle computer for computing a second set of refined cycles; a first concatenator for concatenating the first set of refined cycles; a second concatenator for concatenating the second set of refined cycles; a mixer for combining the first set of concatenated refined cycles with the second set of concatenated refined cycles to generate a combined output; and a linear-prediction synthesis filter for performing linear-prediction filtering on the combined output.<br>22) An apparatus for pre-processing a speech signal to be input to a speech coding apparatus, comprising: an input for receiving a speech signal; a speech pre-processor coupled to said input and responsive to said received speech signal for producing a modified speech signal and a plurality of markers respectively indicative of relatively low signal energy points in said modified speech signal, said speech pre-processor including a speech synthesis filter for producing the modified speech signal; and an output coupled to said speech pre-processor for providing said modified speech signal and said plurality of markers to a speech coding apparatus that can produce therefrom encoded information from which a speech decoding apparatus can reconstruct the modified speech signal.</p></layer>
<layer id = "layer150"><p><b>US6381570B2:Adaptive two-threshold method for discriminating noise from speech in a communication signal</b><br>A cyclopropane-1,1-dicarboxylic acid compound is prepared by reacting a malonic acid compound and a 1,2-dihalogeno compound with an alcoholate as a condensation agent which is gradually added to a mixture of said malonic acid compound and said 1,2-chloro compound as a solution or suspension is an alcohol.<br><b>Independant Claims</b><br>1) A method of discriminating noise and voice energy in a communication signal, comprising the steps of: for a plurality of block periods: sampling said signal a number of times to obtain sample values; calculating a block energy value for said signal by summing the squares of said sample values from said number of samples; and for an update period equal to a sum of said plurality of block periods: assigning a maximum block energy value calculated during said update period to a variable Emax; assigning a minimum block energy value calculated during said update period to a variable Emin; calculating a noise energy threshold value based on the relative values of Emax and Emin, wherein between a first upper bound and a first lower bound said noise energy threshold may assume a continuum of values; calculating a voice energy threshold value based on the relative values of Emax and Emin, wherein between a second upper bound and a second lower bound said voice energy threshold may assume a continuum of values; and updating said noise energy threshold and said voice energy threshold in accordance with said calculations for their respective values; said voice energy estimation value Evoice is updated according to the formula: Evoice, n=(1-αvoice)*Evoice,n−1+αvoice*En, where Evoice, n  is said voice energy estimation value for said current block period, αvoice is a voice time constant, Evoice, n−1 is said voice energy estimation value for an immediately preceding voice block period, and En is said current block energy; and said noise energy estimation value Enoise is updated according to the formula: Enoise, n=(1-αnoise)*Enoise,n−1+α-noise*En, where Enoise,n </p></layer>
<layer id = "layer151"><p><b>US20020123887A1:Concealment of frame erasures and method</b><br>An image forming apparatus having a timer function includes a main switch for manually switching between supply and interruption of electric power to the apparatus, a detector for detecting whether the main switch is in a power-interruption state or in a power-supply state, a memory for storing a state indicating that the main switch is in a power-interruption state when it has been detected that the main switch is in a power-interruption state, a controller for placing the apparatus in a standby state in which an image can be formed or in a shutdown state in which an image cannot be formed during a preset time period, and a power supply for supplying power to the controller, wherein the apparatus is placed in a standby state even by a set shutdown time period in the case a power-interruption state is stored and wherein the apparatus is placed in a shutdown state during the set shutdown time period in the case the power-interruption state is not stored.<br><b>Independant Claims</b><br>1. A method for decoding code-excited linear prediction signals, comprising: (a) forming an excitation for an erased interval of encoded code-excited linear prediction signals by a weighted sum of (i) an adaptive codebook contribution and (ii) a fixed codebook contribution, wherein said adaptive codebook contribution derives from an excitation and pitch and first gain of one or more intervals prior to said erased interval and said fixed codebook contribution derives from a second gain of at least one of said prior intervals; (b) wherein said weighted sum has sets of weights depending upon a periodicity classification of at least one prior interval of encoded signals, said periodicity classification with at least three classes; and (c) filtering said excitation.<br>3. A method for decoding code-excited linear prediction signals, comprising: (a) forming a reconstruction for an erased interval of encoded code-excited linear prediction signals by use parameters of one or more intervals prior to said erased interval; (b) preliminarily decoding a second interval subsequent to said erased interval; (c) combining the results of step (b) with said parameters of step (a) to form a reestimation of parameters for said erased interval; and (d) using the results of step (c) as part of an excitation for said second interval.<br>5. A decoder for CELP encoded signals, comprising: (a) a fixed codebook vector decoder; (b) a fixed codebook gain decoder; (c) an adaptive codebook gain decoder; (d) an adaptive codebook pitch delay decoder; (e) an excitation generator coupled to said decoders; and (f) a synthesis filter; (g) wherein when a received frame is erased, said decoders generate substitute outputs, said excitation generator generates a substitute excitation, said synthesis filter generates substitute filter coefficients, and said excitation generator uses a weighted sum of (i) an adaptive codebook contribution and (ii) a fixed codebook contribution with said weighted sum uses sets of weights depending upon a periodicity classification of at least one prior frame, said periodicity classification with at least three classes;<br>6. A decoder for CELP encoded signals, comprising: (a) a fixed codebook vector decoder; (b) a fixed codebook gain decoder; (c) an adaptive codebook gain decoder; (d) an adaptive codebook pitch delay decoder; (e) an excitation generator coupled to said decoders; and (f) a synthesis filter; (g) wherein when a received frame is erased, said decoders generate substitute outputs, said excitation generator generates a substitute excitation, said synthesis filter generates substitute filter coefficients, and when a second frame is received after said erased frame, said excitation generator combines parameters of said second frame with said substitute outputs to reestimate said substitute outputs to form an excitation for said second frame.</p></layer>
<layer id = "layer152"><p><b>US5787387A:Harmonic adaptive speech coding method and system</b><br>A method for enhanced detection and statistical analysis of differentially expressed genes in gene chip microarrays employs: (a) transformation of gene expression data into an expression data matrix (image data paradigm); (b) wavelet denoising of expression data matrix values to enhance their signal-to-noise ratio; and (c) singular value decomposition (SVD) of the wavelet-denoised expression data matrix to concentrate most of the gene expression signal in primary matrix eigenarrays to enhance the separation of true gene expression values from background noise. The transformation of gene chip data into an image data paradigm facilitates the use of powerful image data processing techniques, including a generalized logarithm (g-log) function to stabilize variance over intensity, and the WSVD combination of wavelet packet transform and denoising and SVD to clearly enhance separation of the truly changed genes from background noise. Detection performance can be assessed using a true false discovery rate (tFDR) computed for simulated gene expression data, and comparing it to estimated FDR (eFDR) rates based on permutations of the available data. Where a small number (N) of samples in a group is involved, a pair of specific WSVD algorithms are employed complementarily if N>5 and if N<6.<br><b>Independant Claims</b><br>1. A method for processing an audio signal comprising the steps of: dividing the signal into segments, each segment representing one of a succession of time intervals; detecting for each segment the presence of a fundamental frequency; if such a fundamental frequency is detected, estimating the amplitudes of a set of sinusoids harmonically related to the detected fundamental frequency, the set of sinusoids being representative of the signal in the time segment; and encoding for subsequent storage and transmission the set of the estimated harmonic amplitudes, each amplitude being normalized by the sum of all amplitudes.<br>16. A method for synthesizing audio signals from data packets, at least one of the data packets representing a time segment of a signal characterized by the presence of a fundamental frequency, said at least one data packet comprising a sequence of encoded amplitudes of harmonic frequencies related to the fundamental frequency, the method comprising the steps of: for each data packet detecting the presence of a fundamental frequency; and synthesizing an audio signal in response only to the detected fundamental frequency and the sequence of amplitudes of harmonic frequencies in said at least one data packet.<br>27. A system for processing audio signals comprising: means for dividing an audio signal into segments, each segment representing one of a succession of time intervals; means for detecting for each segment the presence of a fundamental frequency; means for estimating the amplitudes of a set of sinusoids harmonically related to the detected fundamental frequency, the set of sinusoids being representative of the signal in the time segment; and means for encoding the set of harmonic amplitudes, each amplitude being normalized by the sum of all amplitudes.<br>38. A system for synthesizing audio signals from data packets, at least one of the data packets representing a time segment of a signal characterized by the presence of a fundamental frequency, said at least one data packet comprising a sequence of encoded amplitudes of harmonic frequencies related to the fundamental frequency, the system comprising: means for determining the fundamental frequency of the signal represented by said at least one data packet; means for synthesizing an audio signal segment in response to the determined fundamental frequency and the sequence of amplitudes of harmonic frequencies in said at least one data packet; and means for providing amplitude and phase continuity on the boundary between adjacent synthesized audio signal segments.<br>44. A system for synthesizing speech from data packets, the data packets representing voiced or unvoiced speech segments, comprising: means for determining whether a data packet represents a voiced or unvoiced speech segment; means for synthesizing unvoiced speech in response to encoded information in an unvoiced data packet; means for synthesizing voiced speech segment signal in response only to a sequence of amplitudes of harmonic frequencies encoded in a voiced data packet; and means for providing amplitude and phase continuity on the boundary between adjacent synthesized speech segments.<br>48. A method for processing an audio signal comprising the steps of: dividing the signal into segments, each segment representing one of a succession of time intervals; detecting for each segment the presence of a fundamental frequency; if such a fundamental frequency is detected, estimating the amplitudes of a set of sinusoids harmonically related to the detected fundamental frequency, the set of sinusoids being representative of the signal in the time segment; encoding for subsequent storage and transmission the set of the estimated harmonic amplitudes, each amplitude being normalized by the sum of all amplitudes; and synthesizing an audio signal in response only to the fundamental frequency and the sequence of normalized amplitudes of harmonic frequencies.</p></layer>
<layer id = "layer153"><p><b>US5544250A:Noise suppression system and method therefor</b><br>In a photo-sensitive recording medium cartridge comprising a housing and a photo-sensitive recording medium accommodated therein, information is provided on an outer surface of a peripheral wall of the housing. The information contains data capable of being automatically read out. The data is representative of exposure, developing and fixing conditions of the recording medium. An image recording apparatus comprises a reader unit for reading out the data contained in the information to generate signals respectively indicative of the exposure, developing and fixing conditions, and a control unit operative in response to the signals for controlling an exposure unit, a developing unit and a fixing unit.<br><b>Independant Claims</b><br>1. A noise suppression system comprising: a signal estimator, operatively coupled to receive an input signal, for producing a noise energy estimate of the input signal and a signal to noise ratio (SNR) estimate of the input signal; a signal gain calculator, operatively coupled to the signal estimator, for calculating a gain value for the input signal according to a first function responsive to the noise energy estimate and the SNR estimate until the SNR estimate reaches a first predetermined SNR threshold, then calculating the gain value for the input signal according to a second function responsive to the noise energy estimate and the SNR estimate until the SNR estimate reaches a second predetermined SNR threshold below the first predetermined SNR threshold; and a signal level adjuster, operatively coupled to the signal gain calculator, for adjusting the level of the input signal responsive to the gain value to produce an adjusted signal having suppressed noise.<br>9. A noise suppression system comprising: a signal estimator, operatively coupled to receive an input signal, for producing a noise energy estimate of the input signal and a signal to noise ratio (SNR) estimate of the input signal; a signal gain calculator, operatively coupled to the signal estimator, for calculating a constant gain value for the input signal according to a first function responsive to the noise energy estimate and the SNR estimate until the SNR estimate reaches a first predetermined SNR threshold, then calculating a variable gain value for the input signal according to a second function responsive to the noise energy estimate and the SNR estimate until the SNR estimate reaches a second predetermined SNR threshold below the first predetermined SNR threshold, wherein the constant gain value calculated according to the first function is less than the variable gain value calculated according to the second function when the SNR estimate is between the first predetermined SNR threshold and the second predetermined SNR threshold; and a signal level adjuster, operatively coupled to the signal gain calculator, for adjusting the level of the input signal to produce an adjusted signal having suppressed noise responsive to either the constant gain value or the variable gain value.<br>14. A noise suppression system comprising: a signal divider, operatively coupled to receive the input signal, for dividing an input signal to produce a plurality of divided signals corresponding to a plurality of frequency bands; a signal estimator, operatively coupled to the signal divider, for producing a plurality of noise energy estimates corresponding to the plurality of divided signals and a plurality of SNR estimates corresponding to the plurality of divided signals; a signal gain calculator, operatively coupled to the signal estimator, for calculating a plurality of constant gain values corresponding to the plurality of divided signals according to a first function responsive to the plurality of noise energy estimates, respectively, and the plurality of SNR estimates, respectively, until the plurality of SNR estimates, respectively, reach a first predetermined SNR threshold, then calculating a plurality of variable gain values corresponding to the plurality of divided signals according to a second function responsive to the plurality of noise energy estimates, respectively, and the plurality of SNR estimates, respectively, until the plurality of SNR estimates, respectively, reach a second predetermined SNR threshold below the first predetermined SNR threshold, wherein the plurality of constant gain values calculated according to the first function are less than the plurality of variable gain values calculated according to the second function, respectively, when the plurality of SNR estimates, respectively, are between the first predetermined SNR threshold and the second predetermined SNR threshold; a signal level adjuster, operatively coupled to the signal gain calculator, for adjusting the level of the plurality of divided signals to produce a plurality of adjusted signals, respectively, responsive to either the plurality of constant gain values, respectively, or the plurality of variable gain values, respectively; and a signal combiner, operatively coupled to the signal divider and the signal level adjuster, for combining the plurality of adjusted signals to produce an output signal having suppressed noise.<br>17. A noise suppression system comprising: a signal divider, operatively coupled to receive an input signal, for dividing the input signal to produce a plurality of divided signals corresponding to a plurality of frequency bands; an energy estimator, operatively coupled to the signal divider, for producing a plurality of energy estimates corresponding to the plurality of divided signals; a noise energy estimator, operatively coupled to the signal divider, for producing a plurality of noise energy estimates corresponding to the plurality of divided signals; and a signal to noise ratio (SNR) estimator, operatively coupled to the energy estimator and the noise energy estimator, for producing a plurality of SNR estimates corresponding to the plurality of divided signals responsive to the plurality of energy estimates, respectively, and the plurality of noise energy estimates, respectively; a signal gain calculator, operatively coupled to the signal estimator, for calculating a plurality of constant gain values corresponding to the plurality of divided signals according to a first function responsive to the plurality of noise energy estimates, respectively, and the plurality of SNR estimates, respectively, until the plurality of SNR estimates, respectively, reach a first predetermined SNR threshold, then calculating a plurality of variable gain values corresponding to the plurality of divided signals according to a second function responsive to the plurality of noise energy estimates, respectively, and the plurality of SNR estimates, respectively, until the plurality of SNR estimates, respectively, reach a second predetermined SNR threshold below the first predetermined SNR threshold, then calculating the plurality of constant gain values according to the first function responsive to the plurality of the noise energy estimates, respectively, and the plurality of the SNR estimates, respectively, when the plurality of the SNR estimates, respectively, reach the second predetermined SNR threshold, wherein the plurality of constant gain values calculated according to the first function are less than the plurality of variable gain values calculated according to the second function, respectively, when the plurality of SNR estimates, respectively, are between the first predetermined SNR threshold and the second predetermined SNR threshold; a signal level adjuster, operatively coupled to the signal gain calculator, for adjusting the level of the plurality of divided signals to produce a plurality of adjusted signals, respectively, responsive to either the plurality of constant gain values, respectively, or the plurality of variable gain values, respectively; and a signal combiner, operatively coupled to the signal divider and the signal level adjuster, for combining the plurality of adjusted signals to produce an output signal having suppressed noise.<br>18. A method for suppressing noise in a noise suppression system comprising the steps of: producing a noise energy estimate of the input signal and a signal to noise ratio (SNR) estimate of the input signal; calculating a gain value for the input signal according to a first function responsive to the noise energy estimate and the SNR estimate until the SNR estimate reaches a first predetermined SNR threshold, then calculating the gain value for the input signal according to a second function responsive to the noise energy estimate and the SNR estimate until the SNR estimate reaches a second predetermined SNR threshold below the first predetermined SNR threshold; and adjusting the level of the input signal responsive to the gain value to produce an adjusted signal having suppressed noise.<br>26. A method for suppressing noise in a noise suppression system comprising the steps of: producing a noise energy estimate of an input signal and a signal to noise ratio (SNR) estimate of the input signal; calculating a constant gain value for the input signal according to a first function responsive to the noise energy estimate and the SNR estimate until the SNR estimate reaches a first predetermined SNR threshold, then calculating a variable gain value for the input signal according to a second function responsive to the noise energy estimate and the SNR estimate until the SNR estimate reaches a second predetermined SNR threshold below the first predetermined SNR threshold, wherein the constant gain value calculated according to the first function is less than the variable gain value calculated according to the second function when the SNR estimate is between the first predetermined SNR threshold and the second predetermined SNR threshold; and adjusting the level of the input signal to produce an adjusted signal having suppressed noise responsive to either the constant gain value or the variable gain value.<br>31. A method for suppressing noise in a noise suppression system comprising the steps of: dividing an input signal to produce a plurality of divided signals corresponding to a plurality of frequency bands; producing a plurality of noise energy estimates corresponding to the plurality of divided signals and a plurality of SNR estimates corresponding to the plurality of divided signals; calculating a plurality of constant gain values corresponding to the plurality of divided signals according to a first function responsive to the plurality of noise energy estimates, respectively, and the plurality of SNR estimates, respectively, until the plurality of SNR estimates, respectively, reach a first predetermined SNR threshold, then calculating a plurality of variable gain values corresponding to the plurality of divided signals according to a second function responsive to the plurality of noise energy estimates, respectively, and the plurality of SNR estimates, respectively, until the plurality of SNR estimates, respectively, reach a second predetermined SNR threshold below the first predetermined SNR threshold, wherein the plurality of constant gain values calculated according to the first function are less than the plurality of variable gain values calculated according to the second function, respectively, when the plurality of SNR estimates, respectively, are between the first predetermined SNR threshold and the second predetermined SNR threshold; adjusting the level of the plurality of divided signals to produce a plurality of adjusted signals, respectively, responsive to either the plurality of constant gain values, respectively, or the plurality of variable gain values, respectively; and combining the plurality of adjusted signals to produce an output signal having suppressed noise.<br>34. A method for suppressing noise in a noise suppression system comprising the steps of: dividing an input signal to produce a plurality of divided signals corresponding to a plurality of frequency bands; producing a plurality of energy estimates corresponding to the plurality of divided signals; producing a plurality of noise energy estimates corresponding to the plurality of divided signals; producing a plurality of signal to noise ratio (SNR) estimates corresponding to the plurality of divided signals responsive to the plurality of energy estimates, respectively, and the plurality of noise energy estimates, respectively; calculating a plurality of constant gain values corresponding to the plurality of divided signals according to a first function responsive to the plurality of noise energy estimates, respectively, and the plurality of SNR estimates, respectively, until the plurality of SNR estimates, respectively, reach a first predetermined SNR threshold, then calculating a plurality of variable gain values corresponding to the plurality of divided signals according to a second function responsive to the plurality of noise energy estimates, respectively, and the plurality of SNR estimates, respectively, until the plurality of SNR estimates, respectively, reach a second predetermined SNR threshold below the first predetermined SNR threshold, then calculating the plurality of constant gain values according to the first function responsive to the plurality of the noise energy estimates, respectively, and the plurality of the SNR estimates, respectively, when the plurality of the SNR estimates, respectively, reach the second predetermined SNR threshold, wherein the plurality of constant gain values calculated according to the first function are less than the plurality of variable gain values calculated according to the second function, respectively, when the plurality of SNR estimates, respectively, are between the first predetermined SNR threshold and the second predetermined SNR threshold; adjusting the level of the plurality of divided signals to produce a plurality of adjusted signals, respectively, responsive to either the plurality of constant gain values, respectively, or the plurality of variable gain values, respectively; and combining the plurality of adjusted signals to produce an output signal having suppressed noise.</p></layer>
<layer id = "layer154"><p><b>US6496797B1:Apparatus and method of speech coding and decoding using multiple frames</b><br>A preferred novel breaker-crosslinker-polymer complex and a method for using the complex in a fracturing fluid to fracture a subterranean formation that surrounds a well bore by pumping the fluid to a desired location within the well bore under sufficient pressure to fracture the surrounding subterranean formation. The complex may be maintained in a substantially non-reactive state by maintaining specific conditions of pH and temperature, until a time at which the fluid is in place in the well bore and the desired fracture is completed. Once the fracture is completed, the specific conditions at which the complex is inactive are no longer maintained. When the conditions change sufficiently, the complex becomes active and the breaker begins to catalyze polymer degradation causing the fracturing fluid to become sufficiently fluid to be pumped from the subterranean formation to the well surface.<br><b>Independant Claims</b><br>1) An Analysis by Synthesis method for determining the spectral envelope information in speech coding systems based. on synthesizing a synthetic digital speech signal from a data structure produced by dividing an initial speech signal into a plurality of frames, determining a pitch frequency, determining voicing information, representing whether each of a plurality of frequency bands of each frame should be synthesized as voiced or unvoiced frequency bands, and processing the frames to determine spectral envelope information representative of the magnitudes of a spectrum in the frequency bands, wherein the method of determining the spectral envelope information comprises the steps of: a) forming a model set of the spectral magnitudes by assigning fixed values; b) synthesizing a model speech signal for the model set of the spectral magnitudes using both pitch frequencies and a set of voicing decisions determined for previous and current frames; c) calculating a spectrum of the model speech signal; d) approximating a spectrum of the initial speech signal by the spectrum of the model speech signal; and e) encoding coefficients obtained from the approximated spectrum.<br>7) A hybrid method for spectral magnitudes encoding of each speech frame, comprising the steps of: a) reducing a number of spectral magnitudes; b) using different types of encoding schemes for simultaneously encoding the spectral magnitudes; c) evaluating the encoding schemes; and d) selecting from the evaluated encoding schemes the best encoding scheme for spectral magnitudes encoding as a base scheme.<br>10) A method for synthesizing a synthetic digital speech signal from a data structure produced by dividing an initial speech signal into a plurality of frames, determining a pitch frequency, determining voicing information, representing whether each of a plurality of frequency bands of each frame should be synthesized as voiced or unvoiced frequency bands, and processing the frames to determine spectral envelope information representative of the magnitudes of a spectrum in the frequency bands, wherein the method for synthesizing the synthetic digital speech signal comprises the steps of: a) building a frequency correspondence between bands of current and previous frames; b) synthesizing speech components for the voiced frequency bands for couples of harmonics with the closest frequencies in the current and previous frames utilizing the built bands' frequency correspondence and lacing the coupled harmonics, wherein all uncoupled harmonics of the previous frame are smoothly decreased down to zero amplitude and wherein all uncoupled harmonics of the current frame are smoothly increased up to their own amplitudes; c) synthesizing speech components for the unvoiced frequency bands; and d) synthesizing the synthetic digital speech signal by combining the synthesized speech components for the voiced and the unvoiced frequency bands.<br>12) A system for speech signal coding and decoding, comprising a speech signal coder and a speech signal decoder, wherein the speech signal coder comprises: a processor dividing an input digital speech signal into a plurality of frames to be analyzed in time and frequency domains; an orthogonal transforming unit transforming each frame to provide spectral data on the frequency axis; a pitch determination unit determinating a pitch frequency for each frame; a voiced/unvoiced discrimination unit generating group voiced/unvoiced decisions utilizing the determined pitch frequencies; a spectral magnitudes determination unit estimating spectral magnitudes by utilizing an Analysis by Synthesis method; and a parameter encoding unit encoding the determined pitch frequency, the estimated spectral magnitude and the voiced/unvoiced decisions for each of the plurality of frames, and combining encoded data into a plurality of bits; and wherein the speech signal decoder comprises: a parameters decoding unit decoding the plurality of bits to provide the pitch frequency, spectral magnitudes and voiced/unvoiced decisions for each of the plurality of frames; a bands' frequency correspondence map building unit building a bands' frequency correspondence map between bands of current and previous frames; and a signal synthesizing unit synthesizing a speech signal from the pitch frequency, spectral magnitudes and voiced/unvoiced decision, and utilizing the bands' frequency correspondence map.</p></layer>
<layer id = "layer155"><p><b>US20010018650A1:Method and apparatus for performing speech frame encoding mode selection in a variable rate encoding system</b><br><b>Independant Claims</b><br>1. An apparatus for selecting an encoding rate from a predetermined set of encoding rates and for encoding a frame of speech including a plurality of speech samples, comprising: means, responsive to said speech samples and to at least one signal derived from said speech samples, for generating a set of parameters indicative of characteristics of said frame of speech; and means for receiving said set of parameters, for determining the psychoacoustic significance of said speech samples in accordance with said set of parameters, and for selecting an encoding rate from said predetermined set of encoding rates using predetermined rate selection rules.<br>2. An apparatus for selecting an encoding rate from a predetermined set of encoding rates and for encoding a frame of speech including a plurality of speech samples, comprising: a mode measurement calculator that generates a set of parameters indicative of characteristics of said frame of speech in accordance with said speech samples and a signal derived from said speech samples; and a rate determination logic for receiving said set of parameters, for determining the psychoacoustic significance of said speech samples in accordance with said set of parameters, and for selecting an encoding rate from said predetermined set of encoding rates.<br>3. In a communication system wherein a remote station communicates with a central communication center, a subsystem for dynamically changing the transmission rate of a frame of speech transmitting from said remote station, comprising: means, responsive to said speech frame and to a signal derived from said speech frame, for generating a set of parameters indicative of characteristics of said speech frame; and means for receiving said set of parameters, for determining the pyschoacoustic significance of said speech samples in accordance with said set of parameters, for receiving a rate command signal for generating at least one threshold value in accordance with said rate command signal, for comparing at least one parameter of said set of parameters with said at least one threshold value, and for selecting an encoding rate in accordance with said comparison.<br>4. In a communication system wherein a remote station communicates with a central communication center, a subsystem for dynamically changing the transmission rate of a frame of speech transmitting from said remote station, comprising: a mode measurement calculator that generates a set of parameters indicative of characteristics of said frame of speech in accordance with said speech samples and a signal derived from said speech samples; and a rate determination logic that receives said set of parameters for determining the psychoacoustic significance of said speech samples in accordance with said set of parameters, receives a rate command signal for generating at least one threshold value in accordance with said rate command signal, compares at least one parameter of said set of parameters with said at least one threshold value, and selects an encoding rate in accordance with said comparison.<br>5. A method for selecting an encoding rate of a predetermined set of encoding rates for encoding a frame of speech including a plurality of speech samples, comprising: generating a set of parameters indicative of characteristics of said frame of speech in accordance with said speech samples and with a signal derived from said speech samples; and selecting an encoding rate from said predetermined set of encoding rates in accordance with said set of parameters, said set of parameters for determining the psychoacoustic significance of said speech samples.<br>6. A method for adjusting the average data rate of a variable rate encoder that encodes speech frames based on mode measurements of the speech frames, comprising: increasing a threshold value for an output of a target matching signal to noise ratio (TMSNR) element within the variable rate encoder if the average data rate of the speech frames is to be increased; and decreasing the threshold value for the output of the TMSNR element within the variable rate encoder if the average data rate of the speech frames is to be decreased.</p></layer>
<layer id = "layer156"><p><b>US5742734A:Encoding rate selection in a variable rate vocoder</b><br>An electronic control unit adjusts an electronic throttle valve to a starting opening in a cold start mode of an engine, then maintains the opening of the electronic throttle valve so that an engine rotational speed detected by a crank angle sensor increases to a target rotational speed, and increases the opening of the electronic throttle valve and retards an ignition timing if the engine rotational speed is increased above the target rotational speed.<br><b>Independant Claims</b><br>1. An apparatus for determining an encoding rate for an input signal in a variable rate vocoder comprising: subband energy computation means for receiving said input signal and determining a plurality of subband energy values in accordance with a predetermined subband energy computation format; a plurality of subband rate determination means wherein each of said plurality of subband rate determination means is for receiving a corresponding one of said plurality of subband energy values and determining a subband encoding rate in accordance with said corresponding one of said plurality of subband energy values to provide a plurality of subband encoding rates; and encoding rate selection means for receiving said plurality of said subband encoding rates and for selecting said encoding rate for said input signal in accordance with said plurality of subband encoding rates.<br>10. An apparatus for determining an encoding rate for a variable rate vocoder comprising: signal to noise ratio means for receiving an input signal and generating an estimate of the information signal energy in said input signal and for generating an estimate of the background noise energy in said input signal and for providing a signal to noise ratio in accordance with said estimate of the information signal energy, and said estimate of the background noise energy; rate determination means for receiving said signal to noise ratio value and determining said encoding rate in accordance with said signal to noise ratio value.<br>11. An apparatus for determining an encoding rate for a variable rate vocoder comprising: a signal to noise ratio calculator that receives an input signal and generates an estimate of the information signal energy in said input signal and generates an estimate of the background noise energy in said input signal and for providing a signal to noise ratio in accordance with said estimate of the information signal energy and said estimate of the background noise energy; rate selector that receives said signal to noise ratio value and selects said encoding rate in accordance with said signal to noise ratio value.<br>12. A method for determining an encoding rate for an input signal in a variable rate vocoder comprising the steps of: receiving said input signal; determining a plurality of subband energy values in accordance with a predetermined subband energy computation format; determining a corresponding subband encoding rate for each of said plurality of subband energy values to provide a plurality of subband encoding rates; and selecting said encoding rate for said input signal in accordance with said plurality of subband encoding rates.<br>21. A method for determining an encoding rate for a variable rate vocoder comprising the steps of: receiving an input signal; generating an estimate of the information signal energy in said input signal generating an estimate of the background noise energy in said input signal; calculating a signal to noise ratio in accordance with said estimate of the information signal energy and said estimate of the background noise energy; and determining said encoding rate in accordance with said signal to noise ratio value.<br>22. A method for determining the presence of music in a variable rate vocoder, comprising the steps of: receiving a frame of an input signal; generating linear predictive coding (LPC) coefficients for said frame; generating a normalized autocorrelation value in accordance with said frame and said LPC coefficients; generating a background noise estimate for said frame; generating an average normalized autocorrelation value for the consecutive frames in which said background noise estimate has been increasing from a predetermined initial background noise estimate; and determining the presence of music in accordance with said average normalized autocorrelation value and a predetermined threshold value.</p></layer>
<layer id = "layer157"><p><b>US6363338B1:Quantization in perceptual audio coders with compensation for synthesis filter noise spreading</b><br>Tooth inserts are described for positioning between interproximal surfaces of teeth during a dental procedure. The tooth inserts have thin regions positioned in the interproximal contact area of the teeth.<br><b>Independant Claims</b><br>1) A method for establishing quantization resolutions for quantizing subband signals obtained from analysis filters that are applied to an input signal, wherein an output signal that is a replica of the input signal is to be obtained by applying synthesis filters to dequantized representations of the quantized subband signals and by applying an overlap-add process to blocks of information obtained from the synthesis filters, the method comprising: generating a desired noise spectrum in response to the input signal; and determining the quantization resolutions for the subband signals by applying a synthesis-filter noise-spreading model to obtain estimated noise levels in subbands of the output signal obtained from the synthesis filters, wherein the synthesis-filter noise-spreading model represents noise-spreading characteristics of the synthesis filters and accounts for effects of the overlap-add process, and wherein the quantization resolutions are determined such that a comparison of the desired-noise spectrum with the estimated noise levels satisfies one or more comparison criteria.<br>10) An apparatus for establishing quantization resolutions for quantizing subband signals obtained from analysis filters that are applied to an input signal, wherein an output signal that is a replica of the input signal is to be obtained by applying synthesis filters to dequantized representations of the quantized subband signals and by applying an overlap-add process to blocks of information obtained from the synthesis filters, the apparatus comprising: an input terminal that receives the input signal; and one or more processing circuits coupled to the input terminal for generating a desired noise spectrum in response to the input signal, and for determining the quantization resolutions for the subband signals by applying a synthesis-filter noise-spreading model to obtain estimated noise levels in subbands of the output signal obtained from the synthesis filters, wherein the synthesis-filter noise-spreading model represents noise-spreading characteristics of the synthesis filters and accounts for effects of the overlap-add process, and wherein the quantization resolutions are determined such that a comparison of the desired-noise spectrum with the estimated noise levels satisfies one or more comparison criteria.<br>19) A receiver that receives and decodes a signal conveying encoded information and generates an output signal by applying synthesis filters to dequantized representations of quantized components of subband signals and by applying an overlap-add process to blocks of information obtained from the synthesis filters, wherein the encoded information comprises: (1) signal information that represents the quantized components of subband signals generated by an encoder that applies analysis filters to an input signal; and (2) control information that represents quantizing resolutions of the quantized subband signal components, wherein the quantizing resolutions are determined in the encoder by (a) generating a desired noise spectrum in response to the input signal; and (b) applying a synthesis-filter noise-spreading model to obtain estimated noise levels in subbands of an output signal obtained from synthesis filters, wherein the synthesis-filter noise-spreading model represents noise-spreading characteristics of the synthesis filters and the overlap-add process, and wherein the quantization resolutions are determined such that a comparison of the desired-noise spectrum with the estimated noise levels satisfies one or more comparison criteria; and wherein the receiver comprises: (1) an input coupled to the signal conveying the encoded information; (2) one or more processing circuits coupled to the input that (a) extract the signal information and the control information from the encoded information and obtain therefrom the quantized subband signal components and the quantizing resolutions of the quantized subband signal components; (b) dequantize the quantized subband signal components according to the quantizing resolutions to obtain dequantized subband signals; and (c) apply the synthesis filters to the dequantized subband signals and apply the overlap-add process to blocks of information obtained from the synthesis filters to generate an output signal, wherein quantizing noise in the subband signals is spread by the synthesis filters to produce noise levels in subbands of the output signal that substantially satisfy the one or more comparison criteria with the desired-noise spectrum; and (3) an output coupled to the one or more processing circuits that conveys the output signal.<br>21) A medium conveying encoded information to be decoded by applying synthesis filters to dequantized representations of quantized components of subband signals and by applying an overlap-add process to blocks of information obtained from the synthesis filters, wherein the encoded information comprises: (1) signal information that represents the quantized components of subband signals generated by applying analysis filters to an input signal; and (2) control information that represents quantizing resolutions of the quantized subband signal components, wherein the quantizing resolutions are determined by (a) generating a desired noise spectrum in response to the input signal; and (b) applying a synthesis-filter noise-spreading model to obtain estimated noise levels in subbands of an output signal obtained from synthesis filters, wherein the synthesis-filter noise-spreading model represents noise-spreading characteristics of the synthesis filters and accounts for effects of the overlap-add process, and wherein the quantization resolutions are determined such that a comparison of the desired-noise spectrum with the estimated noise levels satisfies one or more comparison criteria.<br>23) A medium readable by a device embodying a program of instructions for execution by the device to perform a method for establishing quantization resolutions for quantizing subband signals obtained from analysis filters that are applied to an input signal, wherein an output signal that is a replica of the input signal is to be obtained by applying synthesis filters to dequantized representations of the quantized subband signals and by applying an overlap-add process to blocks of information obtained from the synthesis filters, the method comprising: generating a desired noise spectrum in response to the input signal; and determining the quantization resolutions for the subband signals by applying a synthesis-filter noise-spreading model to obtain estimated noise levels in subbands of the output signal obtained from the synthesis filters, wherein the synthesis-filter noise-spreading model represents noise-spreading characteristics of the synthesis filters and accounts for effects of the overlap-add process, and wherein the quantization resolutions are determined such that a comparison of the desired-noise spectrum with the estimated noise levels satisfies one or more comparison criteria.</p></layer>
<layer id = "layer158"><p><b>US4441200A:Digital voice processing system</b><br>A watch case includes a middle-bezel having a non-circular upper opening receiving a glass of corresponding non-circular shape. The glass has an outwardly-directed peripheral flange able to pass with a slight play through the upper opening in the middle-bezel, and the middle-bezel has an inwardly-directed collar defining its upper opening. A packing seal is disposed with a part under the collar and a part resting on the flange. A screw-fitted circular back applies pressure to the glass to compress the seal between the collar and flange and thereby hold the glass in the upper opening.<br><b>Independant Claims</b><br>1. A digital voice processing system incorporating a complete vocoder algorithm and including means for converting audio signals to digital electrical signals comprising: (a) a first integrated circuit semiconductor chip including pitch extraction means connected to receive the digital electrical signals for providing a first plurality of signals representing a plurality of different audio characteristics; (b) a second integrated circuit semiconductor chip including partial correlation voice analyzer means connected to receive the digital electrical signals for providing a plurality of signals representing a second plurality of different audio characteristics; (c) a third integrated circuit semiconductor chip including partial correlation audio synthesizer means for receiving a plurality of signals representing different audio characteristics and synthesizing audio signals therefrom; (d) transmission and receiving means; (e) a fourth integrated circuit semiconductor chip including a microprocessor coupled to said transmission and reciving means; and (f) means coupling the first and second pluralities of signals from said first and second chips to said fourth chip and coupling a plurality of signals representing different audio characteristics from said fourth chip to said third chip for duplex operation, the complete vocoder algorithm being partitioned among the first, second, third and fourth chips so that only low data rate signals are coupled by said coupling means.<br>8. A method of manufacturing a digital voice processing system incorporating a complete vocoder algorithm for analyzing and synthesizing the audio to provide duplex operation including the steps of: (a) providing a plurality of integrated circuit semiconductor chips carrying circuitry for performing the vocoder algorithm; and (b) partitioning the vocoder algorithm among the chips so that all communication therebetween occurs at low data rates.</p></layer>
<layer id = "layer159"><p><b>US6324505B1:Amplitude quantization scheme for low-bit-rate speech coders</b><br>The compound of the formula<chemistry id="CHEM-US-00001" num="1"><img id="EMI-C00001" he="16.26mm" wi="49.28mm" file="US20050221990A1-20051006-C00001.TIF" alt="embedded image" img-content="chem" img-format="tif"/></chemistry>wherein Y, X, Z, T and Q are defined in the specification.<br><b>Independant Claims</b><br>1) A method of quantizing spectral information in a speech coder, comprising the steps of: extracting a vector of spectral information from a frame, the vector having a vector energy value; normalizing the vector energy value to generate a plurality of gain factors; differentially vector quantizing the plurality of gain factors; non-uniformly downsampling the plurality of normalized gain factors to generate a fixed-dimension vector having a plurality of elements associated with a respective plurality of non-uniform frequency bands; splitting the fixed-dimension vector into a plurality of sub-vectors; and differentially quantizing the plurality of sub-vectors.<br>16) A speech coder, comprising: means for extracting a vector of spectral information from a frame, the vector having a vector energy value; means for normalizing the vector energy value to generate a plurality of gain factors; means for differentially vector quantizing the plurality of gain factors; means for non-uniformly downsampling the plurality of normalized gain factors to generate a fixed-dimension vector having a plurality of elements associated with a respective plurality of non-uniform frequency bands; means for splitting the fixed-dimension vector into a plurality of sub-vectors; and means for differentially quantizing the plurality of sub-vectors.<br>31) A speech coder, comprising: an extraction module configured to extract a vector of spectral information from a frame, the vector having a vector energy value; a normalization module coupled to the extraction module and configured to normalize the vector energy value to generate a plurality of gain factors; a differential vector quantization module coupled to the normalization module and configured to differentially vector quantize the plurality of gain factors; a downsampler coupled to the normalization module and configured to non-uniformly downsample the plurality of normalized gain factors to generate a fixed-dimension vector having a plurality of elements associated with a respective plurality of non-uniform frequency bands; a splitting mechanism for splitting the fixed-dimension vector into a high-band sub-vector and a low-band sub-vector; and a differential quantization module coupled to the splitting mechanism and configured to differentially quantize the high-band sub-vector and the low-band sub-vector.</p></layer>
<layer id = "layer160"><p><b>US6434519B1:Method and apparatus for identifying frequency bands to compute linear phase shifts between frame prototypes in a speech coder</b><br>A boot retaining device for use with a snowboard includes a plate equipped with straps for retaining an associated boot. A pivot body is located at a central region of the plate. The pivot body retains the plate on the board and includes a central screw or central nut. A support base is attached to the board. The support base includes threading configured for threadably engaging the central screw or nut of the pivot body. The pivot body includes a downwardly open housing which receives the support base. The threaded stem of the central screw or the threaded portion of the central nut projects downward into the housing. A length of the threaded stem of the central screw or the threaded portion of the central nut is less than or equal to a depth of the housing.<br><b>Independant Claims</b><br>1) A method of partitioning the frequency spectrum of a prototype of a frame, comprising the steps of: dividing the frequency spectrum into a plurality of segments; assigning a plurality of bands to each segment; establishing, for each segment, a set of bandwidths for the plurality of bands, wherein the establishing step comprises the step of allocating variable bandwidths to the plurality of bands in a particular segment, and wherein the allocating step comprises the steps of: setting a target bandwidth; searching, for each band, an amplitude vector of the prototype to determine the maximum harmonic number in the band, excluding from the search ranges covered by any previously established band edges; positioning, for each hand, the band edges around the maximum harmonic number such that the total number of harmonics located between the band edges is equal to the target bandwidth divided by the fundamental frequency; and removing gaps between adjacent band edges.<br>7) A speech coder configured to partition the frequency spectrum of a prototype of a frame, comprising: means for dividing the frequency spectrum into a plurality of segments; means for assigning a plurality of bands to each segment; and means for establishing, for each segment, a set of bandwidths for the plurality of bands, wherein the means for establishing comprises means for allocating variable bandwidths to the plurality of bands in a particular segment, and wherein the means for allocating comprises: means for setting a target bandwidth; means for searching, for each band, an amplitude vector of the prototype to determine the maximum harmonic number in the band, excluding from the search ranges covered by any previously established band edges; means for positioning, for each band, the band edges around the maximum harmonic number such that the total number of harmonics located between the band edges is equal to the target bandwidth divided by the fundamental frequency; and means for removing gaps between adjacent band edges.<br>13) A speech coder comprising: a prototype extractor configured to extract a prototype from a frame being processed by the speech coder; and a prototype quantizer coupled to the prototype extractor and configured to divide the frequency spectrum of the prototype into a plurality of segments, assign a plurality of bands to each segment, and establish, for each segment, a set of bandwidths for the plurality of bands, wherein the prototype quantizer is further configured to establish the set of bandwidths as variable bandwidths for the plurality of bands in a particular segment, and wherein the prototype quantizer is further configured to set the variable bandwidths by setting a target bandwidth, searching, for each band, an amplitude vector of the prototype to determine the maximum harmonic number in the band, excluding from the search ranges covered by any previously established band edges, positioning, for each band, the band edges around the maximum harmonic number such that the total number of harmonics located between the band edges is equal to the target bandwidth divided by the fundamental frequency, and removing gaps between adjacent band edges.</p></layer>
<layer id = "layer161"><p><b>US5751903A:Low rate multi-mode CELP codec that encodes line SPECTRAL frequencies utilizing an offset</b><br>A process for fabricating integrated resistors in high density interconnect substrates for multi-chip modules. In addition, the resistor material can be converted selectively into an insulator for optionally allowing for the simultaneous fabrication of integrated resistors and capacitors in relatively few steps. The process is well suited for copper/polyimide substrates.<br><b>Independant Claims</b><br>1. A method of coding a digitized speech signal comprising the steps of: analyzing the digitized speech signal in discrete segments; classifying each discrete segment of the digitized speech signal in one of a plurality of predetermined modes comprising a first mode and a second mode; determining a set of unquantized line spectral frequencies for each discrete segment of the digitized speech signal to represent short term predictor parameters for the digitized speech signal segment; quantizing each unquantized line spectral frequency in each determined set of unquantized line spectral frequencies representing discrete segments of the digitized speech signal classified in the first mode; and encoding the unquantized line spectral frequencies in each set of unquantized line spectral frequencies representing discrete segments of the digitized speech signal classified in the second mode using at least one offset generated from analysis of a representation of at least one preceding discrete segment of the digitized speech signal.<br>12. A method of decoding a data bitstream containing encoded parameters for a segment of a digitized speech signal comprising the steps of: extracting from the data bitstream: a mode parameter encoding a mode of the digitized speech signal segment, a set of scalar quantizer parameters, and a vector quantizer parameter; classifying the digitized speech signal segment in one of a plurality of predetermined modes based on the extracted mode parameter, the plurality of predetermined modes comprising a first mode and a second mode; determining a set of inverse quantized line spectral frequencies for the digitized speech signal segment by determining a first subset of inverse quantized line spectral frequencies based on the extracted set of scalar quantizer parameters, and determining a second subset of inverse quantized line spectral frequencies based on the extracted vector quantizer parameter, wherein the set of scalar quantizer parameters and the vector quantizer parameter, for digitized speech signal segments classified in the second mode, represent a set of offsets generated through backward prediction from analysis of a preceding digitized speech signal segment.<br>15. A coder for encoding a segment of a digitized speech signal comprising: a mode classifier for classifying the digitized speech signal segment in one of a plurality of predetermined modes comprising a first mode and a second mode; a determinator section for determining a set of unquantized line spectral frequencies to represent short term predictor parameters for the digitized speech signal segment; a quantizer section for quantizing the determined set of unquantized line spectral frequencies representing digitized speech signal segments classified in the first mode; and an encoder section for encoding the determined set of unquantized line spectral frequencies representing digitized speech signal segments classified in the second mode using at least one offset generated from analysis of a representation of at least one preceding discrete digitized speech signal segment.<br>26. A decoder for decoding a data bitstream containing encoded parameters for a segment of a digitized speech signal comprising: an extractor section for extracting from the data bitstream: a mode parameter encoding a mode of the digitized speech signal segment, a set of scalar quantizer parameters, and a vector quantizer parameter; a mode classifier for classifying the digitized speech signal segment in one of a plurality of predetermined modes based on the extracted mode parameter, the plurality of predetermined modes comprising a first mode and a second mode; and a determinator section for determining a set of inverse quantized line spectral frequencies, comprised of a scalar quantized set determinator section for determining a first subset of inverse quantized line spectral frequencies based on the extracted set of scalar quantizer parameters, and a vector quantized set determinator section for determining a second subset of inverse quantized line spectral frequencies based on the extracted vector quantizer parameter, wherein the extracted set of scalar quantizer parameters and the extracted vector quantizer parameter, for digitized speech signal segments classified in the second mode, represent a set of offsets generated through backward prediction from analysis of a preceding digitized speech signal segment.</p></layer>
<layer id = "layer162"><p><b>US4486900A:Real time pitch detection by stream processing</b><br>In one embodiment a system and method is arranged for bridging the dead-band when asynchronous signals are compared against each other. There is developed a pair of phase related signals from one of the signals, each phase related signal phase shifted from each other, but having the same frequency as the signal from which it was derived. The other frequency signal is compared against each of the phase-related developed signals to generate an error signal which quadrature rotates when the first and second signals are out of frequency with each other. A control signal is generated when the quadrature rotation is outside a certain limit. The error signal is controllably buffered to insure that the error signal only occurs when the frequencies are offset for a selected period of time.<br><b>Independant Claims</b><br>1. A method for detecting the pitch of a speech pattern, comprising the steps of: sampling a speech pattern at spaced time intervals to form a series of sample signals representative of the pattern; gating every Q.sup.th sample, Q between 2 and 6, into a storage device, thereby storing a predetermined number of past samples, and processing said original samples and said stored Q.sup.th samples to generate a signal representative of the pitch of the speech pattern.<br>7. Apparatus for detecting the pitch of a speech pattern comprising: means for sampling a speech pattern at spaced time intervals to form a series of sample signals representative of the pattern; means for gating every Q.sup.th sample, Q between 2 and 6, into a storage device, thereby storing a predetermined number of past samples, and means for processing said original samples and said stored Q.sup.th samples to generate a signal representative of the pitch of the speech pattern.</p></layer>
<layer id = "layer163"><p><b>US20050222842A1:Acoustic signal enhancement system</b><br>The invention relates to a method of performing a processing of a multimedia content. The method according to the invention comprises performing said processing by analyzing a structured description of a bit stream obtained from coding said multimedia content. The description is advantageously written in a markup language such as XML. In a first embodiment said processing comprises the generation of coding data exclusive of the coding format, relating to the bit stream and adding them to the description (cut between video sequences, character depending on or independent of the coding of elementary video units, presentation time and decoding time . . . ). In a second embodiment said processing is an applicable processing (reading of a video stream based on a point defined by a user, copying, pasting, video sequence concatenation . . . ).<br><b>Independant Claims</b><br>1. A method for enhancing an input signal, the method comprising: determining a time-frequency representation of a noisy input signal; estimating a background noise level and a signal-to-noise ratio; determining a matching low noise signal template for the time-frequency representation; and replacing a portion of the time-frequency representation with a mix of the time-frequency representation and the matching low noise signal template, the mix weighted by the signal-to-noise ratio.<br>10. A system for enhancing an input signal, the system comprising: means for transforming the acoustic input signal to a time-frequency representation; means for determining a matching low noise signal template for the time-frequency representation; and means for replacing a portion of the time-frequency representation with a signal-to-noise ratio weighted mix of the time-frequency representation and the matching low noise signal template.<br>14. A signal enhancement system comprising: a processor; memory coupled to the processor, the memory comprising instruction which cause the processor to: establish a signal model comprising multiple low noise signal templates; obtain an input signal; determine a matching low noise signal template in the signal model for the input signal; and replace a portion of the input signal with a signal-to-noise ratio weighted mix of the input signal and the matching low noise signal template.<br>21. A product comprising: a machine readable medium; and instructions stored on the machine readable medium which cause a processor to: determine a matching low noise signal template for a noisy input signal from a signal model comprising multiple low noise signal templates; and replace a portion of the input signal with a signal-to-noise ratio weighted mix of the input signal and the matching low noise signal template.</p></layer>
<layer id = "layer164"><p><b>US8428945B2:Acoustic signal classification system</b><br>A composition for preventing or treating a viral infection, which includes an ethanol extract of <i>Tetracera scandens </i>as an effective component, is provided. The composition exhibits low toxicity and few side effects and effectively inhibits reverse transcriptase activities to suppress synthesis of DNA, and thus can be useful in preventing or treating infections caused by various kinds of RNA viruses.<br><b>Independant Claims</b><br>1) A method for classifying a signal, comprising: obtaining an input signal; determining a time-frequency representation of the input signal; determining whether a signal of interest is present in the time-frequency representation; identifying an interval of the time-frequency representation that contains the signal of interest; measuring a signal-to-noise ratio of the time-frequency representation; rescaling frequency bands of the time-frequency representation by a weighting proportional to the measured signal-to-noise ratio of the time-frequency representation; comparing the rescaled time-frequency representation of the interval to a plurality of time-frequency spectrogram templates in response to identifying the interval of the time-frequency representation that contains the signal of interest; and selecting a matching time-frequency spectrogram template from the plurality of time-frequency spectrogram templates, by a processor, based on an amount of distortion between the rescaled time-frequency representation and at least one of the plurality of time-frequency spectrogram templates.<br>11) An acoustic signal classification system, comprising: a processor; memory coupled to the processor, the memory comprising instructions operable to cause the processor to: obtain an input signal; determine a time-frequency representation of the input signal; measure a signal-to-noise ratio of the time-frequency representation or a template of the plurality of time-frequency spectrogram templates; and rescale the template according to the measured signal-to-noise ratio; determine whether a signal of interest is present in the time-frequency representation; identify an interval of the time-frequency representation that contains the signal of interest; compare the time-frequency representation of the interval to a plurality of time-frequency spectrogram templates in response to identifying the interval of the time-frequency representation that contains the signal of interest; and select a matching time-frequency spectrogram template from the plurality of time-frequency spectrogram templates based on an amount of distortion between the time-frequency representation and at least one of the plurality of time-frequency spectrogram templates, where the instructions operable to cause the processor to select the matching time-frequency spectrogram template comprise instructions operable to cause the processor to compare the time-frequency representation with the rescaled template.<br>12) An acoustic signal classification system, comprising: a processor; memory coupled to the processor, the memory comprising instructions operable to cause the processor to: obtain an input signal; determine a time-frequency representation of the input signal; determine whether a signal of interest is present in the time-frequency representation; identify an interval of the time-frequency representation that contains the signal of interest; measure a signal-to-noise ratio of the time-frequency representation; rescale frequency bands of the time-frequency representation by a weighting proportional to the measured signal-to-noise ratio of the time-frequency representation; compare the rescaled time-frequency representation of the interval to a plurality of time-frequency spectrogram templates in response to identifying the interval of the time-frequency representation that contains the signal of interest; and select a matching time-frequency spectrogram template from the plurality of time-frequency spectrogram templates based on an amount of distortion between the rescaled time-frequency representation and at least one of the plurality of time-frequency spectrogram templates.<br>16) A product, comprising: a non-transitory computer readable medium; and instructions stored on the non-transitory computer readable medium that cause a processor in a signal processing system to: obtain an input signal; determine a time-frequency representation of the input signal; determine whether a signal of interest is present in the time-frequency representation; identify an interval of the time-frequency representation that contains the signal of interest; measure a signal-to-noise ratio of the time-frequency representation; rescale the time-frequency representation according to the measured signal-to-noise ratio of the time-frequency representation; compare the time-frequency representation of the interval to a plurality of time-frequency spectrogram templates in response to identifying the interval of the time-frequency representation that contains the signal of interest; and select a matching time-frequency spectrogram template from the plurality of time-frequency spectrogram templates based on an amount of distortion between the time-frequency representation and at least one of the plurality of time-frequency spectrogram templates.<br>17) An acoustic signal classification system, comprising: a processor; memory coupled to the processor, the memory comprising instructions operable to cause the processor to: obtain an input signal; determine a time-frequency representation of the input signal; determine whether a signal of interest is present in the time-frequency representation; identify an interval of the time-frequency representation that contains the signal of interest; compare the time-frequency representation of the interval to a plurality of time-frequency spectrogram templates in response to identifying the interval of the time-frequency representation that contains the signal of interest; select a matching time-frequency spectrogram template from the plurality of time-frequency spectrogram templates based on an average distance measurement between the time-frequency representation and at least one of the plurality of spectrogram templates; and weight the time-frequency representation or the at least one of the plurality of spectrogram templates based on a measured signal-to-noise ratio so that a first frequency band of the input signal, with a lower signal-to-noise ratio than a second frequency band of the input signal, contributes less to the average distance measurement than the second frequency band.<br>8) A method for classifying a signal, comprising: obtaining an input signal; determining a time-frequency representation of the input signal; determining whether a signal of interest is present in the time-frequency representation; identifying an interval of the time-frequency representation that contains the signal of interest; comparing the time-frequency representation of the interval to a plurality of time-frequency spectrogram templates in response to identifying the interval of the time-frequency representation that contains the signal of interest; selecting a matching time-frequency spectrogram template from the plurality of time-frequency spectrogram templates, by a processor, based on an average distance measurement between the time-frequency representation and at least one of the plurality of spectrogram templates; and weighting the time-frequency representation or the at least one of the plurality of spectrogram templates based on a measured signal-to-noise ratio so that a first frequency band of the input signal, with a lower signal-to-noise ratio than a second frequency band of the input signal, contributes less to the average distance measurement than the second frequency band.<br>18) An acoustic signal classification system, comprising: a processor; memory coupled to the processor, the memory comprising instructions operable to cause the processor to: obtain an input signal; determine a time-frequency representation of the input signal; determine whether a signal of interest is present in the time-frequency representation; identify an interval of the time-frequency representation that contains the signal of interest; compare the time-frequency representation of the interval to a plurality of time-frequency spectrogram templates in response to identifying the interval of the time-frequency representation that contains the signal of interest; and select a matching time-frequency spectrogram template from the plurality of time-frequency spectrogram templates based on an amount of distortion between the time-frequency representation and at least one of the plurality of time-frequency spectrogram templates; where the instructions operable to cause the processor to select the matching time-frequency spectrogram template comprise instructions operable to cause the processor to: calculate a first root mean square distance difference between the time-frequency representation and a first template of the plurality of time-frequency spectrogram templates; calculate a second root mean square distance difference between the time-frequency representation and a second template of the plurality of time-frequency spectrogram templates; identify the first template as the matching time-frequency spectrogram in response to a determination that the first root mean square distance difference is lower than the second root mean square distance difference; and identify the second template as the matching time-frequency spectrogram in response to a determination that the second root mean square distance difference is lower than the first root mean square distance difference.<br>9) A method for classifying a signal, comprising: obtaining an input signal; determining a time-frequency representation of the input signal; determining whether a signal of interest is present in the time-frequency representation; identifying an interval of the time-frequency representation that contains the signal of interest; comparing the time-frequency representation of the interval to a plurality of time-frequency spectrogram templates in response to identifying the interval of the time-frequency representation that contains the signal of interest; and selecting a matching time-frequency spectrogram template from the plurality of time-frequency spectrogram templates, by a processor, based on an amount of distortion between the time-frequency representation and at least one of the plurality of time-frequency spectrogram templates; where selecting the matching time-frequency spectrogram template comprises: calculating a first root mean square distance difference between the time-frequency representation and a first template of the plurality of time-frequency spectrogram templates; calculating a second root mean square distance difference between the time-frequency representation and a second template of the plurality of time-frequency spectrogram templates; identifying the first template as the matching time-frequency spectrogram in response to a determination that the first root mean square distance difference is lower than the second root mean square distance difference; and identifying the second template as the matching time-frequency spectrogram in response to a determination that the second root mean square distance difference is lower than the first root mean square distance difference.<br>10) A method for classifying a signal, comprising: obtaining an input signal; determining a time-frequency representation of the input signal; measuring a signal-to-noise ratio of the time-frequency representation or a template of a plurality of time-frequency spectrogram templates; and rescaling the template according to the measured signal-to-noise ratio; determining whether a signal of interest is present in the time-frequency representation; identifying an interval of the time-frequency representation that contains the signal of interest; comparing the time-frequency representation of the interval to the plurality of time-frequency spectrogram templates in response to identifying the interval of the time-frequency representation that contains the signal of interest; and selecting a matching time-frequency spectrogram template from the plurality of time-frequency spectrogram templates, by a processor, based on an amount of distortion between the time-frequency representation and at least one of the plurality of time-frequency spectrogram templates, where selecting the matching time-frequency spectrogram template comprises comparing the time-frequency representation with the rescaled template.</p></layer>
<layer id = "layer165"><p><b>US5701390A:Synthesis of MBE-based coded speech using regenerated phase information</b><br>The onset and progression of chronic autoimmune diseases, including human rheumatoid arthritis (RA) are likely determined by differential expression of genes that influence inflammatory and immune responses. The collagen-induced arthritis (CIA) mouse model for RA exhibits many of the same genetic and immunological features of RA; however, the profiles of gene expression during the inflammatory and immune responses of CIA or RA have not been well characterized. Previous studies have demonstrated that mRNA levels, particularly that of cytokines, can change over the course of CIA. To determine the contribution of various genes in the pathogenesis of CIA, microarray technology was used to simultaneously monitor 8,734 target cDNAs to discover arthritic stage-specific genes. The resulting gene expression profile identified 333 genes that were at least 2-fold up-regulated in all synovial samples: normal, acute disease and chronic disease. In addition, 385 disease-specific genes were identified that were greater than or equal to 2-fold over- or under-expressed in the disease state as compared to normal synovium. Clustering analysis among the arthritic states allowed for the identification of four distinct kinetic expression patterns based on differential expression levels in normal, acute disease and chronic disease synovial samples.<br><b>Independant Claims</b><br>1. A method for decoding and synthesizing a synthetic digital speech signal from a plurality of digital bits of the type produced by dividing a speech signal into a plurality of frames, determining voicing information representing whether each of a plurality of frequency bands of each frame should be synthesized as voiced or unvoiced bands; processing the speech frames to determine spectral envelope information representative of the magnitudes of the spectrum in the frequency bands, and quantizing and encoding the spectral envelope and voicing information, wherein the method for decoding and synthesizing the synthetic digital speech signal comprises the steps of: decoding the plurality of bits to provide spectral envelope and voicing information for each of a plurality of frames; processing the spectral envelope information to determine regenerated spectral phase information based on local envelope smoothness for each of the plurality of frames, determining from the voicing information whether frequency bands for a particular frame are voiced or unvoiced; synthesizing speech components for voiced frequency bands using the regenerated spectral phase information, synthesizing a speech component representing the speech signal in at least one unvoiced frequency band, and synthesizing the speech signal by combining the synthesized speech components for voiced and unvoiced frequency bands.<br>2. Apparatus for decoding and synthesizing a synthetic digital speech signal from a plurality of digital bits of the type produced by dividing a speech signal into a plurality of frames, determining voicing information representing whether each of a plurality of frequency bands of each frame should be synthesized as voiced or unvoiced bands; processing the speech frames to determine spectral envelope information representative of the magnitudes of the spectrum in the frequency bands, and quantizing and encoding the spectral envelope and voicing information, wherein the apparatus for decoding and synthesizing the synthetic digital speech comprises: means for decoding the plurality of bits to provide spectral envelope and voicing information for each of a plurality of frames; means for processing the spectral envelope information to determine regenerated spectral phase information based local envelope smoothness for each of the plurality of frames, means for determining from the voicing information whether frequency bands for a particular frame are voiced or unvoiced; means for synthesizing speech components for voiced frequency bands using the regenerated spectral phase information, means for synthesizing a speech component representing the speech signal in at least one unvoiced frequency band, and means for synthesizing the speech signal by combining the synthesized speech components for voiced and unvoiced frequency bands.</p></layer>
<layer id = "layer166"><p><b>US5754974A:Spectral magnitude representation for multi-band excitation speech coders</b><br>A clamping device with a locking mechanism that is well known wherein the clamping jaws are modified so that they may be rotated around an axis extending between the clamping jaws. This allows opposing clamping jaws to be rotated to the side of the device thereby allowing clamping around corners and in crevice.<br><b>Independant Claims</b><br>1. A method for encoding a speech signal into a plurality of digital bits from which the speech signal can later be synthesized, the method comprising the steps of: processing the speech signal to divide the signal into a plurality of speech frames, each of the speech frames representing a time interval of the speech signal; processing the speech frames to determine voicing information for a plurality of frequency bands of the speech frames; processing the speech frames to determine spectral magnitudes representative of the magnitudes of the spectrum at determined frequencies across the frequency bands, and quantizing and encoding the spectral magnitudes and the voicing information for subsequent use in decoding and synthesizing the speech signal, wherein the processing of the speech frames to determine spectral magnitudes and the quantizing and encoding of the spectral magnitudes is done in such a manner that spectral magnitudes independent of the voicing information are available for later synthesizing.<br>2. Apparatus for encoding a speech signal into a plurality of digital bits from which the speech signal can later be synthesized, the apparatus comprising: means for processing the speech signal to divide the signal into a plurality of speech frames, each of the speech frames representing a time interval of the speech signal; means for processing the speech frames to determine voicing information for a plurality of frequency bands of the speech frames; means for processing the speech frames to determine spectral magnitudes representative of the magnitudes of the spectrum at determined frequencies across the frequency bands, and means for quantizing and encoding the spectral magnitudes and the voicing information for subsequent use in decoding and synthesizing the speech signal, wherein the processing of the speech frames to determine spectral magnitudes and the quantizing and encoding of the spectral magnitudes is done in such a manner that spectral magnitudes independent of the voicing information are available for later synthesizing.<br>15. A method for encoding a speech signal into a plurality of digital bits from which the speech signal can later be synthesized, the method comprising the steps of: processing the speech signal to divide the signal into a plurality of speech frames, each of the speech frames representing a time interval of the speech signal; processing the speech frames to determine voicing information for a plurality of frequency bands of the speech frames; processing the speech frames to determine spectral magnitudes representative of the magnitudes of the spectrum at determined frequencies across the frequency bands, and quantizing and encoding the spectral magnitudes and the voicing information for subsequent use in decoding and synthesizing the speech signal, wherein the processing to determine spectral magnitudes includes a spectral transformation of the speech frames from time domain samples to frequency samples, and wherein the spectral magnitudes are formed as weighted sums of the frequency samples.<br>16. Apparatus for encoding a speech signal into a plurality of digital bits from which the speech signal can later be synthesized, the apparatus comprising: means for processing the speech signal to divide the signal into a plurality of speech frames, each of the speech frames representing a time interval of the speech signal, means for processing the speech frames to determine voicing information for a plurality of frequency bands of the speech frames; means for processing the speech frames to determine spectral magnitudes representative of the magnitudes of the spectrum at determined frequencies across the frequency bands, and means for quantizing and encoding the spectral magnitudes and the voicing information for subsequent use in decoding and synthesizing the speech signal, wherein the processing to determine spectral magnitudes includes a spectral transformation of the speech frames from time domain samples to frequency samples, and wherein the spectral magnitudes are formed as weighted sums of the frequency samples.</p></layer>
<layer id = "layer167"><p><b>US5920840A:Communication system and method using a speaker dependent time-scaling technique</b><br>A process of purifying and stabilizing a high molecular weight polylactide polymer by contacting solid polymer particles with methyl alcohol and subsequently acetone.<br><b>Independant Claims</b><br>1. A method for time-scale modification of speech using a modified version of the Waveform Similarity based Overlap-Add technique (WSOLA), the method comprising the steps of: a) storing a portion of an input speech signal in a memory; b) analyzing the portion of the input speech signal to determined at least one filtered pitch value; c) calculating an estimated pitch value from the at least one filtered pitch value; d) determining a segment size in response to the estimated pitch value, the segment size having a value greater than the estimated pitch value and; e) time-scale compressing the input speech signal in response to the segment size determined.<br>6. A method for time-scale modification of speech using a modified version of the Waveform Similarity based Overlap-Add technique (WSOLA), the method comprising the steps of: a) storing a portion of an input speech signal in a memory; b) determining at least one filtered pitch value from the portion of the input speech signal; c) calculating an estimated pitch value from the at least one filtered pitch value; d) determining a segment size in response to the estimated pitch value, the segment size having a value greater than the estimated pitch value; e) time-scale compressing the input speech signal in response to the segment size determined; and f) time-scale expanding the input speech signal in response to the segment size determined.<br>11. A method for use in a voice capable device for time-scale modification of speech using a modified version of the Waveform Similarity based Overlap-Add technique (WSOLA) to form an output signal, comprising the steps of: at an output device: a) determining at least one filtered pitch value from a portion of an input speech signal; b) calculating an estimated pitch value from the at least one filtered pitch value; c) determining an analysis segment size in response to estimated pitch value, the analysis segment size having a value greater than the estimated pitch value; and d) time-scale expanding the input speech signal to provide a resultant output speech signal.<br>13. A method for time-scale modification of speech dependent upon a pitch period of a speaker using a modified version of the Waveform Similarity based Overlap-Add technique (WSOLA), comprising the steps of: a) determining at least one filtered pitch value from a portion of an input speech signal; b) calculating an estimated pitch value from the at least one filtered pitch value; c) determining an analysis segment size being approximately twice the estimated pitch value; d) increasing a time-scaling factor above an average time-scaling factor if the estimated pitch value is below a predetermined threshold; and e) decreasing the time-scaling factor below an average time-scaling factor if the estimated pitch value is above the predetermined threshold.<br>17. A method for compressing a plurality of voice signals within a voice communication resource having a given bandwidth within a voice communication system, comprising the steps of: (a) subchanneling the voice communication resource and simultaneously placing at least one voice signal of the plurality of voice signals on a subchannel of a plurality of subchannels; (b) compressing a time of the at least one voice signal within the subchannel, wherein the step of compressing the time of the at least one voice signal includes the steps of: c) determining at least one filtered pitch value from a portion of the at least one voice signal; d) calculating an estimated pitch value from the at least one filtered pitch value for the at least one voice signal; e) determining a segment size for analysis approximately twice the estimated pitch value; f) increasing a time-scaling factor above an average time-scaling factor if the estimated pitch value is below a predetermined threshold; and g) decreasing the time-scaling factor below an average time-scaling factor if the estimated pitch value is above the predetermined threshold, wherein the result of steps (a) through (g) provide a plurality of compressed voice signals.<br>21. A communication system using voice compression having at least one transmitter base station and a plurality of selective call receivers, comprising: at the at least one transmitter base station: an input device for receiving an audio signal, a processing device which compresses the audio signal to produce a compressed audio signal and which modulates the compressed audio signal using quadrature amplitude modulation to provide a processed signal, said processing device compresses the audio signal in accordance with the steps of a) analyzing a portion of the audio signal to determined at least one filtered pitch value, b) calculating an estimated pitch value from the at least one filtered pitch value, c) determining a segment size in response to the estimated pitch value, the segment size having a value greater than the estimated pitch value, and d) time-scale compressing the audio signal in response to the segment size determined, and a quadrature amplitude modulation transmitter for transmitting the processed signal; and at each of the plurality of selective call receivers: a selective call receiver for receiving the processed signal which is transmitted, a processing device for demodulating the processed signal which is received using a quadrature amplitude demodulation technique and for time-scale expanding the processed signal which is demodulated to provide a reconstructed signal, and an amplifier for amplifying the reconstructed signal into an reconstructed audio signal.<br>27. A selective call receiver for receiving compressed voice signals, comprising: a selective call receiver for receiving a processed signal which is transmitted, the processed signal being processed in accordance with the steps of: a) analyzing a portion of an input speech signal to determined at least one filtered pitch value, b) calculating an estimated pitch value from the at least one filtered pitch value, c) determining a segment size in response to the estimated pitch value, the segment size having a value greater than the estimated pitch value, and d) time-scale expanding the input speech signal in response to the segment size determined; a processing device for demodulating the processed signal which is received using a single side band demodulation technique and a time-scale expansion technique to provide a reconstructed signal; and an amplifier for amplifying the reconstructed signal into an reconstructed audio signal.<br>30. A selective call paging base station for transmitting selective call signals on a communication resource having a predetermined bandwidth, comprising: an input device for receiving a plurality of audio signals; a means for subchanneling the communication resource into a predetermined number of subchannels; an amplitude compression and filtering module, for each subchannel of the predetermined number of subchannels, for compressing an amplitude of a respective audio signal and for filtering the respective audio signal; a time-scale compression module which provides compression of the respective audio signal for each of the predetermined number of subchannels, said time-scale compression module operating to generate a processed signal in accordance with the steps of: a) analyzing a portion of an input speech signal to determined at least one filtered pitch value, b) calculating an estimated pitch value from the at least one filtered pitch value, c) determining a segment size in response to the estimated pitch value, the segment size having a value greater than the estimated pitch value, and d) time-scale compressing the input speech signal in response to the segment size determined; and a quadrature amplitude modulation transmitter for transmitting the processed signal.<br>34. A selective call receiver, comprising: a receiver having an analog to digital converter for receiving a compressed voice signal that has been compressed using a modified version of the Waveform Similarity based Overlap-Add (WSOLA) compression technique that uses a compression factor that is dependent upon a pitch period of a voice signal which is input in accordance with the steps of: a) analyzing a portion of the voice signal which is input to determined at least one filtered pitch value, b) calculating an estimated pitch value from the at least one filtered pitch value, c) determining a segment size in response to the estimated pitch value, the segment size having a value greater than the estimated pitch value, and d) time-scale compressing the voice signal in response to the segment size determined to generate the compressed voice signal, and providing therefrom a digitized received signal, wherein the compressed voice signal further contains data for determining an expansion factor from the compression factor used in compressing the voice signal; and a signal processor for processing the digitized received signal and for expanding the digitized received signal in accordance with the expansion factor to generate a processed signal.<br>40. An electronic device that uses a modified version of the Waveform Similarity based Overlap-Add technique (WSOLA) for time-scale modification of speech, comprising: memory for storing a portion of an input speech signal; a processor for analyzing a portion of an input speech signal to determine at least one filtered pitch value, for calculating an estimated pitch value from the at least one filtered pitch value, and for further determining a segment size in response to the estimated pitch value, the segment size having a value greater than the estimated pitch value; and a means for time-scaling the input speech signal in response to the segment size determined.<br>46. A method for time-scale and frequency-scale modification of speech using a modified version of the Waveform Similarity based Overlap-Add technique (WSOLA), the method comprising the steps of: a) storing a portion of an input speech signal in a memory; b) analyzing the portion of the input speech signal to determined at least one filtered pitch value; c) calculate an estimated pitch value from the at least one filtered pitch value; d) determining a segment size in response to the estimated pitch value, the segment size having a value greater than the estimated pitch value; e) time-scaling the input speech signal in response to the segment size determined and a predetermined time-scaling factor, wherein time-scaling provides a time-scaled signal; and f) frequency-scaling of the time-scaled signal.</p></layer>
<layer id = "layer168"><p><b>US5097508A:Digital speech coder having improved long term lag parameter determination</b><br>An electrical outlet box optionally having in combination therewith, a connector fitting for connecting a corrugated conduit to the box, the box having a back wall and at least one side wall of synthetic resin. A pressure removable plug is displaced out of the plane of the side wall so as to provide a precisely delineated zone of weakness surrounding the plug. When one preferred type of connector fitting is used in combination with the box, a wedge-shaped end portion of the fitting, having a relatively small surface area, is manually pressed against the pressure removable plug along a pressure zone immediately radially inwardly from the zone of weakness. This pops the plug out of the wall of the box, leaving a neat, smooth hole into which the connector fitting may be inserted by continued manual pressure applied thereto. The connector fitting includes an expandable cylindrical body portion, and further includes an external circumferential groove at the intersection of the cylindrical body portion with the wedge-shaped end portion. The edge of the wall which defines the opening formed on removal of the plug snaps into this groove to interlock the connector fitting in the wall of the box.<br><b>Independant Claims</b><br>1. A digital speech encoding method that produces parameters representative of samples of digitized speech comprising the steps of: storing a plurality of excitation signals; filtering said excitation signals using a long term filter to produce corresponding filtered signals, said long term filter having a time lag filter characteristic controlled by a time lag parameter; generating error signals based upon the difference between said filtered signals and a sample of digitized speech; selecting the excitation signal corresponding to the smallest error signal for use with said sample of digitized speech; generating said time lag parameter by: calculating correlation values based on trial time lags of different lengths; evaluating said correlation values and selecting a predetermined number of the trial time lags having the larger of said correlation values, the maximum value of said number having a corresponding lag D.sub.p ; determining if at least one of said number of trial time lags is harmonically related to lag D.sub.p, if at least one of said predetermined number of lags is harmonically related to lag D.sub.p selecting the smallest to said harmonically related lags for use as said lag parameter, if none of said number of trial time lags are harmonically related to lag D.sub.p selecting D.sub.p as said lag parameter; filtering a sample of digitized speech using the long term filter with the time lag filter characteristic controlled by said selected lag parameter.<br>3. A digital speech encoder that produces parameters representative of samples of digitized speech comprising: codebook means for storing a plurality of excitation signals; long term filter which filters said excitation signals to produce corresponding filtered signals, said long term filter having a time lag filter characteristic controlled by a time lag parameter; means for generating error signals based upon the difference between said filtered signals and a sample of digitized speech; means for selecting the excitation signal corresponding to the smallest error signal for use with said sample of digitized speech; means for generating said time lag parameter comprising: means for calculating correlation values based on trial time lags of different lengths; means for evaluating said correlation values and means for selecting a predetermined number of the trial time lags having the larger of said correlation values, the maximum value of said number having a corresponding lag D.sub.p ; means for determining if at least one of said predetermined number of trial time lags is harmonically related to lag D.sub.p ; means for selecting the smallest of said harmonically related lags as said lag parameter if a harmonically related lag exists, if none of said number of trial time lags are harmonically related to lag D.sub.p selecting D.sub.p as said lag parameter; said long term filter filtering samples of digitized speech using the time lag filter characteristic controlled by said selected lag parameter.<br>5. A digital speech encoding method that produces parameters representative of samples of digitized speech comprising the steps of: storing a plurality of excitation signals; filtering said excitation signals using a long term filter to produce corresponding filtered signals, said long term filter having a time lag filter characteristic controlled by a time lag parameter; generating error signals based upon the difference between said filtered signals and a sample of digitized speech; selecting the excitation signal corresponding to the smallest error signal for use with said sample of digitized speech; generating said time lag parameter by: calculating an open loop lag parameter L.sub.open ; conducting a predetermined series of tests of closed loop lag parameters dependent on the value of open loop lag parameter L.sub.open to determine the error associated with each closed loop lag parameter tested; selecting the closed loop lag parameter with the smallest error as said time lag parameter; filtering samples of digitized speech using the long term filter with the time lag filter characteristic controlled by lag parameter L.<br>11. A digital speech encoder that produces parameters representative of samples of digitized speech comprising: codebook means for storing a plurality of excitation signals; long term filter which filters said excitation signals to produce corresponding filtered signals, said long term filter having a time lag filter characteristic controlled by a time lag parameter; means for generating error signals based upon the difference between said filtered signals and a sample of digitized speech; means for selecting the excitation signal corresponding to the smallest error signal for use with said sample of digitized speech; means for generating said time lag parameter comprising: means for calculating an open loop lag parameter L.sub.open ; means for conducting a predetermined series of tests of closed loop lag parameters dependent on the value of open loop lag parameter L.sub.open to determine the error associated with each test; means for selecting said closed loop lag parameter with the smallest error as said time lag parameter; said filter filtering samples of digitized speech with the time lag filter characteristic controlled by said time lag parameter.</p></layer>
<layer id = "layer169"><p><b>US5054075A:Subband decoding method and apparatus</b><br>The invention presented herein comprises apparatus and method for remote activation of heating and cooling systems in homes or other buildings. A user may wish to turn the heat on before returning home after a day in a distant office and by simply dialing the telephone at his office and allowing it to ring at his home a prescribed number of times a thermostatic regulated furnace may be turned on and his house is warmed to the desired temperature before his arrival. The invention may be used for heating or air conditioning systems and can be effectively activated wherever telephone lines are available.<br><b>Independant Claims</b><br>1. In a subband coding system including an encoder having an input signal and a decoder, a method for providing an improved reconstructed signal at the decoder, comprising the following steps: (a) providing a partially reconstructed signal based on information received from the encoder: (b) receiving from the encoder N subband energy values E.sub.k, where k varies from 1-N, each E.sub.k based on the energy present in a particular spectral subband of the original input signal: (c) providing N noise/waveform fill signals, each having an energy value E'.sub.k, where the E'.sub.k is provided by the following steps: (c.sub.1) computing values A, B which minimize ##EQU3## (c.sub.2) computing N values Z.sub.k based on E.sub.k -(Ak+B), where k varies from 1-N; (c.sub.3) identifying the largest Z.sub.k (Z.sub.k.vertline.max); (c.sub.4) computing N values E'.sub.k based on E.sub.k -.xi.(Z.sub.k.vertline.max -Z.sub.k), where k varies from 1-N and .xi. is a predetermined constant; (d) combining the noise/waveform fill signals with said partially reconstructed signal.<br>4. A subband coding system including an encoder having an input signal and a decoder, said decoder having means for providing an improved reconstructed signal, comprising: means for providing a partially reconstructed signal based on information received from the encoder; means for receiving from the encoder N subband energy values E.sub.k, where k varies from 1-N, each E.sub.k based on the energy present in a particular spectral subband of the original input signal; means for providing N noise/waveform fill signals, each having an energy value E'.sub.k, including means for providing the E'.sub.k, comprising: means for computing values A, B which minimize ##EQU4## means for computing N values Z.sub.k based on E.sub.k -(Ak+B), where k varies from 1-N; means for identifying the largest Z.sub.k (Z.sub.k.vertline.max); means for computing N values E'.sub.k based on E.sub.k -.xi.(Z.sub.k.vertline.max -Z.sub.k), where k varies from 1-N and .xi. is a predetermined constant; means for combining the noise/waveform fill signals with said partially reconstructed signal.<br>7. A subband coding system including an encoder having an input signal and a decoder, said decoder being arranged for providing an improved reconstructed signal according to the method comprising the following steps: (a) providing a partially reconstructed signal based on information received from the encoder; (b) receiving from the encoder N subband energy values E.sub.k, where k varies from 1-N, each E.sub.k based on the energy present in a particular spectral subband of the original input signal; (c) providing N noise/waveform fill signals, each having an energy value E'.sub.k, where the E'.sub.k is provided by the following steps: (c.sub.1) computing values A, B which minimize ##EQU5## (c.sub.2) computing N values Z.sub.k based on E.sub.k -(Ak+B), where k varies from 1-N; (c.sub.3) identifying the largest Z.sub.k (Z.sub.k.vertline.max); (c.sub.4) computing N values E'.sub.k based on E.sub.k -.xi.(Z.sub.k.vertline.max -Z.sub.k), where k varies from 1-N and .xi. is a predetermined constant; (d) combining the noise/waveform fill signals with said partially reconstructed signal.<br>10. A subband coding system including an encoder having an input signal and a decoder, said decoder having a computing means such as a microprocessor or a digital signal processor programmed for providing an improved reconstructed signal according to the method comprising the following steps: (a) providing a partially reconstructed signal based on information received from the encoder; (b) receiving from the encoder N subband energy values E.sub.k, where k varies from 1-N, each E.sub.k based on the energy present in a particular spectral subband of the original input signal; (c) providing N noise/waveform fill signals, each having an energy value E'.sub.k, where the E'.sub.k is provided by the following steps: (c.sub.1) computing values A, B which minimize ##EQU6## (c.sub.2) computing N values Z.sub.k based on E.sub.k -(Ak+B), where k varies from 1-N; (c.sub.3) identifying the largest Z.sub.k (Z.sub.k.vertline.max); (c.sub.4) computing N values E'.sub.k based on E.sub.k -.xi.(Z.sub.k.vertline.max -Z.sub.k), where k varies from 1-N and .xi. is a predetermined constant; (d) combining the noise/waveform fill signals with said partially reconstructed signal.<br>13. In a subband coding system including an encoder having an input signal and a decoder, a method for operating a computer such as a microprocessor or a digital signal processor for providing an improved reconstructed signal at the decoder, the method comprising the following steps: (a) providing a partially reconstructed signal based on information received from the encoder; (b) receiving from the encoder N subband energy values E.sub.k, where k varies from 1-N, each E.sub.k based on the energy present in a particular spectral subband of the original input signal; (c) providing N noise/waveform fill signals, each having an energy value E'.sub.k, where the E'.sub.k is provided by the following steps; (c.sub.1) computing values A, B which minimize ##EQU7## (c.sub.2) computing N values Z.sub.k based on E.sub.k -(Ak+B), where k varies from 1-N; (c.sub.3) identifying the largest Z.sub.k (Z.sub.k .vertline..sub.max); (c.sub.4) computing N values E'.sub.k based on E.sub.k -.xi.(Z.sub.k .vertline..sub.max -Z.sub.k), where k varies from 1-N and .xi. is a predetermined constant; (d) combining the noise/waveform fill signals with said partially reconstructed signal.</p></layer>
<layer id = "layer170"><p><b>US6418407B1:Method and apparatus for pitch determination of a low bit rate digital voice message</b><br>The stilbene epoxy resin having two different aryl groups and an epoxy resin mixture including this stilbene epoxy resin have lower melting points than those of the stilbene epoxy resin having two identical aryl groups and the epoxy resin mixture of the latter stilbene epoxy resin. Compared with the conventional resins, the present resin or resin mixture has improved working and molding properties, which shortens the time required for the molding and working process, resulting in economic advantages and a preferred affect on productivity. The present epoxy resin or resin mixture is preferably used as an adhesive, a coating, an insulating material, an electrical or electronic material for laminated sheets or the like. It is especially suited for use as material for encapsulating electronic parts.<br><b>Independant Claims</b><br>1) A system controller comprises a pitch determiner that generates a smoothed pitch value for a current frame of a low bit rate voice message, the pitch determiner comprising: a pitch function generator that generates a pitch detection function (PDF) for each frame of digital samples of a voice signal; a pitch candidate selector that selects a future frame pitch candidate from a pitch detection function (PDF); and a subharmonic pitch corrector that determines a future frame pitch value by performing pitch subharmonic correction of the future frame pitch candidate using a roughness factor of the frequency transformed window.<br>4) A system controller comprises a pitch function generator that generates a smoothed pitch value for a current frame of a low bit rate voice message, the pitch function generator comprising: a band correlator that determines a plurality of band autocorrelations that correspond to a plurality of bands of a frequency transformed window of the digital samples, the window being related to a future frame of digital samples; and a pitch function selector that generates the pitch detection function based on the plurality of band autocorrelations, wherein the pitch function selector generates⁢ ⁢Γn=M⁢ ⁢max⁡(0,&LeftBracketingBar;Yn&RightBracketingBar;-maxk=0K⁢&LeftBracketingBar;Yk&RightBracketingBar;-P)for⁢ ⁢n⁢ ⁢from⁢ ⁢1⁢ ⁢to⁢ ⁢K⁢ ⁢when⁢ ⁢rmax[1] is less than Q and el is greater than R, wherein Γn is a value of the pitch detection function, n is an index, rmax[1] is a maximum value of rn[1] for n from 1 to K, rn[1] is a first band autocorrelation value, K is a quantity of values in the frequency transformed window, Yn is a value in the frequency transformed window, el is a first band entropy value, and M, P, Q, and R are predetermined positive real values.<br>5) A system controller comprises a pitch candidate selector that selects a future frame pitch candidate from a pitch detection function (PDF), the pitch candidate selector comprising: a fine tune function that determines a fine tune peak frequency of a relative peak of the PDF; a low frequency search function that identifies a smallest low frequency peak of the PDF using the fine tune function; a high frequency search function that identifies a largest high frequency peak of the PDF using the fine tune function; and a rough pitch candidate selector that selects one of the smallest low frequency peak and the largest high frequency peak as a future frame rough pitch candidate.<br>10) A system controller comprises a pitch adjuster that generates a smoothed pitch value for a current frame of digital samples of a voice signal, the pitch adjuster comprising: a subharmonic pitch corrector that determines a future frame pitch value by performing pitch subharmonic correction of a future frame pitch candidate using a roughness factor of the frequency transformed window; and a pitch smoothing function that determines a smoothed pitch value as one of an integer multiple of a current frame pitch value, the current frame pitch value, and an integer sub-multiple of the current frame pitch value.<br>16) A system controller comprises a pitch determiner that generates a smoothed pitch value for a current frame of a low bit rate voice message, the pitch determiner comprising: a band autocorrelator that determines a plurality of band autocorrelations that correspond to a plurality of bands of a frequency transformed window of the digital samples, the frequency transformed window corresponding to a future frame of digital samples, comprising a vector filter that generates a reverse filtered spectrum by performing a magnitude transform, a logarithmic transform, and a reverse spectral filtering of the frequency transformed window, and a spectral autocorrelator that generates the band autocorrelations by applying a spectral autocorrelation function to each band of the reverse filtered spectrum; a pitch function generator that determines a pitch detection function using the plurality of band autocorrelations; a pitch candidate selector that selects a future frame pitch candidate from the pitch detection function; and a pitch adjuster that generates a smoothed pitch value from the future frame pitch candidate and the pitch detection function, comprising a subharmonic pitch corrector that determines a corrected future frame pitch value by performing pitch subharmonic correction of the future frame pitch candidate using a roughness measure of the frequency transformed window, and a pitch smoother that determines a smoothed pitch value from the corrected future frame pitch value, the current frame pitch value, and a past frame pitch value.<br>17) A method used in a system controller that generates a smoothed pitch value for a current frame of a low bit rate voice message, the method comprising the steps of: generating a pitch detection function (PDF) for each frame of digital samples of a voice signal, comprising the step of generating the pitch detection function based on a plurality of band autocorrelations; selecting a future frame pitch candidate from a pitch detection function (PDF), comprising the steps of identifying a smallest low frequency peak of the PDF using a fine tune function, and identifying a largest high frequency peak of the PDF using the fine tune function; and generating the smoothed pitch value, comprising a step of determining a future frame pitch value by performing pitch subharmonic correction of a future frame pitch candidate using a roughness factor of the frequency transformed window.</p></layer>
<layer id = "layer171"><p><b>US6418405B1:Method and apparatus for dynamic segmentation of a low bit rate digital voice message</b><br>Disclosed is a method for producing a polymeric hydroperoxide which forms a radical polymer but no low-molecular radical under redox influence. According to the inventive method, a synthetic polymer containing at least one tertiary hydroxyl group or olefin function is reacted with concentrated hydrogen peroxide and a concentrated mineral acid.<br><b>Independant Claims</b><br>1) A system controller comprises a speech encoder that dynamically segments frames of a low bit rate digital voice message, wherein speech model parameters have been generated in a sequence of frames, the speech model parameters including quantized speech spectral parameter vectors; and wherein the speech encoder comprises a central processor coupled to a memory that controls the central processor to: a) select a first quantized speech spectral parameter vector as a current anchor vector; b) select a second quantized speech spectral parameter vector located a predetermined number of frames (LMAX) from the current anchor vector as a target speech parameter vector; and c) perturb the target speech parameter vector to derive a plurality (K) of perturbed speech parameter vectors.<br>2) A method used in a speech encoder for dynamically segmenting frames of a low bit rate digital voice message, wherein speech model parameters have been generated in a sequence of frames, the speech model parameters including quantized speech spectral parameter vectors, said method comprising the steps of: a) selecting a first quantized speech spectral parameter vector as a current anchor vector; b) selecting a second quantized speech spectral parameter vector located a predetermined number of frames (LMAX) from the current anchor vector as a target speech parameter vector; and c) perturbing the target speech parameter vector to derive a plurality (K) of perturbed speech parameter vectors.<br>9) A method used in a speech encoder for dynamically segmenting frames of a low bit rate digital voice message, wherein speech model parameters have been generated in a sequence of frames, the speech model parameters including quantized speech spectral parameter vectors, said method comprising the steps of: a) selecting a first quantized speech spectral parameter vector as a current anchor vector; b) selecting a second quantized speech spectral parameter vector located a predetermined number of frames (LMAX) from the current anchor vector as a target speech parameter vector; c) perturbing the target speech parameter vector to derive a plurality, K, of perturbed speech parameter vectors; d) quantizing each of the K perturbed speech parameter vectors; e) interpolating between the current anchor vector and each of the plurality (K) of quantized perturbed speech parameter vectors to derive K sets of interpolated speech parameter vectors; f) comparing each set of the K sets of interpolated speech parameter vectors to corresponding sampled speech parameter vectors to derive K distances; g) testing the K distances against a predetermined distance, and h) selecting one of K quantized perturbed speech parameter vectors from a previous frame as a best perturbed speech parameter vector when none of the plurality of distances is less than the predetermined distance.<br>12) A method used in a speech encoder for dynamically segmenting frames of a low bit rate digital voice message, wherein speech model parameters have been generated in a sequence of frames, the speech model parameters including quantized speech spectral parameter vectors, said method comprising the steps of: a) selecting from quantized speech parameter vectors a current anchor vector, a candidate speech parameter vector, and a terminal anchor vector; b) selecting a subset of M quantized speech parameter vectors about and including the candidate vector; and c) perturbing each selected quantized speech parameter vector of the subset of M quantized speech parameter vectors to generate K*M perturbed speech parameter vectors.</p></layer>
<layer id = "layer172"><p><b>US6405168B1:Speaker dependent speech recognition training using simplified hidden markov modeling and robust end-point detection</b><br><b>Independant Claims</b><br>1) A speech processing system that determines an end-point and a beginning point within a speech utterance having a plurality of frames, the speech recognition training system comprising: an element selection circuitry that selects a plurality of elements from a feature vector using at least one criterion, the feature vector is generated using a speech signal; a speech segmentation circuitry that uses the selected plurality of elements from the feature vector to perform clustering of the plurality of frames to segment the speech utterance; and a state determination circuitry that determines a number of states of the speech signal, the number of states of the speech signal corresponds to the number of segments into which the speech signal is segmented.<br>9) A speech recognition training system that generates a model used to perform speech recognition on a speech signal, the speech recognition training system comprising: a model parameter estimation circuitry that receives a plurality of elements from a feature vector, the feature vector is generated using the speech signal; a speech segmentation circuitry that uses the plurality of elements from the feature vector to segment the speech signal; and a state determination circuitry that determines a number of states of the speech signal, the number of states of the speech signal corresponds, at least in part, to the number of segments into which the speech signal is segmented.<br>16) A method that generates a model used to perform speech recognition on a speech signal, the method comprising: selecting a plurality of elements from a feature vector, the feature vector is generated using the speech signal; segmenting the speech signal using the plurality of elements from the feature vector; and determining a number of states of the speech signal, the number of states of the speech signal corresponds to the number of segments into which the speech signal is segmented.</p></layer>
<layer id = "layer173"><p><b>US6523002B1:Speech coding having continuous long term preprocessing without any delay</b><br>Medical devices incorporate therein imaging materials having selected MRI detectable nuclei to provide useful magnetic resonance images of the medical devices and proximate body tissue. Also, a method generates MRI images of such a medical device, and involves performing first and second MRI processes on a body portion including at least a portion of the medical device to obtain, respectively, first and second image data. The first MRI process is adapted to detect MRI detectable nuclei present in the proximate body tissue, and the second MRI process is adapted to detect the selected MRI detectable nuclei contained in the device's imaging material. The selected MRI detectable nuclei incorporated in the imaging material is not the same nuclei that the first MRI process is adapted to detect. The second image data are combined with the first image data to produce image data for the medical device and the proximate body tissue.<br><b>Independant Claims</b><br>1) A speech codec having a pitch track coding circuitry that operates on a speech signal, the pitch track coding circuitry of the speech codec comprising: a pitch lag selection circuitry that selects an end-of-frame pitch lag, the end-of-frame pitch lag is selected from a speech frame of the speech signal, the pitch lag selection circuitry determines a global pitch track for the speech fame using the end-of-frame pitch lag; a residual modification and warping circuitry that adjusts a local pitch track of the speech frame on a speech sub-fame basis; and wherein the speech signal comprises a plurality of speech frames, each speech frame of the plurality of speech frames contains a plurality of speech sub-frames, each speech sub-frame of the plurality of speech sub-frames has a corresponding pitch lag, the residual modification and warping circuitry adjusts at least one of the corresponding pitch lags.<br>10) A speech codec having a pitch track coding circuitry that operates on a speech signal, the pitch track coding circuitry of the speech codec comprising: a pitch lag selection circuitry that selects a first pitch lag for a speech frame of the speech signal, the first pitch lag determines a global pitch track for the speech frame; and a residual modification and warping circuitry that adjusts a local pitch track of the speech frame an a speech sub-frame basis, the local pitch track of the speech frame is adjusted by modifying and warping a selected plurality of points within the speech frame.<br>16) A method that modifies and wraps a speech coding residual of a speech signal, the method comprising: calculating the speech coding residual of the speech signal, the speech coding residual contains an initial estimate of pitch track; determining an initial estimate for a pitch track of the speech signal; and modifying and warping the speech coding residual on a speech sub-frame basis to provide a better fit of the pitch track of the speech coding residual.</p></layer>
<layer id = "layer174"><p><b>US4519094A:LPC Word recognizer utilizing energy features</b><br>An apparatus and method for removing stored energy from a storage phosphor screen in which a radiation image was recorded and then read by collecting stimulated emission from the phosphor sheet. The phosphor sheet is transported along a path in a first direction at a first speed into an erase area having at least one erasing light source. A portion of the phosphor sheet disposed within the erase area is exposed to the light source to affect erasure of the radiation image on the exposed portion of the phosphor sheet. Transport of the phosphor sheet is stopped when the trailing edge of the phosphor sheet enters the erase area and the phosphor sheet dwells within the erase area for a predetermined time period. The phosphor sheet is then transported along the path in a second direction at a second speed, and then transported along the path in the second direction at a third speed when the leading edge exits the erase area.<br><b>Independant Claims</b><br>1. A speech analyzer for recognizing a speech pattern comprising: means for storing a plurality of reference pattern templates, each template including a time frame sequence of acoustic feature signals of a prescribed reference pattern; means responsive to the speech pattern for generating a time frame sequence of acoustic feature signals corresponding to said speech pattern; means responsive to the feature signals of said speech pattern and said reference pattern templates for generating a set of signals each representative of the similarity between the feature signal sequence of the speech pattern and the feature signal sequence of one of said reference patterns; and means responsive to said similarity signals for identifying the speech pattern as one of the reference patterns; said prescribed reference feature signal sequence and said speech pattern feature signal sequence each comprising at least a time frame sequence of predetermined type acoustic spectral feature signals and a time frame sequence of predetermined type acoustic nonspectral feature signals; said similarity signal generating means including: means responsive to said time frame sequences of speech pattern and reference template spectral and nonspectral feature signals for generating a plurality of signals for each time frame of the speech pattern including a signal measuring the correspondence between said spectral feature signals of the speech pattern time frame and the spectral feature signals of the reference pattern template and a signal measuring the correspondence between the nonspectral feature signals of the speech pattern time frame and the nonspectral feature signals of the reference pattern template; and means responsive to the plurality of correspondence measuring signals for forming a signal for the reference pattern representative of the similarity between said speech pattern and said reference pattern.<br>10. In a speech analyzer having a plurality of stored reference pattern templates, each comprising a time frame sequence of feature signals of a prescribed reference pattern, a method for recognizing a speech pattern comprising the steps of: generating a time frame sequence of acoustic feature signals corresponding to said speech pattern; generating a set of signals each representative of the similarity between the feature signal sequence of the speech pattern and the feature signal sequence of one of said reference patterns responsive to the feature signals of said speech pattern and said reference pattern templates; and identifying the speech pattern as one of said reference patterns responsive to said similarity signals; said prescribed reference feature signal sequence and said speech pattern feature signal sequence each comprising at least a time frame sequence of predetermined type acourstic spectral feature signals and a time frame sequence of predetermined type acoustic nonspectral feature signals; said similarity signal generating step comprising: generating a plurality of signals for each time frame of the speech pattern, including a signal measuring the correspondence between said spectral feature signals of the speech pattern time frame and the spectral feature signals of the reference pattern template and a signal measuring the correspondence between the nonspectral feature signals of the speech pattern and the nonspectral feature signals of the reference pattern template responsive to said time frame sequences of speech pattern and reference pattern template spectral and nonspectral feature signals; and forming a signal for the reference pattern representative of the similarity between said speech pattern and said reference pattern responsive to the plurality of correspondence measuring signals.</p></layer>
<layer id = "layer175"><p><b>US20010021908A1:SYSTEM FOR ADJUSTING PSYCHO-ACOUSTIC PARAMETERS IN A DIGITAL AUDIO CODEC</b><br>An aircraft landing gear wheel stowage structure including a wing rear spar extending laterally across the aircraft; a mid bulkhead extending laterally across the aircraft and displaced rearwardly of the wing rear spar; a pressure bulkhead extending laterally across the aircraft and displaced rearwardly of the mid bulkhead; first and second longitudinal keel structures laterally spaced on each side of a longitudinal axis of the aircraft and traversing the wing rear spar, the mid bulkhead and the pressure bulkhead. The wing rear spar, the mid bulkhead, the first keel structure, and the second keel structure form a first forward outboard wheel well compartment that is outboard of the first keel structure, a second forward outboard wheel well compartment that is outboard of the second keel structure, and a forward central wheel well compartment that is between the first keel structure and the second keel structure. The mid bulkhead, the pressure bulkhead, the first keel structure, and the second keel structure form a first aft outboard wheel well compartment that is outboard of the first keel structure and behind the first forward outboard wheel well compartment, and a second aft outboard wheel well compartment that is outboard of the second keel structure and behind the second forward outboard wheel well compartment. A horizontal pressure panel forms the ceilings of the wheel well compartments.<br><b>Independant Claims</b><br>1. An audio CODEC for providing high quality digital audio comprising: an analog to digital converter for converting an analog audio signal to a digital audio bit stream; an encoder for compressing said digital audio bit stream; a decoder for decompressing said compressed digital audio bit stream; an output allowing a user to monitor the digital audio output; and at least one control for allowing said user to adjust said digital audio output.<br>2. A method for providing high quality digital audio comprising the steps of: providing an input analog audio signal; providing at least one psycho-acoustic parameters; converting said input analog audio signal into a digital signal; coding said digital signal in accordance with said at least one psycho-acoustic parameter; decompressing said digital signal to provide an output audio signal; and providing an adjustment means for allowing the user to adjust said at least one psycho-acoustic parameter.</p></layer>
<layer id = "layer176"><p><b>US5706395A:Adaptive weiner filtering using a dynamic suppression factor</b><br>The meshing between a rack which moves according to steering operation and a sector gear meshed with the rack is adjusted by the movement of an output shaft in its own axis direction which is united with the sector gear. A through hole is formed along the axis center line of the output shaft, and a threaded shaft is inserted into the through hole. The threaded shaft is screwed into the output shaft. One end of the threaded shaft is accessible for rotating from the side where a steering mechanism member is mounted. The other end of the threaded shaft is connected to a housing in a manner that the threaded shaft is rotatable around in its own axis but that the threaded shaft is unmovable in its own axis direction.<br><b>Independant Claims</b><br>1. A filter, comprising: (a) an input for receiving frames of sampled signals; (b) an attenuation filter coupled to said input, wherein said attenuation filter includes a noise suppression factor with said noise suppression factor depending on E.sub.N divided by E.sub.Y where E.sub.N is an estimate of noise energy of a frame and E.sub.Y is an estimate of signal energy of said frame; and (c) an output coupled to said attenuation filter for emitting filtered frames.<br>10. A method of filtering a stream of sampled acoustic signals, comprising the steps of: (a) partitioning a stream of sampled acoustic signals into a sequence of frames; (b) Fourier transforming said frames to yield a sequence of transformed frames; (c) applying a generalized Wiener filter with a noise suppression factor to said transformed frames to yield a sequence of filtered transformed frames, wherein said noise suppression factor of said filter for a transformed frame depends upon estimates of the signal-to-noise ratio of said transformed frame; and (d) inverse Fourier transforming said sequence of filtered transformed frames to yield a sequence of filtered frames.<br>12. A speech system comprising: a. a speech acquiring module; b. a noise suppressing module couple to said acquiring module; c. an analyzing module coupled to said suppressing module; d. a transmitting/storing module coupled to said analyzing module; e. a synthesizing module coupled to said transmitting/storing module; f. a playingback module coupled to said synthesizing module; g. wherein said noise suppressing module includes an attenuating filter with a noise suppressing factor depending upon E.sub.N divide by E.sub.Y where E.sub.N is an estimate of noise energy of a frame of speech and E.sub.Y is an estimate of signal energy of said frame.</p></layer>
<layer id = "layer177"><p><b>USRE43191E1:Adaptive Weiner filtering using line spectral frequencies</b><br>A detection system for remotely determining the speed of a rotating tool tip in a pneumatic dental handpiece. A means for detecting the speed of the rotating tool tip monitors a periodic mechanical function at the pneumatic hose connected to the handpiece. The monitored periodic mechanical function serves to provide feedback that is used to control the speed of the rotating tool tip. The means for detecting the speed of the rotating tool detects a mechanical function of the rotating tool tip, which in transmitted to a controller. The controller in turn regulates the operation of an air supply valve in response to the detected mechanical function. The valve regulates the flow of air to the handpiece. By continuously adjusting the flow of air through the valve into the pneumatic hose, the speed of the rotating tool is maintained at the desired cutting speed.<br><b>Independant Claims</b><br>1) A method of filtering a stream of sampled acoustic signals, comprising the steps of: (a) partitioning athe stream of sampled acoustic signals into a sequence of frames; (b) Fourier transforming said flamesthe frames using processing circuitry to yield a sequence of transformed frames; (c) applying a generalized Wiener filter to saidthe transformed frames to yield a sequence of filtered transformed frames, wherein saidthe filter uses power spectrum estimates from LSFsline spectral frequencies (LSFs) defined as weighted sums of LSFs of a codebook of LSFs with the weights determined by the LSFs of saidthe transformed frames; and (d) inverse Fourier transforming said sequence of filtered transformed frames to yield a sequence of filtered frames.<br>4) 4. A method of noise suppression filtering for a sequence of frames of noisy speech, comprising: filtering a frame of noisy speech that includes the sub-steps of: estimating a noise power spectrum, PNOISE(ω), of the frame of noisy speech, wherein the variable ω is the discrete frequency; computing a noisy speech power spectrum for the frame of noisy speech using processing circuitry; smoothing noisy speech power spectrum with respect to the variable ω to yield a smoothed noisy speech power spectrum, PSMOOTHEDNOISYSPEECH(ω), for the frame of noisy speech; defining a noise-suppression filter using the noisy speech power spectrum, and the smoothed noisy speech power spectrum; filtering the frame of noisy speech with the noise suppression filter; and repeating the step of filtering for each frame of noisy speech for a plurality of frames of noisy speech.</p></layer>
<layer id = "layer178"><p><b>US4980916A:Method for improving speech quality in code excited linear predictive speech coding</b><br>A method for preparing 2-alkenylimidazoles from readily available 2-alkylimidazoles or 2-alkylimidazolines by dehydrogenating the 2-alkylimidazole or 2-alkylimidazoline in the presence of a suitable dehydrogenation catalyst. The preferred method provides 2-vinylimidazole by dehydrogenating 2-ethylimidazole or 2-ethylimidazoline. The reaction is advantageously carried out in a vapor phase in the presence of an inert carrier gas using as preferred dehydrogenation catalysts, copper chromites and catalysts comprising one or more of the metals molybdenum, iron, cobalt, zinc or chromium on non-reducible oxide supports such as alumina or silica.<br><b>Independant Claims</b><br>1. A method for improving speech quality in code excited linear predictive voice coders, comprising the steps of: determining a pitch predictor tap gain as a normalized cross-correlation of an input sequence and pitch buffer samples by copying previous samples at a distance of P samples so as to extend pitch buffer length; modifying a pitch synthesis filter so that a pitch predictor output sequence is a series computed for each interval P; and simultaneously solving for pulse amplitudes and pitch tap gain, thereby minimizing estimator bias in the code excitation.<br>2. A code excited linear predictive coder comprising: linear predictive code analysis means for receiving an input signal and generating from said input signal a set of linear predictive filter coefficients; weighting means for receiving said input sequence and said set of linear predictive filter coefficients for generating a weighted input sequence; codebook means for generating output codewords; first weighted linear predictive synthesis filter means responsive to said set of linear predictive filter coefficients and said codewords for generating synthesis filtered codewords; pitch filter means for generating pitch excitation sequences; second weighted linear predictive synthesis filter means responsive to said set of linear predictive filter coefficients and said pitch excitation sequences for generating synthesis filtered pitch excitation sequences; equation solving means receiving said weighted input sequence, said synthesis filtered codewords and said synthesis filtered pitch excitation sequences for computing a pitch predictor tap gain and a codeword excitation gain; first multiplying means for multiplying said codebook output sequences by said codeword excitation gain to produce a codebook excitation output signal; second multiplying means for multiplying said pitch excitation sequences by said pitch predictor tap gain to produce a pitch predictive excitation; and summing means for summing said codebook excitation output signal and said pitch predictive excitation to generate a combined excitation to be transmitted with said linear prediction coefficients.<br>4. A method of generating an excitation sequence for transmission with linear predictive coefficients of an input signal in a code excited linear predictive speech coder, comprising the steps of: computing a pitch lag by finding the location of a maximum cross-correlation between a weighted input sequence and synthesis-filtered contents of a pitch buffer of the coder; generating an unscaled pitch prediction sequence using the computed pitch lag and a pitch tap gain of 1.0; passing the unscaled pitch prediction sequence through a weighted linear predictive synthesis filter to produce an unscaled weighted synthesis pitch prediction sequence; computing a pitch prediction sequence variance from the unscaled weighted synthesis pitch prediction sequence and a cross-correlation between the weighted input sequence and unscaled weighted synthesis pitch prediction sequence; conducting an exhaustive Gaussian codebook search and, for each codeword output sequence obtained from said codebook, computing a codeword output sequence variance and a cross-correlation between the codeword output sequence and the weighted input sequence; determining optimal values for codeword gain and pitch tap gain from said computed variances and said cross-correlations; multiplying the pitch prediction sequence by the optimal value of pitch tap gain to arrive at a scaled pitch prediction sequence; multiplying the codeword output sequence by the optimal codeword gain to arrive at a scaled codeword sequence; and summing the scaled pitch and codeword sequences to generate parameters representing said excitation sequence.</p></layer>
<layer id = "layer179"><p><b>US6513004B1:Optimized local feature extraction for automatic speech recognition</b><br>A method and apparatus for storing data in a memory device is described. The apparatus is configured to perform the following steps. The method employs a two-step technique which allows the out-of-order completion of read and write operations. When a write operation requires a resource needed for the completion of a read operation, the data being written is stored in a write data buffer in the memory device. The write data is stored in the buffer until a datapath is available to communicate the data to the memory device's memory core. Once the resource is free (or the memory device, or its controller force the write to complete) the data is written to the memory core of the memory device using the now-free datapath.<br><b>Independant Claims</b><br>1) A method of extracting features for automatic speech recognition, comprising: decomposing an acoustic speech signal using a set of wavelets, where the set of wavelets is organized into a set of subsignals in a data structure having a plurality of frequency subband nodes; computing the average magnitude of each subsignal respective to each node; defining and selecting a wavelet basis to enhance discrimination of particular classes of sounds; and applying said basis to said set of wavelets to generate from said computed average magnitudes a plurality of decomposition coefficients representing features extracted from said acoustic speech signal.<br>19) The method of claim 19 wherein said first class of sounds corresponds to a first level of discrimination between broad classes of sounds and wherein said second class of sounds corresponds to a second level of discrimination between narrow classes of sounds.<br>20) A method of extracting features for automatic speech recognition, comprising: decomposing an acoustic speech signal using a set of wavelets, where the set of wavelets is organized into a tree structure having a plurality of nodes; defining and selecting a wavelet basis to enhance discrimination of particular classes of sounds, including selecting a portion of said nodes by computing the discriminative power of a first one of said nodes, further computing the discriminative power of the child nodes of said first one of said nodes and pruning said child nodes if the sum of the discriminative powers of said child nodes is less than the discriminative power of said first one of said nodes; and applying said basis to said set of wavelets to generate a plurality of decomposition coefficients representing features extracted from said acoustic speech signal.<br>21) A method of extracting features for automatic speech recognition, comprising: decomposing an acoustic speech signal using a set of wavelets, where the set of wavelets is organized into an unbalanced tree structure, such that speech signals at lower frequencies undergo filtering at a higher frequency resolution than speech signals at higher frequencies; defining and selecting a wavelet basis to enhance discrimination of particular classes of sounds; and applying said basis to said set of wavelets to generate a plurality of decomposition coefficients representing features extracted from said acoustic speech signal.</p></layer>
<layer id = "layer180"><p><b>US6366880B1:Method and apparatus for suppressing acoustic background noise in a communication system by equaliztion of pre-and post-comb-filtered subband spectral energies</b><br>The present invention discloses an optical switching element that uses reversible electroplating mirrors includes a trench with transparent sidewalls located at the intersection of two waveguides A and B. The trench has two electrodes; one, which is transparent, is placed on the trench sidewall and the other is placed on the trench floor. The trench is filled with an index-matching electrolytic solution containing ions of a metal that can electro-deposit on these two electrodes. To actuate the switching element, a negative electrical potential is applied to the sidewall electrode. Actuation causes metal deposits to form on the sidewall electrode, creating a mirror that reflects light from waveguide A to waveguide B. To deactivate the switching element, a positive electrical potential is applied to the sidewall electrode. Deactivation causes metal deposits move off the sidewall and form on the trench floor. The lack of metal deposits on the sidewall allows light to pass through the switching element and continue along the original waveguide A<br><b>Independant Claims</b><br>1) A method of suppressing acoustic background noise in a communication system comprising the steps of: generating a frequency spectrum of an input signal; determining a measure of the periodicity of the input signal; determining a gain function from at least the measure of periodicity of the input signal; applying the gain function to the frequency spectrum of the input signal; and equalizing the energy of a plurality of frequency bands of the corresponding pre and post filtered spectra.<br>5) A method of suppressing acoustic background noise in a communication system comprising the steps of: generating a frequency spectrum of an input signal; determining a gain function from at least a measure of periodicity of the input signal; applying the gain function to the frequency spectrum of the input signal; and equalizing the energy of a plurality of frequency bands of the corresponding pre and post filtered spectra.<br>8) An apparatus for suppressing acoustic background noise in a communication system comprising: means for generating a frequency spectrum of an input signal; means for determining a measure of the periodicity of the input signal; means for determining a gain function from at least the measure of periodicity of the input signal; means for applying the gain function to the frequency spectrum of the input signal; and means for equalizing the energy of a plurality of frequency bands of the corresponding pre and post filtered spectra.<br>12) An apparatus for suppressing acoustic background noise in a communication system comprising: means for generating a frequency spectrum of an input signal; means for determining a gain function from at least a measure of periodicity of the input signal; means for applying the gain function to the frequency spectrum of the input signal; and means for equalizing the energy of a plurality of frequency bands of the corresponding pre and post filtered spectra.</p></layer>
<layer id = "layer181"><p><b>US3982070A:Phase vocoder speech synthesis system</b><br>An embodiment of the present invention is an air brush including a housing, a head assembly, and a trigger assembly. The housing has a main body with an air valve, reservoir and a handle. The head assembly mounts to the main body with a nozzle, nozzle cap, and a needle cap. The trigger assembly fits within the housing and includes a needle engaging the head assembly, a needle chucking guide, a needle chucking nut, a lever assembly, a spring guide and a spring device. The lever assembly actuates the needle to release compressed air and contents of the reservoir. The spring device controls release of the contents relative to the air flow through the air valve and nozzle. The spring device includes a first spring, a second spring, and a ring member. The ring member is positioned between the springs, and the springs have different strengths.<br><b>Independant Claims</b><br>1. Apparatus for synthesizing a natural sounding speech message from phase vocoder stored signals representative of a vocabulary of words comprising: means for selectively extracting preselected locations of said stored signals for constructing a predetermined sequence of signals representative of said speech message; means for altering the pitch parameters of said extracted signals; and means for combining said pitch modified signals.<br>2. Apparatus for synthesizing a natural sounding speech message comprising: means for storing phase vocoder signals representative of a vocabulary of words; first means, responsive to an applied duration control signal, for selectively extracting from said means for storing preselected signals to form a duration modified sequence of signals representative of said speech message; means for altering the pitch parameters of said extracted signals; and means for combining said signals modified in pitch and duration to form a sum signal for activating a speech synthesizer.<br>3. Apparatus for generating natural sounding synthesized speech comprising: a memory for storing phase vocoder encoded signals representative of a vocabulary of words; means for extracting signals from selected storage locations of said memory to affect the duration of said synthesized speech; means for altering the pitch parameters of said extracted signals to affect the pitch of said synthesized speech; and means for phase vocoder decoding of said altered signals to form said synthesized speech signal.<br>4. A system for synthesizing speech messages from phase vocoder encoded word signals stored in a memory comprising: means for extracting selected signals from said memory a repeated number of times to affect the duration of said speech messages; means for altering the pitch parameters of said extracted signals; and means for decoding said pitch and duration altered signals to form said speech messages.<br>5. A system for composing speech messages from phase vocoder encoded and stored words comprising: means for extracting selected signals from said encoded stored words a repeated number of times to affect the duration of said composed speech; means for altering the pitch parameters of said extracted signals; means for interpolating the spectrum parameters of said extracted signals; and means for decoding said interpolated and pitch altered signals to form a composed speech message signal.<br>6. Apparatus for synthesizing natural sounding speech comprising: a phase vocoder analyzer responsive to an applied vocabulary of words; means for storing the output signals of said analyzer; means for extracting the signals of selected storage locations in said means for storing; means for modifying the pitch parameters of said extracted signals; and means for converting said pitch modified signals in accordance with phase vocoder techniques to develop a natural sounding speech signal.<br>7. Apparatus for processing phase vocoder type representations of selected prerecorded spoken words to form a description of a desired message suitable for actuating a speech synthesizer to develop synthesized speech, which comprises: first means, for encoding said prerecorded words in accordance with phase vocoder techniques to form short-time Fourier transform signal vectors and phase derivative signal vectors; second means, for storing said phase derivative and said short-time Fourier transform signal vectors; third means, for extracting selected locations of said stored signals a preselected number of times of control the duration of said synthesized speech; fourth means, for modifying said phase derivative signal vectors to control the pitch of said synthesized speech; fifth means, for interpolating the shorttime Fourier transform signal vectors in accordance with predetermined rules responsive to an applied duration control signal and to the modified phase derivative signal vectors to effect a smooth spectrum envelope; and sixth means, for combining said modified phase derivative signal vector and said spectrum interpolated short-time Fourier transform signal vector in accordance with phase vocoder techniques to form a synthesized speech signal suitable for actuating said speech synthesizer.<br>11. Apparatus for processing phase vocoder type representations of selected prerecorded spoken words to form a description of a desired message suitable for actuating a speech synthesizer to develop synthesized speech, which comprises: first means, for encoding said prerecorded words in accordance with phase vocoder techniques to form short-time Fourier transform signal vectors and phase derivative signal vectors; second means, for storing said phase derivative and said short-time Fourier transform signal vectors; third means, for extracting selected locations of said stored signals a preselected number of times to control the duration of said synthesized speech; fourth means, for modifying said phase derivative signal vectors to control the pitch of said synthesized speech; and fifth means, for combining said modified phase derivative signal vector and said duration controlled short-time Fourier transformed signal vector in accordance with phase vocoder techniques to form a synthesized speech signal suitable for actuating said speech synthesizer.<br>12. A method for synthesizing a natural sounding speech message from phase vocoder stored signals representative of a vocabulary of words comprising the steps of: selectively extracting preselected locations of said stored signals for the construction of a predetermined sequence of signals representative of said speech message; altering the pitch parameters of said extracted signals; and combining said pitch modified signals.<br>13. A method for synthesizing a natural sounding speech message comprising the steps of: storing phase vocoder signals representative of a vocabulary of words; selectively extracting from said stored signals preselected signals forming a duration modified predetermined sequence of signals representative of said speech message; altering the pitch parameters of said extracted signals; and combining said pitch and function modified signals to form a sum signal for activating a speech synthesizer.<br>14. A method for composing speech message from phase vocoder encoded and stored words comprising the steps of: extracting selected signals from said encoded stored words a repeated number of times to affect the duration of synthesized speech; altering the pitch parameters of said extracted signals; interpolating the spectrum parameters of said extracted signal; and phase vocoder decoding of said interpolated and pitch and duration altered signals to form a speech message signal.<br>15. A method for processing phase vocoder type representations of selected prerecorded spoken words to form a description of a desired message suitable for actuating a speech synthesizer to develop synthesized speech, which comprises the steps of: encoding said prerecorded words in accordance with phase vocoder techniques to form short-time Fourier transform signal vectors and phase derivative signal vectors; storing said phase derivative and said short-time Fourier transform signal vectors; extracting selected locations of said stored signals a preselected number of times to control the duration of said synthesized speech; modifying said phase derivative signal vectors to control the pitch of said synthesized speech; interpolating the short-time Fourier transform signal vectors in accordance with predetermined rules responsive to an applied duration control signal and to the modified phase derivative signal vectors to effect a smooth spectrum envelope; and combining said modified phase derivative signal vectors and said spectrum interpolated shorttime Fourier transform signal vectors in accordance with phase vocoder techniques to form a synthesized speech signal suitable for actuating said speech synthesizer.</p></layer>
<layer id = "layer182"><p><b>US5732389A:Voiced/unvoiced classification of speech for excitation codebook selection in celp speech decoding during frame erasures</b><br>The systems and methods of the present invention facilitate database row-level security by utilizing SQL extensions to create and associate named security expressions with a query initiator(s). Such expressions include Boolean expressions, which must be satisfied by a row of data in order for that data to be made accessible to the query initiator. In general, a query is augmented with security expressions, which are aggregated and utilized during querying rows of data. The systems and methods variously place security expressions within a query in order to optimize query performance while mitigating information leaks. This is achieved by tagging security expressions as special and utilizing rules of predicate to pull or push non-security expressions above or below security expressions, depending on the likelihood of a non-security being safe, as determined via a static and/or dynamic analysis.<br><b>Independant Claims</b><br>1. A method for use in a speech decoder which includes a first portion comprising an adaptive codebook and a second portion comprising a fixed codebook, said decoder generating a speech excitation signal selectively based on output signals from said first and second portions when said decoder fails to receive reliably at least a portion of a current frame of compressed speech information, the method comprising: classifying a speech signal to be generated by the decoder as representing periodic speech or as representing non-periodic speech; based on the classification of the speech signal, either generating said excitation signal based on the output signal from said first portion and not on the output signal from said second portion if the speech signal is classified as representing periodic speech, or generating said excitation signal based on the output signal from said second portion and not on the output signal from said first portion if the speech signal is classified as representing non-periodic speech.<br>11. A speech decoder for generating a speech signal based on compressed speech information received from a communication channel, the decoder comprising: an adaptive codebook memory; a fixed codebook memory; means for classifying the speech signal to be generated by the decoder as representing periodic speech or as representing non-periodic speech; means for forming an excitation signal, said means comprising first means for forming an excitation signal when said decoder fails to receive reliably at least a portion of a current frame of compressed speech information, said first means forming said excitation signal based on a vector signal from said adaptive codebook memory and not based on a vector signal from said fixed codebook memory, when the speech signal to be generated is classified as representing periodic speech, and based on a vector signal from said fixed codebook memory and not on a vector signal from said adaptive codebook memory, when said speech signal to be generated is classified as representing non-periodic speech; and a linear predictive filter for synthesizing a speech signal based on said excitation signal.</p></layer>
<layer id = "layer183"><p><b>US5664055A:CS-ACELP speech compression system with adaptive pitch prediction filter gain based on a measure of periodicity</b><br>Hydrogen gas sensors employ an epitaxial layer of the thermodynamically stable form of aluminum nitride (AlN) as the “insulator” in an MIS structure having a thin metal gate electrode suitable for catalytic dissociate of hydrogen, such as palladium, on a semiconductor substrate. The AlN is deposited by a low temperature technique known as Plasma Source Molecular Beam Epitaxy (PSMBE). When silicon (Si) is used the semiconducting substrate, the electrical behavior of the device is that of a normal nonlinear MIS capacitor. When a silicon carbide (SiC) is used, the electrical behavior of the device is that of a rectifying diode. Preferred structures are Pd/AlN/Si and Pd/AlN/SiC wherein the SiC is preferably 6H—SiC.<br><b>Independant Claims</b><br>1. A method for use in a speech processing system which includes a first portion comprising an adaptive codebook and corresponding adaptive codebook amplifier and a second portion comprising a fixed codebook coupled to a pitch filter, the pitch filter comprising a delay memory coupled to a pitch filter amplifier, the method comprising: determining the pitch filter gain based on a measure of periodicity of a speech signal; and amplifying samples of a signal in said pitch filter based on said determined pitch filter gain.<br>7. A speech processing system comprising: a first portion including an adaptive codebook and means for applying an adaptive codebook gain, and a second portion including a fixed codebook, a pitch filter, wherein the pitch filter includes a means for applying a pitch filter gain, and wherein the improvement comprises: means for determining said pitch filter gain, based on a measure of periodicity of a speech signal.<br>17. A method for determining a gain of a pitch filter for use in a speech processing system, the system including a first portion comprising an adaptive codebook and corresponding adaptive codebook amplifier and a second portion comprising a fixed codebook coupled to a pitch filter, the pitch filter comprising a delay memory coupled to a pitch filter amplifier for applying said determined gain, the speech processing system for processing a speech signal, the method comprising: determining the pitch filter gain based on periodicity of the speech signal.<br>18. A method for use in a speech processing system which includes a first portion which comprises an adaptive codebook and corresponding adaptive codebook amplifier and a second portion which comprises a fixed codebook coupled to a pitch filter, the pitch filter. comprising a delay memory coupled to a pitch filter amplifier, the method comprising: delaying the adaptive codebook gain; determining the pitch filter gain to be equal to the delayed adaptive codebook gain, except when the adaptive codebook gain is either less than 0.2 or greater than 0.8., in which cases the pitch filter gain is set equal to 0.2 or 0.8, respectively; and amplifying samples of a signal in said pitch filter based on said determined pitch filter gain.<br>19. A speech processing system comprising: a first portion including an adaptive codebook and means for applying an adaptive codebook gain, and a second portion including a fixed codebook, a pitch filter, means for applying a second gain, wherein the pitch filter includes a means for applying a pitch filter gain, and wherein the improvement comprises: means for determining said pitch filter gain, said means for determining including means for setting the pitch filter gain equal to an adaptive codebook gain, said signal gain is either less than 0.2 or greater than 0.8., in which cases-the pitch filter gain is set equal to 0.2 or 0.8, respectively.</p></layer>
<layer id = "layer184"><p><b>US4731846A:Voice messaging system with pitch tracking based on adaptively filtered LPC residual signal</b><br>An inventive solid phase forming process, and related structure, using conventional pelletized thermoplastic compositions to form the of a non-textile fabric by coining a single pellet or briquette of the polymer into an individual element in a single forming step. The steps of the process generally include: a) positioning a pellet in or adjacent to a mold cavity, and b) forcing the pellet into contact with the mold surfaces of the mold cavity to plastically deform the pellet to cause the pellet to adapt the shape of the mold cavity. The mold cavity has a shape to form the desired element, and its volume is substantially the same as the volume of the pellet. The forcing step or act preferably uses an energy and speed where the pellet superplastically deforms to substantially fill the volume of the mold cavity. This process is repeated with the particular element being formed in the appropriate order to form interconnected plates and rivets, as an example, with the final result being a non-textile fabric. The elements formed by the inventive process can have any of a variety of shapes, and can form base units for the formation of the non textile fabric of two, three or more elements. This inventive process eliminates the need to first form the pelletized polymer into a sheet or other type of preform prior to the forming of the final product.<br><b>Independant Claims</b><br>1. A voice messaging system for encoding and regenerating human speech comprising: LPC analysis means for analyzing an analog speech signal provided as an input thereto in accordance with an LPC (Linear Predictive Coding) model, said LPC analysis means providing LPC parameters and a residual signal as an output representative of the analog speech signal; adaptive filter means operably coupled to the output of said LPC analysis means for receiving said residual signal and at least one LPC parameter from said LPC analysis means, said adaptive filter means filtering said residual signal in accordance with a time-varying filter characteristic defined by said at least one LPC parameter, wherein the time-varying filter characteristic provides for the removal of high frequency noise from the residual signal during periods of voiced speech and for the retention of high frequency energy in the residual signal during periods of unvoiced speech, to provide an adaptively filtered residual signal as an output therefrom; means operably connected to the output of said adaptive filter means for extracting pitch and voicing information from said adaptively filtered residual signal; and means operably connected to the outputs of said extracting means and said LPC analysis means for encoding said pitch and voicing information and said LPC parameters.<br>5. A method for determining the pitch of human speech comprising the steps of: analyzing a speech signal input in accordance with an LPC (Linear Predictive Coding) model to provide LPC parameters and a residual signal; adaptively filtering said residual signal in accordance with a time-varying filtering characteristic as defined by at least one of said LPC parameters provided by the analyzing of said speech signal input, wherein the time-varying filtering characteristic provides for the removal of high frequency noise from the residual signal during periods of voiced speech and for the retention of higher frequency energy in the residual signal during periods of unvoiced speech, to provide an adaptively filtered residual signal; and extracting pitch period candidates from said adaptively filtered residual signal.<br>16. A method for determining the pitch of human speech, comprising the steps of: receiving an input speech signal at a sample rate; analyzing said input speech signal according to an LPC (Linear Predictive Coding) model to provide LPC parameters and a residual signal, wherein said LPC parameters are calculated in a sequence of frames at a predetermined frame rate, and wherein the sample rate at which said input speech signal is received is much higher than said frame rate; adaptively filtering said residual signal by a filter having a time-varying filtering characteristic defined by at least one of said LPC parameters provided by said LPC analyzing step, wherein the time-varying filtering characteristic provides for the removal of high frequency noise from the residual signal during periods of voiced speech and for the retention of high frequency energy in the residual signal during periods of unvoiced speech, to provide an adaptively filtered residual signal; extracting pitch period candidates from said adaptively filtered residual signal; performing dynamic programming with respect both to said pitch period candidates for each frame and also to a voiced/unvoiced decision for each frame to determine both an optimal pitch period and an optimal voicing decision for each frame, in the context of said sequence of frames, said dynamic programming step defining a transition error between each period candidate of the current frame and each candidate of the preceding frame and wherein a cumulative error is defined for each pitch period candidate in the current frame which is equal to the transition error between said pitch period candidate of said current frame plus the cumulative error at an optimally identified pitch period candidate in the preceding frame chosen from among said pitch period candidates in said preceding frame such that the cumulative error of said corresponding pitch period candidate in said current frame is at a minimum; and determining an optimal pitch and voicing decision for each said frame in accordance with said dynamic programming performance.</p></layer>
<layer id = "layer185"><p><b>US4696038A:Voice messaging system with unified pitch and voice tracking</b><br>A system for keeping a dispensing apparatus for a zigzag folded web of towel material optimally filled, which system is provided with a holder included in a housing for receiving a stock of zigzag folded web of towel material, which, on the one side, runs from the holder to a space of use and, on the other side, has an end that is connectable with a first free end of a correspondingly zigzag folded web of towel material forming a refill stock. The holder is provided with a fill meter with, in thickness direction of the stock of zigzag folded web of towel material, a division into at least three areas each having its own coding, with a first upper coding in said thickness direction indicating that no refilling is required, a second coding following the first indicating refilling with a refill stock provided with a coding equal to the second coding and each further coding indicating refilling with an increasingly thicker refill stock with corresponding coding.<br><b>Independant Claims</b><br>1. In a voice messaging system for receiving a human speech signal and reconstituting said human speech signal at a receiver which is spatially or temporally remote, the combination comprising: LPC analysis means for analyzing an analog speech signal provided as an input thereto in accordance with an LPC (Linear Predictive Coding) model, said LPC analysis means providing LPC parameters and a residual signal organized in a sequence of speech data frames and the respective residual signals corresponding thereto as an output representative of the analog speech signal; pitch extraction means operably associated with said LPC analysis means for determining a plurality of pitch candidates for each of the speech data frames in said sequence; optimization means operably associated with said LPC analysis means and said pitch extraction means for performing dynamic programming with respect both to said plurality of pitch candidates for each speech data frame and also to a voiced/unvoiced decision for each speech data frame to determine both an optimal pitch and an optimal voicing decision for each speech data frame in the context of sequence of speech data frames, said optimization means defining a transition error between each pitch candidate of the current frame and each pitch candidate of the preceding frame, and defining a cumulative error for each pitch candidate in the current frame which is equal to the transition error between said pitch candidate of said current frame plus the cumulative error of an optimally identified pitch cnadidate in the preceding frame, said optimally identified pitch candidate in the preceding frame being chosen from among the pitch candidates for said preceding frame such that the cumulative error of said corresponding pitch candidate in said current frame is at a minimum; and means operably associated with said LPC analysis means, said pitch extraction means and said optimization means for encoding said LPC parameters and said optimal pitch and optimal voicing decision for each speech data frame.<br>2. A method for determining the pitch and voicing of human speech comprising the steps of: analyzing a speech signal input in accordance with an LPC (Linear Predictive Coding) model to provide LPC parameters and a residual signal organized into a sequence of speech data frames and the respective residual signals corresponding thereto; determining a plurality of pitch candidates for each of the speech data frames in said sequence; performing dynamic programming with respect both to said plurality of pitch candidates for each speech data frame and also to a voiced/unvoiced decision for each speech data frame by defining a transition error between each pitch candidate of the current frame and each pitch candidate of the preceding frame, defining a cumulative error for each pitch candidate of the current frame equal to the transition error between said pitch candidate of said current frame plus the cumulative error of an optimally identified pitch candidate in the preceding frame, and choosing said optimally identified pitch candidate in the preceding frame such that the cumulative error of said corresponding pitch candidate in said current frame is at a minimum; and determining both an optimal pitch and an optimal voicing decision for each speech data frame in the context of said sequence of speech data frames in response to the performance of said dynamic programming.</p></layer>
<layer id = "layer186"><p><b>US4667340A:Voice messaging system with pitch-congruent baseband coding</b><br>A semicrystalline silicon solar energy cell formed from individual grains of silicon having portions thereof at the light-receiving surface of the cell. An electrical junction is formed at said light-receiving surface and extends across and below that surface and into and between the boundaries of adjoining grains to an extent such that the total junction area substantially exceeds the product of the linear dimensions of the wafer surface but does not extend completely around the boundaries of the silicon grains or to the opposed surface of the wafer.<br><b>Independant Claims</b><br>1. A system for encoding human speech so as to enable the subsequent regeneration thereof, said system comprising: LPC analysis means for analyzing an analog speech signal provided as an input thereto as respective frames of speech data in accordance with the LPC (Linear Predictive Coding) model to extract LPC parameters and a corresponding residual signal as an output representative of the analog speech signal for each frame; pitch estimation means for extracting a pitch frequency from the speech signal and producing a pitch frequency estimation signal as an output therefrom for each frame of speech data; filter means operably coupled to the outputs of said LPC analysis means and said pitch estimation means for filtering said residual signal to discard frequencies in said residual signal above a baseband frequency for each frame of speech data, said baseband frequency being selected to be an integral multiple of the frequency of said pitch as estimated for each frame of speech and being variable from frame to frame in accordance with changes in the magnitude of said pitch frequency estimation signal; and means operably coupled to the outputs of said LPC analysis means and said filter means for encoding information corresponding to said LPC parameters and to said filtered residual signal in compressed form representative of the analog speech signal and from which a replica of the analog speech signal may be derived.<br>13. A method for encoding an input speech signal, comprising the steps of: analyzing said input speech signal as provided in respective frames of speech data to extract linear predictive coding (LPC) parameters and a corresponding residual signal from said input speech signal, said LPC parameters being extracted once per frame of speech at a predetermined frame rate; estimating the pitch of said input speech signal for each frame of speech; filtering said residual signal to discard frequencies in said residual signal above a baseband frequency for each frame of speech, said baseband frequency being an integral multiple of the frequency of said pitch as estimated for each frame of speech and being variable from frame to frame in accordance with changes in the magnitude of the estimated pitch; and encoding information corresponding to said LPC parameters and to said filtered residual signal.<br>15. A method for digitally transmitting human speech as represented by a speech signal, comprising the steps of: receiving an input speech signal as provided in respective frames of speech data during corresponding frame periods; extracting linear predictive coding (LPC) parameters and a corresponding residual signal from said input speed signal, said LPC parameters being extracted once every frame period, said frame period being a predetermined length of time; estimating the pitch of said input speech signal during each said frame period; filtering said residual signal to discard frequencies in said residual signal above a baseband frequency for each frame period, said baseband frequency being an integral multiple of the frequency of said pitch as estimated for each frame period and being variable from frame period to frame period in accordance with changes in the magnitude of the estimated pitch; encoding information corresponding to said LPC parameters and to said filtered residual signal in compressed form representative of the input speech signal and from which a replica of the speech signal may be derived; passing said encoded information corresponding to said LPC parameters and to said filtered residual signal through a data channel; decoding the encoded information corresponding to said LPC parameters and to said filtered residual signal from said data channel; copying up said decoded filtered residual signal to produce a full bandwidth excitation signal; filtering said excitation signal in accordance with said LPC parameters to provide a reconstituted speech signal.<br>16. A method of encoding an analog speech signal comprising: analyzing the analog speech signal as provided in respective frames of speech data to extract a plurality of Linear Predictive Coding (LPC) parameters and a corresponding residual signal from said analog speech signal, with said LPC parameters being extracted once for each frame of speech at a predetermined frame rate; estimating the pitch p and voiced or unvoiced status of said analog speech signal for each frame of speech; setting a nominal baseband width when the analog speech signal has been estimated as unvoiced; setting a baseband width W in accordance with the estimated pitch p for each frame of speech selected to be equal to an integral multiple of the estimated pitch p which is closest to the nominal baseband width when the analog speech signal has been estimated as voiced, said baseband width W being variable from frame to frame in accordance with changes in the magnitude of the estimated pitch p; filtering said residual signal in accordance with the baseband widths as set for respective frames of speech so as to discard frequencies in said residual signal above the baseband width for each frame of speech; and encoding information corresponding to said LPC parameters and to said filtered residual signal as digital speech data in compressed form representative of the analog speech signal and from which a replica of the analog speech signal may be derived.</p></layer>
<layer id = "layer187"><p><b>US6717991B1:System and method for dual microphone signal noise reduction using spectral subtraction</b><br>A magnetic cell comprises: a first ferromagnetic layer whose magnetization is substantially fixed in a first direction; a second ferromagnetic layer whose magnetization is substantially fixed in a second direction opposite to the first direction; a third ferromagnetic layer provided between the first and the second ferromagnetic layers, a direction of magnetization of the third ferromagnetic layer being variable; a first intermediate layer provided between the first and the third ferromagnetic layers; and a second intermediate layer provided between the second and the third ferromagnetic layers. The direction of magnetization of the third ferromagnetic layer can be determined under an influence of spin-polarized electrons upon the third ferromagnetic layer by passing a current between the first and the second ferromagnetic layers.<br><b>Independant Claims</b><br>1) A noise reduction system, comprising: a first spectral subtraction processor configured to filter a first signal to provide a first noise reduced output signal, wherein an amount of subtraction performed by the first spectral subtraction processor is controlled by a first subtraction factor, k1; a second spectral subtraction processor configured to filter a second signal to provide a noise estimate output signal, wherein an amount of subtraction performed by the second spectral subtraction processor is controlled by a second subtraction factor, k2; a third spectral subtraction processor configured to filter said first signal as a function of said noise estimate output signal, wherein an amount of subtraction performed by the third spectral subtraction processor is controlled by a third subtraction factor, k3; and a controller for dynamically determining at least one of the subtraction factors k1, k2, and k3 during operation of the noise reduction system.<br>31) A method for processing a noisy input signal and a noise signal to provide a noise reduced output signal, comprising the steps of: (a) using spectral subtraction to filter said noisy input signal to provide a first noise reduced output signal, wherein an amount of subtraction performed is controlled by a first subtraction factor, k1; (b) using spectral subtraction to filter said noise signal to provide a noise estimate output signal, wherein an amount of subtraction performed is controlled by a second subtraction factor, k2; and (c) using spectral subtraction to filter said noisy input signal as a function of said noise estimate output signal, wherein an amount of subtraction performed is controlled by a third subtraction factor, k3, wherein at least one of the first, second, and third subtraction factors is dynamically determined during the processing of the noisy input signal and the noise signal.</p></layer>
<layer id = "layer188"><p><b>US6732070B1:Wideband speech codec using a higher sampling rate in analysis and synthesis filtering than in excitation searching</b><br>In a ground contact load control apparatus for a vehicle having front and rear, left and right load bearing means (<b>11, 12, 13, 14</b>) which support the ground contact load of each of the front and rear, left and right wheels, respectively, a load changing means which can operate to change the ground contact load supported by these load bearing means, vehicle state sensing means (sensors) which sense the state of the vehicle, and a control means (electric control unit ECU) which controls the operation of the load changing means in accordance with signals from the vehicle state sensing means, load changing means (<b>50, 60</b>) which can increase and decrease the ground contact load of any pair of diagonally opposed wheels and the ground contact load of the other pair of diagonally opposed wheels in opposite directions and which can operate to increase or decrease the ground contact load of diagonally opposed wheels in the same direction are used as the load changing means.<br><b>Independant Claims</b><br>1) A system for encoding an nth frame in a succession of frames of a wideband (WB) speech signal, the system comprising: a) a WB linear predictive (LP) analysis module (11) responsive to the nth frame of the wideband speech signal, for providing LP analysis filter characteristics; b) a WB LP analysis filter (12a), also responsive to the nth frame of the WB speech signal, for providing a filtered WB speech input; c) a band-splitting module (14), responsive to a WB target signal xw(n) determined from the filtered WB speech input for the nth frame, for splitting the filtered WB target signal xw(n) into a plurality of bands, the band-splitting module for providing a lower band (LB) target signal x(n); d) an excitation search module (16), responsive to the LB target signal x(n), for providing an LB excitation exc(n); and e) a band-combining module (17), responsive to the LB excitation exc(n) and optionally to an additional signal serving as a higher band (HB) excitation exch(n), for interpolating the LB excitation exc(n) to provide an interpolated LB excitation, and for optionally combining the interpolated excitation and the additional signal so as to provide a WB excitation excw(n).<br>7) A method for use by a codec in encoding a wideband (WB) speech signal, comprising the steps of: a) performing (11) a WB linear predictive (LP) analysis, responsive to the WB speech signal, for providing LP filter characteristics; b) performing (12) WB LP filtering of the WB speech signal at a WB sampling rate, responsive to the WB speech signal and to the LP filer characteristics, for providing a WB target signal xw(n); c) performing (14) a band-splitting of the WB target signal xw(n) so as to provide a lower band (LB) target signal x(n), responsive to the WB target signal xw(n), the LB target signal x(n) containing information about error in reproducing components of the speech signal at frequencies contained in a lower frequency band compared to at least one higher frequency band in a plurality of frequency bands spanned by the WB speech signal; and d) performing (16) an excitation search for a LB excitation exc(n) representing the LB target signal x(n), the excitation search for a LB excitation exc(n) including sampling at a LB sampling rate; wherein the LB sampling rate is less than the WB sampling rate; and also e) performing (17) a band-combining step, responsive to the LB excitation exc(n) and optionally to an additional signal serving as a higher band (HB) excitation exch(n), for interpolating the LB excitation exc(n) to provide an interpolated LB excitation, and for optionally combining the interpolated excitation and the additional signal so as to provide a WB excitation excw(n).<br>14) A system for encoding an nth frame in a succession of frames of a wideband (WB) speech signal, the system comprising: a) a WB linear predictive (LP) analysis module (11), responsive to the nth frame of the WB speech signal, for providing LP analysis filter characteristics; b) a WB LP analysis filter (12a), also responsive to the nth frame of the WB speech signal, for providing a filtered WB speech input; c) a decimation module (14), responsive to a WB target signal xw(n) determined from the filtered WB speech input for the nth frame, for decimating the filtered WB speech input, to provide a lower band (LB) target signal x(n); d) an excitation search module (16), responsive to the LB target signal x(n), for providing a LB excitation exc(n); e) an interpolation module (17), responsive to the LB excitation exc(n) and optionally to an additional signal serving as a higher band (HB) excitation exch(n), for interpolating the LB excitation signal exc(n) to provide an interpolated LB excitation, and for optionally combining the interpolated excitation and the additional signal so as to provide a WB excitation excw(n); and f) a WB LP synthesis filter (18), responsive to the LP analysis filter characteristics and to the WB excitation excw(n), for providing WB synthesised speech.<br>15) A system for encoding an nth frame in a succession of frames of a wideband (WB) speech signal, the system comprising: a) a WB linear predictive (LP) analysis module (11), responsive to the nth frame of the WB speech signal, for providing LP analysis filter characteristics, further for providing an LP analysis filter impulse response hw(n) for the nth frame, further for providing a quantified inverse filter characterization Ãw(z); b) a WB LP analysis filter (12a), also responsive to the nth frame of the WB speech signal, for providing a filtered WB speech input; c) a perceptual weighting and zero-input response subtraction module (12b), responsive to the filtered WB speech input, for providing a WB target signal xw(n) for the nth frame; d) a band-splitting module (14), responsive to the WB target signal xw(n) for the nth frame, for splitting the WB target signal into a higher band (HB) and a lower band (LB), the band-splitting module for providing a lower-band (LB) target signal x(n) and an LB impulse response h(n); e) an LB analysis-by-synthesis (A-b-S) filter (16), responsive to the LB target signal x(n) and the LB impulse response h(n), for providing an LB excitation exc(n); f) a band-combining module (17), responsive to the LB excitation exc(n) and optionally to an additional signal serving as a higher band (HB) excitation exch(n), for interpolating the LB excitation exc(n) to provide an interpolated LB excitation, and for optionally combining the interpolated excitation and the additional signal so as to provide a WB excitation excw(n); and g) a WB LP synthesis filter (18), responsive to Ãw(z), and further responsive to the WB excitation excw(n), for providing WB synthesized speech, and further for providing a zero-input memory update MemSynw(n) useful for making a zero-input response subtraction; thereby providing an LP encoding in which the sampling rate used for the search for an LB excitation exc(n) is less than the WB sampling rate used in the LP analysis and synthesis.<br>19) A mobile terminal, including a system for encoding an nth frame in a succession of frames of a wideband (WB) speech signal, the system comprising: a) a WB linear predictive (LP) analysis module (11) responsive to the nth frame of the wideband speech signal, for providing LP analysis filter characteristics; b) a WB LP analysis filter (12a), also responsive to the nth frame of the WB speech signal, for providing a filtered WB speech input; c) a band-splitting module (14), responsive to a WB target signal xw(n) determined from the filtered WB speech input for the nth frame, for splitting the filtered WB speech input into a plurality of bands, the band-splitting module for providing a lower band (LB) target signal x(n); d) an excitation search module (16), responsive to the LB target signal x(n), for providing an LB excitation exc(n); and e) a band-combining module (17), responsive to the LB excitation exc(n) and optionally to an additional signal serving as a higher band (HB) excitation exch(n), for interpolating the LB excitation exc(n) to provide an interpolated LB excitation, and for optionally combining the interpolated excitation and the additional signal so as to provide a WB excitation excw(n).<br>21) A telecommunications network having a network element including a system for encoding an nth frame in a succession of frames of a wideband (WB) speech signal, the system comprising: a) a WB linear predictive (LP) analysis module (11) responsive to the nth frame of the wideband speech signal, for providing LP analysis filter characteristics; b) a WB LP analysis filter (12a), also responsive to the nth frame of the WB speech signal, for providing a filtered WB speech input; c) a band-splitting module (14), responsive to a WB target signal xw(n) determined from the filtered WB speech input for the nth frame, for splitting the filtered WB speech input into a plurality of bands, the band-splitting module for providing a lower band (LB) target signal x(n); d) an excitation search module (16), responsive to the LB target signal x(n), for providing an LB excitation exc(n); and e) a band-combining module (17), responsive to the LB excitation exc(n) and optionally to an additional signal serving as a higher band (HB) excitation exch(n), for interpolating the LB excitation exc(n) to provide an interpolated LB excitation, and for optionally combining the interpolated excitation and the additional signal so as to provide a WB excitation excw(n).</p></layer>
<layer id = "layer189"><p><b>US3995116A:Emphasis controlled speech synthesizer</b><br>The invention relates to methods and apparatus for manufacturing intravascular stents wherein the intravascular stent has its inner surface treated to promote the migration of endothelial cells onto the inner surface of the intravascular stent. In particular, the inner surface of the intravascular stent has at least one groove formed therein.<br><b>Independant Claims</b><br>1. Apparatus for generating natural sounding synthesized speech comprising: a memory having stored therein phase vocoder encoded short-time spectrum envelope and phase derivative signals representative of a vocabulary of words; means for extracting the signals of selected storage locations of said memory to affect the pitch and duration of said synthesized speech; means for multiplying a plurality of the short-time spectrum envelope signals of said extracted signals by an intensity control factor; and decoder means responsive to the output signal of said means for multiplying and to the unaltered phase derivative signals of said extracted signal for phase vocoder decoding of the input signals of said decoder means.<br>4. A method for synthesizing a natural sounding speech message comprising the steps of: storing short-time spectrum envelope and phase derivative phase vocoder signals representative of a vocabulary of words; selectively extracting from said stored signals preselected signals to form a pitch and duration modified predetermined sequence of signals representative of said speech message; altering the extracted short-time spectrum envelope signals to affect the intensity of said speech message; and combining the extracted phase derivative signals and said intensity modified short-time spectrum envelope signals to form a signal appropriate for activating a speech synthesizer.<br>5. A method for composing speech messages from phase vocoder encoded and stored short-time spectrum envelope and phase derivative signals comprising the steps of: extracting selected signals from said encoded and stored signals a repeated number of times to affect the pitch and duration of said composed speech message; altering the short-time spectrum envelope signals of said extracted signals to affect the intensity of said composed speech message; interpolating said altered short-time spectrum envelope signals to effect a smooth spectrum envelope; and phase vocoder decoding of the phase derivative signals of said extracted signals and of said interpolated short-time spectrum envelope signals to form a signal representative of said composed speech message.</p></layer>
<layer id = "layer190"><p><b>US5890108A:Low bit-rate speech coding system and method using voicing probability determination</b><br>An indoor air quality module includes an ultraviolet light source located between two titanium dioxide coated honeycombs. Photons of ultraviolet light are absorbed by the titanium dioxide coating to form reactive hydroxyl radicals that attack and oxidize contaminants in the to water, carbon dioxide, and other substances. An outer compartment is attached to an air duct and an HVAC unit, and an inner compartment supports the honeycombs, a particle filter, and the ultraviolet light source. When the module is in the working position and the honeycombs and the particle filter are correctly installed, the components contact switches on the outer compartment, and the ultraviolet light source is activated. When the inner compartment is pivoted relative to the outer compartment during servicing or if any of the components are incorrectly installed or not installed, one of the components does not engage the corresponding switch, deactivating the ultraviolet light source.<br><b>Independant Claims</b><br>1. A method for processing an audio signal comprising: dividing the signal into segments, each segment representing one of a succession of time intervals; computing for each segment a model of the signal in such segment; subtracting the computed model from the original signal to obtain a residual excitation signal; detecting for each segment the presence of a fundamental frequency F.sub.0 ; determining for the excitation signal in each segment a ratio between voiced and unvoiced components of the signal in such segment on the basis of the fundamental frequency F.sub.0, said ratio being defined as a voicing probability Pv; separating the excitation signal in each segment into a voiced portion and an unvoiced portion on the basis of the voicing probability Pv; and encoding parameters of the model of the signal in each segments and the voiced portion and the unvoiced portion of the excitation signal in each segment in separate data paths.<br>12. A system for processing an audio signal comprising: means for dividing the signal into segments, each segment representing one of a succession of time intervals; means for computing for each segment a model of the signal in such segment; means for subtracting the computed model from the original signal to obtain a residual excitation signal; means for detecting for each segment the presence of a fundamental frequency F.sub.0 ; means for determining for the excitation signal in each segment a ratio between voiced and unvoiced components of the signal in such segment on the basis of the fundamental frequency F.sub.0, said ratio being defined as a voicing probability Pv; means for separating the excitation signal in each segment into a voiced portion and an unvoiced portion on the basis of the voicing probability Pv; and means for encoding parameters of the model of the signal in each segments and the voiced portion and the unvoiced portion of the excitation signal in each segment in separate data paths.<br>21. A method for synthesizing audio signals from one or more data packets representing at least one time segment of a signal, the method comprising: decoding said one or more data packets to extract data comprising: a fundamental frequency parameter, parameters representative of a spectrum model of the signal in said at least one time segment, and a voicing probability Pv defined as a ratio between voiced and unvoiced components of the signal in said at least one time segment; generating a set of harmonics H corresponding to said fundamental frequency, the amplitudes of said harmonics being determined on the basis of the model of the signal, and the number of harmonics being determined on the basis of the decoded voicing probability Pv; and synthesizing an audio signal using the generated set of harmonics.<br>28. A method for synthesizing audio signals from one or more data packets representing at least one time segment of a signal, the method comprising: decoding said one or more data packets to extract data comprising: a fundamental frequency parameter, parameters representative of a spectrum model of the signal in said at least one time segment, one or more parameters representative of a residual excitation signal associated with said spectrum model of the signal, and a voicing probability Pv defined as a ratio between voiced and unvoiced components of the signal in said at least one time segment; providing a filter, the frequency response of which corresponds to said spectrum model of the signal; and synthesizing an audio signal by passing a residual excitation signal through the provided filter, said residual excitation signal being generated from said fundamental frequency, said one or more parameters representative of a residual excitation signal associated with said spectrum model of the signal, and the voicing probability Pv.</p></layer>
<layer id = "layer191"><p><b>US5949888A:Comfort noise generator for echo cancelers</b><br>An order wire device in a communication system having a plurality of order wire devices, signals output from each of the order wire devices being serially transmitted to remaining order wire devices, each of the order wire devices being capable of simultaneously calling remaining order wire devices in an all station calling mode. The order wire device includes, a tone ringer circuit for outputting a ring-back-tone signal, a first detection circuit for detecting a request for a call in the all station calling mode, a first control circuit for activating the tone ringer circuit when the first detection circuit detects the request, a second control circuit for inactivating the tone ringer circuit when an off-hook operation is carried out in response to the request, a signal output circuit for outputting a stop signal when the first detection circuit detects the request and the off-hook operation is carried out, a second detection circuit for detecting a stop signal output from an order wire device in which the off-hook operation has been carried out, and a third control circuit for inactivating the tone ringer circuit when the first detection circuit detects the requirement and the second detection circuit detects the stop signal.<br><b>Independant Claims</b><br>1. A method of providing a comfort noise generator for use with echo suppressors comprising the steps of: storing actual background noise samples of a channel into a delay buffer; transferring said actual background noise samples from said delay buffer to an output buffer after a delay period during which said delay buffer receives only background noise; and providing said background noise onto said channel from said output buffer when said echo suppressor is active.<br>10. A device for providing a continuous background noise comprising: a noise delay buffer for storing an actual background noise of a channel; and an output buffer for outputting said stored actual background noise from said delay buffer into said channel; wherein said stored actual background noise is transferred from said noise delay buffer to said output buffer after said noise delay buffer receives only background noise for a predetermined delay period.<br>16. A method of providing a comfort noise generator for use with echo suppressors to generate comfort noise on a channel, comprising the steps of: comparing a signal energy level of a signal sample to a threshold energy level; checking a hangover delay counter for a hangover duration; increasing a noise counter if said hangover delay counter indicates said hangover duration is exceeded and if said signal energy level is less than said threshold energy level; storing signal samples in a first buffer if said noise counter is increased; transferring said signal samples from said first buffer to a second buffer when said noise counter exceeds a threshold noise count; and outputting said signal samples from the second buffer onto said channel if said echo suppressor is active.<br>19. A device for generating comfort noise on a channel during echo suppression by an echo suppressor, wherein the comfort noise is actual background noise from the channel that is stored by said device, said device comprising: a comparator adapted to determine that a signal sample on said channel is a background noise samples; and a first buffer adapted to store signal samples from said comparator that are determined to be background noise samples; and a second buffer adapted to store background noise samples from said first buffer and to output said stored background noise samples to said channel when said echo suppressor is active; wherein said first buffer transfers background noise samples to the second buffer after a predetermined number of consecutive signal samples are determined by said comparator to be background noise samples.<br>23. A method for generating comfort noise on a channel during echo suppression by an echo suppressor, wherein said comfort noise is actual background noise from said channel that is stored by said device, said method comprising the steps of: determining that signal samples on said channel are background noise samples; storing said signal samples in a first buffer if said signal samples are determined to be background noise samples; transferring background noise samples from said first buffer to a second buffer after a predetermined number of consecutive signal samples are determined to be background noise samples; outputting stored background noise samples from said second buffer to said channel when said echo suppressor is active.</p></layer>
<layer id = "layer192"><p><b>US5704003A:RCELP coder</b><br>The present invention relates to a multi-stage process for the continuous preparation of thermoplastically processable polyurethanes with improved processing properties based on various polyols<br><b>Independant Claims</b><br>1. A method of speech coding for use in conjunction with speech coding methods wherein speech is digitized into a plurality of temporally defined frames, each frame having a plurality of sub-frames including a current sub-frame present during a specified time interval, each frame having a pitch delay value specifying the change in pitch with reference to the immediately preceding frame, each sub-frame including a plurality of samples, and the digitized speech is partitioned into periodic components and a residual signal; the improved method of speech coding comprising the steps of: (a) for each of a plurality of sub-frames of the residual signal, determining a time shift T based upon (i) the current sub-frame of the residual signal, and (ii) a delayed residual signal from a previously-occurring frame; and (b) applying the time shift T determined in step (a) to the current sub-frame of the residual signal.</p></layer>
<layer id = "layer193"><p><b>US6014621A:Synthesis of speech signals in the absence of coded parameters</b><br>A coding mode deciding portion includes a motion vector detecting portion, a prediction image generating portion and an image quality deterioration prediction portion. The image quality deterioration prediction portion generates image quality deterioration prediction information in accordance with second motion associated information that is obtained by the motion vector detecting portion. The generated image quality deterioration prediction information is used for selecting a coding mode and for quantization control.<br><b>Independant Claims</b><br>1. A method of generating coefficient signals representing frequency components of a signal representing speech information based on an estimate of the signal spectrum and a noise masking measure associated with the speech signal, the method comprising: generating a first signal relating the estimate of the signal spectrum to the noise masking measure at each of one or more frequencies; for one or more of said frequencies, forming a coefficient signal magnitude based on said first signal at a corresponding frequency, and selecting a coefficient phase at random, wherein the step of forming a coefficient signal magnitude comprises forming the magnitude as a function of a quantized gain signal associated with the frequency corresponding to said coefficient, wherein the first signal relating the estimate of the signal spectrum to the noise masking measure at each of one or more frequencies comprises a ratio of the estimate of the signal spectrum to a perceptual threshold signal, and wherein when said ratio is greater than a predetermined threshold, the magnitude of said coefficients is at least a predetermined amount above said gain signal evaluated at said frequency.<br>4. A method of generating coefficient signals representing frequency components of a signal representing speech information based on an estimate of the signal spectrum and a noise masking measure associated with the speech signal, the method comprising: generating a first signal relating the estimate of the signal spectrum to the noise masking measure at each of one or more frequencies; for one or more of said frequencies, forming a coefficient signal magnitude based on said first signal at a corresponding frequency, and selecting a coefficient phase at random, wherein the step of forming a coefficient signal magnitude comprises forming the magnitude as a function of a quantized gain signal associated with the frequency corresponding to said coefficient, wherein the first signal relating the estimate of the signal spectrum to the noise masking measure at each of one or more frequencies comprises a ratio of the estimate of the signal spectrum to a perceptual threshold signal, and wherein when said ratio is less than or equal to a predetermined threshold, the magnitude of said coefficients is at least a predetermined amount below said gain signal evaluated at said frequency.</p></layer>
<layer id = "layer194"><p><b>US5235669A:Low-delay code-excited linear-predictive coding of wideband speech at 32 kbits/sec</b><br>The present invention relates to a device for joining and separating a storage medium, storing inputted data by being mounted on a computer or a digital video recorder and being simply separated from a housing of the storage medium capable of reproducing the stored data with a switching operation of a door, and comprises, a storage medium tray mounting a data storage medium thereon; a housing for receiving and guiding the storage medium tray; and a door for joining and separating the storage medium tray from the housing.<br><b>Independant Claims</b><br>1. A method for coding a speech signal comprising generating a plurality of parameter signals representative of said speech signal, synthesizing a plurality of estimate signals based on said parameter signals, each of said estimate signals being identified by a corresponding index signal, performing a frequency weighted comparison of each of said estimate signals with said speech signal, said weighting relatively emphasizing perceptually significant frequencies within a band-limited frequency spectrum of said speech signal, and higher frequencies to a greater degree than lower frequencies within said band-limited spectrum, and representing said speech signal by at least one of said corresponding index signals identifying said estimate signals which, upon said comparison, meet a preselected comparison criterion.</p></layer>
<layer id = "layer195"><p><b>US4004096A:Process for extracting pitch information</b><br>A gate drive circuit includes plural stages connected together one after each other. Each of the plural stages includes a circuit transistor, a capacitor part, a first connection part and a second connection part. The circuit transistor outputs the gate signal through a source electrode in response to a control signal applied through a gate electrode. The capacitor part includes a first electrode, a second electrode formed on the first electrode, and a third electrode formed on the second electrode. The first connection part electrically connects the gate electrode of the circuit transistor and the second electrode of the capacitor part. The second connection part electrically connects the source electrode of the circuit transistor and the first electrode of the capacitor part. Thus, an integrated size of a gate drive circuit may be decreased, and a reliability of a gate drive circuit may be enhanced.<br><b>Independant Claims</b><br>1. A process for extracting pitch information from a digitized speech signal comprising the steps of: selecting a plurality of values .tau..sub.i, each value representative of a frequency within the speech spectrum and logarithmically spaced within said spectrum; segmenting the digitized signal into frames of predetermined length; generating, for each frame and each value of pitch period .tau..sub.i, a score W.sub.t (i) representative of the cost of the cheapest sequence of pitch values ending with .tau..sub.i at time t; generating for each frame an array P.sub.t (i) representative of the index of the immediately preceeding pitch period in said cheapest sequence, and selecting for the current frame that .tau..sub.i for which W.sub.t (i) is minimum.</p></layer>
<layer id = "layer196"><p><b>US5659622A:Method and apparatus for suppressing noise in a communication system</b><br>The nifD promoter regions of Bradyrhizobium japonicum and Bradyhizobium sp. (Parasponia) have been sequenced and found to be significantly homologous. Recombinant DNA molecules comprising foreign genes under the control of such promoters are provided. Rhizobial species containing such recombinant constructions, either in plasmids or integrated into the genome, are provided. These are especially useful for expressing desired foreign genes within root nodules.<br><b>Independant Claims</b><br>1. A method of suppressing noise in a communication system, the communication system implementing information transfer by using frames of information in channels, the frames of information in channels having noise which results in a noise estimate of the channel, the method comprising the steps of: estimating a channel energy within a current frame of information; estimating a total channel energy within a current frame of information based on the estimate of the channel energy; estimating a power of a spectra of the current frame of information based on the estimate of the channel energy; estimating a power of a spectra of a plurality of past frames of information based on the estimate of the power of the spectra of the current frame; determining a deviation between the estimate of the spectra of the current frame and the estimate of the power of the spectra of the plurality of past frames; and updating the noise estimate of the channel based on the estimate of the total channel energy and the determined deviation.<br>11. An apparatus for suppressing noise in a communication system, the communication system implementing information transfer by using frames of information in channels, the frames of information in channels having noise which results in a noise estimate of the channel, the apparatus comprising: means for estimating a channel energy within a current frame of information; means for estimating a total channel energy within a current frame of information based on the estimate of the channel energy; means for estimating a power of a spectra of the current frame of information based on the estimate of the channel energy; means for estimating a power of a spectra of a plurality of past frames of information based on the estimate of the power of the spectra of the current frame; means for determining a deviation between the estimate of the spectra of the current frame and the estimate of the power of the spectra of the plurality of past frames; and means for updating the noise estimate of the channel based on the estimate of the total channel energy and the determined deviation.<br>23. A speech coder for coding speech in a communication system, the communication system transferring speech samples by using frames of information in channels, the frames of information in charmels having noise therein, the speech coder having as input the speech samples, the speech coder comprising; means for estimating a total channel energy within a current frame of speech samples based on the estimate of the channel energy; means for estimating a power of a spectra of the current frame of speech samples based on the estimate of the channel energy; means for estimating a power of a spectra of a plurality of past frames of speech samples based on the estimate of the power of the spectra of the current frame; means for determining a deviation between the estimate of the spectra of the current frame and the estimate of the power of the spectra of the plurality of past frames; and means for updating the noise estimate of the channel based on the estimate of the total channel energy and the determined deviation; means for modifying a gain of the channel based on the update of the noise estimate to produce the noise suppressed speech samples; and means for coding the noise suppressed speech samples for transfer by the communication system.<br>26. A method of speech coder in a communication system, the communication system transferring speech signals by using frames of information in channels, the frames of information in channels having noise therein, the speech coder having as input a speech signal, the method comprising the steps of: estimating a total channel energy within a current frame including the speech signal based on the estimate of the channel energy; estimating a power of a spectra of the current frame including the speech signal based on the estimate of the channel energy; estimating a power of a spectra of a plurality of past frames including speech signals based on the estimate of the power of the spectra of the current frame; determining a deviation between the estimate of the spectra of the current frame and the estimate of the power of the spectra of the plurality of past frames; and updating the noise estimate of the channel based on the estimate of the total channel energy and the determined deviation; and modifying a gain of the channel based on the update of the noise estimate to produce the noise suppressed speech signal; and coding the noise suppressed speech signal for transfer by the communication system.</p></layer>
<layer id = "layer197"><p><b>US20030151454A1:Adaptive speech filter</b><br>A microscope suitable for use together with MRI, and a support stand for the microscope are provided. A microscope <highlight><bold>1 </bold></highlight>is a non-magnet type where any electric motor is not used, and hence does not induce fluctuations of magnetic field having effects on image quality of an MRI <highlight><bold>3 </bold></highlight>by focusing or zooming. Hence, the microscope of the invention is suitable for use together with MRI <highlight><bold>13</bold></highlight>. Since a clutch C is of non-magnet type, a support stand <highlight><bold>2 </bold></highlight>does not induce changes in the surrounding magnetic field environments if the clutch is operated, and hence it is suitable for use, for example, in proximity to the MRI.<br><b>Independant Claims</b><br>1. A filter circuit comprising: a filter circuit input terminal; a filter circuit output terminal; a high pass filter having a control input terminal, a signal input terminal, and a signal output terminal configured to provide a signal to said filter circuit output terminal; a peak detector having a control output connected to said control input terminal of the high pass filter; and a preamplifier configured to accept a signal from the filter circuit input terminal and further to provide a signal to said signal input terminal of the high pass filter and to a signal input terminal of the peak detector; wherein the corner frequency of the high pass filter is controlled by the control output of the peak detector; and the filter circuit is configured for receiving direct current power from said filter circuit signal output terminal.<br>11. A method for conditioning speech, comprising: a) providing a high pass filter; b) providing a peak detector for sensing of a signal level and providing a control signal in response thereto; c) controlling said high pass filter with said control signal such that a corner frequency of said high pass filter is dependent upon said signal level; and providing direct current power to said high pass filter, said peak detector, and the signal conditioning amplifier at an output of the signal conditioning amplifier.<br>15. A speech conditioning circuit for conditioning a signal, comprising: a variable filter circuit for filtering said signal to produce a conditioned signal, controlled by an amplitude detector circuit; and an output circuit receiving said conditioned signal from said variable filter circuit and providing an output signal to an output terminal, the speech conditioning circuit being constructed to accept a direct current input form said output terminal for powering the speech conditioning circuit.<br>21. A telephone input apparatus, comprising: a microphone preamplifier; a filter for removing low frequency signal content; a peak detector for controlling said filter; a peak detector amplifier for amplifying input to said peak detector; and a telephone input apparatus output terminal for providing signal output from the telephone input apparatus and also for providing direct current power input to the telephone input apparatus; wherein a signal from the preamplifier is provided to an input of the filter and said signal is also provided to an input of the peak detector, and further wherein a filtered signal is provided from the filter to the telephone input apparatus output terminal.<br>27. A filter circuit comprising: a filter circuit input terminal for receiving a filter circuit input signal; a filter circuit output terminal for providing a filter output signal; a high pass filter having a control input terminal, the high pass filter for processing a high pass filter input signal to produce said filter output signal; a peak detector having a control output connected to said control input terminal of the high pass filter; and a preamplifier configured to receive said filter circuit input signal and further to provide said high pass filter input signal to the high pass filter and to the peak detector; wherein the corner frequency of the high pass filter is controlled by the control output of the peak detector; the high pass filter, the peak detector and the preamplifier are embodied in an integrated circuit; and the gain of the preamplifier is adjustable through gain adjusting means external to said integrated circuit; whereby the preamplifier is configurable to adapt gain for a device connected to said filter circuit input terminal.</p></layer>
<layer id = "layer198"><p><b>US5732189A:Audio signal coding with a signal adaptive filterbank</b><br>The present invention is generally a flexible tubing to use in such devices as spray bottles, toxic containers, pick up tubes used in medical applications, and in containers in fast food restaurants so that any fluid in the bottom of the container could be immediately and virtually completely removed. The tubing is shaped to conform generally to the bottom of the container, generally in a partial elliptical configuration in a horizontal plane. The tubing or pick up device comprises two parts, normally integrally joined, or fabricated as one piece. More specifically, the upper section of the pick up device is generally vertical, while the lower section is generally in an elliptical configuration. Multiple embodiments exist, including using materials such as rubber, plastic, or metal.<br><b>Independant Claims</b><br>1. A method of digitally encoding a digital/audio input signal to generate a compressed digital bit stream comprising the steps of: calculating a plurality of threshold noise levels in response to time frequency characteristics of the digital audio input signal, selectively filtering said digital/audio input signal in a time varying non-uniform filterbank to generate a filtered signal, said time varying form filter bank having a plurality of uniformly spaced filterbank sections covering a portion of a predetermined frequency axis and a transition filter being selected to cover a remaining portion of said predetermined frequency axis, said selective filtering step being responsive to said calculated threshold noise levels, quantizing said filtered signal to generate a quantized signal, said quantizing step being responsive to said threshold noise levels, and encoding said quantized signal to generate said compressed digital bit stream.<br>5. A method of digitally encoding a digital/audio input signal to generate a compressed digital bit stream comprising the steps of: calculating a plurality of threshold noise levels in response to time-frequency characteristics of the digital/audio input signal, dividing said digital/audio input signal into a plurality of frequency sub-bands by inputting said digital/audio signal into a time varying non-uniform filterbank comprised of a plurality of uniformly spaced filterbank sections with a selectively added transition filter, generating one or more digital samples for each of said plurality of frequency subbands, the number of digital samples generated being responsive to selected ones of the plurality of frequency sub-bands, quantizing said digital samples to generate a quantized digital signal, said dividing, generating and quantizing steps being responsive to said threshold noise levels, and encoding said quantized digital signal to generate said compressed digital bit stream.</p></layer>
<layer id = "layer199"><p><b>US5737716A:Method and apparatus for encoding speech using neural network technology for speech classification</b><br><b>Independant Claims</b><br>1. A speech coding apparatus for encoding speech data which is input to the speech coding apparatus, the speech coding apparatus comprising: an input device for receiving the speech data; and at least one processor coupled to the input device, the at least one processor for parameterizing the speech data to produce at least one feature vector which describe parameters of the speech data, applying a first neural network to the at least one feature vector to obtain at least one speech classification of the speech data, creating characterized speech data by characterizing the speech data using a characterization methodology which depends on the at least one speech classification, and creating an encoded bitstream by encoding the characterized speech data.<br>18. A speech decoding apparatus for decoding an encoded bitstream to produce synthesized speech data, the speech decoding apparatus comprising: a transmission channel interface for receiving the encoded bitstream from a speech encoding apparatus; and at least one processor coupled to the transmission channel interface, the at least one processor for decoding a speech classification from a first portion of the encoded bitstream, wherein the speech classification was derived by a neural network in the speech encoding apparatus, the at least one processor also for decoding a remainder of the encoded bitstream using a decoding methodology which depends on the speech classification, resulting in a decoded bitstream, the at least one processor also for creating reconstructed speech basis elements from the decoded bitstream and producing the synthesized speech data using the reconstructed speech basis elements.<br>20. A method for encoding speech data by a speech coding apparatus comprising the steps of: a) acquiring a segment of the speech data; b) parameterizing the segment of the speech data to produce at least one feature vector which describes parameters of the speech data; c) applying a first neural network to the at least one feature vector to obtain at least one speech classification of the speech data; d) creating characterized speech data by characterizing the speech data using a characterization methodology which depends on the at least one speech classification; and e) creating an encoded bitstream by encoding the characterized speech data.<br>40. A method for decoding an encoded bitstream to produce synthesized speech data, the method comprising the steps of: a) receiving the encoded bitstream from a speech encoding apparatus; b) decoding a speech classification from a fit portion of the encoded bitstream, wherein the speech classification was derived by a neural network in the speech encoding apparatus; c) decoding a remainder of the encoded bitstream using a decoding methodology which depends on the speech classification, resulting in a decoded bitstream; d) creating reconstructed speech basis elements from the decoded bitstream; and e) producing the synthesized speech data using the reconstructed speech basis elements.</p></layer>
<layer id = "layer200"><p><b>US5689615A:Usage of voice activity detection for efficient coding of speech</b><br>A method of preparing copper arsenate compositions having unique advantges in lower cost and higher performance for use in preparing chromated copper arsenate wood preserving formulations. These copper arsenate compositions are insoluble copper arsenate in water or as a dry reactive powder, have a mol ratio of As.sub.2 O.sub.5 to CuO of 1:4, and is readily soluble in chromic acid to form CCA wood preservatives. This copper arsenate is prepared by reacting suitable copper-bearing materials with arsenic trioxide and air or oxygen in ammoniacal solutions. Either or both of the starting raw materials, i.e., the copper and the arsenic, may be very impure, which impure materials were heretofore unsuitable for the production of copper arsenate.<br><b>Independant Claims</b><br>1. In a speech communication system comprising: (a) a speech encoder for receiving and encoding an incoming speech signal to generate a bit stream for transmission to a speech decoder; (b) a communication channel for transmission; and (c) a speech decoder for receiving the bit stream from the speech encoder to decode the bit stream to generate a reconstructed speech signal, said incoming speech signal comprising periods of active voice and non-active voice, a method for efficient encoding of non-active voice, comprising the steps of: a) extracting predetermined sets of parameters from said incoming speech signal for each frame, said parameters comprising spectral content and energy; b) making a frame voicing decision of the incoming speech signal for each frame according to a first set of the predetermined sets of parameters; c) if the frame voicing decision indicates active voice, the incoming speech signal being encoded by an active voice encoder to generate an active voice bit stream, continuously concatenating and transmitting the active voice bit stream over the channel; d) if receiving said active voice bit stream by said speech decoder, invoking an active voice decoder to generate the reconstructed speech signal; e) if the frame voicing decision indicates non-active voice, the incoming speech signal being encoded by a non-active voice encoder to generate a non-active voice bit stream, said non-active bit stream comprising at least one packet with each packet being 2-byte wide, each packet comprising a plurality of indices into a plurality of tables representative of non-active voice parameters; f) if the frame voicing decision indicates non-active voice, transmitting the non-active voice bit stream only if a predetermined comparison criteria is met; g) if the frame voicing decision indicates non-active voice, invoking an non-active voice decoder to generate the reconstructed speech signal; b) updating the non-active voice decoder when the non-active voice bit stream is received by the speech decoder, otherwise using a non-active voice information previously received.<br>7. In a speech communication system comprising: (a) a speech encoder for receiving and encoding an incoming speech signal to generate a bit stream for transmission to a speech decoder; (b) a communication channel for transmission; and (c) a speech decoder for receiving the bit stream from the speech encoder to decode the bit stream to generate a reconstructed speech signal, said incoming speech signal comprising periods of active voice and non-active voice, an apparatus coupled to said speech encoder for efficient encoding of non-active voice, said apparatus comprising: a) extraction means for extracting predetermined sets of parameters from said incoming speech signal for each frame, said parameters comprising spectral content and energy; b) VAD means for making a frame voicing decision of the incoming speech signal for each frame according to a first set of the predetermined sets of parameters; c) active voice encoder means for encoding said incoming speech signal, if the frame voicing decision indicates active voice, to generate an active voice bit stream, for continuously concatenating and transmitting the active voice bit stream over the channel; d) active voice decoder means for generating the reconstructed speech signal, if receiving said active voice bit stream by said speech decoder; e) non-active voice encoder means for encoding the incoming speech signal, if the frame voicing decision indicates non-active voice, to generate a non-active voice bit stream, said non-active bit stream comprising at least one packet with each packet being 2-byte wide, each packet comprising a plurality of indices into a plurality of tables representative of non-active voice parameters, said non-active voice transmitting the non-active voice bit stream only if a predetermined comparison criteria is met; f) non-active voice decoder means for generating the reconstructed speech signal, if the frame voicing decision indicates non-active voice; g) update means for updating the non-active voice decoder when the non-active voice bit stream is received by the speech decoder.</p></layer>
<layer id = "layer201"><p><b>US6018706A:Pitch determiner for a speech analyzer</b><br>The invention relates to a clamping terminal unit for electrical conductors in the power sector using insulation displacement technique. The clamping terminal unit forms a variety of different terminations in the medium voltage sector with medium currents that can reliably and rapidly be made. A housing 1 includes introduction openings 2 to insulation displacement contacts 3 for electrical conductors, an opening 4 and latch devices 14, 15 for the alignment of housings 1 and a recess 5 for the series arrangement of housings 1.<br><b>Independant Claims</b><br>1. A pitch determiner for use with a speech analyzer for determining a pitch within one or more sequential segments of speech, each segment of speech being represented by a predetermined number of digitized speech samples, said pitch determiner comprising: a pitch function generator for generating from the predetermined number of digitized speech samples, a plurality of pitch components representing a pitch function, wherein said pitch function defines an amplitude of each of the plurality of pitch components; a pitch enhancer, for enhancing the pitch function of a current segment of speech utilizing the pitch function of one or more sequential segments of speech, by generating a plurality of enhanced pitch components; and a pitch detector for detecting the pitch of the current segment of speech by determining the pitch of an enhanced pitch component having a largest amplitude of the plurality of enhanced pitch components.</p></layer>
<layer id = "layer202"><p><b>US5684926A:MBE synthesizer for very low bit rate voice messaging systems</b><br>A support post system for a flexible cover that is attached around its periphery to ground, e.g., a cover for a boat. The system includes, in preferred form, a collar with throughbore that is attached to the cover. A support post is inserted in telescoped relation through the collar's bore from above the cover, one end of the support post being supported on ground and the other end of the support post extending above the cover. In one preferred embodiment a flexible tension member, e.g., a rope, is fixed at one end to the collar, and is trained over a guide head fixed to the post above the cover. In use, the rope is manually pulled downwardly by a person from above the cover so as to lift the collar up the post. This simultaneously lifts the cover to a desired location above ground at which it is taut so that rainwater does not puddle on it. After the collar and cover are lifted to the preferred elevated location, the rope is tied off on the collar so as to maintain tautness of the cover.<br><b>Independant Claims</b><br>1. An MBE synthesizer for generating a segment of speech from compressed speech data which is received by a receiver coupled thereto, the compressed speech data which is received includes one or more indexes, the MBE synthesizer comprising: an excitation generator for generating voiced excitation components and unvoiced excitation components; a memory for storing a table of predetermined spectral vectors identified by indexes, at least a portion of the table of the predetermined spectral vectors having associated therewith predetermined voicing vectors; a harmonic amplitude estimator, responsive to one or more predetermined spectral vectors identified by indexes corresponding to the one or more indexes received, and for generating therefrom harmonic amplitude control signals; a multi-band voicing controller, responsive to the predetermined voicing vectors which are associated with the one or more predetermined spectral vectors identified, for controlling a selection of the excitation components; and a multiplier, for multiplying the harmonic amplitude control signals and the excitation components selected, for generating spectral components representing the segment of speech.<br>9. An MBE synthesizer for generating a segment of speech from compressed speech data which is received by a receiver coupled thereto, the compressed speech data which is received including one or more indexes and pitch data, the MBE synthesizer comprising: an excitation generator utilizing a transform function for generating excitation components which are transformed voiced excitation components and transformed unvoiced excitation components, wherein the generation of the transformed voiced excitation components being responsive to the pitch data; a memory for storing one or more tables of predetermined spectral vectors identified by indexes; a harmonic amplitude estimator, responsive to one or more predetermined spectral vectors identified by indexes corresponding to the one or more indexes received, and for generating therefrom harmonic amplitude control signals; a multi-band voicing controller for controlling a selection of the transformed voiced excitation components and transformed unvoiced excitation components; and a multiplier, for multiplying the harmonic amplitude control signals and the transformed voiced excitation components and transformed unvoiced excitation components selected, for generating spectral components representing the segment of speech.<br>19. An MBE synthesizer for generating a segment of speech from compressed speech data which is received by a receiver coupled thereto, the compressed speech data which is received including one or more indexes and pitch data, the MBE synthesizer comprising: an excitation generator for generating transformed voiced excitation components and transformed unvoiced excitation components, wherein the generation of the voiced excitation components being responsive to the pitch data; a memory for storing one or more tables of predetermined spectral vectors identified by indexes; a harmonic amplitude estimator, responsive to one or more predetermined spectral vectors identified by indexes corresponding to the one or more indexes received, and for generating therefrom harmonic amplitude control signals which are further associated with harmonics defined by the pitch data which is received, and wherein said harmonic amplitude estimator further comprises a peak detector having a peak magnitude threshold for detecting harmonic amplitude control signals having a magnitude greater than the peak magnitude threshold, a peak enhancer for generating peak enhanced harmonic amplitude control signals by enhancing magnitudes of harmonic amplitude control signals having magnitudes greater then the peak magnitude threshold, a valley detector having a minimum magnitude threshold for detecting peak enhanced harmonic amplitude control signals having a magnitude less than the minimum magnitude threshold, and a valley enhancer for generating enhanced harmonic amplitude control signals by decreasing the magnitudes of the peak enhanced harmonic amplitude control signals having magnitudes less than the minimum magnitude threshold; a multi-band voicing controller for controlling a selection of the transformed voiced excitation components and transformed unvoiced excitation components; and a multiplier, for multiplying the harmonic amplitude control signals and the transformed voiced excitation components and transformed unvoiced excitation components selected, for generating spectral components representing the segment of speech.<br>26. An MBE synthesizer for generating a segment of speech from compressed speech data which is received by a receiver coupled thereto, the compressed speech data which is received including one or more indexes, the MBE synthesizer comprising: a memory for storing a table of predetermined spectral vectors identified by indexes, at least a portion of the table of the predetermined spectral vectors having associated therewith predetermined voicing vectors, wherein the predetermined voicing vectors comprise a plurality of voicing parameters associated with a plurality of bands of spectral information, a voicing parameter identifying a likelihood of a band of the plurality of bands being voiced or unvoiced; a harmonic amplitude estimator, responsive to the one or more indexes for identifying one or more predetermined spectral vectors, and for generating therefrom harmonic amplitudes coefficients; multi-band voicing controller, being responsive to the predetermined voicing vector and to the harmonic amplitudes coefficients, for controlling voiced/unvoiced characteristics of each of the plurality of bands of spectral information; multi-band excitation generator for generating excitation components, the excitation components being divided into a plurality of bands of spectral information; and a multiplier, coupled to the harmonic amplitude estimator and to the multi-band voicing controller, for controlling amplitudes of the excitation components by multiplying the harmonic amplitude coefficients and the excitation components to generate a spectral components representing a segment of speech.</p></layer>
<layer id = "layer203"><p><b>US5794199A:Method and system for improved discontinuous speech transmission</b><br>A device and method for stretching, toning and strengthening the chest, shoulder, neck and upper back muscles of a patient thereby relieving pain and improving posture. Typically the patient is suffering from tension related muscle problems. The device and method are used to facilitate therapeutic treatment of the muscle problems by progressively stretching the muscles and thereby relieving the muscle problems.<br><b>Independant Claims</b><br>1. A method of generating comfort noise to interleave between bursts of speech in a speech synthesizer, comprising the steps of: providing an 8th order auto-regressive filter ##EQU4## where n=1, 2, . . . , 40; i=(k+1), . . . , N; and where j=1, 2, . . . , 40; feeding a first excitation signal, e.sub.i,j (n), to the 8th order auto-regressive filter with coefficients aÂ0!=1.0, aÂ1!, . . . , aÂ8! to generate a synthetic speech component, s(i, j)Ân! in each noisy subframe (i, j); and generating a second excitation signal which includes both a pseudo-random noise component and a component which depends upon past excitations, wherein said component which depends upon past excitations is the synthetic speech component, s(i, j)Ân!.</p></layer>
<layer id = "layer204"><p><b>US4058676A:Speech analysis and synthesis system</b><br>Variable pressure weighting material particles that include a hollow, elastically deformable particle which itself comprises a wall and an internal fluid at a pressure of 15 psi to about 100 psi. The variable pressure weighting material particles generally include a hollow, elastically deformable particle that compresses during introduction into a subterranean formation and returns to substantially the same shape when removed from the subterranean formation.<br><b>Independant Claims</b><br>1. A speech analysis and synthesis system capable of processing a plurality of speech channels in real time, said system comprising: an analyzer including, means for analyzing a plurality of electrical speech signals by Cepstrum technique to generate a pitch period parameter for each speech signal, means for analyzing said plurality of speech signals to generate a voiced/unvoiced decision parameter for each speech signal, means for analyzing said plurality of speech signals by linear prediction technique to generate a predetermined number of coefficient parameters and a power parameter for each speech signal; and a synthesizer including, pitch pulse generator means for receiving said pitch period parameters and generating pitch pulses having a corresponding pitch period, random noise generator means, switch means connected to said pitch pulse generator means and to said random noise generator means for receiving said voiced/unvoiced decision parameters, an output of said switch means being derived from said pitch pulse generator means if said decision is voiced and from said random noise generator means if said decision is invoiced, gain control means connected to said output of said switch means for receiving said power parameters, an output level of said gain control means being dependent upon said power parameters, and linear prediction filter means connected to said output of said gain control means for receiving and applying said coefficient parameters to said filter means to generate a replica of each of said plurality of speech signals at an output of said filter means.<br>2. A speech analysis and synthesis system comprising: an analyzer including, means for analyzing an electrical speech signal by Cepstrum technique to generate a pitch period parameter, means for analyzing said speech signal to generate a voiced/unvoiced decision parameter, and means for analyzing said speech signal by linear prediction technique to generate a predetermined number of coefficient parameters and a power parameter; and a synthesizer including, pitch pulse generator means for receiving said pitch period parameter and generating pitch pulses having a corresponding pitch period, random noise generator means, switch means connected to said pitch pulse generator means and to said random noise generator means for receiving said voiced/unvoiced decision parameter, an output of said switch means being derived from said pitch pulse generator means if said decision is voiced, and from said random noise generator means if said decision is unvoiced, gain control means connected to said output of said switch means for receiving said power parameter, an output level of said gain control means being dependent upon said power parameter, and linear prediction filter means connected to said output of said gain control means for receiving and applying said coefficient parameters to said filter means to generate a replica or said speech signal at an output of said filter means; wherein said means for analyzing said speech signal to generate a voiced/unvoiced decision parameter includes means for scanning a Cepstrum signal within an auxilliary signal range on each side of a Cepstrum peak amplitude signal, means for detecting and storing a range peak signal within the scanned auxilliary ranges, means for summing the absolute values of the signal within the auxilliary ranges to form a range signal sum, means for dividing said Cepstrum peak amplitude signal by said range peak signal to form a range peak factor, means for dividing said range signal sum by said Cepstrum peak amplitude signal to form an average peak factor, means for first comparing said range peak factor with predetermined upper and lower limits and generating a voiced decision parameter if said range peak factor is above said upper limit and generating an unvoiced decision parameter if said range peak factor is equal to or below said lower limit, and means for secondarily comparing said average peak factor with predetermined upper and lower limits and generating a voiced decision parameter if said average peak factor is equal to or less than said lower limit and generating an unvoiced decision parameter if said average peak factor is equal to or greater than said upper limit.<br>8. A speech analysis and synthesis system comrising: an analyzer including, means for analyzing an electrical speech signal by Cepstrum technique to generate a pitch period parameter, means for analyzing said speech signal to generate a voiced/unvoiced decision parameter, and means for analyzing said speech signal by linear prediction technique to generate a predetermined number of coefficient parameters and a power parameter; and a synthesizer including, pitch pulse generator means for receiving said pitch period parameter and generating pitch pulses having a corresponding pitch period, random noise generator means, switch means connected to said pitch pulsed generator means to said random noise generator means for receiving said voiced/unvoiced decision parameter, an output of said switch means being derived from said pitch pulse generator means if said decision is voiced, and from said random noise generator means if said decision is unvoiced, gain control means connected to said output of said switch means for receiving said power parameter, an output level of said gain control means being dependent upon said power parameter, and linear prediction filter means connected to said output of said gain control means for receiving and applying said coefficient parameters to said filter means to generate a replica or said speech signal at an output of said filter means; wherein said means for analyzing an electrical speech signal by Cepstrum technique includes means for conditioning a Cepstrum signal generated by said Cepstrum technique, said signal conditioning means generating a weighting signal which linearly increases in value during the time span of said Cepstrum and said means for conditioning said Cepstrum further adding said weighting signal to said Cepstrum during said time span to create a weighted Cepstrum signal.<br>10. A method of analyzing and synthesizing, in real time, speech signals in a plurality of speech channels, said method comprising the steps of: analyzing said speech signals by, analyzing each of said plurality of speech signals by a Cepstrum technique to generate a pitch period parameter, analyzing each of said plurality of speech signals to generate a voiced/unvoiced decision parameter, and analyzing each of said pluality of signals by linear prediction technique to generate a predetermined number of coefficient parameters and a power parameter; and synthesizing said speech signals by, generating pitch pulses having a pitch period corresponding to said pitch period parameter generated in said first analyzing step, generating a random noise signal, switching the output of said generated pitch pulses to an output of a switch means if said voiced/unvoiced decision parameter generated during said second analysis step is voiced and switching said random noise signal to said output of said switch means if said voiced/unvoiced decision is unvoiced, controlling the gain of said output of said switch means with gain control means in accordance with said generated power parameter, and connecting the output of said gain control means to the input of linear prediction filter means and applying said coefficient parameters to said filter means to generate a replica of each of said plurality of speech signals at an output of said filter means.<br>11. A method of analyzing and synethesizing speech signals comprising the steps of: analyzing said speech signals by, analyzing said electrical speech signal by a Cepstrum technique to generate a pitch period parameter, analyzing said speech signal to generate a voiced/unvoiced decision parameter, analyzing said speech signal by linear prediction technique to generate a predetermined number of coefficient parameters and a power parameter; and p1 synthesizing said speech signal by, generating pitch pulses having a pitch period corresponding to said pitch period parameter generated in said first analyzing step, generating a random noise signal, switching the output of said generated pitch pulses to an output of a switch means if said voiced/unvoiced decision parameter generated during said second analysis step is voiced and switching said random noise signal to said output of said switch means if said voiced/unvoiced decision is unvoiced, controlling the gain of said output of said switch means with gain control means in accordance with said generated power parameter, and connecting the output of said gain control means to the input of linear prediction filter means and applying said coefficient parameters to said filter means to generate a replica of said speech signal to an output of said filter means; wherein said step of analyzing said speech signal to generate a voiced/unvoiced decision parameter includes scanning a Cepstrum signal within an auxilliary signal range on each side of a Cepstrum peak amplitude signal, detecting and storing a range peak signal within the scanned auxilliary ranges, summing the absolute values of the signals within the auxilliary ranges to form a range signal sum, dividing said Cepstrum peak amplitude signal by said range peak signal to form a range peak factor; dividing said range signal sum by said Cepstrum peak amplitude signal to form an average peak factor, first comparing said range peak factor with predetermined upper and lower limits and generating a voiced decision parameter if said range peak factor is above said upper limit and generating an unvoiced decision parameter if said range peak factor is equal to or below said lower limit, and secondarily comparing said average peak factor with predetermined upper and lower limits and generating a voiced decision parameter if said average peak factor is equal to or less than said lower limit and generating an unvoiced decision parameter if said average peak factor is equal to or greater than said upper limit.<br>16. A method of analyzing and synthesizing speech signals comprising the steps of: analyzing said speech signals by, analyzing said electrical speech signal by a Cepstrum technique to generate a pitch period parameter, analyzing said speech signal to generate a voiced/unvoiced decision parameter, analyzing said speech signal by linear prediction technique to generate a predetermined number of coefficient parameters and a power parameter; and synthesizing said speech signal by, generating pitch pulses having a pitch period corresponding to said pitch period parameter generated in said first analyzing step, generating a random noise signal, switching the output of said generated pitch pulses to an output of a switch means if said voiced/unvoiced decision parameter generated during said second analysis step is voiced and switching said random noise signal to said output of said switch means if said voiced/unvoiced decision is unvoiced, controlling the gain of said output of said switch means with gain control means in accordance with said generated power parameter, and connecting the output of said gain control means to the input of linear prediction filter means and applying said coefficient parameters to said filter means to generate a replica of said speech signal to an output of said filter means; wherein said step of analyzing electrical speech signals by Cepstrum technique includes a signal conditioning step for conditioning a Cepstrum signal which has a dimension in the direction of an ordinate axis, which is the amplitude of said Cepstrum signal and has a dimension in the direction of the abscissa which is a quantity representing time, said signal conditioning step having the steps of, generating a weighting signal which linearly increases in value with the dimension in the direction of the abscissa corresponding to said quantity representing time of said Cepstrum, and adding said weighting signal to said Cepstrum signal along said dimension in the direction of the abscissa thereof to generate a weighted Cepstrum signal.<br>17. A method of analyzing and synthesizing speech signals comprising the steps of: analyzing said speech signals by, analyzing said electrical speech signal by a Cepstrum technique to generate a pitch period parameter, analyzing said speech signal to generate a voiced/unvoiced decision parameter, analyzing said speech signal by linear prediction technique to generate a predetermined number of coefficient parameters and a power parameter; and synthesizing said speech signal by, generating pitch pulses having a pitch period corresponding to said pitch period parameter generated in said first analyzing step, generating a random noise signal, switching the output of said generated pitch pulses to an output of a switch means if said voiced/unvoiced decision parameter generated during said second analysis step is voiced and switching said random noise signal to said output of said switch means if said voiced/unvoiced decision is unvoiced, controlling the gain of said output of said switch means with gain control means in accordance with said generated power parameter, and `connecting the output of said gain control means to the input of linear prediction filter means and applying said coefficient parameters to said filter means to generate a replica of said speech signal to an output of said filter means; wherein said pitch pulse generating step includes generating a sequence of control signals in response to receipt of said pitch period parameter, and generating a substantially periodic, amplitude increasing pitch pulse excitation signal in response to said sequence of control signals.<br>19. A system for analyzing a plurality of speech signals in real time and generating representative control parameters therefor, said system comprising: means for analyzing a plurality of electrical speech signals by Cepstrum technique to generate a pitch period parameter for each of said signals; means for analyzing each of said plurality of speech signals to generate a voiced/unvoiced decision parameter; means for analyzing each of said plurality of speed signals by linear prediction technique to generate a predetermined number of coefficent parameters and a power parameter; and means for combining said pitch period parameter, said voiced/unvoiced decision parameter, said coefficient parameters and said power parameter into a composite signal representative of each of said plurality of speech signals for transmission in compressed form to a point of utilization.<br>20. A system for analyzing a speech signal and generating representative control parameters therefor, said system comprising: means for analyzing an electrical speech signal by Cepstrum technique to generate a pitch period parameter; means for analyzing said speech signal to generate a voiced/unvoiced decision parameter; means for analyzing said speech signal by linear prediction technique to generate a predetermined number of coefficient parameters and a power parameters; and means for combining said pitch period parameter, said voiced/unvoiced decision parameter, said coefficient parameters and said power parameter into a composite signal representative of said speech signal; wherein said means for analyzing said speech signal to generate a voiced/unvoiced decision parameter includes means for scanning a Cepstrum signal within an auxilliary signal range on each side of a Cepstrum peak amplitude signal, means for detecting and storing a range peak signal within the scanned auxilliary ranges; means for summing the absolute values of the signals within the auxilliary ranges to form a range signal sum, means for dividing said Cepstrum peak amplitude signal by said range peak signal to form a range peak factor, means for dividing said range signal sum by said Cepstrum peak amplitude signal to form an average peak factor, means for first comparing said range peak factor with predetermined upper and lower limits and generating a voiced decision parameter if said range peak factor is above said upper limit and generating an unvoiced decision parameter if said range peak factor is equal to or below said lower limit, and means for secondarily comparing said average peak factor with predetermined upper and lower limits and generating a voiced decision parameter if said average peak factor is equal to or less than said lower limit and generating an unvoiced decision parameter if said average peak factor is equal to or greater than said upper limit.<br>26. A system for analyzing a speech signal and generating representative control parameters therefor, said system comprising: means for analyzing an electrical speech signal by Cepstrum technique to generate a pitch period parameter; means for analyzing said speech signal to generate a voiced/unvoiced decision parameter; means for analyzing said speech signal by linear prediction technique to generate a predetermined number of coefficient parameters and a power parameter; and means for combining said pitch period parameter, said voiced/unvoiced decision parameter, said coefficient parameters and said power parameter into a composite signal representative of said speech signal; wherein said means for analyzing an electrical speech signal by Cepstrum technique includes a signal conditioning system for conditioning a Cepstrum signal which has, in the direction of an ordinate axis, an amplitude dimension of said Cepstrum signal and, in the direction of the abscissa, a quantity representing time, said signal conditioning system having, means for generating a weighting signal which linearly increases in value with the dimension in the direction of the abscissa corresponding to said quantity representing time of said Cepstrum, and means for adding said weighting signal to said Cepstrum signal along said dimension in the direction of the abscissa thereof to generate a weighted Cepstrum signal.<br>27. A method for analyzing a plurality of speech signals in real time and generating representative control parameters therefor, said method comprising the steps of: analyzing each of a plurality of speech signals by a Cepstrum technique to generate a pitch period parameter; analyzing each of said plurality of speech signals to generate a voiced/unvoiced decision parameter; and analyzing each of said plurality of speech signals by linear prediction technique to generate a predetermined number of coefficient parameters and a power parameter.<br>28. A method for analyzing a speech signal and generating representative control parameters therefor, said method comprising the steps of: analyzing said speech signal by a Cepstrum technique to generate a pitch period parameter; analyzing said speech signal to generate a voiced/unvoiced decision parameter; and analyzing said speech signal by linear prediction technique to generate a predetermined number of coefficient parameters and a power parameter; wherein said step of analyzing said speech signal to generate a voiced/unvoiced decision parameter includes scanning a Cepstrum signal within an auxilliary signal range on each side of a Cepstrum peak amplitude signal, detecting and storing a range peak signal within the scanned auxilliary ranges, summing the absolute values of the signals within the auxilliary ranges to form a range signal sum, dividing said Cepstrum peak amplitude signal by said range peak signal to form a range peak factor, dividing said range signal sum by said Cepstrum peak amplitude signal to form an average peak factor, first comparing said range peak factor with predetermined upper and lower limits and generating an voiced decision parameter if said range peak factor is above said upper limit and generating an unvoiced decision parameter if said range peak factor is equal to or below said lower limit, and secondarily comparing said average peak factor with predetermined upper and lower limits and generating a voiced decision parameter if said average peak factor is equal to or less than said lower limit and generating an unvoiced decision parameter if said average peak factor is equal to or greater than said upper limit.<br>34. A method for analyzing a speech signal and generating representative control parameters therefor, said method comprising the steps of: analyzing said speech signal by a Cepstrum technique to generate a pitch period parameter; analyzing said speech signal to generate a voiced/unvoiced decision parameter; and analyzing said speech signal by linear prediction technique to generate a predetermined number of coefficient parameters and a power parameter; wherein said analyzing electrical speech signal by Cepstrum technique includes the step of conditioning a Cepstrum signal, which has a dimension in the direction of an ordinate axis which is the amplitude of said Cepstrum signal and has dimension in the direction of the abscissa which is a quantity representing time, said signal conditioning step including, generating a weighting signal which linearly increases in value with the dimension in the direction of the abscissa corresponding to said quantity representing time of said Cepstrum, and adding said weighting signal to said Cepstrum signal along said dimension in the direction of the abscissa thereof to generate a weighted Cepstrum signal.<br>35. A system for synthesizing speech in real time from a plurality of sets of control parameters representative of a plurality of speech signals, said parameters including a pitch period parameter, a voiced/unvoiced decision parameter, a predetermined number of coefficient parameters and a power parameter, said system comprising: pitch pulse generator means for receiving said pitch period parameter and generating pitch pulses having a corresponding pitch period; random noise generator means; switch means connected to said pitch pulse generator means and to said random noise generator means for receiving said voiced/unvoiced decision parameter, an output of said switch means being derived from the output of said pitch pulse generator means if said decision is voiced and from said random noise generator means if said decision is unvoiced; gain control means connected to said output of said switch means, for receiving said power parameter, an output level of said gain control means being dependent upon said power parameter; and linear prediction filter means connected to said output of said control means for receiving and applying said coefficient parameters to said filter means to generate a replica of each of said plurality of speech signals at an output of said filter means.<br>36. A system for synthesizing speech from a combination of control parameters representative of a speech signal, said parameters including a pitch period parameter, a voiced/unvoiced decision parameter, a predetermined number of coefficient parameters and a power parameter, said system comprising: pitch pulse generator means for receiving said pitch period parameter and generating pitch pulses having a corresponding pitch period; random noise generator means; switch means connected to said pitch pulse generator means and to said random noise generator means for receiving said voiced/unvoiced decision parameter, an output of said switch means being derived from the output of said pitch pulse generator means if said decision is voiced and from said random noise generator means if said decision is unvoiced; gain control means connected to said output of said switch means, for receiving said power parameter, an output level of said gain control means being dependent upon said power parameter; and linear prediction filter means connected to said output of said control means, for receiving and applying said coefficient parameters to said filter means to generate a replica of said speech signal at an output of said filter means; wherein said pitch pulse generator means includes means responsive to receipt of said pitch period parameter for generating a sequence of control signals, and means responsive to said sequence of control signals for generating a substantially periodic, amplitude increasing pitch pulse excitation signal.<br>37. A method of synthesizing speech in real time from a plurality of combinations of control parameters representative of a plurality of speech signals, said parameter including a pitch period parameter, a voiced/unvoiced decision parameter, a predetermined number of coefficient parameters and a power parameter, said method comprising the steps of: receiving said pitch period parameter and generating pitch period pulses having a corresponding pitch period; generating a random noise signal; switching said pitch period signals to an output of a switch means when said voiced/unvoiced decision parameter is voiced and switching said random noise signal to said output of said switch means if said voiced/unvoiced decision parameter is unvoiced; controlling the gain of the output of said switch means in response to said power parameter; and connecting the output of said gain controlled switch means to a linear prediction filter means connected to said coefficient parameters to generate a replica of each of said plurality of speech signals at an output of said filter means.<br>38. A method of synthesizing speech from a combination of control parameters representative of a speech signal, said parameters including a pitch period parameter, a voiced/unvoiced decision parameter, a predetermined number of coefficient parameters and a power parameter, said method comprising the steps of: receiving said pitch period parameter and generating pitch period pulses having a corresponding pitch period; generating a random noise signal; switching said pitch period signals to an output of a switch means when said voiced/unvoiced decision parameter is voiced and switching said random noise signal to said output of said switch means if said voiced/unvoiced decision parameter is unvoiced; controlling the gain of the output of said switch means in response to said power parameter; and connecting the output of said gain controlled switch means to a linear prediction filter means connected to said coefficient parameters to generate a replica of said speech signal at an output of said filter means; wherein said pitch pulse generating step includes generating a sequence of control signals in response to receipt of said pitch period parameter; and generating a substantially periodic, amplitude increasing pitch period pulse excitation signal in response to said sequence of control signals.<br>39. A system for speech analysis and synthesis, comprising: an analyzer including, means for analyzing a plurality of speech signal channels in real time by Cepstrum technique to generate a pitch period parameter for each of said speech signal channels, means for analyzing each of said plurality of speech signal channels, to generate a voiced/unvoiced decision parameter for each channel, means for analyzing each of said plurality of speech signal channels by linear prediction technique to generate a predetermined number of coefficient parameters and a power parameter for each of said channels, means for combining said pitch period parameter, coefficient parameters, power parameter, and voiced/unvoiced decision parameter into a set of parameters for each of said speech channels, means for combining said sets of parameters for each speech channel into a single transmission channel signal, means for transmitting said single transmission channel signal to a receiver, and means for separating said received single transmission channel signal into respective sets of parameters for a respective plurality of synthesis channels; and a synthesizer including, pitch pulse generator means for receiving said pitch period parameter for each of said synthesis channels and generating pitch pulses having a corresponding pitch period, random noise generator means, switch means connected to said pitch pulse generator means and to said random noise generator means for receiving said voiced/unvoiced decision parameters for each of said synthesis channels, an output of said switch means being said pitch pulse generator means if said decision for a channel is voiced and said output of said switch means being said random noise generator means if said decision for a channel is unvoiced, gain control means connected to said output of said switch means for receiving said power parameters for each of said synthesis channels, an output level of said gain control means being dependent upon said power parameter for each of said synthesis channels, and linear prediction filter means connected to said output of said gain control means for receiving and applying said coefficient parameters for each of said synthesis channels to said filter means to generate a replica of each of said speech signals at an output of said filter means.<br>40. A system for speech analysis and synthesis, comprising: an analyzer including, means for analyzing a plurality of speech signal channels by Cepstrum technique to generate a pitch period parameter for each of said speech signal channels, means for analyzing each of said plurality of speech signal channels, to generate a voiced/unvoiced decision parameter for each channel, means for analyzing each of said plurality of speech signal channels by linear prediction technique to generate a predetermined number of coefficient parameters and a power parameter for each of said channels, means for combining said pitch period parameter, coefficient parameters, power parameter, and voiced/unvoiced decision parameter into a set of parameters for each of said speech channels, means for combining said sets of parameters for each speech channel into a single transmission channel signal, means for transmitting said single transmission channel signal to a receiver, and means for separating said received single transmission channel signal into respective sets of parameters for a respective plurality of synthesis channels; and a synthesizer including, pitch pulse generator means for receiving said pitch period parameter for each of said synthesis channels and generating pitch pulses having a corresponding pitch period, random noise generator means, switch means connected to said pitch pulse generator means and to said random noise generator means for receiving said voiced/unvoiced decision parameters for each of said synthesis channels, an output of said switch means being said pitch pulse generator means if said decision for a channel is voiced and said output of said switch means being said random noise generator means if said decision for a channel is unvoiced, gain control means connected to said output of said switch means for receiving said power parameters for each of said synthesis channels, an output level of said gain control means being dependent upon said power parameter for each of said synthesis channels, and linear prediction filter means connected to said output of said gain control means for receiving and applying said coefficient parameters for each of said synthesis channels to said filter means to generate a replica of each of said speech signals at an output of said filter means; wherein said means for analyzing each of said plurality of speech signal channels said speech signal to generate a voiced/unvoiced decision parameter includes means for scanning a Cepstrum signal within an auxilliary signal range on each side of a Cepstrum peak amplitude signal, means for detecting and storing a range peak signal within the scanned auxilliary ranges, means for summing the absolute values of the signal within the auxilliary ranges to form a range signal sum, means for dividing said Cepstrum peak amplitude signal by said range peak signal to form a range peak factor, means for dividing said range signal sum by said Cepstrum peak amplitude signal to form an average peak factor, means for first comparing said range peak factor with predetermined upper and lower limits and generating a voiced decision parameter if said range peak factor is above said upper limit and generating an unvoiced decision parameter if said range peak factor is equal to or below said lower limit, and means for secondarily comparing said average peak factor with predetermined upper and lower limits and generating a voiced decision parameter if said average peak factor is equal to or less than said lower limit and generating an unvoiced decision parameter if said average peak factor is equal to or greater than said upper limit.<br>47. A system for speech analysis and synthesis, comprising: an analyzer including, means for analyzing a plurality of speech signal channels by Cepstrum technique to generate a pitch period parameter for each of said speech signal channels, means for analyzing each of said plurality of speech signal channels, to generate a voiced/unvoiced decision parameter for each channel, means for analyzing each of said 1lurality of speech signal channels by linear prediction technique to generate a predetermined number of coefficient parameters and a power parameter for each of said channels, means for combining said pitch period parameter, coefficient parameters, power parameter, and voiced/unvoiced decision parameter into a set of parameters for each of said speech channels, means for combining said sets of parameters for each speech channel into a single transmission channel signal, means for transmitting said single transmission channel signal to a receiver, and means for separating said received single transmission channel signal into respective sets of parameters for a respective plurality of synthesis channels; and a synthesizer including, pitch pulse generator means for receiving said pitch period parameter for each of said synthesis channels and generating pitch pulses having a corresponding pitch period, random noise generator means, switch means connected to said pitch pulse generator means and to said random noise generator means for receiving said voiced/unvoiced decision parameters for each of said synthesis channels, an output of said switch means being said pitch pulse generator means if said decision for a channel is voiced and said output of said switch means being said random noise generator means if said decision for a channel is unvoiced, gain control means connected to said output of said switch means for receiving said power parameters for each of said synthesis channels, an output level of said gain control means being dependent upon said power parameter for each of said synthesis channels, and linear prediction filter means connected to said output of said gain control means for receiving and applying said coefficient parameters for each of said synthesis channels to said filter means to generate a replica of each of said speech signals at an output of said filter means; wherein said means for analyzing the plurality of speech signal channels by Cepstrum technique to generate a pitch period parameter includes a signal conditioning system for conditioning a Cepstrum signal which has, in the direction of an ordinate axis, an amplitude dimension of said Cepstrum signal and, in the direction of the abscissa, a quantity representing time, said signal conditioning system having, means for generating a weighting signal which linearly increases in value with the dimension in the direction of the abscissa corresponding to said quantity representing time of said Cepstrum, and means for adding said weighting signal to said Cepstrum signal along said dimension in the direction of the abscissa thereof to generate a weighted Cepstrum signal.<br>48. A system for analyzing a plurality of speech signal channels, in real time, said system comprising an analyzer including: means for analyzing a plurality of speech signal channels by Cepstrum technique to generate a pitch period parameter for each of said speech signal channels; means for analyzing each of said plurality of speech signal channels to generate a voiced/unvoiced decision parameter for each channel; and means for analyzing each of said plurality of speech signal channels by linear prediction technique to generate a predetermined number of coefficient parameters and a power parameter for each of said channels.<br>49. A system for analyzing a plurality of speech signal channels, comprising an analyzer including: means for analyzing a plurality of speech signal channels by Cepstrum technique to generate a pitch period parameter for each of said speech signal channels; means for analyzing each of said plurality of speech signal channels to generate a voiced/unvoiced decision parameter for each channel; and means for analyzing each of said plurality of speech signal channels by linear prediction technique to generate a predetermined number of coefficient parameters and a power parameter for each of said channels; wherein said means for analyzing said speech signal to generate a voiced/unvoiced decision parameter includes means for scanning a Cepstrum signal within an auxilliary signal range on each side of Cepstrum peak amplitude signal, means for detecting and storing a range peak signal within the scanned auxilliary ranges, means for summing the absolute values of the signal within the auxilliary ranges to form a range signal sum, means for dividing said Cepstrum peak amplitude signal by said range peak signal to form a range peak factor; means for dividing said range signal sum by said Cepstrum peak amplitude signal to form an average peak factor, means for first comparing said range peak factor with predetermined upper and lower limits and generating a voiced decision parameter if said range peak factor is above said upper limit and generating an unvoiced decision parameter if said range peak factor is equal to or below said lower limit, and means for secondarily comparing said average peak factor with predetermined upper and lower limits and generating a voiced decision parameter if said average peak factor is equal to or less than said lower limit and generating an unvoiced decision parameter if said average peak factor is equal to or greater than said upper limit.<br>55. A system for analyzing a plurality of speech signal channels, comprising an analyzer including: means for analyzing a plurality of speech signal channels by Cepstrum technique to generate a pitch period parameter for each of said speech signal channels; means for analyzing each of said plurality of speech signal channels to generate a voiced/unvoiced decision parameter for each channel; and means for analyzing each of said plurality of speech signal channels by linear prediction technique to generate a predetermined number of coefficient parameters and a power parameter for each of said channels; wherein said means for analyzing a plurality of speech signal channels by Cepstrum technique includes a signal conditioning system for conditioning a Cepstrum signal which has, in the direction of an ordinate axis, an amplitude dimension of said Cepstrum signal and, in the direction of the abscissa, a quantity representing time, said signal conditioning system having, means for generating a weighting signal which linearly increases in value with the dimension in the direction of the abscissa corresponding to said quantity representing time of said Cepstrum, and means for adding said weighting signal to said Cepstrum signal along said dimension in the direction of the abscissa thereof to generate a weighted Cepstrum signal.<br>56. A system for synthesizing speech in a plurality of speech synthesis channels in real time, said system comprising: pitch pulse generator means for receiving pitch period parameters for each of said synthesis channels and generating pitch pulses having a corresponding pitch period; random noise generator means; switch means connected to said pitch pulse generator means and to said random noise generator means for receiving voiced/unvoiced decision parameters for each of said synthesis channels, an output of said switch means being derived from said pitch pulse generator means if said decision for a channel is voiced and from said random noise generator means if said decision for a channel is unvoiced; gain control means connected to said output of said switch means for receiving power parameters for each of said synthesis channels, an output level of said gain control means being dependent upon said power parameter for each of said synthesis channels; and linear prediction filter means connected to said output of said gain control means for receiving and applying a plurality of coefficient parameters for each of said synthesis channels to said filter means to generate a replica of each of said speech signals at an output of said filter means.<br>57. A system for speech synthesis, comprising a synthesizer including: pitch pulse generator means for receiving pitch period parameters for each of said synthesis channels and generating pitch pulses having a corresponding pitch period; random noise generator means; switch means connected to said pitch pulse generator means and to said random noise generator means for receiving voiced/unvoiced decision parameters for each of said synthesis channels, an output of said switch means being derived from said pitch pulse generator means if said decision for a channel is voiced and from said random noise generator means if said decision for a channel is unvoiced; gain control means connected to said output of said switch means for receiving power parameters for each of said synthesis channels, an output level of said gain control means being dependent upon said power parameter for each of said synthesis channels; and linear prediction filter means connected to said output of said gain control means for receiving and applying a plurality of coefficient parameters for each of said synthesis channels to said filter means to generate a replica of each of said speech signals at an output of said filter means; wherein said pitch pulse generator means includes means responsive to receipt of said pitch period parameters for generating a sequence of control signals, and means responsive to said sequence of control signals for generating a substantially periodic, amplitude increasing pitch pulse excitation signal.<br>59. A speech analysis system for generating in real time a plurality of sets of paramaters each representative of an analog speech signal as produced by a model speech generator, said system comprising: means for sampling each of said analog speech signals to produce a plurality of digital speech data signals; means for separating a fixed number of said speech data signals into a frame of speech data signals; means for analyzing said frame of said speech data with a Cepstrum generator to produce a digital speech pitch period parameter for said frame of data; means for analyzing said frame of data with a linear prediction coefficient generator to produce a plurality of digital coefficeint generator to produce a plurality of digital coefficeint parameters and a digital power parameter; means for analyzing said frame of speech data with a voiced/unvoiced decision generator to produce a digital voiced/unvoiced decision parameter; and means for combining, for each speech signal, said digital pitch period parameter, said plurality of digital coefficient parameters, said digital power parameter, and said digital voiced/unvoiced decision parameter into a set of parameters representative of each of said analog speech signals.<br>60. A speech analysis system for generating a set of parameters representative of an analog speech signal as produced by a model speech generator, said system comprising: means for sampling said analog speech signal to produce a plurality of digital speech data signals; means for separating a fixed number of said speech data signals into a frame of speech data signals; means for analyzing said frame of said speech data with a Cepstrum generator to produce a digital speech pitch period parameter for said frame of data; means for analyzing said frame of data with a linear prediction coefficient generator to produce a plurality of digital coefficient parameters and a digital power parameter; means for analyzing said frame of speech data with a voiced/unvoiced decision generator to produce a digital voiced/unvoiced decision parameter; and means for combining said digital pitch period parameter, said plurality of digital coefficient parameters, said digital power parameter, and said digital voiced/unvoiced decision paramater into said set of parameters representative of said analog speech signal; wherein said means for analyzing said frame of speech data to produce a digital voiced/unvoiced decision parameter includes means for scanning a Cepstrum signal within an auxilliary signal range on each side of a Cepstrum peak amplitude signal, means for detecting and storing a range peak signal within the scanned auxilliary ranges, means for summing the absolute values of the signal within the auxilliary ranges to form a range signal sum, means for dividing said Cepstrum peak amplitude signal by said range peak signal to form a range peak factor, means for dividing said range signal sum by said Cepstrum peak amplitude signal to form an average peak factor, means for first comparing said range peak factor will predetermined upper and lower limits and generating a voiced decision parameter if said range peak factor is above said upper limit and generating an unvoiced decision parameter if said range peak factor is equal to or below said lower limit, and means for secondarily comparing said average peak factor with predetermined upper and lower limits and generating a voiced decision parameter if said average peak factor is equal to or less than said lower limit and generating an unvoiced decision parameter if said average peak factor is equal to or greater than said upper limit.<br>66. A speech analysis system for generating a set of parameters representative of an analog speech signal as produced by a model speech generator, said system comprising: means for sampling said analog speech signal to produce a plurality of digital speech data signals; means for separating a fixed number of said speech data signals into a frame of speech data signals; means for analyzing said frame of said speech data with a Cepstrum generator to produce a digital speech pitch period parameter for said frame of data; means for analyzing said frame of data with a linear prediction coefficient generator to produce a plurality of digital coefficient parameters and a digital power parameter; means for analyzing said frame of speech data with a voiced/unvoiced decision generator to produce a digital voiced/unvoiced decision parameter; and means for combining said digital pitch period parameter, said plurality of digital coefficient parameters, said digital power parameter, and said digital voiced/unvoiced decision parameter into said set of parameters representative of said analog speech signal; wherein said means for analyzing said frame of speech data by Cepstrum technique includes a signal conditioning system for conditioning a Cepstrum signal which has, in the direction of an ordinate axis, an amplitude dimension of said Cepstrum signal and, in the direction of the abscissa, a quantity representing time, said signal conditioning system having, means for generating a weighting signal which linearly increases in value with the dimension in the direction of the abscissa corresponding to said quantity representing time of said Cepstrum, and means for adding said weighting signal to said Cepstrum signal along said dimension in the direction of the abscissa thereof to generate a weighted Cepstrum signal.<br>67. A pitch pulse generating system for use in a speech synthesizer which receives a pitch period parameter, said pitch pulse generating system comprising: means responsive to receipt of said pitch period parameter for generating a sequence of control signals; and means responsive to said sequence of control signals for generating a substantially periodic, amplitude increasing pitch pulse excitation signal.<br>69. A speech analysis system for generating a set of parameters representative of an analog speech signal as produced by a model speech generator, said system comprising: means for sampling said analog speech signal to produce a plurality of digital speech data signals; means for separating a fixed number of said speech data signals into a frame of speech data signals; means for analyzing said frame of said speech data with a Cepstrum generator to produce a digital speech pitch period parameter for said frame of data; means for analyzing said frame of data with a linear prediction coefficient generator to produce a plurality of digital coefficient parameters and a digital power parameter; means for analyzing said frame of speech data with a voiced/unvoiced decision generator to produce a digital voiced/unvoiced decision parameter; and means for combining said digital pitch period parameter, said plurality of digital coefficient parameters, said digital power parameter, and said digital voiced/unvoiced decision parameter into said set of parameters representative of said analog speech signal; wherein said means for analyzing said frame of said speech data to produce a speech pitch period parameter includes means for interpolating between sample values in a sample data Cepstrum signal, and wherein a pitch period value is initially chosen as corresponding to a maximum amplitude sample, said interpolating system having means for storing said maximum value sample, an immediately preceding sample, and an immediately following sample, means for subtracting said immediately preceding sample from said immediately following sample to form a sample difference, means for dividing said sample difference by four to form a sample difference quotient, means for adding said immediately preceding sample to said immediately following sample to form a sample sum, means for dividing said sample sum by two to form a sample sum quotient, means for subtracting said maximum amplitude sample from said sample sum quotient to form a weighted sample sum quotient, means for dividing said sample difference quotient by said weighted sample sum quotient to form a pitch value increment, and means for adding said pitch value increment to said pitch period value to form an interpolated pitch value.<br>70. A speech analysis system for generating a set of parameters representative of an analog speech signal as produced by a model speech generator, said system comprising: means for sampling said analog speech signal to produce a plurality of digital speech data signals; means for separating a fixed number of said speech data signals into a frame of speech data signals; means for analyzing said frame of said speech data with a Cepstrum generator to produce a digital speech pitch period parameter for said frame of data; means for analyzing said frame of data with a linear prediction coefficient generator to produce a plurality of digital coefficient parameters and a digital power parameter; means for analyzing said frame of speech data with a voiced/unvoiced decision generator to produce a digital voiced/unvoiced decision parameter; and means for combining said digital pitch period parameter, said plurality of digital coefficient parameters, said digital power parameter, and said digital voiced/unvoiced decision parameter into said set of parameters representative of said analog speech signal; wherein said means for analyzing said frame of data with a linear prediction coefficient generator includes a signal conditioning means for a frame of digital speech data samples, said signal conditioning means having means for generating a window signal having a characteristic waveshape which is completed in a data sample span which is shorter than said frame of data; means for centering said window signal data span in said frame of speech data samples; and means for multiplying corresponding sample positions of said frame of speech data and said window signal to generate a limited and windowed frame of speech data.<br>72. A speech analysis and synthesis system for generating a plurality of sets of parameters representative of a plurality of analog speech signals as produced by a model speech generator and reproducing in real time from said sets of parameters a replica of each of said analog speech signals, said system comprising: an analyzer including, means for sampling each analog speech signal to produce a plurality of digital speech data signals, means for separating said plurality of said speech data signals into a frame of speech data signals, means for analyzing said frame of speech data with a Cepstrum generator to produce a digital pitch period parameter for said frame of data, means for analyzing said frame of speech data with a voiced/unvoiced decision generator to produce a digital voiced/unvoiced decision parameter, and means for analyzing said frame of speech data with a linear prediction coefficient generator to produce a plurality of digital coefficient parameters and a digital power parameter; and a synthesizer including, digital pitch pulse generator means for receiving said digital pitch period parameter and generating for each original speech signal pitch pulses having a corresponding pitch period, digital random noise generator means, switch means connected to said pitch pulse generator means and to said random noise generator means for receiving said digital voiced/unvoiced decision parameter, an output of said switch means being derived from said pitch pulse generator means if said decision is voiced and from said random noise generator means if said decision in unvoiced, gain control means connected to said output of said switch means for receiving said digital power parameter, a digital output level of said gain control means being dependent upon said power parameter, digital linear prediction filter means connected to said output of said gain control means for receiving and applying said digital coefficient parameters to said filter means to generate a digital replica of each of said original speech signals at an output of said filter means, and means for converting said digital output of said filter means to a corresponding analog replica of each of said original analog speech signals.<br>73. A speech analysis and synthesis system for generating a set of parameters representative of an analog speech signal as produced by a model speech generator and reproducing from said set of parameters a replica of said analog speech signal, said system comprising: an analyzer including, means for sampling said analog speech signal to produce a plurality of digital speech data signals, means for separating said plurality of said speech data signals into a frame of speech data signals, means for analyzing said frame of speech data with a Cepstrum generator to produce a digital pitch period parameter for said frame of data, means for analyzing said frame of speech data with a voiced/unvoiced decision generator to produce a digital voiced/unvoiced decision parameter, and means for analyzing said frame of speech data with a linear prediction coefficient generator to produce a plurality of digital coefficient parameters and a digital power parameter; and a synthesizer including, digital pitch pulse generator means for receiving said digital pitch period parameter and generating pitch pulses having a corresponding pitch period, digital random noise generator means, switch means connected to said pitch pulse generator means and to said random noise generator means for receiving said digital voiced/unvoiced decision parameter, an output of said switch means being derived from said pitch pulse generator means if said decision is voiced and from said random noise generator means if said decision is unvoiced, gain control means connected to said output of said switch means for receiving said digital power parameter, a digital output level of said gain control means being dependent upon said power parameter, digital linear prediction filter means connected to said output of said gain control means for receiving and applying said digital coefficient parameters to said filter means to generate a digital replica of said speech signal at an output of said filter means, and means for converting said digital output of said filter means to a corresponding analog replica of said analog speech signal; wherein said means for analyzing said frame of speech data to produce a digital voiced/unvoiced decision parameter includes means for scanning a Cepstrum signal within an auxilliary signal range on each side of a Cepstrum peak amplitude signal, means for detecting and storing a range peak signal within the scanned auxilliary ranges, means for summing the absolute values of the signal within the auxilliary ranges to form a range signal sum, means for dividing said Cepstrum peak amplitude signal by said range peak signal to form a range peak factor; means for dividing said range signal sum by said Cepstrum peak amplitude signal to form an average peak factor, means for first comparing said range peak factor with predetermined upper and lower limits and generating a voiced decision parameter if said range peak factor is equal to or above said upper limit and generating an unvoiced decision if said range peak factor is equal to or below said lower limit, and means for secondarily comparing said average peak factor with predetermined upper and lower limits and generating a voiced decision parameter if said average peak factor is equal to or less than said lower limit and generating an unvoiced decision parameter if said average peak factor is equal to or greater than said upper limit.<br>79. A speech analysis and synthesis system for generating a set of parameters representative of an analog speech signal as produced by a model speech generator and reproducing from said set of parameters a replica of said analog speech signal, said system comprising: an analyzer including, means for sampling said analog speech signal to produce a plurality of digital speech data signals, means for separating said plurality of said speech data signals into a frame of speech data signals, means for analyzing said frame of speech data with a Cepstrum generator to produce a digital pitch period parameter for said frame of data, means for analyzing said frame of speech data with a voiced/unvoiced decision generator to produce a digital voiced/unvoiced decision parameter, and means for analyzing said frame of speech data with a linear prediction coefficient generator to produce a plurality of digital coefficient parameters and a digital power parameter; and a synthesizer including, digital pitch pulse generator means for receiving said digital pitch period parameter and generating pitch pulses having a corresponding pitch period, digital random noise generator means, switch means connected to said pitch pulse generator means and to said random noise generator means for receiving said ditigal voiced/unvoiced decision parameter, an output of said switch means being derived from said pitch pulse generator means if said decision is voiced and from said random noise generator means if said decision is unvoiced, gain control means connected to said output of said switch means for receiving said digital power parameter, a digital output level of said gain control means being dependent upon said power parameter, digital linear prediction filter means connected to said output of said gain control means for receiving and applying said ditigal coefficient parameters to said filter means to generate a digital replica of said speech signal at an output of said filter means, and means for converting said digital output of said filter means to a corresponding analog replica of said analog speech signal; wherein said means for analyzing said frame of speech data with a Cepstrum generator includes a signal conditioning system for conditioning a Cepstrum signal which has, in the direction of an ordinate axis, an amplitude dimension of said Cepstrum signal and, in the direction of the abscissa, a quantity representing time, said signal conditioning system having, means for generating a weighting signal which linearly increases in value with the dimension in the direction of the abscissa corresponding to said quantity representing time of said Cepstrum, and means for adding said weighting signal to said Cepstrum signal along said dimension in the direction of the abscissa thereof to generate a weighted Cepstrum signal.<br>80. A speech analysis and synthesis system for generating a set of parameters representative of an analog speech signal as produced by a model speech generator and reproducing from said set of parameters a replica of said analog speech signal, said system comprising: an analyzer including, means for sampling said analog speech signal to produce a plurality of digital speech data signals, means for separating said plurality of said speech data signals into a frame of speech data signals, means for analyzing said frame of speech data with a Cepstrum generator to produce a digital pitch period parameter for said frame of data, means for analyzing said frame of speech data with a voiced/unvoiced decision generator to produce a digital voiced/unvoiced decision parameter, and means for analyzing said frame of speech data with a linear prediction coefficient generator to produce a plurality of digital coefficient parameters and a digital power parameter; and a synthesizer including, digital pitch pulse generator means for receiving said digital pitch period parameter and generating pitch pulses having a corresponding pitch period, digital random noise generator means, switch means connected to said pitch pulse generator means and to said random noise generator means for receiving said digital voiced/unvoiced decision parameter, an output of said switch means being derived from said pitch pulse generator means if said decision is voiced and from said random noise generator means if said decision is unvoiced, gain control means connected to said output of said switch means for receiving said digital power parameter, a digital output level of said gain control means being dependent upon said power parameter, digital linear prediction filter means connected to said output of said gain control means for receiving and applying said digital coefficient parameters to said filter means to generate a digital replica of said speech signal at an output of said filter means, and means for converting said digital output of said filter means to a corresponding analog replica of said analog speech signal; wherein said digital pitch pulse generator means comprises means responsive to receipt of said digital pitch period parameter, for generating a sequence of control signals, and means responsive to said sequence of control signals for generating a substantially periodic, amplitude increasing pitch pulse excitation signal.<br>82. A speech analysis and synthesis system for generating a set of parameters representative of an analog speech signal as produced by a model speech generator and reproducing from said set of parameters a replica of said analog speech signal, said system comprising: an analyzer including, means for sampling said analog speech signal to produce a plurality of digital speech data signals, means for separating said plurality of said speech data signals into a frame of speech data signals, means for analyzing said frame of speech data with a Cepstrum generator to produce a digital pitch period parameter for said frame of data, means for analyzing said frame of speech data with a voiced/unvoiced decision generator to produce a digital voiced/unvoiced decision parameter, and means for analyzing said frame of speech data with a linear prediction coefficient generator to produce a plurality of digital coefficient parameters and a digital power parameter; and a synthesizer including, digital pitch pulse generator means for receiving said digital pitch period parameter and generating pitch pulses having a corresponding pitch period, digital random noise generator means, switch means connected to said pitch pulse generator means and to said random noise generator means for receiving said digital voiced/unvoiced decision parameter, an output of said switch means being derived from said pitch pulse generator means if said decision is voiced and from said random noise generator means if said decision is unvoiced, gain control means connected to said output of said switch means for receiving said digital power parameter, a digital output level of said gain control means being dependent upon said power parameter, digital linear prediction filter means connected to said output of said gain control means for receiving and applying said digital coefficient parameters to said filter means to generate a digital replica of said speech signal at an output of said filter means, and means for converting said digital output of said filter means to a corresponding analog replica of said analog speech signal; wherein said means for analyzing said frame of said speech data to produce a digital pitch period parameter includes means for interpolating between sample values in a sample data Cepstrum signal wherein a pitch period value is initially chosen as corresponding to a maximum amplitude sample, said interpolating system having means for storing said maximum value sample, an immediately preceding sample, and an immediately following sample, means for substracting said immediately preceding sample from said immediately following sample to form a sample difference, means for dividing said sample difference by four to form a sample difference quotient, means for adding said immediately preceding sample to said immediately following sample to form a sample sum, means for dividing said sample sum by two to form a sample sum quotient, means for subtracting said maximum amplitude sample from said sample sum quotient to form a weighted sample sum quotient, means for dividing said sample difference quotient by said weighted sample sum quotient to form a pitch value increment, and means for adding said pitch value increment to said pitch period value to form an interpolated pitch value.<br>83. A speech analysis and synthesis system for generating a set of parameters representative of an analog speech signal as produced by a model speech generator and reproducing from said set of parameters a replica of said analog speech signal, said system comprising: an analyzer including, means for sampling said analog speech signal to produce a plurality of digital speech data signals, means for separating said plurality of said speech data signals into a frame of speech data signals, means for analyzing said frame of speech data with a Cepstrum generator to produce a digital pitch period parameter for said frame of data, means for analyzing said frame of speech data with a voiced/unvoiced decision generator to produce a digital voiced/unvoiced decision parameter, and means for analyzing said frame of speech data with a linear prediction coefficient generator to produce a plurality of digital coefficient parameters and a digital power parameter; and a synthesizer including, digital pitch pulse generator means for receiving said digital pitch period parameter and generating pitch pulses having a corresponding pitch period, digital random noise generator means, switch means connected to said pitch pulses generator means and to said random noise generator means for receiving said digital voiced/unvoiced decision parameter, an output of said switch means being derived from said pitch pulse generator means if said decision is voiced and from said random noise generator means if said decision is unvoiced, gain control means connected to said output of said switch means for receiving said digital power parameter, a digital output level of said gain control means being dependent upon said power parameter, digital linear prediction filter means connected to said output of said gain control means for receiving and applying said digital coefficient parameters to said filter means to generate a digital replica of said speech signal at an output of said filter means, and means for converting said digital output of said filter means to a corresponding analog replica of said analog speech signal; wherein said means for analyzing said frame of data with a linear prediction coefficient generator includes a signal conditioning means for a frame of digital speech data samples, said signal conditioning means having means for generating a window signal having a characteristic waveshape which is completed in a data sample span which is shorter than said frame of data, means for centering said window signal data sample span in said frame of speech data samples, and means for multiplying corresponding sample positions of said frame of speech data and said window signal to generate a limited and windowed frame of speech data.<br>85. A speech synthesis system for generating in real time an analog replica of each of a plurality of original analog speech signals represented by corresponding sets of digital parameters, each set of said parameters including a digital speech pitch period parameter, a digital voiced/unvoiced decision parameter, a plurality of digital coefficient parameters and a digital power parameter, said synthesis system including: digital pitch pulse generator means for receiving said digital pitch period parameter and generating pitch pulses having a corresponding pitch period; digital random noise generator means; switch means connected to said pitch pulse generator means and to said random noise generator means for receiving said digital voiced/unvoiced decision parameter, an output of said switch means being derived from said pitch pulse generator means if said decision is voiced and from said random noise generator means if said decision is unvoiced; gain control means connected to said output of said switch means for receiving said digital power parameter, a digital output level of said gain control means being dependent upon said power parameter; digital linear prediction filter means connected to said output of said gain control means for receiving and applying said digital coefficient parameters to said filter means to generate a digital replica of each of said plurality of speech signals at an output of said filter means; and means for converting said digital output of said filter means to a corresponding analog replica of each of said plurality of analog speech signals.<br>86. A speech synthesis system for generating an analog replica of an original analog speech signal represented by a set of digital parameters, said parameters including a digital speech pitch period parameter, a digital voiced/unvoiced decision parameter, a plurality of digital coefficient parameters and a digital power parameter, said synthesis system including: digital pitch pulse generator means for receiving said digital pitch period parameter and generating pitch pulses having a corresponding pitch period; digital random noise generator means; switch means connected to said pitch pulse generator means and to said random noise generator means for receiving said digital voiced/unvoiced decision parameter, an output of said switch means being derived from said pitch pulse generator means if said decision is voiced and from said random noise generator means if said decision is unvoiced; gain control means connected to said output of said switch means for receiving said digital power parameter, a digital output level of said gain control means being dependent upon said power parameter; digital linear prediction filter means connected to said output of said gain control means for receiving and applying said digital coefficient parameters to said filter means to generate a digital replica of said speech signal at an output of said filter means; and means for converting said digital output of said filter means to a corresponding analog replica of said analog speech signal; wherein said digital pitch pulse generator means includes means responsive to receipt of said digital pitch period parameter, for generating a sequence of control signals, and means responsive to said sequence of control signals for generating a substantially periodic, amplitude increasing pitch pulse excitation signal.<br>88. A signal conditioning system for conditioning a Cepstrum signal having as a dimension, in the direction of the ordinate axis, the amplitude of said Cepstrum signal and as a dimension, in the direction of the abscissa, a quantity representing time, said signal conditioning comprising: means for generating a weighting signal which linearly increases in value with the dimension in the direction of the abscissa corresponding to said quantity representing time of said Cepstrum signal; and means for adding said weighting signal to said Cepstrum signal along said dimension in the direction of the abscissa thereof to generate a weighted Cepstrum signal.<br>90. A method for conditioning a Cepstrum signal having as a dimension in the direction of the ordinate axis the amplitude of said Cepstrum signal and as a dimension in the direction of the abscissa a quantity representing time, said method comprising the steps of: generating a weighting signal which linearly increases in value with the dimension in the direction of the abscissa corresponding to said quantity representing time of said Cepstrum signal; and adding said weighting signal to said Cepstrum signal along said dimension in the direction of the abscissa thereof to generate a weighted Cepstrum signal.<br>91. A system for generating a voiced/unvoiced decision parameter in a speech analysis system wherein a pitch parameter is generated by a Cepstrum technique and coefficient parameters are generated by a linear prediction technique, said system comprising: means for scanning said Cepstrum signal within an auxilliary sample range on each side of a Cepstrum peak amplitude sample; means for detecting and storing a range peak sample within the scanned auxilliary ranges; means for summing the absolute values of the samples within the auxilliary ranges to form a range sample sum; means for dividing said Cepstrum peak amplitude sample by said range peak sample to form a range peak factor; means for dividing said range sample sum by said Cepstrum peak amplitude sample to form an average peak factor; means for first comparing said range peak factor with predetermined upper and lower limits and generating an unvoiced decision parameter if said range peak factor is above said upper limit and generating an unvoiced decision parameter if said range peak factor is equal to or below said lower limit; and means for secondly comparing said average peak factor with predetermined upper and lower limits and generating a voiced decision parameter if said average peak factor is equal to or less than said lower limit and generating an unvoiced decision parameter if said average peak factor is equal to or greater than said upper limit.<br>92. A signal conditioning system for a frame of digital speech data samples, said system comprising: means for generating a window signal having a characteristic waveshape which is completed in a data sample span which is shorter than said frame of data; means for centering said window signal data sample span in said frame of speech data samples; and means for multiplying corresponding sample positions of said frame of speech data and said window signal to generate a limited and windowed frame of speech data.</p></layer>
<layer id = "layer205"><p><b>US5806038A:MBE synthesizer utilizing a nonlinear voicing processor for very low bit rate voice messaging</b><br>A flow control valve for maintaining a selected and constant flow rate over a range of liquid delivery pressures is disclosed which includes a housing, a cavity defined within the housing, an input channel in fluid communication with the cavity, the input channel adapted to transport liquid into the cavity, an output channel in fluid communication with the cavity, the output channel adapted to transport liquid from the cavity, an adjustment member receivable into the housing, a spring operative with the adjustment member, a sleeve, the sleeve having a plurality of apertures defined therein, the sleeve disposed within the cavity, a piston sized to fit within the sleeve, the piston adapted for reciprocal movement in the sleeve, the piston operative to vary the operational size of the apertures in the sleeve, the spring adapted to impart a force upon the piston to move the piston in a direction away from the sleeve, a membrane positioned between the sleeve and the piston, the membrane attached at one end to the piston, and at the other end to the sleeve, whereby introduction of liquid under pressure through the input channel into the cavity will occasion movement of the piston against the force of the spring, thus affecting the operational size of the apertures in the sleeve, for maintaining the selected liquid flow rate.<br><b>Independant Claims</b><br>1. A MBE (Multi-Band Excitation) synthesizer for generating excitation components from information received by a receiver, the information received including indexes which designate predetermined line spectral frequencies which are stored within the receiver as spectral vectors representing a segment of speech, said MBE synthesizer comprising: an excitation generator for generating voiced excitation components and unvoiced excitation components; and a nonlinear voicing processor, comprising a matrix multiplier for calculating a product of a predetermined matrix and the spectral vectors comprising predetermined line spectral frequencies, a voicing metric calculator, coupled to the matrix multiplier, for calculating from the product a plurality of band voicing metrics, and a threshold comparator for comparing the plurality of band voicing metrics with a predetermined threshold value, to derive an output vector comprising a plurality of binary voicing metrics for controlling a selection of the excitation components for the number of bands within the segment of speech from the voiced excitation components and the unvoiced excitation components for the segment of speech.<br>6. An MBE (Multi-Band Excitation) synthesizer for generating a segment of speech from compressed speech data which is received by a receiver coupled thereto, the compressed speech data which is received includes one or more indexes, the MBE synthesizer comprising: an excitation generator for generating excitation components including voiced excitation components and unvoiced excitation components; a memory for storing a table of predetermined spectral vectors which are identified by indexes and which comprise predetermined line spectral frequencies; a harmonic amplitude estimator, responsive to one or more predetermined spectral vectors identified by indexes corresponding to the one or more indexes received, and for generating therefrom harmonic amplitude control signals; a multi-band voicing controller comprising a nonlinear voicing processor comprising a matrix multiplier for calculating a product of a predetermined matrix and the one or more predetermined spectral vectors comprising predetermined line spectral frequencies, a voicing metric calculator, coupled to the matrix multiplier, for calculating from the product a plurality of band voicing metrics, and a threshold comparator for comparing the plurality of band voicing metrics with a predetermined threshold value, to derive an output vector comprising a plurality of binary voicing metrics for controlling a selection of the excitation components for the number of bands within the segment of speech from the voiced excitation components and the unvoiced excitation components for the segment of speech; and a multiplier, for multiplying the harmonic amplitude control signals and the excitation components selected, for generating spectral components representing the segment of speech.</p></layer>
<layer id = "layer206"><p><b>US5749064A:Method and system for time scale modification utilizing feature vectors about zero crossing points</b><br><b>Independant Claims</b><br>1. A method of generating a time scale modification of a signal comprising the steps of: determining zero crossing points in the signal using a zero crossing module; determining feature vectors in neighborhood of said zero crossing points based on absolute magnitude and slope of sample points before and after zero crossing points using a feature vector module wherein each feature vector has j dimensions; determining distance metrics associated with said zero crossing points using said feature vectors bases on accumulation of differences for each of the j dimensions, each of said distance metrics to measure closeness of local characteristics between two of said zero crossing points, using a distance metric module; finding minimum measure of said accumulation of differences for each of the dimensions; and aligning the signal along similar segments using said feature vectors and said distance metrics based on said minimum measure of said accumulation of differences for each of the j dimensions to achieve the time scale modification of the signal using said alignment module.<br>7. A system for generating a time scale modification of a signal comprising: a zero crossing module for determining zero crossing points in the signal; a feature vector module coupled to said zero crossing module for determining feature vectors in neighborhood of said zero crossing points based on absolute magnitude and slope of sample points before and after zero crossing point; said feature vector having j dimensions; a distance metric module coupled to said feature vector module for determining distance metrics based on accumulation of differences for each of the j dimensions, said distance metrics indicating closeness of local characteristics between two of said zero crossing points; means for finding minimum measure of said accumulation of differences for each of the j dimensions; and an alignment module coupled to said distance metric module for aligning said signal using said zero crossing points and said distance metrics based on said minimum measure of said accumulation of differences for each of the j dimensions to generate the time scale modification of the signal.</p></layer>
<layer id = "layer207"><p><b>US6587816B1:Fast frequency-domain pitch estimation</b><br>A node <b>1 </b>and a node <b>2 </b>are in a mutual failover relationship and share information used in failover through a shared LU. Of filesystems FS<b>1</b>A, FS<b>1</b>B that are mounted at the node <b>1</b>, the actions of level <b>1 </b>are allocated to FS<b>1</b>A and the actions of level <b>2 </b>are allocated to FS<b>1</b>B. The level <b>1 </b>filesystem FS<b>1</b>A is taken over to the node <b>2 </b>simultaneously with commencement of failover. The level <b>2 </b>filesystem FS<b>1</b>B is taken over to the node <b>2 </b>when an access request for FS<b>1</b>B is generated after commencement of failover. In this way, business services with high availability can be restarted at an early stage.<br><b>Independant Claims</b><br>1) A method for estimating a pitch frequency of a speech signal, comprising: computing a first transform of the speech signal to a frequency domain over a first time interval; computing a second transform of the speech signal to the frequency domain over a second time interval, which contains the first time interval; and estimating the pitch frequency of the speech signal responsive to the first and second transforms, wherein the first and second transforms comprise Short Time Fourier Transforms.<br>10) A method for estimating a pitch frequency of a speech signal, comprising: finding a line spectrum of the speech signal, the spectrum comprising spectral lines having respective line amplitudes and line frequencies; computing a utility function, which is indicative, for each candidate pitch frequency in a given pitch frequency range, of a compatibility of the spectrum with the candidate pitch frequency, the utility function comprising at least one influence function that is periodic in a ratio of the frequency of one of the spectral lines to the candidate pitch frequency; and estimating the pitch frequency of the speech signal responsive to the utility function.<br>18) A method for estimating a pitch frequency of a speech signal, comprising: finding a line spectrum of the signal, the spectrum comprising spectral lines having respective line amplitudes and line frequencies; computing a utility function that is periodic in the frequencies of the lines in the spectrum, which function is indicative, for each candidate pitch frequency in a given pitch frequency range, of a compatibility of the spectrum with the candidate pitch frequency; and estimating the pitch frequency of the speech signal responsive to the utility function, wherein computing the utility function comprises computing at least one influence function that is periodic in a ratio of the frequency of one of the spectral lines to the candidate pitch frequency, and wherein computing the at least one influence function comprises computing a function of the ratio having maxima at integer values of the ratio and minima therebetween, and wherein computing the function of the ratio comprises computing values of a piecewise linear function c(f), having a maximum value in a first interval surrounding f=0, a minimum value in a second interval surrounding f=1/2, and a value that varies linearly in a transition interval between the first and second intervals.<br>19) A method for estimating a pitch frequency of a speech signal, comprising: finding a line spectrum of the speech signal, the spectrum comprising spectral lines having respective line amplitudes and line frequencies; computing a utility function that is periodic in the frequencies of the lines in the spectrum, which function is indicative, for each candidate pitch frequency in a given pitch frequency range, of a compatibility of the spectrum with the candidate pitch frequency; and estimating the pitch frequency of the speech signal responsive to the utility function, wherein computing the utility function comprises computing at least one influence function that is periodic in a ratio of the frequency of one of the spectral lines to the candidate pitch frequency, and wherein computing the at least one influence function comprises computing respective influence functions for multiple lines in the spectrum, and wherein computing the utility function comprises computing a superposition of the influence functions, and wherein the respective influence functions comprise piecewise linear functions having break points, and wherein computing the superposition comprises calculating values of the influence functions at the break points, such that the utility function is determined by interpolation between the break points.<br>21) A method for estimating a pitch frequency of a speech signal, comprising: finding a line spectrum of the speech signal, the spectrum comprising spectral lines having respective line amplitudes and line frequencies; computing a utility function that is periodic in the frequencies of the lines in the spectrum, which function is indicative, for each candidate pitch frequency in a given pitch frequency range, of a compatibility of the spectrum with the candidate pitch frequency; and estimating the pitch frequency of the speech signal responsive to the utility function, wherein computing the utility function comprises computing at least one influence function that is periodic in a ratio of the frequency of one of the spectral lines to the candidate pitch frequency, and wherein computing the at least one influence function comprises computing respective influence functions for multiple lines in the spectrum, and wherein computing the utility function comprises computing a superposition of the influence functions, and wherein computing the respective influence functions comprises performing the following steps iteratively over the lines in the spectrum: computing a first influence function for a first line in the spectrum; responsive to the first influence function, identifying one or more intervals in the pitch frequency range that are incompatible with the spectrum; defining a reduced pitch frequency range from which the one or more intervals have been eliminated; and computing a second influence function for a second line in the spectrum, while substantially restricting computation of the second influence function to pitch frequencies within the reduced range.<br>25) Apparatus for estimating a pitch frequency of a speech signal, comprising an audio processor, which is adapted to compute a first transform of the speech signal to a frequency domain over a first time interval and a second transform of the speech signal to a frequency domain over a second time interval, which contains the first time interval, and to estimate the pitch frequency of the speech signal responsive to the first and second frequency transforms, wherein the first and second transforms comprise Short Time Fourier Transforms.<br>28) Apparatus for estimating a pitch frequency of a speech signal, comprising an audio processor, which is adapted to compute a first transform of the speech signal to a frequency domain over a first time interval and a second transform of the speech signal to a frequency domain over a second time interval, which contains the first time interval, and to estimate the pitch frequency of the speech signal responsive to the first and second frequency transforms, wherein the first time interval comprises a current frame of the speech signal, and the second time interval comprises the current frame and a preceding frame, and wherein the processor is adapted to compute the second transform by combining the first transform with a transform computed over the preceding frame, and wherein the transforms generate respective spectral coefficients, and wherein the processor is adapted to apply a phase shift to the coefficients generated by the transform computed over the preceding frame and to add the phase-shifted coefficients to the coefficients generated by the transform computed over the first time interval.<br>30) Apparatus for estimating a pitch frequency of a speech signal, comprising an audio processor, which is adapted to compute a first transform of the speech signal to a frequency domain over a first time interval and a second transform of the speech signal to a frequency domain over a second time interval, which contains the first time interval, and to estimate the pitch frequency of the speech signal responsive to the first and second frequency transforms, wherein the processor is adapted to derive first and second line spectra of the signal from the first and second transforms, respectively, and to determine the pitch frequency based on the line spectra.<br>34) Apparatus for estimating a pitch frequency of a speech signal, comprising an audio processor, which is adapted to find a line spectrum of the speech signal, the spectrum comprising spectral lines having respective line amplitudes and line frequencies, to compute a utility function, which is indicative, for each candidate pitch frequency in a given pitch frequency range, of a compatibility of the spectrum with the candidate pitch frequency, the utility function comprising at least one influence function that is periodic in a ratio of the frequency of one of the spectral lines to the candidate pitch frequency, and to estimate the pitch frequency of the speech signal responsive to the periodic function.<br>48) Apparatus for estimating a pitch frequency of a speech signal, comprising an audio processor, which is adapted to find a line spectrum of the speech signal, the spectrum comprising spectral lines having respective line amplitudes and line frequencies, to compute a utility function that is periodic in the frequencies of the lines in the spectrum, which function is indicative, for each candidate pitch frequency in a given pitch frequency range, of a compatibility of the spectrum with the candidate pitch frequency, and to estimate the pitch frequency of the speech signal responsive to the periodic function, wherein the utility function comprises at least one influence function that is periodic in a ratio of the frequency of one of the spectral lines to the candidate pitch frequency, and wherein the at least one influence function comprises a function of the ratio having maxima at integer values of the ratio and minima therebetween, and wherein the at least one influence function comprises a piecewise linear function c(f), having a maximum value in a first interval surrounding f=0, a minimum value in a second interval surrounding f=1/2, and a value that varies linearly in a transition interval between the first and second intervals.<br>49) A computer software product, comprising a computer-readable storage medium in which program instructions are stored, which instructions, when read by a computer receiving a speech signal, cause the computer to compute a first transform of the speech signal to a frequency domain over a first time interval and a second transform of the speech signal over a second time interval to the frequency domain, which contains the first time interval, and to estimate the pitch frequency of the speech signal responsive to the first and second transforms, wherein the first and second transforms comprise Short Time Fourier Transforms.<br>51) A computer software product, comprising a computer-readable storage medium in which program instructions are stored, which instructions, when read by a computer receiving a speech signal, cause the computer to find a line spectrum of the speech signal, the spectrum comprising spectral lines having respective line amplitudes and line frequencies, to compute a utility function, which is indicative, for each candidate pitch frequency in a given pitch frequency range, of a compatibility of the spectrum with the candidate pitch frequency, the utility function comprising at least one influence function that is periodic in a ratio of the frequency of one of the spectral lines to the candidate pitch frequency, and to estimate the pitch frequency of the speech signal responsive to the periodic function.</p></layer>
<layer id = "layer208"><p><b>US5696873A:Vocoder system and method for performing pitch estimation using an adaptive correlation sample window</b><br>This invention relates to a balloon and its process which is used in endoscope for observing, diagnosing and curing diseased parts within blood vessel or tubes, a transparent thin film body is provided in forming an inflating portion incorporatedly with an end of a fixing portion wherein the fixing portion is fixed with the end of endoscope, and the transparent thin film body will protect those attachments of endoscope such as light-guide, object glass, optical fiber and the like which are installed in said the end portion of endoscope, wherein it is useful for observation, diagnosis, cure and the like by means of the inflating portion being inflated by injection of physiological salt solution into the interior of inflating portion, in addition a medical laser beam is irradiated so as to be able to cure, that is, the laser beam is transmissible through the balloon itself which is also seeable through.<br><b>Independant Claims</b><br>1. A method for estimating pitch in a speech waveform, wherein the speech waveform includes a plurality of frames each comprising a plurality of samples, the method comprising: calculating a long term energy parameter for a plurality of said frames of said speech waveform; calculating an energy value for a current frame; comparing said long term energy parameter to the current frame energy value to determine if a transition from unvoiced to voiced speech is occurring; adjusting a correlation sample window for said current frame if said comparing determines that a transition from unvoiced to voiced speech is occurring; and performing a correlation calculation on said current frame of the speech waveform using said adjusted correlation sample window if said comparing determines that a transition from unvoiced to voiced speech is occurring, wherein the correlation calculation for said current frame produces one or more correlation peaks at respective numbers of delay samples, wherein said adjusted correlation sample window reduces the effect of the first Formant in the pitch estimation; and determining a single correlation peak from said one or more correlation peaks, wherein said single correlation peak indicates a pitch of the speech waveform.<br>11. A method for estimating pitch in a speech waveform, wherein the speech waveform includes a plurality of frames each comprising a plurality of samples, the method comprising: determining if a transition from unvoiced to voiced speech is occurring in a current frame; adjusting a correlation sample window for said current frame if said comparing determines that a transition from unvoiced to voiced speech is occurring; and performing a correlation calculation on said current frame of the speech waveform using said adjusted correlation sample window if said determining determines that a transition from unvoiced to voiced speech is occurring in said current frame, wherein the correlation calculation for said current frame produces one or more correlation peaks at respective numbers of delay samples, wherein said adjusted correlation sample window reduces the effect of the first Formant in the pitch estimation; and determining a single correlation peak from said one or more correlation peaks, wherein said single correlation peak indicates a pitch of the speech waveform.<br>23. A vocoder for generating a parametric representation of speech signals, wherein the vocoder more accurately estimates pitch in a speech waveform, the vocoder comprising: means for receiving a plurality of digital samples of a speech waveform, wherein the speech waveform includes a plurality of frames each comprising a plurality of samples; a processor for calculating a plurality of parameters for each of said frames, wherein said processor determines a pitch value for each of said frames; wherein said processor performs a correlation calculation on each frame of the speech waveform which produces one or more correlation peaks at respective numbers of delay samples, wherein said processor determines a single correlation peak from said one or more correlation peaks to estimate the pitch of the received waveform; wherein said processor determines if a transition from unvoiced to voiced speech is occurring in a current frame and adjusts a correlation sample window for the current frame if a transition from unvoiced to voiced speech is occurring; and wherein said processor performs a correlation calculation on the current frame of the speech waveform using the adjusted correlation sample window if a transition from unvoiced to voiced speech is occurring in the current frame, wherein the adjusted correlation sample window reduces the effect of the first Formant in the pitch estimation.</p></layer>
<layer id = "layer209"><p><b>US5822370A:Compression/decompression for preservation of high fidelity speech quality at low bandwidth</b><br>Disclosed are pharmaceutical compositions comprising a thrombin peptide derivatives and a chelating agent and/or a pharmaceutically acceptable thiol-containing compound. The pharmaceutical compositions optionally further comprise an antioxidant. Also, disclosed are methods for activating the non-proteolytically activated thrombin receptor in a subject in need of such treatment. The methods comprise the step of administering an effective amount of a thrombin peptide derivative in the pharmaceutical composition described above.<br><b>Independant Claims</b><br>1. A spectra compression system for compressing a spectrum of an input signal having a first predetermined bandwidth into a second predetermined bandwidth, the input signal containing information, the system comprising: bandpass filter means for generating a plurality of filtered signals for each of a plurality of predetermined bandwidths, responsive to the input signal, power detector means, responsive to the filtered signals for generating a power signal indicative of a power level of each of the filtered signals; comparator means for generating a decision signal in response to a comparison of the power signal to a predetermined threshold; classifier means for generating a classification signal in response to the decision signal; coding means for generating a code signal in response to the classification signal; transform means for generating a plurality of transform values responsive to the plurality of filtered signals; shifting means responsive to the decision signal and the plurality of transform values for moving the information from a first predetermined bandwidth of the plurality of predetermined bandwidths to a second predetermined bandwidth of the plurality of predetermined bandwidths, thus forming a compressed transform signal; and inverse transform means for generating a compressed signal responsive to the compressed transform signal and to the code signal.<br>18. A spectra compression system for compressing a spectrum of an input signal having a first bandwidth into a second bandwidth that is smaller than the first bandwidth, the input signal containing information, the system comprising: a plurality of bandpass filters for generating a plurality of filtered signals, each bandpass filter having a predetermined bandwidth, the plurality of filtered signal thus being in a plurality of predetermined bandwidths, at least one of the plurality of predetermined bandwidths being in an upper band and the remaining predetermined bandwidths being in a lower band; a plurality of power detectors, each power detector coupled to a different bandpass filter of the plurality of bandpass filters, each power detector generating a power level signal, indicative of the power level present in the respective filtered signal, in response to squaring an amplitude of the respective filtered signal and averaging the squared amplitude over a predetermined time interval; a plurality of comparators, each comparator coupled to a different power detector of the plurality of power detectors, each comparator generating a decision signal in response to the power level signal being compared to a predetermined power threshold; a classifier, coupled to the plurality of comparators, for generating a classification signal in response to the plurality of decision signals, the classification signal indicating a compression condition if at least one of the decision signals indicates that a power level in the upper band is greater than the predetermined power threshold, the classification signal indicating a non-compression condition if none of the decision signals indicate that a power level in the upper band is greater than the predetermined power threshold; a code bandpass filter, coupled to the classifier, for generating a code signal indicative of the classification signal; a wavelet transform circuit, coupled to the plurality of filtered signals, for generating a plurality of wavelet transform values; a shifting circuit, coupled to the wavelet transform, the shifting circuit moving, in response to the classification output signal, the information from the upper band to the lower band, thus generating a plurality of shifted values located in the lower band; and an inverse wavelet transform circuit, coupled to the shifting circuit, for performing an inverse wavelet transform on the plurality of shifted values, thus producing a compressed signal responsive to the code signal.<br>22. A decompression system for selectively decompressing an input signal having information which may have been compressed into a lower frequency band of a plurality of frequency bands, the system comprising: a receiver for receiving a compressed signal comprising information and a decompression code; a plurality of band pass filters, coupled to the receiver, for generating a plurality of received filtered signals and a decompression code signal responsive to the compressed signal; a classification circuit, coupled to a first band pass filter of the plurality of band pass filters, for generating a respreading code from the decompression code signal; a wavelet transform circuit coupled to the plurality of band pass filters, the wavelet transform performing a wavelet transform on the plurality of received filtered signals to provide output of transformed signals; a respreading circuit, coupled to the classification circuit, for selectively respreading the transformed from the lower frequency band to respective ones of the plurality of frequency bands, to provide an output of respread transformed signals in response to the respreading code; and an inverse wavelet transform, coupled to the respreading circuit, for generating a decompressed signal from the respread transformed signals.<br>24. A method for compressing the spectrum of an input signal containing information, the method comprising the steps of: filtering the input signal with a plurality of bandpass filters, each filter having a predetermined bandwidth, to generate a plurality of filtered signals having information; detecting a power level in the plurality of filtered signals to generate a plurality of power signals, each signal indicative of the power level of a different filtered signal; comparing the plurality of power signals to a predetermined threshold to generate at least one decision signal in response to a comparison of the power signal to a predetermined threshold; generating a code signal in response to the result of comparing; wavelet transforming the plurality of filtered signals to generate a plurality of wavelet transformed signals; shifting, in response to the result of comparing, information in the plurality of wavelet transformed signals, from a first predetermined bandwidth of the plurality of predetermined bandwidths to a second predetermined bandwidth of the plurality of predetermined bandwidths, thus forming compressed wavelet transform signals; and inverse wavelet transforming the compressed wavelet transform signals into a compressed transmission signal.<br>26. A system for speech compression and decompression for use with a high bandwidth speech incoming signal for preservation of high fidelity speech quality in a low bandwidth compressed signal, the system comprising: an array of Band Pass (BP) filters having pass bands of 200-700 Hz (A), 700-1400 Hz (B), 1400-2800 Hz (C), 3500-5600 Hz (D), and 5600-11,200 Hz (E), at a sampling frequency of 22,400 Hz, and an anti-aliasing filter at 11,200 Hz, the array of BP filters receiving the incoming signal and outputting filtered signals; a subsystem that produces at its output a signal that is proportional to a measure of power in the spectrum at each of the bands A-E, the subsystem squaring the amplitude of the output of each band and averaging this squared output over a time interval of approximately 20 milliseconds; a decision circuit, coupled to the subsystem, that outputs a "yes" signal if the power in each band A-E is above a threshold value and a "no" signal otherwise, each threshold being pre-setable for each band; a classifier subsystem for determining compression conditions responsive to the yes/no signals in each band to detect if the filtered signals belong to any of classes (a) to (b) where class (a) to (b) are such that: (a) corresponds to all situations where no signal lies at bands D and E, and (b) corresponds to all other situations; a circuit that shifts, if class (b) has been detected, the spectrum of the output of both bands A and B to band A by compressing the spectrum of bands A and B; a sub-classification circuit for providing outputs b.sub.1, b.sub.2 or b.sub.3 responsive to classification between and distinguishing sub-classes (b.sub.1 to b.sub.3) of class (b) as follows: b.sub.1 : the power in both of the two highest frequency bands, bands D, E is above their respective thresholds, each of the bands A-E having a predefined threshold, b2: the power in band E is above its respective threshold, b3: the power in band D is above its threshold; a band pass filter at 2800-3500 Hz (X), the band X band pass filter being used to output coding signals responsive to the outputs from the subclassification; a wavelet transform (WT) sub-system that processes the filtered signals generating outputs of WT values, a shifting subsystem for shifting the WT values from one band to another, and providing a shifted output, wherein if b.sub.2 has been detected then the WT values of WT band C are shifted to WT band B, and then the moved WT band C values are replaced by those from WT band E which are shifted to Band C; wherein if sub-class b.sub.3 has been detected then the WT values of WT band B are shifted to WT band A and the WT values of WT band C are shifted to band B, and then the WT values of band D are moved to band C; wherein if b.sub.1 has been detected then the values of WT band B are moved to band A, then the WT values of band C are moved to band B, then the WT values of D are shifted to WT band B and the WT values of band E are moved to band C; and an inverse wavelet transform (IWT) stage, for providing a compressed signal output in bands A, B, and C, responsive to the shifted output and the output code signal.<br>31. A system for compressing the spectrum of an input signal containing information, the system comprising: means for filtering the input signal in a plurality of bands each having a pre-determined bandwidth, to generate a plurality of filtered signals having information; means for detecting a power level in the plurality of filtered signals to generate a plurality of power signals, each of the power signals indicative of the power level of a different respective one of the filtered signals; means for comparing the plurality of power signals to a pre-determined threshold to generate a decision signal in response to the comparison of at least one of the power signals to the pre-determined threshold; means for generating a code signal in response to the decision signal; means for wavelet transforming the plurality of filtered signals to generate a plurality of wavelet transformed signals; means for shifting information in the plurality of wavelet transformed signals from a first pre-determined bandwidth of the plurality of predetermined bandwidths to a second predetermined bandwidth of the plurality of predetermined bandwidths, thus forming compressed wavelet transform signals responsive to the means for comparing; and means for inverse wavelet transforming the compressed wavelet transform signals into a compressed signal.<br>34. A telephony system for communicating telephonic signals from at least a first telephonic device to a second telephonic device, the telephonic signals containing information, the system comprising: at least one receiver for receiving the telephonic signals; and a spectra compression system for compressing a spectrum of an input signal having a first predetermined bandwidth into a second predetermined bandwidth, the input signal containing information, the system comprising: a plurality of bandpass filters, each filter having a predetermined bandwidth, the plurality of bandpass filters thus forming a plurality of predetermined bandwidths and generating a plurality of filtered signals; at least one power detector, coupled to the plurality of bandpass filters, for generating a power signal indicative of a power level of each filtered signal; at least one comparator, coupled to the at least one power detector, for generating at least one decision signal in response to a comparison of the power signal to a predetermined threshold; a classifier, coupled to the at least one comparator, for generating a classification signal in response to the at least one decision signal; a code bandpass filter, coupled to the classifier, for generating a code signal in response to the classification signal; a transform circuit, coupled to the plurality of filtered signals, for generating a plurality of transform values; a shifting circuit, coupled to the plurality of transform values, for moving, in response to the comparison, the information from a first predetermined bandwidth of the plurality of predetermined bandwidths to a second predetermined bandwidth of the plurality of predetermined bandwidths, thus forming at least one compressed transform signal; an inverse transform circuit, coupled to the shifting circuit, for generating a compressed signal from the at least one compressed transform signal; and at least one transmitter for transmitting the telephonic signals.</p></layer>
<layer id = "layer210"><p><b>US5559900A:Compression of signals for perceptual quality by selecting frequency bands having relatively high energy</b><br>Methods, systems and programs in an information processing system comprising one or a plurality of devices managed by a manager device, for decreasing the cost of monitoring measurements, while using conventional techniques for managing problems. The cost saving is achieved when the managed devices conform to the expected quality of service. This saving does not negatively affect the response time required to detect either solid failures or performance problems.<br><b>Independant Claims</b><br>1. A method for coding a physical, electrical, signal comprising the steps of: receiving said electrical signal at an apparatus port; separating said signal into band signals, where each band signal occupies a frequency band and where the collection of the band signals corresponds to said signal; comparing the energy level of each of said band signals to a noise measure specified for the frequency band of each of said band signals; selecting N band signalss that have the highest energy relative to the given noise measure for that frequency band; coding the selected band signals; and delivering to an output port of said apparatus a physical, electrical, signal corresponding to the aggregate of the selected and coded band signals.<br>13. A method for modifying an analog signal comprising the steps of: separating the signal into signals of distinct frequency bands to form band signals; selecting N of said band signals characterized by a signal energy level in each of the N bands, relative to a threshold associated with each of the N bands, that is not lower than the signal energy level of the non-selected band signals relative to a threshold associated with each of the non-selected band signals, where N is a number such that the sum of bandwidths of the selected band signals does not exceed a preselected bandwidth; and down-shifting each of said N band signals to form N down-shifted band signal that occupy unique bands within a baseband having said preselected bandwidth, and outputting a single output signal that corresponds to the aggregate of the N down-shifted band signals.</p></layer>
<layer id = "layer211"><p><b>US4914701A:Method and apparatus for encoding speech</b><br>A capacitance keyboard switch is provided which reduces in a keyboard the overall space requirements therefore while providing at the same time the property of increasing the switch module force curve in the activating movement thereof. The tactile feel construction includes a reduced number of integrally molded inexpensive parts.<br><b>Independant Claims</b><br>1. A speech encoder comprising: Fourier transform means for performing a Fourier transform of a window of speech with formants to generate a Fourier transform spectrum; normalizing means for defining from the Fourier transform spectrum at least one curve of different magnitudes approximating different magnitudes of the Fourier transform spectrum across the spectrum, for digitally encoding the at least one defined curve and for defining the Fourier transform spectrum relative to the at least one defined curve to provide a normalized spectrum; and means for encoding at least a portion of the normalized spectrum.<br>7. A speech encoder comprising: means for sampling a speech signal; an analog to digital converter for providing digital representations of the speech samples; a preemphasis filter; Fourier transform means for performing a Fourier transform of a window of digital speech samples to generate a Fourier transform spectrum; means for determining the maximum magnitude of the Fourier transform spectrum within each of a plurality of regions of the spectrum; means for digitally encoding the maximum magnitude of each region; means for dividing each coefficient of the Fourier spectrum in each region by the maximum magnitude of each region to provide a first set of normalized outputs; means for determining the maximum magnitude of the first set of normalized outputs in each of a plurality of subregions of the spectrum; means for digitally encoding the maximum magnitude of each subregion; means for dividing each output of the first set of normalized outputs by the maximum magnitude of each subregion to provide a second set of normalized outputs; and means for encoding a baseband of the second set of normalized outputs.<br>8. A method of encoding speech comprising: performing a Fourier transform of a window of speech with formants to generate a Fourier transform spectrum; providing a normalized spectrum by defining from the Fourier transform spectrum at least one curve of different magnitudes approximately different magnitudes of the Fourier transform spectrum across the spectrum, digitally encoding the at least one defined curve and defining the Fourier transform spectrum relative to the at least one defined curve; and encoding at least a portion of the normalized spectrum.<br>14. A speech encoder comprising: transform means for performing a transform of an incoming speech signal with formants to generate a transform spectrum which varies significantly in magnitude across the spectrum; equalizing means for modifying the transform spectrum to provide a substantially flat spectrum and for encoding a function derived from the transform spectrum by which the transform spectrum is modified; and means for encoding at least a portion of the equalized spectrum.<br>18. A speech encoder comprising: transform means for performing a transform of a window of speech with formants to generate a transform spectrum; normalizing means for defining a magnitude relative to each of a plurality of regions of the transform spectrum and for scaling each coefficient of the transform spectrum, in each region of at least a portion of the spectrum, to the defined magnitude of the region of provide a normalized spectrum; and means for encoding the defined magnitudes and at least a portion of the normalized spectrum.<br>20. A method of encoding speech comprising: performing a transform of an incoming speech signal to generate a transform spectrum which varies significantly in magnitude across the spectrum; modifying the transform spectrum by a function derived from the transform spectrum to provide a substantially flat spectrum; and encoding the function derived from the transform spectrum by which the transform spectrum is modified and encoding at least a portion of the modified spectrum.<br>22. A method of encoding speech comprising: performing a transform of a window of speech with formants to generate a transform spectrum; defining a magnitude relative to each of a plurality of regions of the transform spectrum and scaling each coefficient of the transform spectrum, in each region of at least a portion of the spectrum, to the defined magnitude of the region; and encoding the defined magnitudes and at least a portion of the scaled coefficients of the transform spectrum.</p></layer>
<layer id = "layer212"><p><b>US6947888B1:Method and apparatus for high performance low bit-rate coding of unvoiced speech</b><br>A fibrous material, which can be an absorbent material, includes a plurality of natural fibers treated with a carboxylic acid-based odor control agent, which are able to withstand insults with an aqueous liquid without dissolving the odor control agent. The acid-based odor control agent is bound to the natural fibers by an organosilicone polymer binder. The binder is water-insoluble, and can form a highly gas permeable coating. The binder is also highly porous, so as to expose the odor control agent to ammonia and other odoriferous gases which it is intended to control.<br><b>Independant Claims</b><br>1) A method of encoding unvoiced segments of speech, comprising: partitioning a residual signal frame into a plurality of sub-frames; creating a group of sub-frame gains by computing a codebook gain for each of the plurality of sub-frames; partitioning the group of sub-frame gains into sub-groups of sub-frame gains; normalizing the sub-groups of sub-frame gains to produce a plurality of normalization factors wherein each of the plurality of normalization factors is associated with one of the normalized sub-groups of sub-frame gains; converting each of the plurality of normalization factors into an exponential form and quantizing the converted plurality of normalization factors; quantizing the normalized sub-groups of sub-frame gains to produce a plurality of quantized codebook gains wherein each of the codebook gains is associated with a codebook gain index for one of the plurality of sub-groups; generating a random noise signal comprising random numbers for each of the plurality of sub-frames; selecting a pre-determined percentage of the highest-amplitude random numbers of the random noise signal for each of the plurality of sub-frames; scaling the selected highest-amplitude random numbers by the quantized codebook gains for each sub-frame to produce a scaled random noise signal; band-pass filtering and shaping the scaled random noise signal; analyzing the energy of the residue signal frame and the energy of the scaled random signal to produce an energy analysis; selecting a second filter based on the energy analysis and further shaping the scaled random noise signal with the selected filter; and generating a second filter selection indicator to identify the selected filter.<br>8) A speech coder for encoding unvoiced segments of speech, comprising: means for partitioning a residual signal frame into a plurality of sub-frames; means for creating a group of sub-frame gains by computing a codebook gain for each of the plurality of sub-frames; means for partitioning the group of sub-frame gains into sub-groups of sub-frame gains; means for normalizing the sub-groups of sub-frame gains to produce a plurality of normalization factors wherein each of the plurality of normalization factors is associated with one of the normalized sub-groups of sub-frame gains; means for converting each of the plurality of normalization factors into an exponential form and quantizing the converted plurality of normalization factors; means for quantizing the normalized sub-groups of sub-frame gains to produce a plurality of quantized codebook gains wherein each of the codebook gains is associated with a codebook gain index for one of the plurality of sub-groups; means for generating a random noise signal comprising random numbers for each of the plurality of sub-frames; means for selecting a pre-determined percentage of the highest-amplitude random numbers of the random noise signal for each of the plurality of sub-frames; means for sealing the selected highest-amplitude random numbers by the quantized codebook gains for each sub-frame to produce a scaled random noise signal; means for band-pass filtering and shaping the scaled random noise signal; means for analyzing the energy of the residue signal frame and the energy of the scaled random signal to produce an energy analysis; means for selecting a second filter based on the energy analysis and further shaping the scaled random noise signal with the selected filter; and means for generating a second filter selection indicator to identify the selected filter.<br>14) A speech coder for encoding unvoiced segments of speech, comprising: a gain computation component configured to partition a residual signal frame into a plurality of sub-frames, create a group of sub-frame gains by computing a codebook gain for each of the plurality of sub-frames, partition the group of sub-frame gains into sub-groups of sub-frame gains, normalize the sub-groups of sub-frame gains to produce a plurality of normalization factors wherein each of the plurality of normalization factors is associated with one of the normalized sub-groups of sub-frame gains, and convert each of the plurality of normalization factors into an exponential form; a gain quantizer configured to quantize the converted plurality of normalization factors to produce a quantized normaliztion factor index, and quantize the normalized sub-groups of frame gains to produce a plurality of quantized codebook gains wherein each of the codebook gains is associated with a codebook gain index for one of the plurality of sub-groups; a random number generator configured to generate a random noise signal comprising random numbers for each of the plurality of sub-frames; a random number selector configured to select a pre-determined percentage of the highest-amplitude random numbers of the random noise signal for each of the plurality of sub-frames; a multiplier configured to scale the selected highest-amplitude random numbers by the quantized codebook gains for each sub-frame to produce a scaled random noise signal; a band-pass filter for eliminating for eliminating low-end and high-end frequencies from the scaled random noise signal; a first shaping filter for perceptual filtering of the scaled random noise signal; an unscaled band energy analyzer configured to analyze the energy of the residue signal; a scaled band energy analyzer configured to analyze the energy of the scaled random signal, and to produce a relational energy analysis of the energy of the residual signal compared to the energy of the scaled random signal; a second shaping filter configured to select a second filter based on the relational energy analysis, further shape the scaled random noise signal with the selected filter, and generate a second filter selection indicator to identify the selected filter.<br>23) A speech coder for encoding unvoiced segments of speech, comprising: a gain computation component configured to partition a residual signal frame into sub-frames, each sub-frame having a codebook gain associated therewith; a gain quantizer configured to quantize the gains to produce indices; a random number selector and multiplier configured to scale a percentage of random noise associated with each sub-frame by the indices associated with the sub-frame; a first perceptual filter configured to perform a first filtering of the scaled random noise; a band energy analyzer configured to compare the filtered noise with the residual signal; and a second shaping filter configured to perform a second filtering of the random noise based on the comparison, and generate a second filter selection indicator to identify the second filtering performed, wherein the second shaping filter configured to perform a second filtering of the random noise is further configured to have two fixed filters.<br>24) A speech coder for encoding unvoiced segments of speech, comprising: a gain computation component configured to partition a residual signal frame into sub-frames, each sub-frame having a codebook gain associated therewith; a gain quantizer configured to quantize the gains to produce indices; a random number selector and multiplier configured to scale a percentage of random noise associated with each sub-frame by the indices associated with the sub-frame; a first perceptual filter configured to perform a first filtering of the scaled random noise; a band energy analyzer configured to compare the filtered noise with the residual signal; and a second shaping filter configured to perform a second filtering of the random noise based on the comparison, and generate a second filter selection indicator to identify the second filtering performed, wherein the second shaping filter configured to generate a second filter selection indicator is further configured to generate a two bit filter selection indicator.</p></layer>
<layer id = "layer213"><p><b>US6691085B1:Method and system for estimating artificial high band signal in speech codec using voice activity information</b><br>A method and apparatus for constructing an automotive vehicle parking lot (<highlight><bold>10</bold></highlight>) on a land area (<highlight><bold>12</bold></highlight>) is provided. A composite drainage material (<highlight><bold>20</bold></highlight>) is provided through which water drains. The composite drainage material (<highlight><bold>20</bold></highlight>) comprises a polymeric open mesh core (<highlight><bold>22</bold></highlight>) between first and second layers (<highlight><bold>24 </bold></highlight>and <highlight><bold>26</bold></highlight>) of a non-woven geo-textile fabric. The land area (<highlight><bold>12</bold></highlight>) is covered with the material (<highlight><bold>20</bold></highlight>) by placing rolls (<highlight><bold>28</bold></highlight>) of the material adjacent one another. The rolls (<highlight><bold>28</bold></highlight>) are unrolled over the land area (<highlight><bold>12</bold></highlight>) so that longitudinal edge portions (<highlight><bold>30 </bold></highlight>and <highlight><bold>40</bold></highlight>) of adjacent rolls adjoin one another. A portion (<highlight><bold>34, 44</bold></highlight>) of the longitudinal edge portions (<highlight><bold>30 </bold></highlight>and <highlight><bold>40</bold></highlight>) are overlapped and secured to each other, and not to the land area (<highlight><bold>12</bold></highlight>), to create a gapless and continuous surface (<highlight><bold>84</bold></highlight>) of the material (<highlight><bold>20</bold></highlight>), with the majority of the land area (<highlight><bold>12</bold></highlight>) lying underneath the material. The first layer (<highlight><bold>24</bold></highlight>) of each of the rolls (<highlight><bold>28</bold></highlight>) contacts the land area (<highlight><bold>12</bold></highlight>). The second layer (<highlight><bold>26</bold></highlight>) of each of the rolls (<highlight><bold>28</bold></highlight>) faces away from the land area (<highlight><bold>28</bold></highlight>) and provides the surface (<highlight><bold>84</bold></highlight>) on which vehicles are parked.<br><b>Independant Claims</b><br>1) A method of speech coding for encoding and decoding an input signal having speech periods and non-speech periods for providing synthesized speech having higher frequency components and lower frequency components, wherein the input signal is divided into a higher frequency band and a lower frequency band in encoding and decoding processes, and wherein speech related parameters characteristic of the lower frequency band are used to process an artificial signal for providing the higher frequency components of the synthesized speech, and wherein voice activity information having a first signal and a second signal is used to indicate the speech periods and the non-speech periods, said method comprising the step of: scaling the artificial signal in the speech periods and the non-speech periods based on the voice activity information indicating the first and second signals, respectively.<br>10) A speech signal transmitter and receiver system for encoding and decoding an input signal having speech periods and non-speech periods for providing synthesized speech having higher frequency components and lower frequency components, wherein the input signal is divided into a higher frequency band and a lower frequency band in the encoding and decoding processes, and speech related parameters characteristic of the lower frequency band are used to process an artificial signal for providing the higher frequency components of the synthesized speech, and wherein voice activity information having a first signal and a second signal is used to indicate the speech periods and non-speech periods, said system comprising: a decoder for receiving the encoded input signal and for providing the speech related parameters; an energy scale estimator, responsive to the speech related parameters, for providing an energy scaling factor for scaling the artificial signal in the speech periods and the non-speech periods based on the voice activity information indicating the first and second signals, respectively; and a linear predictive filtering estimator, also responsive to the speech related parameters, for synthesis filtering the artificial signal.<br>20) A decoder for synthesizing speech having higher frequency components and lower frequency components from encoded data indicative of an input signal having speech periods and non-speech periods, wherein the input signal is divided into a higher frequency band and a lower frequency band in the encoding and decoding processes, and the encoding of the input signal is based on the lower frequency band, and wherein the encoded data includes speech parameters characteristic of the lower frequency band for use in processing an artificial signal for providing the higher frequency components of the synthesized speech, and voice actively information having a first signal and a second signal is used to indicate the speech periods and non-speech periods, said decoder comprising: an energy scale estimator, responsive to the speech parameter, for providing a first energy scaling factor for scaling the artificial signal in the speech periods when the voice activity information indicates the first signal, and a second energy scaling factor for scaling the artificial signal in the non-speech periods when the voice activity information indicates the second signal; and a synthesis filtering estimator, for providing a plurality of filtering parameters for synthesis filtering the artificial signal.<br>27) A mobile station, which is arranged to receive an encoded bit stream containing speech data indicative of an input signal, wherein the input signal is divided into a higher frequency band and a lower frequency band, and voice activity information having a first signal and a second signal is used to indicate speech periods and non-speech periods, and wherein the speech data includes speech related parameters obtained from the lower frequency band, said mobile station comprising: a first means, responsive to the encoded bit stream, for decoding the lower frequency band using the speech related parameters; a second means, responsive to the encoded bit stream, for decoding the higher frequency band from an artificial signal; an energy scale estimator, responsive to the voice activity information, for providing a first energy scaling factor for scaling the artificial signal in the speech periods and a second energy scaling factor for scaling the artificial signal in the non-speech periods based on the voice activity information having the first signal and the second signal, respectively.<br>29) An element of a telecommunication network, which is arranged to receive an encoded bit stream containing speech data indicative of an input signal from a mobile station, wherein the input signal is divided into a higher frequency band and a lower frequency band and the speech data includes speech related parameters obtained from the lower frequency band, and wherein voice activity information having a first signal and a second signal is used to indicate the speech periods and the non-speed periods, said element comprising: a first means for decoding the lower frequency band using the speech related parameters; a second means for decoding the higher frequency band from an artificial signal; a third means, responsive to the speech data, for providing information regarding the speech and non-speech periods; and an energy scale estimator, responsive to the speech period information, for providing a first energy scaling factor for scaling the artificial signal in the speech periods and a second energy scaling factor for scaling the artificial signal in the non-speech periods based on the voice activity information having the first or second signal.</p></layer>
<layer id = "layer214"><p><b>US6615169B1:High frequency enhancement layer coding in wideband speech codec</b><br>An assortment of manufactured teeth are disclosed which are fabricated according to their function and color. The outer dimensions of the teeth, especially in the marginal area, are larger than those of a prepared tooth. The teeth are preferably made of plastic, ceramic or hybrid materials. Adjacent teeth can be interconnected in the manner of a bridge. A method for preparing manufactured teeth is also disclosed in which the fabricated tooth is clamped in a device which virtually correlates the same to the situation of the prepared tooth. The inner fit to the prepared teeth is produced by milling out the lumen. The outer fit is produced by milling down until the preparation limit is reached. A clearance fit with a marginal range of less than 100 μm is preferably provided. A clearance fit with a marginal range of less than 200 μm is preferably provided in the inner area.<br><b>Independant Claims</b><br>1) A method of speech coding for encoding and decoding an input signal having active speech periods and non-active speech periods, and for providing a synthesized speech signal having higher frequency components and lower frequency components, wherein the input signal is divided into a higher frequency band and lower frequency band in encoding and speech synthesizing processes, and wherein speech related parameters characteristic of the lower frequency band are used to process an artificial signal for providing the higher frequency components of the synthesized speech, said method comprising the steps of: scaling the processed artificial signal with a first scaling factor during the active speech periods, and scaling the processed artificial signal with a second scaling factor during the non-active speech periods, wherein the first scaling factor is characteristic of the higher frequency band of the input signal, and the second scaling factor is characteristic of the lower frequency band of the input signal.<br>16) A speech signal transmitter and receiver system for encoding and decoding an input signal having active speech periods and non-active speech periods and for providing a synthesized speech signal having higher frequency components and lower frequency components, wherein the input signal is divided into a higher frequency band and a lower frequency band in the encoding and speech synthesizing processes, wherein speech related parameters characteristic of the lower frequency band of the input signal are used to process an artificial signal in the receiver for providing the higher frequency components of the synthesized speech, said system comprising: a decoder in the receiver for receiving an encoded bit stream from the transmitter, wherein the encoded bit stream contains the speech related parameters; a first means in the transmitter, responsive to the input signal, for providing a first scaling factor for scaling the processed artificial signal during the active periods, and a second means in the receiver, responsive to the encoded bit stream, for providing a second scaling factor for scaling the processed artificial signal during the non-active periods, wherein the first scaling factor is characteristic of the higher frequency band of the input signal and the second scaling factor is characteristic of the lower frequency band of the input signal.<br>23) An encoder for encoding an input signal having active speech periods and non-active speech periods and the input signal is divided into a higher frequency band and a lower frequency band, and for providing an encoded bit stream containing speech related parameters characteristic of the lower frequency band of the input signal so as to allow a decoder to use the speech related parameters to process an artificial signal for providing the high frequency components of the synthesized speech, and wherein a scaling factor based on the lower frequency band of the input signal is used to scale the processed artificial signal during the non-active speech periods, said encoder comprising: means, responsive to the input signal, for high-pass filtering the input signal in a frequency range corresponding to the higher frequency components of the synthesized speech, and for providing a further scaling factor based on the high-pass filtered input signal; and means, responsive to the further scaling factor, for providing an encoded signal indicative of the first scaling factor into the encoded bit stream, so as to allow the decoder to receive the encoded signal and use the further scaling factor to scale the processed artificial signal during the active-speech periods.<br>24) A mobile station, which is arranged to transmit an encoded bit stream to a decoder for providing synthesized speech having higher frequency components and lower frequency components, wherein the encoded bit stream includes speech data indicative of an input signal having active speech periods and non-active periods, and the input signal is divided into a higher frequency band and lower frequency band, wherein the speech data includes speech related parameters characteristic of the lower frequency band of the input signal so as to allow the decoder to provide the lower frequency components of the synthesized speech based on the speech related parameters, and to color an artificial signal based on the speech related parameters and to scale the colored artificial signal with a scaling factor, based on the lower frequency components of the synthesized speech, for providing the high frequency components of the synthesized speech during the non-active speech periods, said mobile station comprising: a filter, responsive to the input signal, for high-pass filtering the input signal in a frequency range corresponding to the higher frequency components of the synthesized speech, and for providing a further scaling factor based on the high-pass filtered input signal; and a quantization module, responsive to the scaling factor and the further scaling factor, for providing an encoded signal indicative of the further scaling factor in the encoded bit stream, so as to allow the decoder to scale the colored artificial signal during the active-speech period based on the further scaling factor.<br>25) An element of a telecommunication network, which is arranged to receive an encoded bit stream containing speech data indicative of an input signal from a mobile station for providing synthesized speech, having higher frequency components and lower frequency components, wherein the input signal having active speech periods and non-active periods, and the input signal are divided into a higher frequency band and lower frequency band, wherein the speech data includes speech related parameters characteristic of the lower frequency band of the input signal, said element comprising: a first mechanism, responsive to the speech data, for providing the lower frequency components of the synthesized speech based on the speech related parameters, and for providing a first signal indicative of the lower frequency components of the synthesized speech; a second mechanism, responsive to the speech data, for synthesis and high-pass filtering an artificial signal for providing a second signal indicative of the synthesis and high-pass filtered artificial signal; a third mechanism, responsive to the first signal, for providing a first scaling factor based on the lower frequency components of the synthesized speech; and a forth mechanism, responsive to the encoded bit stream, for providing a second scaling factor based on gain parameters characteristic of the higher frequency band of the input signal, wherein the gain parameters are included in the encoded bit stream; and a fifth mechanism, responsive to the second signal, for scaling the synthesis and high-pass filtered artificial signal with the first and second scaling factors during non-active speech periods and active speech periods, respectively.</p></layer>
<layer id = "layer215"><p><b>US5963899A:Method and system for region based filtering of speech</b><br>A protective glove includes a coating of dehydrated material on its inside surface. The dehydrated material, in contact with perspiration from a hand wearing the glove, soothes the hand. Some methods of placing the coating onto the inside surface of the glove include spraying or dipping with a solution that includes Aloe Vera.<br><b>Independant Claims</b><br>1. A method for adaptively filtering a speech signal, the method comprising: dividing the signal into a plurality of frames, each frame having one of a plurality of sound types associated therewith; determining one of a plurality of classes for each frame, wherein the class determined depends on the sound type associated with the frame; selecting one of a plurality of filters for each frame, wherein the filter selected depends on the class of the frame; filtering each frame according to the filter selected; and combining the plurality of filtered frames to provide a filtered speech signal.<br>10. A system for adaptively filtering a speech signal, the system comprising: means for dividing the signal into a plurality of frames, each frame having one of a plurality of sound types associated therewith; means for determining one of a plurality of classes for each frame, wherein the class determined depends on the sound type associated with the frame; a plurality of filters for filtering the frames; means for selecting one of the plurality of filters for each frame, wherein the filter selected depends upon the class of the frame; and means for combining the plurality of filtered frames to provide a filtered speech signal.</p></layer>
<layer id = "layer216"><p><b>US5806025A:Method and system for adaptive filtering of speech signals using signal-to-noise ratio to choose subband filter bank</b><br>A slant plate type compressor with a capacity or displacement adjusting mechanism is disclosed. The compressor includes a housing having a cylinder block provided with a plurality of cylinders and a crank chamber. A piston is slidably fitted within each of the cylinders and is reciprocated by a drive mechanism which includes a member having a surface with an adjustable incline angle. The incline angle is controlled by the pressure in the crank chamber. The pressure in crank chamber is controlled by control mechanism which comprises a passageway communicating between the crank chamber and a suction chamber, a first valve device to control the closing and opening of the passageway and a second valve device to control pressure in an actuating chamber. The first valve device includes a bellows valve element and a valve shifting element. The valve shifting element of which one end is exposed in the actuating chamber is coupled to the bellows to apply a force to the bellows at another end and thereby shift a control point of the bellows in response changes in the actuating chamber pressure.<br><b>Independant Claims</b><br>1. A method for adaptively filtering a speech signal, the method comprising: decomposing the speech signal into a plurality of subbands; determining a speech quality indicator for each subband; selecting one of a plurality of filters for each subband, wherein the filter selected depends on the speech quality indicator determined for the subband; filtering each subband according to the filter selected; determining an overall average error for a filtered speech signal comprising the filtered subbands; identifying at least one filtered subband which, if excluded from the filtered speech signal, would reduce the overall average error determined; and combining, with the exception of the at least one filtered subband identified, the filtered subbands to provide an estimated filtered speech signal.<br>9. A system for adaptively filtering a speech signal, the system comprising: means for decomposing the speech signal into a plurality of subbands; means for determining a speech quality indicator for each subband; a plurality of filters for filtering the subbands; means for selecting one of the plurality of filters for each subband, wherein the filter selected depends on the speech quality indicator determined for the subband; means for determining an overall average error for a filtered speech signal comprising the filtered subbands; means for identifying at least one filtered subband which, if excluded from the filtered speech signal, would reduce the overall average error determined; and means for combining, with the exception of the at least one filtered subband identified, the filtered subbands to provide an estimated filtered speech signal.</p></layer>
<layer id = "layer217"><p><b>US5680508A:Enhancement of speech coding in background noise for low-rate speech coder</b><br><b>Independant Claims</b><br>1. In a method of low-bit-rate speech coding of input speech occurring in a noisy environment, for a system which employs linear predictive coding (LPC) analysis of input speech frames to generate reflection coefficients, conversion of the reflection coefficients to vectors representing spectral parameters of the input speech frames, and matching of the spectral parameter vectors against reference vectors of a vocabulary of codewords generated in a training sequence in order to select the corresponding index of an optimally matching codeword for transmission, the improvement comprising the steps of: selecting a set of at least two features which are characterized by a probability distribution which is not strongly affected in the noisy environment and which allow discrimination between voiced and unvoiced input speech, wherein said selected features include the feature of zero-crossing counts which are based on average noise energy; measuring the selected features for input speech frames; and using said feature measurements to make voiced/unvoiced speech decisions in order to select the voice/unvoiced excitation for speech synthesis in the receiver; using noise estimates to update the reference vectors of the vocabulary of codewords, wherein new reference vectors are generated corresponding to said vocabulary of codewords in the noisy environment, said noise estimates including noise amplitude and noise reflection coefficients, wherein said noise estimate for speech frame I is performed only if the ith speech frame is unvoiced and more than a given number L of continuous unvoiced speech frames are accumulated, in order to prevent using voiced or unvoiced speech in the noise estimate.<br>12. In a method of low-bit-rate speech coding of input speech occurring in a noisy environment, for a system which employs linear predictive coding (LPC) analysis of input speech frames to generate reflection coefficients, conversion of the reflection coefficients to vectors representing spectral parameters of the input speech frames, and matching of the spectral parameter vectors against reference vectors of a vocabulary of codewords generated in a training sequence in order to select the corresponding index of an optimally matching codeword for transmission, the improvement comprising the steps of: selecting a set of features which are characterized by a probability distribution which is not strongly affected in the noisy environment and which allow discrimination between voiced and unvoiced input speech; measuring the selected features for input speech frames; and using said feature measurements to make voiced/unvoiced speech decisions in order to select the voice/unvoiced excitation for speech synthesis in the receiver; using noise estimates to update the reference vectors of the vocabulary of codewords, wherein new reference vectors are generated corresponding to said vocabulary of codewords in the noisy environment, said noise estimates including noise amplitude and noise reflection coefficients, wherein said noise estimate for speech frame I is performed only if the ith speech frame is unvoiced and more than a given number L of continuous unvoiced speech frames are accumulated, in order to prevent using voiced or unvoiced speech in the noise estimate.</p></layer>
<layer id = "layer218"><p><b>US6092041A:System and method of encoding and decoding a layered bitstream by re-applying psychoacoustic analysis in the decoder</b><br>In a multiplex transmission apparatus and a multiplex transmission method when a control unit reads reception data while a status flag is set, it determines that the reception data is obtained before data in a transmission buffer is transmitted. When the control unit reads the reception data while the status flag is reset, it determines that the read data is response data to transmission data. Thus, the control unit precisely recognizes the time series of data on communication control.<br><b>Independant Claims</b><br>1. A scalable bitrate audio compression system comprising at least one of A-B: A) an encoder, comprising: A1) a coding delay compensation unit, coupled to receive audio samples, for providing delayed audio samples for synchronizing the audio samples with an output of a low bitrate decoding unit; A2) a low bitrate coding unit, coupled to receive the audio samples, for coding the audio samples to provide a low bitrate audio bitstream; A3) the low bitrate decoding unit, coupled to the low bitrate coding unit, for generating decoded lowband audio samples; A4) a difference unit, coupled to the coding delay compensation unit and the low bitrate decoding unit, for generating diffband audio samples by subtracting the decoded lowband audio from the delayed audio samples; A5) a time-to-frequency analysis unit, coupled to the difference unit, for generating diffband frequency coefficients; A6) a quantizer and sample coding unit, coupled to the time-to-frequency unit and a hybrid psychoacoustic modeling and quantizer control unit, for quantizing and coding the diffband frequency coefficients to provide coded diffband frequency coefficients wherein to improve coding efficiency, lowband frequency coefficients are compared against predetermined lowband masking thresholds, lowband frequency coefficients with values below a corresponding predetermined lowband masking threshold are zero-flagged, zero-flagged lowband frequency coefficients are replaced with zero, and the quantizer and sample coding unit omits coding of zero-flagged lowband frequency coefficients when coding the diffband frequency coefficients; A7) the hybrid psychoacoustic modeling and quantizer control unit, coupled to the low bitrate decoding unit, the difference unit and the time-to-frequency analysis unit, for providing to the bitstream coding and formatting unit and to the quantizer and sample coding unit, explicit quantizer stepsize parameters and for providing to the quantizer and sample coding unit, A7a) implicit quantizer stepsize parameters; and A7b) implicit zero-flags; A8) a bitstream and coding formatting unit, coupled to the quantizer and sample coding unit, the hybrid psychoacoustic modeling and quantizer control unit and the low bitrate coding unit, for generating at least one of: A8a) a low bitrate audio bitstream of coded lowband audio from the low bitrate coding unit; and A8b) a supplemental audio bitstream for enhancing audio fidelity of the low bitrate audio bitstream, wherein the bitstream and coding formatting unit provides a hybrid bitstream comprising the low bitrate audio bitstream and the supplemental audio bitstream; B) a decoder, comprising: B1) a bitstream decoding unit, coupled to receive at least one of: the supplemental bitstream and the low bitrate audio bitstream, for redirecting the low bitrate audio bitstream to the low bitrate decoding unit and for separating the supplemental bitstream into explicit quantizer stepsize parameters and coded diffband frequency coefficients wherein the bitstream decoding unit separates the hybrid bitstream into explicit quantizer stepsize parameters, coded diffband frequency coefficients and the low bitrate audio bitstream; B2) a low bitrate decoding unit, coupled to receive the low bitrate audio bitstream from the bitstream decoding unit, for generating decoded lowband audio samples wherein the low bitrate decoding unit further sample rate converts the decoded bitstream to match a sample rate of the audio samples; B3) a lowband psychoacoustic modeling and quantizer control unit, coupled to the low bitrate decoding unit, for generating: B3a) implicit quantizer stepsize parameters; and B3b) implicit zero-flags; B4) a sample decoding unit and requantizer, coupled to the bitstream decoding unit and the lowband psychoacoustic modeling and quantizer control unit, for decoding and requantizing requantized diffband frequency coefficients wherein, where zero-flagging mode is selected, the sample decoding unit and requantizer reconstructs requantized diffband frequency coefficients from coded diffband frequency coefficients and explicit quantizer stepsize parameters, both from the bitstream decoding unit, and at least one of: 1) implicit quantizer stepsize parameters; and 2) implicit zero-flags provided by the lowband psychoacoustic modeling and quantizer control unit and reconstructs zero-flagged diffband frequency coefficients with zero values: B5) a frequency-to-time synthesis unit, coupled to the sample decoding unit and requantizer, for converting the requantized diffband frequency coefficients into requantized diffband audio samples; B6) a time alignment unit, coupled to the low bitrate decoding unit, for synchronizing the output of the low bitrate decoding unit with the requantized diffband audio samples; B7) a summer, coupled to the time-to-frequency synthesis unit and the time alignment unit, for summing the time-aligned, decoded, lowband audio samples with requantized diffband audio samples to provide fullband audio samples.<br>3. A method for using a computer processor for providing scalable bitrate audio compression parameters, comprising: A) generating, using a decoded lowband audio signal and a diffband audio signal, by a hybrid psychoacoustic modeling unit, psychoacoustic data that is composed of at least one of: signal-to-mask ratios, lowband frequency coefficients and lowband masking thresholds, wherein the hybrid psychoacoustic modeling unit performs scalable bitrate audio compression using the steps of at least one of A1-A2: A1) in an encoder: A1a) using a coding delay compensation unit for providing delayed audio samples for synchronizing the audio samples with an output of a low bitrate decoding unit; A1b) using a low bitrate coding unit for coding the audio samples to provide a low bitrate audio bitstream: A1c) using the low bitrate decoding unit for generating decoded lowband audio samples: A1d) using a difference unit for generating diffband audio samples by subtracting the decoded lowband audio from the delayed audio samples: A1e) using a time-to-frequency analysis unit for generating diffband frequency coefficients; A1f) using a quantizer and sample coding unit for quantizing and coding the diffband frequency coefficients to provide coded diffband frequency coefficients wherein, where zero-flagging is implemented to improve coding efficiency, lowband frequency coefficients are compared against predetermined lowband masking thresholds, lowband frequency coefficients with values below a corresponding predetermined lowband masking threshold are zero-flagged, zero-flagged lowband frequency coefficients are replaced with zero, and the quantizer and sample coding unit omits coding of zero-flagged lowband frequency coefficients when coding the diffband frequency coefficients; A1g) using a hybrid psychoacoustic modeling and quantizer control unit for providing to the bitstream coding and formatting unit and to the quantizer and sample coding unit, explicit quantizer stepsize parameters and for providing to the quantizer and sample coding unit, A1g1) implicit quantizer stepsize parameters; and A1g2) implicit zero-flags; A1h) using a bitstream and coding formatting unit for generating at least one of: A1h1) a low bitrate audio bitstream of coded lowband audio from the low bitrate coding unit; and A1h2) a supplemental audio bitstream for enhancing audio fidelity of the low bitrate audio bitstream, wherein the bitstream and coding formatting unit provides a hybrid bitstream comprising the low bitrate audio bitstream and the supplemental audio bitstream; A2) in a decoder; A2a) using a bitstream decoding unit for redirecting the low bitrate audio bitstream to the low bitrate decoding unit and for separating the supplemental bitstream into explicit quantizer stepsize parameters and coded diffband frequency coefficients wherein the bitstream decoding unit separates the hybrid bitstream into explicit quantizer stepsize parameters, coded diffband frequency coefficients and the low bitrate audio bitstream: A2b) using a low bitrate decoding unit for generating decoded lowband audio samples wherein the low bitrate decoding unit further sample rate converts the decoded bitstream to match a sample rate of the audio samples; A2c) using a lowband psychoacoustic modeling and quantizer control unit for generating at least one of: A2c1) implicit quantizer stepsize parameters; and A2c2) implicit zero-flags; A2d) using a sample decoding unit and requantizer for decoding and requantizing requantized diffband frequency coefficients wherein, where zero-flagging mode is selected, the sample decoding unit and requantizer reconstructs requantized diffband frequency coefficients from coded diffband frequency coefficients and explicit quantizer stepsize parameters, both from the bitstream decoding unit, and 1) implicit quantizer stepsize parameters: and 2) implicit zero-flags provided by the lowband psychoacoustic modeling and quantizer control unit and reconstructs zero-flagged diffband frequency coefficients with zero values: A2e) using a frequency-to-time synthesis unit for converting the requantized diffband frequency coefficients into requantized diffband audio samples: A2f) using a time alignment unit for synchronizing the output of the low bitrate decoding unit with the requantized diffband audio samples: A2g) using a summer for summing the time-aligned, decoded, lowband audio samples with requantized diffband audio samples to provide fullband audio samples; and B) generating, by a quantizer control unit and zero-flagging unit, explicit quantizer stepsize parameters and at least one of: implicit quantizer stepsize parameters and implicit zero-flags.<br>5. A hybrid psychoacoustic device for providing scalable bitrate audio compression parameters, wherein the hybrid psychoacoustic device includes a scalabitrate audio compression system comprising at least one of A-B: A) an encoder, comprising: A1) a coding delay compensation unit, coupled to receive audio samples, for providing delayed audio samples for synchronizing the audio samples with an output of a low bitrate decoding unit; A2) a low bitrate coding unit, coupled to receive the audio samples, for coding the audio samples to provide a low bitrate audio bitstream; A3) the low bitrate decoding unit, coupled to the low bitrate coding unit, for generating decoded lowband audio samples; A4) a difference unit, coupled to the coding delay compensation unit and the low bitrate decoding unit, for generating diffband audio samples by subtracting the decoded lowband audio from the delayed audio samples; A5) a time-to-frequency analysis unit, coupled to the difference unit, for generating diffband frequency coefficients; A6) a quantizer and sample coding unit, coupled to the time-to-frequency unit and a hybrid psychoacoustic modeling and quantizer control unit, for quantizing and coding the diffband frequency coefficients to provide coded diffband frequency coefficients wherein, where zero-flagging is selected to improve coding efficiency, lowband frequency coefficients are compared against predetermined lowband masking thresholds, lowband frequency coefficients with values below a corresponding predetermined lowband masking threshold are zero-flagged, zero-flagged lowband frequency coefficients are replaced with zero, and the quantizer and sample coding unit omits coding of zero-flagged lowband frequency coefficients when coding the diffband frequency coefficients; A7) the hybrid psychoacoustic modeling and quantizer control unit, coupled to the low bitrate decoding unit, the difference unit and the time-to-frequency analysis unit, for providing to the bitstream coding and formatting unit and to the quantizer and sample coding unit, explicit quantizer stepsize parameters and for providing to the quantizer and sample coding unit, A7a) implicit quantizer stepsize parameters; and A7b) implicit zero-flags; A8) a bitstream and coding formatting unit, coupled to the quantizer and sample coding unit, the hybrid psychoacoustic modeling and quantizer control unit and the low bitrate coding unit, for generating at least one of: A8a) a low bitrate audio bitstream of coded lowband audio from the low bitrate coding unit; and A8b) a supplemental audio bitstream for enhancing audio fidelity of the low bitrate audio bitstream, wherein the bitstream and coding formatting unit provides a hybrid bitstream comprising the low bitrate audio bitstream and the supplemental audio bitstream; B) a decoder, comprising: B1) a bitstream decoding unit, coupled to receive at least one of: the supplemental bitstream and the low bitrate audio bitstream, for redirecting the low bitrate audio bitstream to the low bitrate decoding unit and for separating the supplemental bitstream into explicit quantizer stepsize parameters and coded diffband frequency coefficients wherein the bitstream decoding unit separates the hybrid bitstream into explicit quantizer stepsize parameters, coded diffband frequency coefficients and the low bitrate audio bitstream; B2) a low bitrate decoding unit, coupled to receive the low bitrate audio bitstream from the bitstream decoding unit; for generating decoded lowband audio samples wherein the low bitrate decoding unit further sample rate converts the decoded bitstream to match a sample rate of the audio samples: B3) a lowband psychoacoustic modeling and quantizer control unit, coupled to the low bitrate decoding unit, for generating: B3a) implicit quantizer stepsize parameters; and B3b) implicit zero-flags; B4) a sample decoding unit and requantizer, coupled to the bitstream decoding unit and the lowband psychoacoustic modeling and quantizer control unit, for decoding and requantizing requantized diffband frequency coefficients wherein, where zero-flagging mode is selected, the sample decoding unit and requantizer reconstructs requantized diffband frequency coefficients from coded diffband frequency coefficients and explicit quantizer stepsize parameters, both from the bitstream decoding unit, and at least one of: 1) implicit quantizer stepsize parameters; and 2) implicit zero-flags provided by the lowband psychoacoustic modeling and quantizer control unit and reconstructs zero-flagged diffband frequency coefficients with zero values; B5) a frequency-to-time synthesis unit, coupled to the sample decoding unit and requantizer, for converting the requantized diffband frequency coefficients into requantized diffband audio samples; B6) a time alignment unit, coupled to the low bitrate decoding unit, for synchronizing the output of the low bitrate decoding unit with the requantized diffband audio samples; B7) a summer, coupled to the time-to-frequency synthesis unit and the time alignment unit, for summing the time-aligned, decoded, lowband audio samples with requantized diffband audio samples to provide fullband audio samples.<br>6. A computer having a hybrid psychoacoustic device for providing scalable bitrate audio compression parameters, wherein the hybrid psychoacoustic device includes a scalabitrate audio compression system comprising at least one of A-B: A) an encoder, comprising: A1) a coding delay compensation unit, coupled to receive audio samples, for providing delayed audio samples for synchronizing the audio samples with an output of a low bitrate decoding unit; A2) a low bitrate coding unit, coupled to receive the audio samples, for coding the audio samples to provide a low bitrate audio bitstream; A3) the low bitrate decoding unit, coupled to the low bitrate coding unit, for generating decoded lowband audio samples; A4) a difference unit, coupled to the coding delay compensation unit and the low bitrate decoding unit, for generating diffband audio samples by subtracting the decoded lowband audio from the delayed audio samples; A5) a time-to-frequency analysis unit, coupled to the difference unit, for generating diffband frequency coefficients; A6) a quantizer and sample coding unit, coupled to the time-to-frequency unit and a hybrid psychoacoustic modeling and quantizer control unit, for quantizing and coding the diffband frequency coefficients to provide coded diffband frequency coefficients wherein to improve coding efficiency, lowband frequency coefficients are compared against predetermined lowband masking thresholds, lowband frequency coefficients with values below a corresponding predetermined lowband masking threshold are zero-flagged, zero-flagged lowband frequency coefficients are replaced with zero, and the quantizer and sample coding unit omits coding of zero-flagged lowband frequency coefficients when coding the diffband frequency coefficients; A7) the hybrid psychoacoustic modeling and quantizer control unit, coupled to the low bitrate decoding unit, the difference unit and the time-to-frequency analysis unit, for providing to the bitstream coding and formatting unit and to the quantizer and sample coding unit, explicit quantizer stepsize parameters and for providing to the quantizer and sample coding unit, A7a) implicit quantizer stepsize parameters; and A7b) implicit zero-flags; A8) a bitstream and coding formatting unit, coupled to the quantizer and sample coding unit, the hybrid psychoacoustic modeling and quantizer control unit and the low bitrate coding unit, for generating at least one of: A8a) a low bitrate audio bitstream of coded lowband audio from the low bitrate coding unit; and A8b) a supplemental audio bitstream for enhancing audio fidelity of the low bitrate audio bitstream, wherein the bitstream and coding formatting unit provides a hybrid bitstream comprising the low bitrate audio bitstream and the supplemental audio bitstream: B) a decoder, comprising: B1) a bitstream decoding unit, coupled to receive at least one of: the supplemental bitstream and the low bitrate audio bitstream, for redirecting the low bitrate audio bitstream to the low bitrate decoding unit and for separating the supplemental bitstream into explicit quantizer stepsize parameters and coded diffband frequency coefficients wherein the bitstream decoding unit separates the hybrid bitstream into explicit quantizer stepsize parameters, coded diffband frequency coefficients and the low bitrate audio bitstream; B2) a low bitrate decoding unit, coupled to receive the low bitrate audio bitstream from the bitstream decoding unit, for generating decoded lowband audio samples wherein the low bitrate decoding unit further sample rate converts the decoded bitstream to match a sample rate of the audio samples; B3) a lowband psychoacoustic modeling and quantizer control unit, coupled to the low bitrate decoding unit, for generating: B3a) implicit quantizer stepsize parameters; and B3b) implicit zero-flags; B4) a sample decoding unit and requantizer, coupled to the bitstream decoding unit and the lowband psychoacoustic modeling and quantizer control unit, for decoding and requantizing requantized diffband frequency coefficients wherein, where zero-flagging mode is selected, the sample decoding unit and requantizer reconstructs requantized diffband frequency coefficients from coded diffband frequency coefficients and explicit quantizer stepsize parameters, both from the bitstream decoding unit, and at least one of: 1) implicit quantizer stepsize parameters: and 2) implicit zero-flags provided by the lowband psychoacoustic modeling and quantizer control unit and reconstructs zero-flagged diffband frequency coefficients with zero values; B5) a frequency-to-time synthesis unit, coupled to the sample decoding unit and requantizer, for converting the requantized diffband frequency coefficients into requantized diffband audio samples; B6) a time alignment unit, coupled to the low bitrate decoding unit, for synchronizing the output of the low bitrate decoding unit with the requantized diffband audio samples; B7) a summer, coupled to the time-to-frequency synthesis unit and the time alignment unit, for summing the time-aligned, decoded, lowband audio samples with requantized diffband audio samples to provide fullband audio samples.</p></layer>
<layer id = "layer219"><p><b>US5297236A:Low computational-complexity digital filter bank for encoder, decoder, and encoder/decoder</b><br>A clock generator (15) and a delay circuit (16) create N dot recording clock signals (.phi..sub.1 to .phi..sub.N) of a cycle t, delayed by t/N. A counter (20) counts a detecting time interval between a start sensor (12) and an end sensor (14) for every surface of a polygon mirror (8) to generate time resolution t/N. The difference between the count value and a reference count value set in a latch (24) is input to a subtracter (23), so that a translation table (28) outputs clock crossover timing responsive to the difference. A latch (17) and an encoder (18) select an N dot recording clock signal synchronous with detection output of the start sensor (12) for every surface of the polygon mirror (8). A second selector (33) outputs a crossover dot recording clock signal (.phi..sub.X) for image recording by performing crossover from the selected dot recording clock signal to other dot recording clock signals that are sequentially along the clock crossover timing.<br><b>Independant Claims</b><br>1. In an encoder a combination for the filtering of one or more signals comprising input samples, said combination comprising means for receiving said input samples representing stimuli intended for human perception, input buffer means for grouping said input samples into time-domain signal sample blocks of length N, where N is a positive integer, wherein said input samples are analysis-window weighted samples, analysis means for generating spectral information in response to said time-domain signal sample blocks, said spectral information comprising spectral coefficients C(k) and S(k) substantially corresponding to the frequency-domain transform coefficients of an Evenly-Stacked Time-Domain Aliasing Cancellation transform applied to said time-domain signal sample blocks, wherein said spectral coefficients C(k) and S(k) substantially correspond to Modified Discrete Cosine Transform coefficients and Modified Discrete Sine Transform coefficients, respectively, comprising forward pre-transform means for generating modified-sample blocks comprising 1/2N modified samples by combining one or more pairs of analysis-window weighted samples to form said modified samples, and forward transform means for generating frequency-domain transform coefficients by applying one or more discrete transform functions to said modified-sample blocks, and means for generating an encoded signal in response to said spectral information.<br>5. In an encoder a combination for the filtering of one or more signals comprising input samples, said combination comprising means for receiving said input samples representing stimuli intended for human perception, input buffer means for grouping said input samples into time-domain signal sample blocks of length a+b, where a and b are non-negative integers and the sum a+b is positive, wherein said length varies from block to block one or more times, and wherein said input samples are analysis-window weighted samples, forward pre-transform means for generating modified-sample blocks comprising 1/2(a+b) modified samples by combining pairs of analysis-window weighted samples to form said modified samples, forward transform means for generating frequency-domain transform coefficients by applying one or more discrete transform functions to said modified-sample blocks, and means for generating an encoded signal in response to said frequency-domain transform coefficients.<br>9. In a decoder a combination for the inverse filtering of one or more digital signals comprising spectral information, said combination comprising means for receiving said spectral information, synthesis means for generating signal samples in response to said spectral information, said signal samples substantially corresponding to the time-domain transform coefficients of an Evenly-Stacked Time-Domain Aliasing Cancellation transform applied to said spectral information, comprising inverse pre-transform means for generating sets of frequency-domain transform coefficients in response to said spectral information, inverse transform means for generating transform blocks comprising time-domain transform coefficients by applying an inverse discrete transform function to said sets of frequency-domain transform coefficients, and inverse post-transform means for generating time-domain signal sample blocks comprising N signal samples, wherein one or more pairs of signal samples are generated from a respective one of said time-domain transform coefficients, and output means for generating output samples representing stimuli intended for human perception by overlapping pairs of said time-domain signal sample blocks and additively combining signal samples from each of said overlapped blocks.<br>14. In a decoder a combination for the inverse filtering of one or more digital signals comprising spectral information, said combination comprising means for receiving said spectral information. inverse pre-transform means for generating sets of frequency-domain transform coefficients in response to said spectral information, said set comprising 1/2(a+b) coefficients wherein the number of coefficients varies from set to set one or more times, inverse transform means for generating transform blocks comprising time-domain transform coefficients by applying one or more inverse discrete transform functions to said set of frequency-domain transform efficients, inverse post-transform means for generating time-domain signal sample blocks comprising a+b signal samples, wherein a pair of signal samples is generated from a respective one of said time-domain transform coefficients, and output means for generating output samples representing stimuli intended for human perception by overlapping pairs of said time-domain signal sample blocks and additively combining signal samples from each of said overlapped blocks.<br>18. In an encoding method a combination for the filtering of one or more signals comprising input samples, said combination comprising receiving said input samples representing stimuli intended for human perception, grouping said input samples into time-domain signal sample blocks of length N, where N is a positive integer, wherein said input samples are analysis-window weighted samples, generating spectral information in response to said time-domain signal sample blocks, said spectral information comprising spectral coefficients C(k) and S(k) substantially corresponding to the frequency-domain transform coefficients of an Evenly-Stacked Time-Domain Aliasing Cancellation transform applied to said time-domain signal sample blocks, wherein said spectral coefficients C(k) and S(k) substantially correspond to Modified Discrete Cosine Transform coefficients and Modified Discrete Sine Transform coefficients, respectively, comprising generating modified-sample blocks comprising 1/2N modified samples by combining one or more pairs of analysis-window weighted samples to form said modified samples, and generating frequency-domain transform coefficients by applying one or more discrete transform functions to said modified-sample blocks, and generating an encoded signal in response to said spectral information.<br>22. In an encoding method a combination for the filtering of one or more signals comprising input samples, said combination comprising receiving said input samples representing stimuli intended for human perception, grouping said input samples into time-domain signal sample blocks of length a+b, where a and b are non-negative integers and the sum a+b is positive, wherein said length varies from block to block one or more times, and wherein said input samples are analysis-window weighted samples, generating modified-sample blocks comprising 1/2(a+b) modified samples by combining pairs of analysis-window weighted samples to form said modified samples, generating frequency-domain transform coefficients by applying one or more discrete transform functions to said modified-sample blocks, and generating an encoded signal in response to said frequency-domain transform coefficients.<br>26. In a decoding method a combination for the inverse filtering of one or more digital signals comprising spectral information, said combination comprising receiving said spectral information, generating signal samples in response to said spectral information, said signal samples substantially corresponding to the time-domain transform coefficients of an Evenly-Stacked Time-Domain Aliasing Cancellation transform applied to said spectral information, comprising generating sets of frequency-domain transform coefficients in response to said spectral information, generating transform blocks comprising time-domain transform coefficients by applying an inverse discrete transform function to said sets of frequency-domain transform coefficients, and generating time-domain signal sample blocks comprising N signal samples, wherein one or more pairs of signal samples are generated from a respective one of said time-domain transform coefficients, and generating output samples representing stimuli intended for human perception by overlapping pairs of said time-domain signal sample blocks and additively combining signal samples from each of said overlapped blocks.<br>31. In a decoding method a combination for the inverse filtering of one or more digital signals comprising spectral information, said combination comprising receiving said spectral information, generating sets of frequency-domain transform coefficients in response to said spectral information, said sets comprising 1/2(a+b) coefficients wherein the number of coefficients varies from set to set one or more times, generating transform blocks comprising time-domain transform coefficients by applying one or more inverse discrete transform functions to said sets of frequency-domain transform coefficients, generating time-domain signal sample blocks comprising a+b signal samples, wherein a pair of signal samples is generated from a respective one of said time-domain transform coefficients, and generating output samples representing stimuli intended for human perception by overlapping pairs of said time-domain signal sample blocks and additively combining signal samples from each of said overlapped blocks.</p></layer>
<layer id = "layer220"><p><b>US6014622A:Low bit rate speech coder using adaptive open-loop subframe pitch lag estimation and vector quantization</b><br>An attenuating circuit for attenuating commercial interruptions in an audio signal, the audio signal including at least a first channel audio signal and a second channel audio signal; the attenuating circuit including a first audio channel detection circuit and a second audio channel detection circuit, each of the audio channel detection circuits including a low pass filter mechanism for receiving the audio signal and for passing only low frequency components of the audio signal, with the low frequency components being beneath a determined frequency; a low frequency comparator circuit for generating a low frequency detection signal whenever the amplitude of the low frequency components exceed a first threshold value; a high pass filter mechanism for receiving the audio signal and for passing only high frequency components of the audio signal, the high frequency components being above the determined frequency; and a high frequency comparator circuit for generating a high frequency detection signal whenever the amplitude of said high frequency components exceed a second threshold value. Finally, the circuit includes a logic circuit for receiving the low frequency detection signals and the high frequency detection signals and for generating an attenuating signal if, and only if, both of the low frequency detection signals are active and both of the high frequency detection signals are null; and an attenuation circuit for receiving the attenuation signal and for substantially attenuating the strength of the audio signal whenever the attenuation signal is active.<br><b>Independant Claims</b><br>1. A system for coding speech, the speech being represented as plural speech samples segregated into a frame, the frame being formed of a plurality of subframes, wherein linear predictive coding (LPC) analysis and quantization of the speech samples in the frame are performed to determine an LPC residual signal, the system comprising: lag means for estimating an unquantized pitch lag value within a predetermined minimum-allowed pitch lag and a predetermined maximum-allowed pitch lag for each subframe within the frame, including; means for constructing an LPC residual signal vector for the frame of speech, means for estimating an open-loop pitch lag value based on the LPC residual signal vector, the open-loop pitch lag value lying within the predetermined minimum-allowed pitch lag and the predetermined maximum-allowed pitch lag: a synthesis filter for filtering the LPC residual signal vector to produce a target signal; means for generating a residual-based pitch contribution vector for each subframe within the frame; means for perceptually filtering each residual-based pitch contribution vector to obtain a perceptually-filtered residual-based pitch contribution vector; and means for estimating the unquantized pitch lag value for each subframe by considering a plurality of pitch lag values that are located around the open-loop pitch lag value within a subset of values that are within the predetermined minimum and maximum-allowed pitch lags and determining which corresponds to a perceptually-filtered residual-based pitch contribution vector that is closest to the target signal; means for obtaining an unquantized pitch lag vector comprising the unquantized pitch lag values for each subframe within the frame; a vector quantizer for quantizing the unquantized pitch lag vector to generate a quantized pitch lag vector containing quantized pitch lag values corresponding to each subframe; means for determining an excitation-based pitch contribution vector for a current subframe based on the corresponding quantized pitch lag vector; codebook means for generating an excitation signal representative of the speech samples of the current subframe; and means for applying the excitation signal of each current subframe to subsequent subframes to provide coded speech for the frame.</p></layer>
<layer id = "layer221"><p><b>US6098038A:Method and system for adaptive speech enhancement using frequency specific signal-to-noise ratio estimates</b><br>A device (<b>1</b>) for transmitting speech information to the human body, comprising:<ul id="ul0001" list-style="none"><li id="ul0001-0001" num="0000"><ul id="ul0002" list-style="none"><li id="ul0002-0001" num="0000">a microphone (<b>2</b>) for inputting speech from an external source; </li><li id="ul0002-0002" num="0000">a speech signal processor (<b>20</b>) that produces a consonant-clarified signal based on the input speech signal; </li><li id="ul0002-0003" num="0000">a carrier signal generator (<b>6</b>) that produces a carrier signal; </li><li id="ul0002-0004" num="0000">an amplitude modulator (<b>8</b>) that modulates the amplitude of the carrier signal based on the consonant-clarified signal; and </li><li id="ul0002-0005" num="0000">a vibrator (<b>12</b>) that transmits mechanical vibrations based on the amplitude-modulated output signal; </li><li id="ul0002-0006" num="0000">the speech signal processor (<b>20</b>) comprising: a consonant extracting unit that extracts the consonant parts from the speech signal; and a repetition processing unit that adds the extracted consonant parts to the speech signal to produce a consonant-clarified signal in which each of the consonant parts of the speech signal is repeated two or more times. This speech information transmitting device realizes good discriminability of speech information. </li></ul></li></ul><br><b>Independant Claims</b><br>1. A method for adaptively filtering a speech signal to suppress noise therein, the method comprising: decomposing the speech signal into a plurality of frequency subbands, each subband having a center frequency; estimating a signal-to-noise ratio for each subband; providing a plurality of filters, each filter designed for one of a plurality of selected signal-to-noise ratios independent of the center frequencies of the plurality of subbands; selecting one of the plurality of filters for each subband, wherein the filter selected depends on the signal-to-noise ratio estimated for the subband; filtering each subband according to the filter selected; and combining the filtered subbands to provide an estimated filtered speech signal.<br>10. A system for adaptively filtering a speech signal to suppress noise therein, the system comprising: means for decomposing the speech signal into a plurality of frequency subbands, each subband having a center frequency; means for estimating a signal-to-noise ratio for each subband; a plurality of filters for filtering the subbands, each filter designed for one of a plurality of selected signal-to-noise ratios independent of the center frequencies of the plurality of subband; means for selecting one of the plurality of filters for each subband, wherein the filter selected depends on the signal-to-noise ratio estimated for the subband; and means for combining the filtered subbands to provide an estimated filtered speech signal.</p></layer>
<layer id = "layer222"><p><b>US4076958A:Signal synthesizer spectrum contour scaler</b><br>A carrier for objects to be sequentially weighed is designed for connection to a load receiver of a weighing cell. The carrier has a supporting structure and a multi-compartment weighing tray. The supporting structure has an element for coupling the supporting structure to the load receiver and an element for connecting the weighing tray to the supporting structure in a guided and constrained manner. The weighing tray is seated or slid into place, leaving it free to perform a defined linear, swiveling, or rotary movement relative to the supporting structure. The weighing tray has at least two receiving compartments, arranged so that each can be sequentially moved into a defined loading position, fixed relative to the supporting structure. A positioning device, arranged between the supporting structure and the weighing tray, precisely aligns with the loading position the receiving compartment that is next to be moved into the loading position.<br><b>Independant Claims</b><br>1. A synthesizer for converting consecutive frames of digital words into analog signals, such consecutive frames including frequency and amplitude information relating to consecutive predetermined instants of time of a first signal, and one word of each frame comprising a channel containing fundamental frequency information bits relating to the fundamental frequency of the original signal at one instant of time, and other consecutive words of each frame comprising channels containing amplitude information bits of consecutive, predetermined frequency bands of the first signal, said bands having a predetermined relation to the fundamental frequency of the first signal at one instant of time, said synthesizer including: input means for receiving consecutive frames of digital words; first means connected to said input means and including memory means for storing digital signals indicative of the predetermined frequency and predetermined amplitude of the words in channels of sequential frames, and means operatively associated with said memory means for causing said memory means to transmit successive digital signals indicative of the amplitude and frequency of words of subsequent frames; second means connected to said first means and including storage means of the differential of amplitude values of words at time interpolation intervals between subsequent frames, and means for receiving successive digital signals indicative of the amplitude of words of subsequent frames, and for generating from the differential of amplitude values and the received digital signals a time scaled value for one of the words of one frame for the receive digital signal; and adder means for receiving the digital words from said second means and for producing a digital signal corresponding to each frame and indicative of the sum of the time scaled signals corresponding to the words of each frame; and a digital-to-analog converter for receiving the output of said adder means and producing an analog signal corresponding to said first signal.<br>9. A synthesizer for converting consecutive frames of digital words into analog signals, said consecutive frames including frequency and amplitude information relating to consecutive, predetermined instants of time of a first signal, and one word of a channel of each frame containing fundamental frequency information bits relating to the fundamental frequency of the first signal at any one instant of time, and other consecutive words of channels of each frame containing amplitude information bits of consecutive, predetermined frequency bands of the first signal, said bands having a predetermined relation to the fundamental frequency of the first signal at one instant of time, said synthesizer including: input means for receiving said consecutive frames of digital words; first means connected to said input means and including multiple arrays of memory means having selectable storage elements for storing digital signals indicative of the predetermined frequency and predetermined amplitude of the words of sequential frames, and control means for writing digital signals into selected storage elements from said input means and for reading digital signals from selected storage elements to transmit successive digital signals indicative of the amplitude and frequency of words of subsequent frames; second means connected to said first means and including an array of memory means for receiving the differential of amplitude values of words at a time interpolation interval between subsequent frames, and means for receiving successive digital signals indicative of the amplitude of words of subsequent frames and for generating from the differential of amplitude values and the received digital signals the time scaled value at established time interpolation intervals for one of the words of one of the frames from the received digital signals; adder means for receiving the digital words from said second means and for producing a digital signal corresponding to each frame and indicative of the sum of the time scaled signals corresponding to the words of each frame; and a digital-to-analog converter for receiving the output of said adder means and producing an analog signal corresponding to said first signal.<br>11. A synthesizer for converting consecutive frames of digital words into analog signals, said consecutive frames including frequency and amplitude information relating to consecutive, predetermined instants of time of a first signal, and one word of each frame comprising a channel containing fundamental frequency information bits relating to the fundamental frequency of the first signal at one instant of time, other consecutive words of each frame comprising channels containing amplitude information bits of consecutive, predetermined frequency bands of the first signal, said bands having a predetermined relation to the fundamental frequency of the first signal at one instant of time, said synthesizer including: input means for receiving said consecutive frames of digital words; first means connected to said input means and including a memory for storing digital signals indicative of the predetermined frequency and predetermined amplitude of the words of sequential frames, and means operatively associated with said memory for causing said memory to transmit successive digital signals indicative of the amplitude and frequency of words of subsequent frames; second means connected to said first means and including arithmetic logic responsive to digital words in channels of successive frames to produce a difference digital signal therefrom, and means for receiving the difference digital signal and the frequency interpolation signal for generating a frequency scaled value for one of the words of one frame for the received digital signal; adder means for receiving the scaled value from said second means and for producing a digital signal corresponding to each frame and indicative of the sum of the frequency scaled signals corresponding to the words of each frame; and a digital-to-analog converter for receiving the output of said adder means for producing an analog signal corresponding to said first signal.<br>19. A synthesizer for converting consecutive frames of digital words into analog signals, said consecutive frames including frequency and amplitude information relating to consecutive, predetermined instants of time of a first signal, and one word of each frame comprising a channel containing fundamental frequency information bits relating to the fundamental frequency of the first signal at one instant of time, and other consecutive words of each frame comprising additional channels containing amplitude information bits of consecutive, predetermined frequency bands of the first signal, said bands having a predetermined relation to the fundamental frequency of the first signal at one instant of time, said synthesizer including: input means for receiving said consecutive frames of digital words, first means connected to said input means and including storage elements in memory means for storing digital signals of three sequential frames each indicative of the predetermined frequency and predetermined amplitude of the words of the sequential frames, and control means for writing digital signals into selected storage elements from said input means and for reading digital signals from selected storage elements to transmit successive digital signals indicative of the amplitude and frequency of the words of subsequent frames; second means connected to said first means and including arithmetic logic operative in a first mode to respond to digital words of successive frames to produce a difference signal therefrom, and means for receiving the difference signal and a frequency interpolation signal for generating an amplitude differential signal for one of the words of one frame, said arithmetic logic units responsive in a second mode to the amplitude differential signal and a digital signal of one frame to generate a frequency scaled value for one of the words of one frame, adder means for receiving the digital words from said second means and for producing a digital signal corresponding to each frame and indicative of the sum of the frequency scaled signals corresponding to words of each frame, and a digital-to-analog converter for receiving the output of said adder means and producing an analog signal corresponding to said first signal.<br>23. A synthesizer for converting consecutive frames of digital words into analog signals, said consecutive frames including frequency and amplitude information relating to consecutive, predetermined instants of time of a first signal, and one word of each frame comprising a channel containing fundamental frequency information bits relating to the fundamental frequency of the first signal at one instant of time, and other consecutive words of each frame comprising channels containing amplitude information bits of consecutive, predetermined frequency bands of the first signal, said bands having a predetermined relation to the fundamental frequency of the first signal at one instant of time, said synthesizer including: input means for receiving said consecutive frames of digital words, first means connected to said input means and including memory means for storing digital signals indicative of the predetermined frequency and predetermined amplitude of the words of sequential frames, and means operatively associated with said memory means for causing said memory means to transmit successive digital signals indicative of the amplitude and frequency of words of subsequent frames, second means connected to said first means and including storage means for the differential of amplitude signals of words at time interpolation intervals between subsequent frames, and means for receiving successive digital signals indicative of the amplitude and frequency of words of subsequent frames, and for generating a time scaled value for one of the words of one frame from the received digital signals, third means connected to said second means and including arithmetic logic responsive to the time scaled value for one of the words of successive frames to produce a difference digital signal therefrom, and means for receiving the difference digital signal and a frequency interpolation signal to generate a frequency scaled signal for one of the words of one frame, adder means for receiving the digital words from said third means and for producing a digital signal corresponding to each frame and indicative of the sum of the time and frequency scaled signals corresponding to the words of each frame, and a digital-to-analog converter for receiving the output of said adder means and producing an analog signal corresponding to said first signal.</p></layer>
<layer id = "layer223"><p><b>US6925435B1:Method and apparatus for improved noise reduction in a speech encoder</b><br>A Web-information manager that is to take locally stored copies of a Web page and the files to which it refers employs two versions of a downloaded Web page if the Web page includes a client-side script. One, “source” version is the one that results from downloading the page with scripting execution disabled. The other, “reference” version is one that results from executing the script. It then locally stores copies of the files referred to by the resultant (potentially script-modified) reference version. And any links in the source version that refer to files thus copied are revised to refer to the local copies. It is this source version, unmodified by the script but updated to refer to local copies of the referred-to files, that is stored for later review.<br><b>Independant Claims</b><br>1) A speech encoder for encoding a speech signal having a spectrum, said spectrum being divided into a plurality of sub-bands, said speech encoder comprising: a background noise suppression element configured to pre-process said speech signal and to generate a background noise reduced speech signal; and a linear prediction (LP)-based synthesis-by-analysis coder coupled to said background noise suppression element and configured to apply an LP-based coding process to said background noise reduced speech signal, said LP-based synthesis-by-analysis coder including an error weighting filter for shaping a spectrum of an error signal; wherein said background noise suppression element is further configured to perform a first background noise reduction operation to emphasize harmonic frequencies of said speech signal in each sub-band of said plurality of sub-bands and to reduce background noise between harmonic peaks of said harmonic frequencies to generate said background noise reduced speech signal; wherein said background noise suppression element is further configured to determine whether said speech signal is a voiced signal or an unvoiced signal, and wherein said background noise suppression element performs said first background noise reduction operation if said speech signal is said voiced signal, and wherein said background noise suppression element performs a second background noise reduction operation if said speech signal is said unvoiced signal; and wherein said LP-based synthesis-by-analysis coder applies said LP-based coding process to said background noise reduced speech signal whether voiced signal or unvoiced signal.<br>8) A speech coding system for coding a speech signal having a spectrum, said spectrum being divided into a plurality of sub-bands, said speech coding system comprising: an encoder comprising: a background noise suppression element configured to pre-process a speech signal and to generate a background noise reduced speech signal, and a linear prediction (LP)-based synthesis-by-analysis coder coupled to said background noise suppression element and configured to apply an LP-based coding process to said background noise reduced speech signal to generate an encoded background noise reduced speech signal, said LP-based synthesis-by-analysis coder including an error weighting filter for shaping a spectrum of an error signal, wherein said background noise suppression element is further configured to perform a first background noise reduction operation to emphasize harmonic frequencies of said speech signal in each sub-band of said plurality of sub-bands and to reduce background noise between harmonic peaks of said harmonic frequencies to generate said background noise reduced speech signal; wherein said background noise suppression element is further configured to determine whether said speech signal is a voiced signal or an unvoiced signal, and wherein said background noise suppression element performs said first background noise reduction operation if said speech signal is said voiced signal, and wherein said background noise suppression element performs a second background noise reduction operation if said speech signal is said unvoiced signal; and wherein said LP-based synthesis-by-analysis coder applies said LP-based coding process to said background noise reduced speech signal whether voiced signal or unvoiced signal; a decoder configured to decode said encoder background noise reduced speech signal to generate a synthesized background noise reduced speech signal; and a transmission channel for transmitting said encoded background noise reduced speech signal from said encoder to said decoder.<br>17) A method for reducing background noise in a speech signal prior to encoding said speech signal, said speech signal having a spectrum, said spectrum being divided into a plurality of sub-bands, said method comprising: receiving said speech signal; determining whether said speech signal is a voiced signal or an unvoiced signal; and if said determining determines that said speech signal is said voiced signal, applying a first noise reduction operation including: emphasizing harmonic frequencies of said speech signal in each sub-band of said plurality of sub-bands; and reducing background noise between harmonic peaks of said harmonic frequencies to generate a background noise reduced speech signal; and if said determining determines that said speech signal is said unvoiced signal, applying a second noise reduction operation; encoding said background noise reduced speech signal using a linear prediction (LP)-based synthesis-by-analysis coder whether said speech signal is said voiced signal or said unvoiced signal, wherein said LP-based synthesis-by-analysis coder includes an error weighting filter for shaping a spectrum of an error signal.</p></layer>
<layer id = "layer224"><p><b>US20020111798A1:Method and apparatus for robust speech classification</b><br>A method for storing a constellation of Pulse Code Modulation (PCM) levels in a condensed representation. The constellation of PCM levels is stored in a condensed representation that can be expanded to the full constellation. A 16 bit binary word stores the full constellation of selected points. The 6 most significant bits represent a number of PCM linear values at the minimum spacing between PCM linear values that should not be selected in the constellation. The 10 least significant bits represent the minimum spacing between PCM linear values selected in the constellation from the condensed representation. Using the number of PCM linear values at the minimum spacing between PCM linear values that should not be selected in the constellation, the minimum spacing between PCM linear values, and the number of selected constellation points, the full constellation can be generated from the condensed representation.<br><b>Independant Claims</b><br>1. A method of speech classification, comprising: inputting classification parameters to a speech classifier from external components; generating, in the speech classifier, internal classification parameters from at least one of the input parameters; setting a Normalized Auto-correlation Coefficient Function threshold and selecting a parameter analyzer according to a signal environment; and analyzing the input parameters and the internal parameters to produce a speech mode classification.<br>33. A speech classifier, comprising: a generator for generating classification parameters; a Normalized Auto-correlation Coefficient Function threshold generator for setting a Normalized Auto-correlation Coefficient Function threshold and selecting a parameter analyzer according to an a signal environment; and a parameter analyzer for analyzing at least one external input parameter and the internal parameters to produce a speech mode classification.</p></layer>
<layer id = "layer225"><p><b>US20020172364A1:Discontinuous transmission (DTX) controller system and method</b><br>A drive system for a curved escalator which has a frame, a transport section including steps, return tracks and guide tracks, and a drive connected to the transport section. The drive system includes: chain wheels connectable to the drive; and chains engaging the chain wheels hingeable in lateral edge areas of the steps, the chains being disposed parallel to one another, each of the chains comprising interior and exterior brackets. The drive system further includes shaft sections disposed adjacent corresponding ones of the brackets and further being adapted to be disposed at respective edge areas of each step; rollers connected to respective ends of each of the shaft sections, each of the shaft sections projecting through a corresponding one of the rollers and being fixed, at a face end thereof, in a wall area of a corresponding one of the interior brackets which is adapted to face outer frame areas of the frame; and traction rollers placed at a distance from the rollers. Bushings are respectively disposed at both end sections of the brackets. Each of the rollers includes a spherical bearing disposed therein, is seated in one dimension between corresponding ones of the interior brackets which are parallel to one another, is adjacent a corresponding one of the shaft sections, and is further seated in another dimension between corresponding ones of the bushings at both end sections of the brackets.<br><b>Independant Claims</b><br>1. A method for controlling discontinuous transmissions, comprising the steps of: determining a voice activity level in a digitized audio signal; generating a control signal based on the level of voice activity detected; generating active vocoder frames at a predetermined rate in a transmitter if said control signal indicates a first level of speech activity; generating inactive vocoder frames if said control signal indicates a second level of speech activity; and generating transition frames if said control signal indicates a transition from said first level to said second level, said transition frames comprising background noise information.<br>2. A method for controlling discontinuous transmissions, comprising the steps of: generating data frames at a receiver; storing said data frames in a queue; providing at least one of said data frames from said queue to a decryption module if available in said queue; providing a state vector to said decryption module, said state vector incremented at a predetermined rate; generating a codebook from said decryption module, using at least said state vector, said codebook for decrypting at least one of said data frames; and disabling said state vector when said queue is in an underflow condition.<br>4. A discontinuous transmission controller, comprising: a vocoder for generating active vocoder frames from said digitized audio signal at a predetermined output rate if speech is present, for generating inactive vocoder frames during periods of speech inactivity, and for generating transition frames during transitions from speech activity to speech inactivity, said transition frames comprising background noise information.</p></layer>
<layer id = "layer226"><p><b>US5450522A:Auditory model for parametrization of speech</b><br>A process for disposing of solvent-containing liquids so that they do not contaminate ground water. An absorbent blend is mixed into a water-containing solvent mixture at the rate of about 1 lb. of blend per gallon of liquid. The blend is made up of a swellable polymer, consisting of polyacrylamide/polyacrylate co-polymer salt or poly 2-propenamide-co-2-propenoic acid homopolymer salt which swells and absorbs liquid. The blend also contains a mixture of solid absorbents. The resulting mixture is stirred in the container until it becomes thick and then it is allowed to set to provide a disposable modeling clay-like solid. The resulting solid material, after curing, may be then simply added to solid trash, and thus, be freed from contaminating ground water.<br><b>Independant Claims</b><br>1. In a speech processing system including means for computing a plurality of temporal speech parameters including short-term parameters having time trajectories, a method for alleviating the harmful effects of distortions of speech, the method comprising: filtering data representing time trajectories of the short-term parameters of speech so as to minimize distortions due to steady-state factors in speech.<br>7. A speech processing system including means for computing a plurality of temporal speech parameters. including short-term parameters having time trajectories, the system being useful for alleviating the harmful effects of steady-state distortions of speech, the system further comprising: means for filtering the time trajectories of the short-term parameters of speech to obtain a temporal pattern in which distortions due to steady-state factors in speech are minimized.</p></layer>
<layer id = "layer227"><p><b>US4630304A:Automatic background noise estimator for a noise suppression system</b><br>A method and apparatus for separating saponified tall oil or soap from black liquor which has been stored in an open pond. During such storage, the tall oil saponifies into soap, and the soap separates somewhat and a portion of it settles with the lignin to the bottom of the pond. A submerged propeller is operated by an internal combustion engine on a boat and directs a liquid and gas stream into the layer of liquid soap "sludge" so that the soap is whipped and dispersed. The whipping action causes the soap particles to agglomerage so as to form larger soap portions. The propeller also produces small bubbles of air which become attached to the soap portions thus aiding them in floating to the pond surface. The soap forms in a layer and is pushed along the liquid surface into a discharge tank from which it is pumped to a tank truck. The soap is then hauled to a plant where it is processed.<br><b>Independant Claims</b><br>1. An improved background noise estimator adapted for use with a noise suppression system wherein the background noise from a noisy pre-processed input signal is attenuated by spectral gain modification to produce a noise-suppressed post-processed output signal, said background noise estimator comprising: noise estimation means for generating and storing an estimate of the background noise power spectral density of the pre-processed signal; and noise detection means for periodically detecting the minima of the post-processed signal energy, and for controlling said noise estimation means in response thereto such that said background noise estimate is updated only during said minima.<br>22. An improved background noise estimator adapted for use with a noise suppression system wherein the background noise from a noisy pre-processed input signal is attenuated by spectral gain modification to produce a noise-suppressed post-processed output signal, said background noise estimator comprising: storage means for storing an estimate of the background noise energy of the pre-processed signal in each of a plurality of selected frequency bands as per-channel noise estimates, and for continuously providing an estimate of the background noise power spectral density of the pre-processed signal to said noise suppression system; valley detection means for periodically detecting the minima of an overall estimate of the energy of said post-processed signal in each of a plurality of selected frequency bands, thereby generating a valley detect signal; and signal controlling means coupled to said storage means and controlled by said valley detect signal for providing new background noise estimates to said storage means only during said minima.<br>32. The method of estimating background noise in a noise suppression system, wherein the background noise from a noisy pre-processed input signal is attenuated by spectral gain modification to produce a noise-suppressed post-processed output signal, comprising the steps of: periodically detecting the minima of the post-processed signal energy; providing a noise detection signal only when said minima is detected; and generating and storing an estimate of the background noise power spectral density of the pre-processed signal only during the presence of said noise detection signal.<br>33. The method of estimating background noise in a noise suppression system, wherein the background noise from a noisy pre-processed input signal is attenuated by spectral gain modification to produce a noise-suppressed post-processed output signal, comprising the steps of: periodically detecting the minima of an overall estimate of the energy of the post-processed signal in each of a plurality of selected frequency bands; providing a positive valley detect signal only when said minima is detected; and storing an estimate of the energy of the pre-processed signal in each of a plurality of selected frequency bands only during the presence of said positive valley detect signal.</p></layer>
<layer id = "layer228"><p><b>US4630305A:Automatic gain selector for a noise suppression system</b><br>A sealing glass and a sealing glass paste for sealing the face plate and funnel portion of a color television tube wherein PbO-containing sealing glass frit contains from an effective amount of a powder, such as Pb.sub.3 O.sub.4 powder, which powder prevents the reduction of PbO to Pb metal during the sealing process, which reduction would otherwise result in a dielectric breakdown in the seal. A sealing glass paste consisting essentially of a PbO-B.sub.2 O.sub.3 -ZnO sealing glass frit and containing an effective amount of said powder, based upon the weight of the frit, together with hydroxypropyl cellulose binder for the frit and a solvent for the binder. A method for sealing the face plate of a color television tube to its funnel portion with a PbO-containing solder glass wherein the reduction of PbO to metallic lead during the sealing step is obviated by the addition of a sufficient amount of Pb.sub.3 O.sub.4 or BaO.sub.2 powder in the solder glass and paste made therewith, which Pb.sub.3 O.sub.4 or BaO.sub.2 is slowly reduced to a lower oxide in a reducing atmosphere during the sealing of the television tube components. A method for increasing the dielectric properties of a PbO-containing sealing glass paste and the devitrified seal made therefrom, which seals the face plate to the funnel of a color television tube, to a value greater than that provided by the solder glass, per se, by incorporating in the solder glass and the solder glass paste made therefrom a small but sufficient amount of Pb.sub.3 O.sub.4 or BaO.sub.2 to accomplish this purpose. A vehicle for a glass frit comprises hydroxypropyl cellulose as a binder and a solvent for said binder.<br><b>Independant Claims</b><br>1. An improved noise suppression system for attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal, said noise suppression system comprising: means for separating the input signal into a plurality of pre-processed signals representative of selected frequency channels; means for modifying an operating parameter of each of said plurality of pre-processed signals provided by said signal separating means to provide a plurality of post-processed signals; and means responsive to said plurality of pre-processed signals for generating a modification signal having a selected modification value for each channel for application to said modifying means to enable the operating parameter to be modified, said modification signal generated by automatically selecting a modification value for each channel from one of a plurality of sets of modification values for that channel.<br>2. An improved noise suppression system for attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal, said noise suppression system comprising: means for separating the input signal into a plurality of pre-processed signals representative of selected frequency channels, each of said plurality of pre-processed signals comprised of a plurality of frames, each frame comprised of a plurality of samples of said input signal; means for modifying an operating parameter of each of said plurality of pre-processed signals provided by said signal separating means to provide a plurality of post-processed signals; and means responsive to said plurality of pre-processed signals for generating a modification signal for application to said modifying means to enable the operating parameter to be modified, said modification signal generating means including means for smoothing said modification signal multiple times per frame.<br>8. An improved noise suppression system for attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal, said noise suppression system comprising: means for separating the input signal into a plurality of pre-processed signals representative of selected frequency channels; means for generating an estimate of the signal-to-noise ratio (SNR) in each individual channel; means for producing a gain value for each channel by automatically selecting one of a plurality of gain tables in response to a multi-channel noise parameter, and selecting one of a plurality of gain values from the selected gain table in response to said channel SNR estimates and the channel number; and means for modifying the gain of each of said plurality of pre-processed signals provided by said signal separating means in response to said gain values to provide a plurality of post-processed signals.<br>9. An improved noise suppression system for attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal, said noise suppression system comprising: means for separating the input signal into a plurality of pre-processed signals representative of selected frequency channels, each of said plurality of pre-processed signals comprised of a plurality of frames, each frame comprised of a plurality of samples of said input signal; means for generating an estimate of the signal-to-noise ratio (SNR) in each individual channel once each frame; means for producing a raw gain value for each channel in response to said SNR estimates once each frame; means for smoothing said raw gain values multiple times per frame; and means for modifying the gain of each of said plurality of pre-processed signals provided by said signal separating means in response to said smoothed gain values to provide a plurality of post-processed signals.<br>17. An improved noise suppression system for attenuating the background noise from a noisy pre-processed input signal to produce a noise-suppressed post-processed output signal by spectral gain modification, said noise suppression system comprising: signal dividing means for separating the pre-processed input signal into a plurality of selected frequency bands, thereby producing a plurality of pre-processed channels; channel energy estimation means for generating an estimate of the energy in each of said plurality of pre-processed channels; channel noise estimation means for generating an estimate of the signal-to-noise ratio (SNR) of each individual channel based upon said channel energy estimates and an estimate of the current background noise energy for that individual channel; channel gain controlling means for providing channel gain values, said channel gain controlling means having a plurality of gain tables, each gain table having predetermined individual channel gain values corresponding to various individual channel SNR estimates, said channel gain controlling means further having gain table selection means for automatically selecting one of said plurality of gain tables according to the overall average background noise level of said input signal; channel gain modifying means for adjusting the gain of each of said plurality of pre-processed channels provided by said signal dividing means according to said channel gain values, thereby producing a plurality of post-processed channels; and channel combination means for recombining said plurality of post-processed channels to produce said post-processed output signal.<br>25. An improved channel gain controller for use with a spectral gain modification noise suppression system having separating means to divide a noisy input signal into a plurality of channels, and a modifying means to adjust the gain of said channels according to gain values provided by the channel gain controller to produce a plurality of noise-suppressed output channels, said channel gain controller comprising: a plurality of gain tables, each having predetermined individual channel gain values corresponding to various individual channel signal-to-noise ratio (SNR) estimates; and gain table selection means for automatically selecting one of said plurality of gain tables according to the overall average background noise level of said noisy input signal.<br>31. The method of attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal comprising the steps of: separating the input signal into a plurality of pre-processed signals representative of selected frequency channels; modifying an operating parameter of each of said plurality of pre-processed signals to provide a plurality of post-processed signals; and generating a modification signal responsive to said plurality of pre-processed signals, said modification signal having a selected modification value for each channel to enable the operating parameter to be modified, said modification signal generated by automatically selecting a modification value for each channel from one of a plurality of sets of modification values for that channel.<br>32. The method of attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal in a noise suppression system comprising the steps of: separating the input signal into a plurality of pre-processed signals representative of selected frequency channels, each of said plurality of pre-processed signals comprised of a plurality of frames, each frame comprised of a plurality of samples of said input signal; modifying an operating parameter of each of said plurality of pre-processed signals to provide a plurality of post-processed signals; and generating a modification signal responsive to said plurality of pre-processed signals, said modification signal having a selected modification value for each channel to enable the operating parameter to be modified, said modification values being smoothed multiple times per frame to reduce discontinuities in said modification signal.<br>36. The method of attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal by spectral gain modification, comprising the steps of: separating the input signal into a plurality of pre-processed signals representative of selected frequency channels; generating an estimate of the signal-to-noise ratio (SNR) in each individual channel; producing a gain value for each channel by automatically selecting one of a plurality of gain tables in response to a multi-channel noise parameter, and selecting one of a plurality of gain values from the selected gain table in response to said channel SNR estimates and the channel number; and modifying the gain of each of said plurality of pre-processed signals in response to said gain values to provide a plurality of post-processed signals.<br>37. The method of attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal by spectral gain modification, comprising the steps of: separating the input signal into a plurality of pre-processed signals representative of selected frequency channels, each of said plurality of pre-processed signals comprised of a plurality of frames, each frame comprised of a plurality of samples of said input signal; generating an estimate of the signal-to-noise ratio (SNR) in each individual channel once each frame; producing a raw gain value for each channel in response to said SNR estimates once each frame; smoothing said raw gain values multiple times per frame; and modifying the gain of each of said plurality of pre-processed signals in response to said smoothed gain values to provide a plurality of post-processed signals.</p></layer>
<layer id = "layer229"><p><b>US4628529A:Noise suppression system</b><br>A pipe-clamping device for coupling together in an end-to-end relationship identical pipe ends, which device comprises a clamping band to encircle the pipe ends, the band having a plurality of slots therein on each side extending generally axially to the coupled pipes, a raised edge means on each edge and a raised central section to define a longitudinally extending band-strap-retaining area; a sealing gasket disposed beneath the clamping band; and band straps disposed on the band-strap-retaining area on either side of the central raised section, the band straps adapted to compress the clamping band into a sealing relationship about the pipe ends.<br><b>Independant Claims</b><br>1. An improved noise suppression system for attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal, said noise suppression system comprising: means for separating the input signal into a plurality of pre-processed signals representative of selected frequency channels; means for modifying an operating parameter of each of said plurality of pre-processed signals provided by said signal separating means to provide a plurality of post-processed signals; and means responsive to said plurality of pre-processed signals and said plurality of post-processed signals for generating a modification signal for application to said modifying means to enable the operating parameter to be modified.<br>2. An improved noise suppression system for attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal, said noise suppression system comprising: means for separating the input signal into a plurality of pre-processed signals representative of selected frequency channels; means for modifying an operating parameter of each of said plurality of pre-processed signals provided by said signal separating means to provide a plurality of post-processed signals; means for generating a control signal representative of said post-processed signals; and means responsive to said plurality of pre-processed signals and said control signal for generating a modification signal for application to said modifying means to enable the operating parameter to be modified.<br>9. An improved noise suppression system for attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal, said noise suppression system comprising: means for separating the input signal into a plurality of pre-processed signals representative of selected frequency channels; means for modifying the gain of each of said plurality of pre-processed signals in response to estimates of the signal-to-noise ratio (SNR) in each individual channel to provide a plurality of post-processed signals; and means for generating said SNR estimates in each individual channel based upon the current signal energy estimate of the pre-processed signal in each individual channel and the previous noise energy estimate of the pre-processed signal in each individual channel as determined by the detected minima of said plurality of post-processed signals.<br>10. An improved noise suppression system for attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal, said noise suppression system comprising: means for separating the input signal into a plurality of pre-processed signals representative of selected frequency channels; means for generating an estimate of the signal-to-noise ratio (SNR) in each individual channel based upon the current signal energy estimate of the pre-processed signal in each individual channel and the previous noise energy estimate of the pre-processed signal in each individual channel as determined by the detected minima of a simulated output signal energy level, said simulated output signal being obtained by multiplying said plurality of pre-processed signals by a predetermined gain value; means for producing said predetermined gain value in response to said SNR estimates; and means for modifying the gain of each of said plurality of pre-processed signals in response to said predetermined gain value to provide a plurality of post-processed signals.<br>22. An improved noise suppression system for attenuating the background noise from a noisy pre-processed input signal to produce a noise-suppressed post-processed output signal by spectral gain modification, said noise suppression system comprising: signal dividing means for separating the pre-processed input signal into a plurality of selected frequency bands, thereby producing a plurality of pre-processed channels; channel energy estimation means for generating an estimate of the energy in each of said plurality of pre-processed channels; background noise estimation means for generating and storing estimates of the background noise energy based upon said channel energy estimates, and for periodically detecting the minima of the post-processed signal energy level obtained from the output of said noise suppression system such that said background noise estimates are updated only during said minima; channel SNR estimation means for generating an estimate of the signal-to-noise ratio (SNR) of each individual channel based upon said channel energy estimates and said background noise estimates; channel gain controlling means for providing channel gain values corresponding to said channel SNR estimates; channel gain modifying means for adjusting the gain of each of said plurality of pre-processed channels provided by said signal dividing means according to said channel gain values, thereby producing a plurality of post-processed channels; and channel combination means for recombining said plurality of post-processed channels to produce said post-processed output signal.<br>23. An improved noise suppression system for attenuating the background noise from a noisy pre-processed input signal to produce a noise-suppressed post-processed output signal by spectral gain modification, said noise suppression system comprising: signal dividing means for separating the pre-processed input signal into a plurality of selected frequency bands, thereby producing a plurality of pre-processed channels; channel energy estimation means for generating an estimate of the energy in each of said plurality of pre-processed channels; background noise estimation means for generating and storing estimates of the background noise energy based upon said channel energy estimates, and for periodically detecting the minima of a simulated post-processed signal energy level such that said background noise estimates are updated only during said minima, said simulated post-processed signal being obtained by multiplying said plurality of pre-processed channels by predetermined channel gain values; channel SNR estimation means for generating an estimate of the signal-to-noise ratio (SNR) of each individual channel based upon said channel energy estimates and said background noise estimates; channel gain controlling means for providing said channel gain values corresponding to said channel SNR estimates; channel gain modifying means for adjusting the gain of each of said plurality of pre-processed channels provided by said signal dividing means according to said channel gain values, thereby producing a plurality of post-processed channels; and channel combination means for recombining said plurality of post-processed channels to produce said post-processed output signal.<br>40. The method of attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal in a noise suppression system comprising the steps of: separating the input signal into a plurality of pre-processed signals representative of selected frequency channels; modifying an operating parameter of each of said plurality of pre-processed signals to provide a plurality of post-processed signals; and generating a modification signal responsive to said plurality of pre-processed signals and said plurality of post-processed signals, whereby said modification signal enables the operating parameter of each of said plurality of pre-processed signals to be modified.<br>41. The method of attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal in a noise suppression system comprising the steps of: separating the input signal into a plurality of pre-processed signals representative of selected frequency channels; modifying an operating parameter of each of said plurality of pre-processed signals to provide a plurality of post-processed signals; generating a control signal representative of said post-processed signals; and generating a modification signal responsive to said plurality of pre-processed signals and said control signal, whereby said modification signal enables the operating parameter of each of said plurality of pre-processed signals to be modified.<br>45. The method of attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal by spectral gain modification, comprising the steps of: separating the input signal into a plurality of pre-processed signals representative of selected frequency channels; modifying the gain of each of said plurality of pre-processed signals in response to estimates of the signal-to-noise ratio (SNR) in each individual channel to provide a plurality of post-processed signals; and generating said SNR estimates in each individual channel based upon the current signal energy estimate of the pre-processed signal in each individual channel and the previous noise energy estimate of the pre-processed signal in each individual channel as determined by the detected minima of said plurality of post-processed signals.<br>46. The method of attenuating the background noise from a noisy input signal to produce a noise-suppressed output signal by spectral gain modification, comprising the steps of: separating the input signal into a plurality of pre-processed signals representative of selected frequency channels; generating an estimate of the signal-to-noise ratio (SNR) in each individual channel based upon the current signal energy estimate of the pre-processed signal in each individual channel and the previous noise energy estimate of the pre-processed signal in each individual channel as determined by the detected minima of a simulated output signal energy level, said simulated output signal being obtained by multiplying said plurality of pre-processed signals by a predetermined gain value; producing said predetermined gain value in response to said SNR estimates; and the gain of each of said plurality of modifying the gain of each of said plurality of pre-processed signals in response to said predetermined gain value to provide a plurality of post-processed signals.</p></layer>
<layer id = "layer230"><p><b>USRE43099E1:Speech coder methods and systems</b><br>A phosphate-containing nanoparticle delivery vehicle includes a nanoparticle, an active ingredient, and a phosphodiester moiety connecting the nanoparticle and the active ingredient and forms a prodrug. The nanoparticle delivery vehicle achieves the function of increasing hydrophilicity of the active ingredient and specificity against tumor cells. Advantages of the nanoparticle material include biocompatibility, magnetism and/or controllable drug release.<br><b>Independant Claims</b><br>1) A method for coding a speech signal to generate a coded signal comprising: generating a sequence of spectral magnitude values for a frame interval of said speech signal representing voiced speech, said spectral magnitude value sequence characterizing spectral components of a short-term frequency spectrum of said interval; performing at least one of a non-linear transformation or spectral warping process on said sequence to produce an intermediate spectral value sequence having an enhanced characterization of at least one particular frequency range relative to another frequency range in the intermediate spectral sequence; and coding said intermediate spectral value sequence to produce at least a portion of said coded signal for said interval of said speech signal.<br>17) A method for decoding a coded speech signal, said coded signal including successive coded frame intervals of a speech signal, the decoding of a frame interval of said coded signal comprising the steps of: generating an intermediate spectral value sequence for at least a portion of said interval representing voiced speech, said intermediate spectral value sequence characterizing spectral components of a short-term frequency spectrum of said interval and further having an enhanced characterization of at least one particular frequency range relative to another frequency range; and processing said intermediate spectral value sequence with at least one of an inverse non-linear transformation or inverse spectral warping process to produce a sequence of spectral magnitude values characterizing the short-term frequency spectrum for the voiced portion of said interval.<br>27) A coder for generating a coded signal based on a speech signal comprising: a spectral transformer for generating a sequence of spectral magnitude values for a frame interval of said speech signal representing voiced speech, said spectral magnitude value sequence characterizing spectral components of a short-term frequency spectrum of said frame interval; an encoder coupled to said spectral processor, said encoder for performing at least one of a non-linear transformation or a spectral warping process on said sequence to produce an intermediate spectral value sequence having an enhanced characterization of at least one particular frequency range relative to another frequency range in the intermediate spectral sequence; and a spectral coder coupled to said encoder, said spectral coder for coding said intermediate spectral value sequence to produce at least a portion of said coded signal for said interval of said speech signal.<br>34) A coder for generating a coded signal from a speech signal comprising: means for generating a sequence of spectral magnitude values for a frame interval of said speech signal representing voiced speech, said spectral magnitude value sequence characterizing spectral components of a short-term frequency spectrum of said interval; means for performing at least one of a non-linear transformation or spectral warping process on said sequence to produce an intermediate spectral value sequence having an enhanced characterization of at least one particular frequency range relative to another frequency range in the intermediate spectral sequence; and means for coding said intermediate spectral value sequence to produce at least a portion of said coded signal for said interval of said speech signal.<br>35) A decoder for decoding a coded speech signal, said coded signal including successive coded frame intervals of a speech signal, said decoder comprising: a spectral decoder, said spectral decoder for generating an intermediate spectral value sequence for voiced speech represented in said frame interval of the coded signal, said intermediate spectral value sequence characterizing spectral components of a short-term frequency spectrum of said voiced speech and further having an enhanced characterization of at least one particular frequency range relative to another frequency range; and inverse processor coupled to said spectral decoder, said inverse processor for processing said intermediate spectral value sequence with at least one of an inverse non-linear transformation or inverse spectral warping process to produce a sequence of spectral magnitude values characterizing a short-term frequency spectrum for the voiced portion of said interval.<br>38) A decoder for decoding a coded speech signal, said coded signal including successive coded frame intervals of a speech signal, said decoder comprising: means for generating an intermediate spectral value sequence for voiced speech represented in said frame interval of the coded signal, said intermediate spectral value sequence characterizing spectral components of a short-term speech spectrum of voiced speech represented in said interval and further having an enhanced characterization of at least one particular frequency range relative to another frequency range; and means for processing said intermediate spectral value sequence with at least one of an inverse non-linear transformation or inverse spectral warping process to produce a sequence of spectral magnitude values characterizing said short-term frequency spectrum for the voiced portion of said interval.</p></layer>
<layer id = "layer231"><p><b>US4879748A:Parallel processing pitch detector</b><br>A new and distinct rootstock variety of <i>Prunus </i>named ‘VVA-1’ that is characterized by a dwarf habit, resistance to low temperatures, the ability to serve well as rootstock that is compatible with other crops, and the ability to propagate well. In combination these traits set the new cultivar apart from all other existing varieties of <i>Prunus </i>rootstock.<br><b>Independant Claims</b><br>1. A pitch detector system for human speech comprising: means for storing a predetermined number of evenly spaced samples of instantaneous amplitude of said speech as a speech frame; means for generating residual samples from said speech samples; a plurality of identical means each responsive to an individual predetemined portion of said residual samples of said frame for estimating a pitch value of said frame; another plurality of identical means each responsive to an individual predetermined portion of said speech samples of said frame for estimating a pitch value of said frame; means for calculating a final pitch value from the estimated pitch values from each of said plurality and said other plurality of estimating means wherein an unvoiced speech frame is indicated by said calculated pitch value being equal to a predefined value and a voiced frame is indicated by said calculated pitch value being equal to a value other than said predefined value; said calculating means comprises means responsive to all of said estimated pitch values having a value different than said predefined value for setting said calculated pitch value equal to the arithmetic average of a subset of said estimated pitch values, said subset comprising all of said estimated pitch values except the lowest magnitude value and the highest magnitude value; means for constraining said final pitch value so that the calculated pitch value is consistent with calculated pitch values from previous frames; said constraining means comprises means responsive to a first sequence of frames comprising a voiced frame and an unvoiced frame and a second voiced frame for generating a new calculated pitch value having an arithmetic relationship to the calculated pitch values of the frames of said first sequence; said generating means comprises a new pitch value generating means responsive to a second sequence of frames comprising an unvoiced frame and a voiced frame and a second unvoiced frame for generating a new calculated value indicating an unvoiced frame; and said new pitch value generating means further reponsive to a third sequence of frames comprising a voiced frame and a second voiced frame and a third voiced frame for generating a new calculated pitch value having an arithmetic relationship to the calculated pitch values of the frames of said third sequence.<br>6. A pitch detector for human speech comprising: means for storing a predetermined number of evenly spaced speech samples of instantaneous amplitude of said speech as a present speech frame; means for filtering said samples to produce residual samples of the speech remaining after the formant effects of the vocal tract have been substantially removed; first means responsive to positive valued ones of said speech samples for estimating a first pitch value of said present speech frame; second means responsive to negative valued ones of said speech samples for estimating a second pitch value of said present speech frame; third means responsive to positive valued ones of said residual samples for estimating a third pitch value of said present speech frame; a fourth means responsive to negative valued ones of said residual samples for estimating a fourth pitch value of said present speech frame; means for calculating a pitch value from the estimated pitch values from said first, second, third and fourth estimating means wherein an unvoiced speech frame is indicated by said calculated pitch value being equal to a predefined value and a voiced frame is indicated by said calculated pitch value being equal to a value other than said predefined value; said calculating means comprises means responsive to all of said estimated pitch values having a value different than said predefined value for setting said calculated pitch value equal to the arithmetic average of a subset of said estimated pitch values, said subset comprising all of said estimated pitch values except the lowest magnitude value and the highest magnitude value; means for constraining said final pitch value so that the calculated pitch value is consistent with calculated pitch values from previous frames; said constraining means comprises means responsive to a first sequence of frames comprising a voiced frame and an unvoiced frame and a second voiced frame for generating a new calculated pitch value having an arithmetic relationship to the calculated pitch values of the frames of said first sequence; means responsive to a second sequence of frames comprising an unvoiced frame and voiced frame and a second unvoiced frame for generating a new calculated value indicating an unvoiced frame; and said generating means further responsive to a third sequence of frames comprising a voiced frame and a second voiced frame and a third voiced frame for generating a new calculated pitch value having an arithmetic relationship to the calculated pitch values of the frames of said third sequence.<br>11. A method for detecting the pitch of human speech with a system comprising a quantizer for converting the speech into frames of digital samples and a digital signal processor responsive to a plurality of program instructions and said frames of digital samples to determine the pitch of the speech, said method comprising the steps of: producing residual samples of the digitized speech that remain after the formant effects of the vocal track have been substantially removed; estimating a first pitch value of a present speech frame in response to positive valued ones of said digitized speech samples; estimating a second pitch value of said present speech frame in response to negative valued ones of said digitized speech samples; estimating a third pitch value of said present speech frame in response to positive valued ones of said residual samples; and estimating a fourth pitch value of said present speech frame in response to negative valued ones of said residual samples; and calculating said final pitch value from said first, second, third, and fourth pitch values wherein an unvoiced speech frame is indicated by said calculated pitch value being equal to a predefined value and a voiced frame is indicated by said calculated pitch value being equal to a value other than said predefined value; said step of calculating comprises the step of setting said calculated pitch value equal to the arithmetic average of a subset of said estimated pitch values, said subset comprising all of said estimated pitch values except the lowest magnitude value and the highest magnitude value; constraining said final pitch value so that said final pitch value is in agreement with final pitch values from previous frames by; said step constraining comprises the steps of generating a new calculated pitch value having an arithmetic relationship to the calculated pitch values of a first sequence of frames comprising a voiced frame and unvoiced frame and a second voiced frame; generating a new calculated value indicating an unvoiced frame in response to a second sequence of frames comprising an unvoiced frame and a voiced frame and a second unvoiced frame; and generating a new calculated pitch value having an arithmetic relationship to the calculated pitch values of the frames of a third sequence of frames comprising a voiced frame and a second voiced frame and a third voiced frame.</p></layer>
<layer id = "layer232"><p><b>US6516299B1:Method, system and product for modifying the dynamic range of encoded audio signals</b><br>A plurality of devices, such as devices that are utilized for implementing radio frequency applications, can be formed in the same substrate. Each of these devices may be formed over a triple well that includes at least one well capable of being biased. Each of the wells is coupled to a well bias through a resistor. In some embodiments, a plurality of wells operating at a relatively high frequency may be connected to the same bias potential, each through separate resistors. The noise coupling may be reduced through the use of the bias resistors.<br><b>Independant Claims</b><br>1) A method for modifying a dynamic range of a subband encoded audio signal having a plurality of frequency subbands and a plurality of scale factors, the method comprising: receiving the subband encoded audio signal, wherein the plurality of scale factors of the subband encoded audio signal are associated with a first dynamic range; identifying one of a plurality of playback destinations, the playback destination identified having a second dynamic range; mapping the plurality of scale factors of the subband encoded audio signal to a plurality of scale factors associated with the second dynamic range; replacing the plurality of scale factors of the subband encoded audio signal with the plurality of scale factors associated with the second dynamic range to create a modified subband encoded audio signal for decoding and reassembly by a decoder at the playback destination identified.<br>5) A system for modifying a dynamic range of a subband encoded audio signal having a plurality of frequency subbands and a plurality of scale factors, the system comprising: a receiver for receiving the subband encoded audio signal, wherein the plurality of scale factors of the subband encoded audio signal are associated with a first dynamic range; and control logic operative to identify one of a plurality of playback destinations, the playback destination identified having a second dynamic range, map the plurality of scale factors of the subband encoded audio signal to a plurality of scale factors associated with the second dynamic range of the playback destination, and replace the plurality of scale factors of the subband encoded audio signal with the plurality of scale factors associated with the second dynamic range to create a modified subband encoded audio signal for decoding and reassembly by a decoder at the playback destination identified.<br>9) A product for modifying a dynamic range of a subband encoded audio signal having a plurality of frequency subbands and a plurality of scale factors, the plurality of scale factors associated with a first dynamic range, the product comprising: a storage medium; and computer readable instructions recorded on the storage medium, the instructions operative to identify one of a plurality of playback destinations, the playback destination identified having a second dynamic range, map the plurality of scale factors of the subband encoded audio signal to a plurality of scale factors associated with the second dynamic range of the playback destination, and replace the plurality of scale factors of the subband encoded audio signal with the plurality of scale factors associated with the second dynamic range to create a modified subband encoded audio signal for decoding and reassembly by a decoder at the playback destination identified.</p></layer>
<layer id = "layer233"><p><b>US5864813A:Method, system and product for harmonic enhancement of encoded audio signals</b><br>A semiconductor device fabrication method includes preparing a substrate having a first circuit pattern of a semiconductor device; providing a mask with at least part of second circuit pattern of the semiconductor device; collimating incident direction of particles; changing at least one of the a substrate angle between a vertical axis of the substrate and the incident direction of the particles and a mask angle between a vertical axis of the mask and the incident direction so that the second circuit pattern on the mask can be aligned to the first circuit pattern on the substrate with a design margin; and selectively irradiating the particles to the substrate using the mask.<br><b>Independant Claims</b><br>1. A method for harmonic enhancement of an encoded audio signal, the method comprising: receiving the encoded audio signal, the encoded audio signal having a plurality of frequency subbands; selecting a first one of the plurality of subbands having a data sample associated therewith; generating a frequency doubled copy of the data sample associated with the first one of the plurality of subbands; generating a new data sample for a second one of the plurality of subbands using the frequency doubled copied data sample, the second one of the plurality of subbands having a frequency greater than the first one of the plurality of subbands by one octave; and modifying the encoded audio signal to create an enhanced encoded audio signal having the new data sample associated with the second one of the plurality of subbands.<br>6. A system for harmonic enhancement of an encoded audio signal, the system comprising: a receiver for receiving the encoded audio signal, the encoded audio signal having a plurality of frequency subbands; means for selecting a first one of the plurality of subbands having a data sample associated therewith; and control logic operative to generate a frequency doubled copy of the data sample associated with the first one of the plurality of subbands, generate a new data sample for a second one of the plurality of subbands using the frequency doubled copied data sample, the second one of the plurality of subbands having a frequency greater than the first one of the plurality of subbands by one octave, and modify the encoded audio signal to create an enhanced encoded audio signal having the new data sample associated with the second one of the plurality of subbands.<br>11. A product for harmonic enhancement of an encoded audio signal, the product comprising a storage medium having computer readable programmed instructions recorded thereon, the instructions operative to generate a frequency doubled copy of a data sample associated with a first one of a plurality of subbands associated with the encoded audio signal, generate a new data sample for a second one of the plurality of subbands using the frequency doubled copied data sample, the second one of the plurality of subbands having a frequency greater than the first one of the plurality of subbands by one octave, and modify the encoded audio signal to create an enhanced encoded audio signal having the new data sample associated with the second one of the plurality of subbands.</p></layer>
<layer id = "layer234"><p><b>US6463405B1:Audiophile encoding of digital audio data using 2-bit polarity/magnitude indicator and 8-bit scale factor for each subband</b><br>A safety device (<b>61</b>) for a lighting valve (<b>23</b>) of a gas burner, comprising a starting button (<b>36</b>), a return spring (<b>57</b>), a cutoff shutter (<b>42</b>) controlled by the starting button (<b>36</b>), a control shutter (<b>41</b>) for a pilot light nozzle, and a holding electromagnet (<b>54</b>) for the control shutter (<b>41</b>). The control shutter (<b>41</b>) is normally closed and is actuatable through the starting button (<b>36</b>) for the flowing of the gas to the pilot light nozzle, whilst the holding electromagnet (<b>54</b>) is dependent on the pilot light to hold open the control shutter (<b>41</b>). The starting button (<b>36</b>) is provided for rotation and can be depressed only for a given angular start position so that, for starting the lighting, the button (<b>36</b>) must be rotated up to said start position and subsequently depressed to close the cutoff shutter (<b>42</b>) and open the control shutter (<b>41</b>). There are provided a hooking condition and an unhooked condition for the starting button: in the hooking condition, the cutoff shutter (<b>42</b>) is closed and the control shutter (<b>41</b>) is open under the control of the holding electromagnet (<b>54</b>) without being influenced by the starting button (<b>36</b>); and, in the unhooked condition, the starting button (<b>36</b>) can return to the lifted position to open the cutoff shutter (<b>42</b>) for the flowing of the gas to the burner, the unhooked condition requiring a further rotation of the starting button (<b>36</b>) spaced away from the angular start position.<br><b>Independant Claims</b><br>1) A method for subband encoding a digital audio signal comprising: dividing the digital signal into a plurality of frames; dividing each of the plurality of frames into a plurality of frequency subbands; assigning each of the plurality of subbands an indicator selected from the group consisting of positive, zero, and negative, wherein the indicator selected is based on a polarity and a magnitude of the subband and without regard to a psychoacoustic model, the indicator comprising a two bit word, one bit representing the polarity of the subband and one bit representing the magnitude of the subband; assigning each of the plurality of subbands one of a plurality of scale factors, each scale factor comprising an eight bit word having a resolution of one decibel per scale factor; and generating a digital word for the plurality of frames, the digital word having a scale factor section including the scale factors for the plurality of subbands in the plurality of frames, and a sample data section including the indicators for the plurality of subbands in the plurality of frames.<br>4) A system for subband encoding a digital audio signal comprising: a sampler for dividing the digital signal into a plurality of frames; a filter for dividing each of the plurality of frames into a plurality of frequency subbands; and control logic operative to assign each of the plurality of subbands an indicator selected from the group consisting of positive, zero, and negative, wherein the indicator selected is based on a polarity and a magnitude of the subband and without regard to a psychoacoustic model, the indicator comprising a two bit word, one bit representing the polarity of the subband and one bit representing the magnitude of the subband, assign each of the plurality of subbands one of a plurality of scale factors, each scale factor comprising an eight bit word having a resolution of one decibel per scale factor, and generate a digital word for the plurality of frames, the digital word having a scale factor section including the scale factors for the plurality of subbands in the plurality of frames, and a sample data section including the indicators for the plurality of subbands in the plurality of frames.<br>7) A product for subband encoding a digital audio signal comprising: a storage medium; and computer readable instructions recorded on the storage medium, the instructions operative to divide the digital signal into a plurality of frames, divide each of the plurality of frames into a plurality of frequency subbands, assign each of the plurality of subbands an indicator selected from the group consisting of positive, zero, and negative, wherein the indicator selected is based on a polarity and a magnitude of the subband and without regard to a psychoacoustic model, the indicator comprising a two bit word, one bit representing the polarity of the subband and one bit representing the magnitude of the subband, assign each of the plurality of subbands one of a plurality of scale factors, each scale factor comprising an eight bit word having a resolution of one decibel per scale factor, and generate a digital word for the plurality of frames, the digital word having a scale factor section including the scale factors for the plurality of subbands in the plurality of frames, and a sample data section including the indicators for the plurality of subbands in the plurality of frames.</p></layer>
<layer id = "layer235"><p><b>US20020133334A1:Time scale modification of digitally sampled waveforms in the time domain</b><br>This invention relates to a method for modifying metabolism in a vertebrate animal which entails the administration of pantethine or cysteamine at a predetermined time daily. The method is useful in the treatment of hyperglycemia, glucose intolerance, insulin resistance, and hyperinsulinemia.<br><b>Independant Claims</b><br>1. A system for generating a time scale modification of a digital waveform comprising: a) a digital waveform provider that produces an input digital waveform at a first time resolution, the digital waveform being a sequence of overlapping speech segment windows; and b) a time-domain time scale modification process that overlap adds selected windows from the input digital waveform to create an output digital waveform representing a time scale modification of the input digital waveform, the process operating at a second time resolution lower than the first time resolution to determine the relative positions between adjacent windows in the output digital waveform.</p></layer>
<layer id = "layer236"><p><b>US5864820A:Method, system and product for mixing of encoded audio signals</b><br>An optical pickup apparatus couples light beams, and corrects a chromatic aberration and a spherical aberration. A coupling lens includes groups of lenses common to the light sources so as to converge a light beam from each of the light sources. An aperture changes an aperture diameter for the light beam, which has been converged by the coupling lens, in accordance with one of the light sources from which the light beam is emitted. An objective lens converges the light beam onto a recording surface of one of the optical information recording media corresponding to the one of the light sources that emits the light beam. A lens moving mechanism moves at least one group of lenses from among the groups of lenses of the coupling lens in a direction of an optical axis thereof in accordance with an aperture diameter of the aperture.<br><b>Independant Claims</b><br>1. A method for mixing encoded audio signal, the method comprising: receiving a first encoded audio signal having a plurality of frequency subbands, each subband having an audio level; receiving a second encoded audio signal having a plurality of frequency subbands, each subband having an audio level; and mixing the first and second signals to create a mixed encoded audio signal having a plurality of subbands, each subband having an audio level based on a masking effect relationship between the audio levels of corresponding subbands of the first and second signals, wherein mixing the first and second signals includes eliminating from the second signal a subband having an audio level sufficient to mask the audio level of a corresponding subband of the first signal, and performing frequency equalization, including generating a user notification signal if frequency equalization would result in destruction of a portion of the first or second encoded audio signal.<br>6. A system for mixing encoded audio signal, the system comprising: a receiver for receiving a first encoded audio signal having a plurality of frequency subbands, each subband having an audio level; a receiver for receiving a second encoded audio signal having a plurality of frequency subbands, each subband having an audio level; and control logic operative to mix the first and second signals to create a mixed encoded audio signal having a plurality of subbands, each subband having an audio level based on a masking effect relationship between the audio levels of corresponding subbands of the first and second signals, wherein to mix the first and second signals, the control logic is operative to eliminate from the second signal a subband having an audio level sufficient to mask the audio level of a corresponding subband of the first signal, and to perform frequency equalization, including generating a user notification signal if frequency equalization would result in destruction of a portion of the first or second encoded audio signal.<br>11. A product for mixing encoded audio signal, the product comprising a storage medium having computer readable programmed instructions thereon, the instructions operative to mix a first encoded audio signal having a plurality of frequency subbands, each subband having an audio level, and a second encoded audio signal having a plurality of frequency subbands, each subband having an audio level, to create a mixed encoded audio signal having a plurality of subbands, each subband having an audio level based on a masking effect relationship between the audio levels of corresponding subbands of the first and second signals, wherein to mix the first and second signals, the programmed instructions are operative to eliminate from the second signal a subband having an audio level sufficient to mask the audio level of a corresponding subband of the first signal, and to perform frequency equalization, including generating a user notification signal if frequency equalization would result in destruction of a portion of the first or second encoded audio signal.</p></layer>
<layer id = "layer237"><p><b>US5189701A:Voice coder/decoder and methods of coding/decoding</b><br>A display device for use in an image forming apparatus which includes, a detection member for detecting the condition of the image forming apparatus, a display section for normally displaying a condition message which represents the conditions of the image forming apparatus on the basis of the detection by the detection member, and a first input key for causing a first message to be displayed on the display section. The first message represents guidance for operating of the image forming apparatus. A second input key is also provided for causing a second message to be displayed on the display section, the second message representing guidance for following the operation procedure of the image forming apparatus. A third input key is further provided for causing a third message to be displayed on the displaying seciton, the third message representing guidance, different from the first message, for an operation procedure of the image forming apparatus.<br><b>Independant Claims</b><br>1. In combination for use in a voice coder to determine the pitch frequency of voice signals introduced to the voice coder, first means for dividing the voice signals into successive time frames, second means for providing a frequency transform of the voice signals in each time frame to obtain a plurality of signals at different frequencies in such time frame, the signals at the different frequencies in each time frame having a pitch frequency, third means for providing a Cepstrum determination of the signals from the Fourier frequency transform in each of the successive time frames to obtain a determination of the pitch frequency of the frequency signals in such time frame, and fourth means for providing a harmonic gap determination of the frequency signals in each of the successive time frames from the Cepstrum determination to refine the determination of the pitch frequency by the third means of the frequency signals in each time frame.<br>8. In combination for use in a voice coder on voice signals having a pitch frequency, first means for dividing the voice signals into successive time frames, second means for converting the voice signals in each time frame into signals in a frequency spectrum, the signals in the frequency spectrum in each time frame having a pitch frequency, third means responsive to the signals from the second means in each time frame for producing signals indicating the pitch frequency of the signals in the frequency spectrum in each time frame, and fourth means responsive to the signals in the frequency spectrum in each time frame for performing additional determinations of pitch frequency on the signals in the frequency spectrum in each successive pair of time frames to refine the determination f the pitch frequency in the signals in each time frame in such successive pair, and fifth means for interpolating the pitch frequency of the signals in the frequency spectrum in the time frames in each successive pair in accordance with the additional determinations by the fourth means of the pitch frequency of the signals in the frequency spectrum in the time frames in that pair.<br>13. In combination or use in a voice coder to determine the pitch frequency of voice signals in the voice coder, first means for dividing the voice signals into successive time frames, second means for obtaining a frequency transform of the voice signals in each of the successive time frames to obtain frequency signals in such time frame, third means for obtaining a log spectrum of the signals in the frequency transform in each of the successive time frames, each of the signals in the frequency transform having a peak amplitude and defining a trough between such peak amplitude and the next peak amplitude, fourth means for determining the peak amplitudes of the signals in the frequency transform in each of the successive time frames and the troughs between the peak amplitudes of such signals, fifth means for determining the pitch frequency of the signals in the frequency transform in each time frame by a harmonic gap analysis of the peak amplitudes of the signals in the frequency transform in each time frame and the troughs between the peak amplitudes of the signals in the frequency transform in each time frame, and sixth means for refining the determination of the pitch frequency of the signals in the frequency transform in each time frame in accordance with the determination of the pitch frequency of the signals in the frequency transforms of previous time frames.<br>19. In a combination for use in a voice coder to determine the pitch frequency of voice signals in the voice coder, first means for dividing the voice signals into successive time frames, second means for obtaining a frequency transform of the voice signals in each of the successive time frames to obtain a spectrum of frequency signals in such time frame, each of the frequency signals in each time frame having a peak amplitude and troughs between successive pairs of such peak amplitudes, third means for obtaining a log spectrum of the frequency signals in each time frame, and fourth means for determining the frequency locations of the peak amplitudes and the troughs between the peak amplitudes in the spectrum of frequency signals from the third means in each time frame to determine the pitch frequency of such frequency signals in such time frame in accordance with the relative differences between such peaks and troughs.<br>27. In combination for use on voice signals in a voice coder, first means for dividing the voice signals into successive time frames, second means for combining the voice signals in successive pairs of time frames to obtain an enhanced resolution of the voice signals in each time frame, third means for obtaining a frequency transform of the voice signals into signals in a frequency spectrum in each of the time frames in each successive pair, the signals in the frequency spectrum in each time frame having a pitch frequency, fourth means for passing the frequency signals in each of the successive pairs of time frames in a first particular range of frequencies and for providing a progressive filtering of the frequency signals in each of the successive pairs of time frames for progressive frequency values above the first particular range, and fifth means for obtaining a frequency transform in each successive pair of the time frames of the signals passed by the fourth means to obtain signals in a frequency spectrum each successive pair of time frames, and sixth means for operating upon the signals from the third means and the fifth means in a particular relationship for determining the pitch frequency of the signals in the frequency spectrum in each time frame.<br>32. In a combination for use in a voice coder to determine the pitch frequency of voice signals introduced to the voice coder, first means for dividing the voice signals into successive time frames, second means for providing a frequency transform of the voice signals in each successive time frame to produce signals in a frequency spectrum in that time frame, each of the signals having an amplitude and the signals constituting harmonics of a pitch frequency, third means for adding the amplitudes of the odd harmonics in the signals in the frequency spectrum in each time frame, fourth means for adding the amplitudes of the even harmonics in the signals in the frequency transform in each time frame, fifth means for normally selecting the odd harmonic in the frequency transform in each time frame with the lowest frequency as the pitch frequency, and sixth means for substituting the even harmonic in the frequency transform with the lowest frequency in each time frame as the pitch frequency when the sum of the amplitudes of the even harmonics in the frequency spectrum in such time frame exceeds the sum of the amplitudes of the odd harmonics in the frequency spectrum in such time frame by a particular threshold.<br>38. In a combination for use on voice signals in a voice coder, first means for dividing the voice signals into successive time frames, second means for providing a frequency transform of the voice signals in each time frame, third means for providing signals representing a log function of the frequency transform of the voice signals in each of the successive time frames, each of the log function signals in each time frame having an amplitude and one of the log function signals in each time frame having a particular amplitude larger than the amplitudes of the other log function signals in such time frame, fourth means for converting the log function signals in each time frame into signals having amplitudes dependent upon the amplitudes of such low function signals relative to the particular amplitude in such time frame, and fifth means for companding the signals from the fourth means.<br>43. In combination for use on voice signals in a voice coder, first means for dividing the voice signals into successive time frames, the voice signals in each time frame having different frequencies, second means for converting the voice signals in each time frame into frequency signals representing the different frequencies of the voice signals in such time frame, such signals having amplitudes and one of such signals in each time frame having a particular amplitude larger than the amplitudes of the other signals in such time frame, third means for emphasizing in each time frame the amplitudes of the frequency signals closer to the particular amplitude than the amplitudes of the frequency signals further away from the particular amplitude, fourth means for limiting the frequency signals at high frequencies in each time frame to reduce the frequency signals in such time frame to a particular number, fifth means for producing in each time frame signals representing a frequency transform of the frequency signals from the fourth means in such time frame, the signals from the fifth means in each time frame having amplitudes, and sixth means for converting the frequency transformed signals from the fifth means to digital signals representative of the amplitudes of such signals.<br>49. In combination for use on voice signals in a voice encoder, first means for separating the voice signals into successive time frames, second means for transforming the voice signals in each successive time frame into frequency signals representative of the voice signals in such time frame, the frequency signals in each time frame having a pitch frequency and each of such signals having an amplitude and a phase, third means for determining the pitch frequency of the frequency signals in each time frame and for producing digital signals representing such pitch frequency, fourth means for determining the amplitudes of the frequency signals in each time frame and for producing digital signals representing such amplitudes, fifth means for determining the phases of the frequency signals in each time frame and for producing signals representing such phases, sixth means for determining a continuity in the phases of the frequency signals in the successive time frames, seventh means for providing signals representing a difference in the phases of the frequency signals in each time frame when the phases of the frequency signals in such time frame and in time frames immediately preceding such time frame have continuities within particular limits and for producing signals presenting such difference, eighth means for providing signals representing the phases of the frequency signals in each time frame when the phases of such frequency signals do not have continuities within the particular limits, ninth means for converting the signals representing the phases of the frequency signals in each time frame, and the differences between the phases of the signals in such time frame and in the immediately preceding time frames, into digital signals representing such phases and such predictions.<br>53. In a combination for use in voice signals in a voice coder, first means for separating the voice signals into successive time frames, second means for transforming the voice signals in each successive time frame into frequency signals representative of the voice signals in such time frame, the frequency signals in each time frame having a pitch frequency and each of such signals having an amplitude and a phase, the frequency signals in each time frame constituting harmonics, third means for providing a determination of the pitch frequency of the frequency signals in each time frame and for producing digital signals representing such pitch frequency, fourth means for determining the frequency of each harmonic in the frequency signals in such time frame relative to individual ones of a plurality of frequency blocks and individual ones of a plurality of grids within each frequency block in such time frame, fifth means for determining the phases of the frequency signals in each time frame in accordance with the determination by the fourth means for such time frame and for producing digital signals representing such phases, sixth means for determining the amplitudes of the frequency signals in each time frame in accordance with the determinations by the fourth means for such time frame and for producing digital signals representing such amplitudes, and seventh means for transmitting the digital signals from the third, fifth and sixth means in each time frame.<br>57. In combination for use in a voice decoder to recover voice signals introduced to a voice coder where the voice signals are processed in the voice coder in successive time frames and where the voice signals in each time frame are subjected in the voice coder to a first frequency transform to produce frequency signals in each time frame and wherein the frequency signals in each time frame have amplitudes and a pitch frequency and where one of the frequency signals in each time frame has a particular amplitude greater than the amplitude of the other frequency signals in the time frame and where inversion signals are produced representing a difference between the particular amplitude of the one frequency signal in each time frame and the amplitudes of the other frequency signals in such time frame and where the amplitudes of the inversion signals are companded and wherein a second frequency transform is performed on the companded signals and wherein the amplitudes of the signals in the second frequency transform are converted to digital signals, first means for receiving the digital signals representing the signals in the second frequency transform in each time frame, second means for providing an inverse frequency transform of the signals from the first means in each time frame, third means for decompanding the signals from the second means in each time frame, and fourth means for inverting the decompanded signals in each time frame relative to the particular amplitude of the one frequency signal in such time frame.<br>62. In combination for use on voice signals in a voice coder, first means for dividing the voice signals into a plurality of successive time frame, second means operative upon the voice signals in each time frame for providing a frequency transform of such signals to produce signals in a frequency spectrum in such time frame, each of such signals in each time frame having a phase and an amplitude, third means responsive to the signals in the frequency spectrum in each time frame for producing signals representing the amplitude and phase of the signals in the frequency spectrum in such time frame, fourth means responsive to the signals from the third means in each time frame for providing a restoration of the signals in the frequency spectrum in such time frame, and fifth means responsive to the signals in the frequency spectrum from the second means and the fourth means in each time frame for comparing such signals to produce resultant signals having first or second characteristics in such time frame dependent upon the results of such comparison.<br>68. In combination for use on voice signals in a voice coder, first means for providing the voice signals into a plurality of successive time frames each having an overlapped relationship to the time frames immediately preceding and immediately following such time frame, second means for providing a frequency transform on the voice signals in each time frame to produce signals in a frequency spectrum in such time frame, the signals in the frequency spectrum in each time frame having a pitch frequency and each of the signals having an amplitude and a phase, third means for limiting the signals in the frequency spectrum in each time frame to a particular number, fourth means for providing a discrete cosine transform of the particular number of the signals in the frequency spectrum in each time frame, fifth means responsive to the discrete cosine transform for each time frame for reconstructing the signals in the frequency spectrum in that time frame, sixth means for providing in each time frame a plurality of signals individually having first and second characteristics dependent upon the amplitudes of the signals from the second means and the fifth means in different portions of the frequency spectrum in such time frame, seventh means for providing signals representing the amplitudes and the phases of the signals in the frequency spectrum in each time frame, and eighth means for providing signals representing the pitch frequencies of the signals in the frequency spectrum in each time frame.<br>73. In combination for use on voice signals in a voice coder, first means for dividing the voice signals into successive time frames, second means for converting the voice signals into frequency signals in a frequency spectrum in each time frame, each of such frequency signals having an amplitude and a phase, third means for providing in the frequency spectrum a frequency pattern represented by blocks and grids within each block, fourth means for determining the particular block and grid in which the frequency of each of the frequency signals in the frequency spectrum in each time frame is located, and fifth means for producing signals representing the amplitudes and phases of the frequency signals in the frequency spectrum in each time frame in accordance with the determinations provided by the fourth means.<br>78. In combination for use on voice signals in a voice coder, first means for separating the voice signals into successive time frames, second means for providing a frequency transform of the signals in each time frame to provide frequency signals in a frequency spectrum in each time frame, each of the frequency signals in each time frame having an amplitude and a phase, third means for limiting the frequency signals from the second means to a particular range of frequencies, fourth means for determining the pitch frequency of the frequency signals in each time frame, fifth means for defining a plurality of frequency blocks and a plurality of frequency grids for each frequency block in the particular range of frequencies limited by the third means, p1 sixth means for determining the frequency of each of the frequency signals in the particular range of frequencies in each time frame in accordance with the determination of the pitch frequency of such frequency signals by the fourth means and the particular one of the blocks, and the particular one of the grids in such block, in which such frequency signal is located, and seventh means responsive to the frequency determined for each of the frequency signals in the particular range in each time frame for producing signals representing the amplitude and phase of such frequency signal.<br>82. In combination in a voice decoder for restoring voice signals coded in a voice coder where the coded signals are provided for successive time frames and the coded signals in each successive time frame are subjected to a frequency transform and the frequency transformed signals in each time frame are represented by a plurality of binary signals indicating the pitch frequency, the amplitudes and the phases in a particular range of frequencies in such time frame and by a plurality of binary signals indicating the accuracy, or lack of accuracy, of the cumulative amplitudes of the frequency transformed signals in progressive frequency bins n the particular frequency range and where the binary signals are transmitted from the voice coder to the voice decoder, first means at the voice decoder for receiving the transmitted signals in each time frame, second means at the voice decoder for operating upon the received signals indicating the pitch frequency, the amplitudes and the phases of the received signals in each time frame to restore the frequency transformed signals in such time frame, third means at the voice decoder for retaining, in individual frequency bins in each time frame, the amplitudes of the restored frequency signals in such frequency bins in accordance with the signals indicating an accuracy in the amplitudes of the frequency signals in such frequency bin and for providing, in other frequency bins in such time frame, the average of the amplitudes of the frequency signals in such frequency bins in such time frame in accordance with the signals indicating an inaccuracy in the amplitudes of the frequency signals in such frequency bins, and means for providing an inverse frequency transform of the frequency signals from the third means in each time frame to restore the frequency signals in that time frame.<br>86. In combination in a voice decoder for restoring voice signals coded in a voice coder where the coded signals are provided for successive time frames and the coded signals in each successive time frame are subjected to a frequency transform and the frequency transformed signals in each time frame are limited to a particular number by eliminating alternating ones of the frequency transformed signals at the high frequency end of the frequency transform in each time frame and wherein the limited number of the frequency transformed signals in each time frame are represented by a plurality of binary signals indicating the pitch frequency, the amplitudes and the phases of the limited number of the frequency transformed signals and wherein the binary signals are transmitted from the voice coder to the voice decoder, first means at the voice decoder for receiving the transmitted signals in each time frame, second means at the voice decoder for operating upon the received signals indicating the pitch frequency, the amplitudes and the phases of the received signals in each time frame to restore the frequency transformed signals in such time frame, third means responsive at the voice decoder to the binary signals representing the pitch frequency of the frequency signals in each time frame for restoring the frequency signals eliminated at the high frequencies at the voice coder, fourth means for providing an inverse frequency transform on the signals from the third means to recover the voice signals in each time frame, and fifth means for combining the signals in the successive time frames to restore the voice signals provided at the voice coder.<br>92. In combination for use in a voice decoder to recover voice signals introduced to a voice coder where the voice signals are processed in the voice coder in successive time frames and where the voice signals in the voice coder are subjected to a frequency transform to produce frequency signals in each time frame and where the frequency signals in each time frame have a pitch frequency, an amplitude and a phase and where logarithms are provided for the amplitudes of the frequency signals in each time frame and where the relative amplitudes of the logarithmic signals in each time frame are determined to define the amplitude with the highest value in such time frame and wherein the differences between the highest amplitude value and the amplitudes of the frequency signals in such time frame are determined and wherein such amplitude differences for the frequency signals in such time frame are converted to binary signals and wherein the binary signals are transmitted by the voice coder, first means at the voice decoder for receiving the transmitted binary signals, second means at the voice decoder for operating upon the received signals to convert the difference amplitudes to frequency signals having the logarithmic amplitudes provided at the voice coder, third means at the voice decoder for converting the logarithmic signals in each time frame to the frequency signals provided in such time frame at the voice coder, and fourth means at the voice decoder for operating upon the signals from the third means for each time frame and the signals representing the pitch frequency and the phases of the frequency signals in each time frame for restoring the voice signals in each time frame.</p></layer>
<layer id = "layer238"><p><b>US5371853A:Method and system for CELP speech coding and codebook for use therewith</b><br>The systems and methods described herein allow dictation and associated routing and formatting information to be forwarded to a transcription system. The transcription system converts the information into a document. The additional information associated with the dictation is then applied to the document to ensure proper formatting, routing, or the like. The completed document is returned to the original dictator for review and proofing. Upon approval, the document is distributed via the transcription system in accordance with distribution information associated with the document.<br><b>Independant Claims</b><br>1. A codebook excited linear predictive (CELP) speech processor comprising: means for supplying a digital speech input representative of human speech; means for performing linear predictive code analysis and perceptual weight filtering on said digital speech input to obtain short term speech information; means for performing linear predictive code analysis and perceptual weight filtering on said digital speech input to obtain long term speech information; a deterministic non-overlapping codebook of a first predetermined number of vectors which are uniformly distributed over a multi-dimensional sphere, each of the first predetermined number of vectors being partitioned into a second predetermined number of sub-vectors, a substantial number of elements of each of the second predetermined number of sub-vectors being defined as zero, and a remaining even number of elements of each of the second predetermined number of sub-vectors defined as +1 or -1, wherein four elements with an index=5N (where N is an integer from 0 to 3) are non-zero for each of the second predetermined number of subvectors and the four non-zero elements of each of the second predetermined number of sub-vectors are all -1, all +1, or two are -1 and two are +1; and means for generating a remaining speech residual of the digital speech input from the deterministic codebook; the short term speech information, the long term speech information and the remaining speech residual being combinable to form a quality reproduction of the digital speech input to reproduce the human speech represented by said digital speech input.<br>12. A method of encoding speech data including the steps of providing a digital speech input, performing linear predictive code analysis and perceptual weight filtering on the digital speech input to produce a short and long term speech information and generating a deterministic non-overlapping codebook of a first predetermined number of vectors which are uniformly distributed over a multi-dimensional sphere comprising the steps of: a) partitioning each of the first predetermined number of vectors into a second predetermined number of sub-vectors; b) setting a substantial number of elements of each of the second predetermined number of sub-vectors to zero; c) setting a remaining even number of elements of each of the second number of sub-vectors to 1 or -1, wherein four elements with an index of SN (where N is an integer from 0 to 3) are non-zero for each of the second number of sub-vectors and the four non-zero elements of each sub-vector are all -1, all +1, or two are -1 and two are +1; and d) generating a remaining speech residual of the digital speech input from the deterministic codebook such that the short and long term speech information and the remaining speech residual are combinable to form a quality reproduction of the digital speech input.</p></layer>
<layer id = "layer239"><p><b>US20020111797A1:Voiced speech preprocessing employing waveform interpolation or a harmonic model</b><br>A cell necrosis apparatus has a flexible introducer including a lumen and a distal end sufficiently sharp to penetrate tissue. An energy delivery device is positionable in the introducer as the introducer is advanced through tissue. The energy delivery device includes a first RF electrode with a tissue piercing distal portion and a second RF electrode with a tissue piercing distal portion. The first and second RF electrodes are deployable with curvature from the introducer at a selected tissue site in a lateral direction away from the periphery of the introducer.<br><b>Independant Claims</b><br>1. A speech codec comprising: a classifier configured to process parameters that identify a transition region between at least two portions of a speech signal, at least one of the portions of the speech signal being a voiced portion; and a periodic smoothing circuit configured to smooth the transition region represented by at least one of a weighted representation of the speech signal, a residual signal, and a speech signal using at least one of an interpolated pitch lag and a constant pitch lag, the interpolated pitch lag being derived from a pitch track corresponding to the voiced portion of the speech signal.<br>9. A speech coding system comprising: a classifier that is configured to detect a transition region between at least two portions of a speech signal, at least one portion of the speech signal being a periodic portion; and a periodic smoothing circuit that is configured to smooth the transition region using at least one of a forward pitch extension and a backward pitch extension that is derived from a pitch track corresponding to the periodic portion of the speech signal.<br>16. A method of smoothing a transition region comprising: detecting a transition region between a periodic portion and a second portion of a speech signal; and smoothing the transition region using at least one of a forward pitch extension and a backward pitch extension that is derived from a pitch track corresponding to the periodic portion of the speech signal.</p></layer>
<layer id = "layer240"><p><b>US20020071573A1:DVE system with customized equalization</b><br>A process for the preparation of an isocyanurate-free uretdione of isophorphone diisocyanate, comprising dimerizing an isophorone diisocyanate of the general formula: ##STR1## in an inert organic solvent or in the absence of a solvent, with the aid of a catalysts, at a temperature of 0 to 80.degree. C.; isolating the uretdione formed from the reaction mixture after a conversion of 5-70%, without prior deactivation of the catalyst, by thin film distillation at 100-180.degree. C. under 0.01-0.5 mbar; wherein the isophorone diisocyanate has a purity of .gtoreq.99.9% by weight, and the concentration of the unknown first runnings component in a gas chromatogram of the isophorone diisocyanate employed for the dimerization is not greater than 0.05 area%; and wherein R.sup.1 and R.sup.2 are identical or different alkyl radicals having 1-8 C atoms, or with the N atom bonded to the ring, can form a common 5- or 6-membered ring which can contain a CH--CH.sub.3 group, an N--CH.sub.3 group or an O atom instead of a CH.sub.2 group.<br><b>Independant Claims</b><br>1. A digital voice enhancement communication system comprising: a set of one or more microphones; a set of one or more loudspeakers; at least one of said sets having plural members; a plurality of electrical transmission paths, one for each microphone and loudspeaker combination, for transmitting electrical signals such that the speech of a person at a respective microphone can be heard by a person at a respective loudspeaker as transmitted by a respective electrical signal from the respective microphone to the respective loudspeaker, each respective microphone being subject to acoustic feedback from a respective loudspeaker, each loudspeaker and microphone combination having an electroacoustic transfer function therebetween; a plurality of individually customized equalization filters, one for each of said paths and custom tailored to the respective electroacoustic transfer function.<br>6. A digital voice enhancement communication system comprising: an acoustic enclosure; a first acoustic zone in said enclosure; a second acoustic zone in said enclosure; a microphone at said first zone; a loudspeaker at said second zone and electrically coupled to said microphone such that the speech of a person at said first zone can be heard by a person at said second zone as transmitted by an electrical signal from said microphone to said loudspeaker, said loudspeaker being acoustically coupled to said microphone such that said microphone is subject to acoustic feedback from said loudspeaker, said loudspeaker and said microphone having an electroacoustic transfer function therebetween; an equalization filter filtering said electrical signal in inverse relationship relative to said electroacoustic transfer function.<br>12. A digital voice enhancement communication system comprising: an acoustic enclosure; a first acoustic zone in said enclosure; a second acoustic zone in said enclosure; at least one microphone in at least one of said zones; at least one loudspeaker in at least the other of said zones, each said loudspeaker being electrically coupled to at least one of said microphones such that the speech of a person at said microphone can be heard by a person at said loudspeaker as transmitted by an electrical signal from said microphone to said loudspeaker, said loudspeaker being acoustically coupled to said microphone such that said microphone is subject to acoustic feedback from said loudspeaker, said loudspeaker and said microphone having a respective electroacoustic transfer fuinction therebetween; at least one equalization filter filtering the electrical signal from a respective microphone to a respective loudspeaker in inverse relationship relative to the respective said electroacoustic transfer function, said respective microphone, equalization filter and loudspeaker being connected in electrical series, with said equalization filter having an input from said microphone, and having an output to said loudspeaker, each said equalization filter comprising a model inversely modeling the respective said electroacoustic transfer function, each said electroacoustic transfer function having frequency dependent peaks limiting the amount of gain that can be applied to the respective said electrical signal, wherein the respective model models spectral frequency dependency of said electroacoustic transfer function and provides said equalization filter in inverse relationship in said electrical series between said microphone and said loudspeaker and substantially nullifies the frequency dependency of the respective said electroacoustic transfer function and substantially reduces said peaks and flattens the spectral transfer function from said microphone to said loudspeaker, to enable increased gain.<br>14. A method for enabling increased gain in a digital voice enhancement communication system having a set of one or more microphones, a set of one or more loudspeakers, at least one of said sets having plural members, a plurality of electrical transmission paths, one for each microphone and loudspeaker combination, for transmitting electrical signals such that the speech of a person at a respective microphone can be heard by a person at a respective loudspeaker as transmitted by a respective electrical signal from the respective microphone to the respective loudspeaker, each respective microphone being subject to acoustic feedback from a respective loudspeaker, each loudspeaker and microphone combination having an electroacoustic transfer function therebetween, said method comprising individually custom equalization filtering each of said electrical signals in each of said paths, and custom tailoring each respective filtering to each respective electroacoustic transfer function.<br>18. A method for enabling increased gain in a digital voice enhancement communication system in an acoustic enclosure having a first acoustic zone in said enclosure, a second acoustic zone in said enclosure, a microphone at said first zone, a loudspeaker at said second zone and electrically coupled to said microphone such that the speech of a person at said first zone can be heard by a person at said second zone as transmitted by an electrical signal from said microphone to said loudspeaker, said loudspeaker being acoustically coupled to said microphone such that said microphone is subject to acoustic feedback from said loudspeaker, said loudspeaker and said microphone having an electroacoustic transfer function therebetween, said method comprising equalization filtering said electrical signal in inverse relationship relative to said electroacoustic transfer function.</p></layer>
<layer id = "layer241"><p><b>US20020147595A1:Cochlear filter bank structure for determining masked thresholds for use in perceptual audio coding</b><br>A method and apparatus for manufacturing a receptacle connector having contacts or terminals to which the wires are crimped includes a contact holder. The contact holder supports the contacts and wires gripped by the contacts. The advance movement of the contacts as retained in the contact holder makes it possible to insert the contacts into holes of a housing simultaneously and after that the wires are extracted from the contact holder. The wire crimped connector can be produced in a cycle time much shorter than a conventional process.<br><b>Independant Claims</b><br>1. A method for determining a plurality of masked thresholds for a perceptual auditory model based on an input audio signal, the method comprising the steps of: filtering the input audio signal with use of a filter bank comprising a plurality of filter bank stages connected in series, each filter bank stage comprising a plurality of low-pass filters connected in series and a corresponding plurality of high-pass filters applied to a corresponding output from each of said low-pass filters, said filter bank further comprising a plurality of downsamplers connected in series between each successive pair of filter bank stages, each of said high-pass filters comprised in each of said filter bank stages producing a corresponding band-pass signal as an output thereof, and generating, for each of said band-pass signals, a corresponding masked threshold based thereon.<br>13. An apparatus for determining a plurality of masked thresholds for a perceptual auditory model based on an input audio signal, the apparatus comprising: a filter bank applied to the input audio signal, the filter bank comprising a plurality of filter bank stages connected in series, each filter bank stage comprising a plurality of low-pass filters connected in series and a corresponding plurality of high-pass filters applied to a corresponding output from each of said low-pass filters. said filter bank further comprising a plurality of downsamplers connected in series between each successive pair of filter bank stages, each of said high-pass filters comprised in each of said filter bank stages producing a corresponding band-pass signal as an output thereof; and a masked threshold generator which generates, for each of said band-pass signals, a corresponding masked threshold based thereon.<br>25. A filter bank comprising: a plurality of filter bank stages connected in series, each filter bank stage comprising a plurality of low-pass filters connected in series and a corresponding plurality of high-pass filters applied to a corresponding output from each of said low-pass filters, each of said high-pass filters comprised in each of said filter bank stages producing a corresponding band-pass signal as an output thereof; and a plurality of downsamplers connected in series between each successive pair of filter bank stages.<br>37. A method of filtering an input audio signal, the method comprising the steps of: applying said input audio signal to a filter bank comprising a plurality of filter bank stages connected in series, each filter bank stage comprising a plurality of low-pass filters connected in series and a corresponding plurality of high-pass filters applied to a corresponding output from each of said low-pass filters, each filter bank stage further comprising a plurality of downsamplers connected in series between each successive pair of filter bank stages; and producing a corresponding plurality of band-pass signals as outputs of each of said high-pass filters comprised in each of said filter bank stages.<br>49. An apparatus for determining a plurality of masked thresholds for a perceptual auditory model based on an input audio signal, the apparatus comprising: means for filtering the input audio signal, said means for filtering comprising a plurality of filter bank stages connected in series, each filter bank stage comprising a plurality of means for low-pass filtering connected in series and a corresponding plurality of means for high-pass filtering applied to a corresponding output from each of said means for low-pass filtering, said means for filtering further comprising a plurality of means for downsampling connected in series between each successive pair of filter bank stages, each of said means for high-pass filtering comprised in each of said filter bank stages producing a corresponding band-pass signal as an output thereof; and means for generating, for each of said band-pass signals, a corresponding masked threshold based thereon.<br>57. A filter bank comprising: a plurality of filter bank stages connected in series, each filter bank stage comprising a plurality of means for low-pass filtering connected in series and a corresponding plurality of means for high-pass filtering applied to a corresponding output from each of said means for low-pass filtering, each of said means for high-pass filtering comprised in each of said filter bank stages producing a corresponding band-pass signal as an output thereof, and a plurality of means for downsampling connected in series between each successive pair of filter bank stages.</p></layer>
<layer id = "layer242"><p><b>US5924061A:Efficient decomposition in noise and periodic signal waveforms in waveform interpolation</b><br>The network print service system includes a distributing terminal which transmits image data of a first image for providing a print as a gift, one or more receiving terminal which transmits order information for ordering the print of a second image selected from the first image in order to receive the print for free as the gift, a gift service center which receives the image data transmitted from the distributing terminal and accepts the order information of the second image transmitted from the receiving terminal, a print output unit which outputs the print of the second image in accordance with the order information accepted in the gift service center and a print delivery unit which delivers the output print of the second image to an image receiving user who has transmitted the order information from the receiving terminal.<br><b>Independant Claims</b><br>1. A method of coding a speech signal, the speech signal having a sequence of time-ordered short-term spectra corresponding thereto, the method comprising the steps of: identifying a time-ordered sequence of speech signal segments; generating a time-ordered sequence of sets of frequency-domain parameters based on samples of the speech signal; performing a cross correlation between two or more of said speech signal segments to generate one or more parameters representing relatively high rates of evolution of said short-term spectra; generating one or more sets of coefficients representing relatively low rates of evolution of said short-term spectra based on two or more of said sets of frequency-domain parameters; and coding said speech signal based on the one or more generated parameters and further based on the one or more sets of coefficients representing relatively low rates of evolution of said short-term spectra.<br>11. An encoder for coding a speech signal, the speech signal having a sequence of time-ordered short-term spectra corresponding thereto, the encoder comprising: means for identifying a time-ordered sequence of speech signal segments; means for generating a time-ordered sequence of sets of frequency-domain parameters based on samples of the speech signal; means for performing a cross correlation between two or more of said speech signal segments to generate one or more parameters representing relatively high rates of evolution of said short-term spectra; means for generating one or more sets of coefficients representing relatively low rates of evolution of said short-term spectra based on two or more of said sets of frequency-domain parameters; and means for coding said speech signal based on the one or more generated parameters and further based on the one or more sets of coefficients representing relatively low rates of evolution of said short-term spectra.</p></layer>
<layer id = "layer243"><p><b>US5903866A:Waveform interpolation speech coding using splines</b><br>A label and RFID tag issuing apparatus comprises a recording apparatus that records information on a production label and an RFID tag reader/writer that writes and reads part of the recorded information to/from an RFID tag. This label and RFID tag issuing apparatus writes a production number to the RFID tag attached to the container if a container for containing an article or articles carrying the production label and RFID tag is judged to be on the container loading plate. The apparatus, subsequently confirming presence of the container on the container loading plate, records on the production label production information including bar-code data corresponding to the production number that has been written to the RFID. Thus, information recorded on the production label and information stored in the RFID tag are tied, and thereby accidental affixing of a wrong production label onto the container can be prevented.<br><b>Independant Claims</b><br>1. A method of synthesizing a reconstructed speech signal based on encoded signals communicated via a communications channel, the method comprising the steps of: receiving at least two communicated signals, including a first communicated signal comprising a first set of frequency domain parameters representing a first speech signal segment of a length equal to a first pitch-period and a second communicated signal comprising a second set of frequency domain parameters representing a second speech signal segment of a length equal to a second pitch-period; generating at least two sets of spline coefficients, including a first set of spline coefficients which comprises a spline representation of a time domain transformation of the first set of frequency domain parameters and a second set of spline coefficients which comprises a spline representation of a time domain transformation of the second set of frequency domain parameters, wherein the spline representations are based on cardinal spline representations; synthesizing the reconstructed signal by interpolating between the spline representation of the time domain transformation of the first set of frequency domain parameters and the spline representation of the time domain transformation of the second set of frequency domain parameters.<br>11. A speech decoder which synthesizes a reconstructed speech signal based on encoded signals communicated via a communications channel, the decoder comprising: a signal receiver which receives at least two communicated signals, including a first communicated signal comprising a first set of frequency domain parameters representing a first speech signal segment of a length equal to a first pitch-period and a second communicated signal comprising a second set of frequency domain parameters representing a second speech signal segment of a length equal to a second pitch-period; a spline coefficient generator which generates at least two sets of spline coefficients, including a first set of spline coefficients which comprises a spline representation of a time domain transformation of the first set of frequency domain parameters and a second set of spline coefficients which comprises a spline representation of a time domain transformation of the second set of frequency domain parameters, wherein the spline representations are based on cardinal spline representations; a signal synthesizer which synthesizes the reconstructed signal by interpolating between the spline representation of the time domain transformation of the first set of frequency domain parameters and the spline representation of the time domain transformation of the second set of frequency domain parameters.</p></layer>
<layer id = "layer244"><p><b>US6041297A:Vocoder for coding speech by using a correlation between spectral magnitudes and candidate excitations</b><br>A spectacle frame has a frameless lens or lens frame, an arm, a clamp that bears upon the arm and is attached hingedly to an arm mounting of the frameless lens or lens frame. The clamp enables easy removal and replacement of the arm without the need for tools.<br><b>Independant Claims</b><br>1. A method of encoding an input frame of speech based on a plurality of candidate excitations, the plurality of candidate excitations being subdivided into a plurality of subsets, each of the subsets including a predetermined amount of the plurality of candidate excitations, the method comprising the steps of: a) determining a plurality of spectral weights based on the input frame of speech; b) determining a target excitation based on the input frame of speech; c) selecting from the plurality of candidate excitations the candidate excitation most closely matching the target excitation; d) identifying the selected candidate excitation by a variable length index code having a data length based on the predetermined amount of candidate excitations included in the subset corresponding to the selected candidate excitation; e) communicating a speech characterization code without communicating the selected candidate excitation, the speech characterization code including at least the variable length index code and the plurality of the spectral weights calculated in step a); f) receiving the speech characterization code communicated in step e); and g) determining, based on the plurality of spectral weights included in the speech characterization code, the subset of candidate excitations which includes the selected candidate excitation.<br>7. A method of encoding an input frame of speech based on a plurality of candidate excitations, the plurality of candidate excitations being subdivided into a plurality of subsets, each of the subsets including a predetermined amount of the plurality of candidate excitations, the method comprising the steps of: a) determining a plurality of spectral weights based on the input frame of speech; b) determining a target excitation based on the input frame of speech; c) selecting from the plurality of candidate excitations the candidate excitation most closely matching the target excitation; d) identifying the selected candidate excitation by a variable length index code having a data length based on the predetermined amount of candidate excitations included in the subset corresponding to the selected candidate excitation; e) communicating a speech characterization code, the speech characterization code including at least the variable length index code and the plurality of the spectral weights calculated in step a); f) receiving the speech characterization code communicated in step e); g) determining, based on the plurality of spectral weights included in the speech characterization code, the subset of candidate excitations which includes the selected candidate excitation; h) obtaining the selected candidate excitation from the subset determined in step g) by using the variable length index code; and i) reconstructing the input frame of speech based on the obtained candidate excitation, wherein the step h) of obtaining the selected candidate excitation comprises: j) determining within the speech characterization code a first bit position of the variable length index code; k) determining how many candidate excitations are included in the subset determined in step g); l) determining the minimum number of bits necessary to uniquely identify the candidate excitations included in the subset determined in step g); m) reading, from the beginning bit position of the variable length index code in the speech characterization code, a number of bits equal to the minimum number of bits determined in step l), the variable length index code comprising the bits read in step m); and n) obtaining the candidate excitation selected in step c) on the basis of the value of the index code.<br>8. A method of encoding an input frame of speech based on a plurality of candidate excitations, each candidate excitation being associated with a fixed amount of spectral weights, the plurality of candidate excitations being subdivided into a plurality of subsets, each of the subsets including a predetermined amount of the plurality of candidate excitations, the method comprising the steps of: a) determining a fundamental frequency of the input frame of speech; b) determining a first plurality of spectral weights based on the input frame of speech; c) generating a second plurality of spectral weights based on the first plurality of spectral weights, the second plurality of spectral weights having an amount of spectral weights equal to the fixed amount of spectral weights; d) selecting from the plurality of candidate excitations a candidate excitation most closely matching the input frame of speech on the basis of the second plurality of spectral weights; e) identifying the selected candidate excitation by a variable length index code having a data length based on the predetermined amount of candidate excitations included in the subset corresponding to the selected candidate excitation; f) communicating a speech characterization code without communicating the selected candidate excitation, the speech characterization code including at least the variable index code, the fundamental frequency, and the first plurality of spectral weights determined in step b); g) receiving the speech characterization code communicated in step f); h) determining the second plurality of spectral weights based on the received first plurality of spectral weights; and i) determining, based on the second plurality of spectral weights, the subset of candidate excitations including the selected candidate excitation.<br>9. The method according to step 8, further comprising the steps of: j) obtaining the selected candidate excitation from the subset determined in step i) on the basis of the variable length index code; k) generating a modified excitation based on the selected candidate excitation, the modified excitation corresponding to a number of frequency bands equal to the first amount of spectral weights; and l) reconstructing the input frame of speech on the basis of the modified excitation.<br>12. A method of encoding an input frame of speech based on a plurality of candidate excitations, each candidate excitation being associated with a fixed amount of spectral weights, the plurality of candidate excitations being subdivided into a plurality of subsets, each of the subsets including a predetermined amount of the plurality of candidate excitations, the method comprising the steps of: a) determining a fundamental frequency of the input frame of speech; b) determining a first plurality of spectral weights based on the input frame of speech; c) generating a second plurality of spectral weights based on the first plurality of spectral weights, the second plurality of spectral weights having an amount of spectral weights equal to the fixed amount of spectral weights; d) selecting from the plurality of candidate excitations a candidate excitation most closely matching the input frame of speech on the basis of the second plurality of spectral weights; e) identifying the selected candidate excitation by a variable length index code having a data length based on the predetermined amount of candidate excitations included in the subset corresponding to the selected candidate excitation; f) communicating a speech characterization code including at least the variable index code, the fundamental frequency, and the first plurality of spectral weights determined in step b); g) receiving the speech characterization code communicated in step f); h) determining the second plurality of spectral weights based on the received first plurality of spectral weights; i) determining, based on the second plurality of spectral weights, the subset of candidate excitations including the selected candidate excitation; j) obtaining the selected candidate excitation from the subset determined in step i) on the basis of the variable length index code; k) generating a modified excitation based on the selected candidate excitation, the modified excitation corresponding to a number of frequency bands equal to the first plurality of spectral weights; and l) reconstructing the input frame of speech on the basis of the modified excitation, wherein each of the plurality of candidate excitations comprises a plurality of values, each of the plurality of values corresponding to one of a voiced decision and an unvoiced decision, and wherein each one of the frequency bands corresponding to the modified excitation includes one of the plurality of values.<br>13. An apparatus for encoding an input frame of speech based on a plurality of candidate excitations, the plurality of candidate excitations being subdivided into a plurality of subsets, each of the subsets including a predetermined amount of the plurality of candidate excitations, the apparatus comprising: a) means for determining a plurality of spectral weights based on the input frame of speech; b) means for determining a target excitation based on the input frame of speech; c) means for selecting from the plurality of candidate excitations the candidate excitation most closely matching the target excitation; d) means for identifying the selected candidate excitation by a variable length index code having a data length based on the predetermined amount of candidate excitations included in the subset corresponding to the selected candidate excitation; e) means for communicating a speech characterization code without communicating the selected candidate excitation, the speech characterization code including at least the variable length index code and the plurality of the spectral weights calculated by the means for determining the plurality of spectral weights; f) means for receiving the speech characterization code communicated by the means for communicating the speech characterization code; and g) means for determining, based on the plurality of spectral weights included in the speech characterization code, the subset of candidate excitations which includes the selected candidate excitation.<br>14. An apparatus for encoding an input frame of speech based on a plurality of candidate excitations, the plurality of candidate excitations being subdivided into a plurality of subsets, each of the subsets including a predetermined amount of the plurality of candidate excitations, the apparatus comprising: a) means for determining a plurality of spectral weights based on the input frame of speech; b) means for determining a target excitation based on the input frame of speech; c) means for selecting from the plurality of candidate excitations the candidate excitation most closely matching the target excitation; d) means for identifying the selected candidate excitation by a variable length index code having a data length based on the predetermined amount of candidate excitations included in the subset corresponding to the selected candidate excitation; e) means for communicating a speech characterization code, the speech characterization code including at least the variable length index code and the plurality of the spectral weights calculated by the means for determining the plurality of spectral weights; f) means for receiving the speech characterization code communicated by the means for communicating; g) means for determining, based on the plurality of spectral weights included in the speech characterization code, the subset of candidate excitations which includes the selected candidate excitation; h) means for obtaining the selected candidate excitation from the subset determined by the means for determining the subset of candidate excitations which includes the selected candidate excitation by using the variable length index code; and i) means for reconstructing the input frame of speech based on the obtained candidate excitation, wherein the means for obtaining the selected candidate excitation comprises: j) means for determining within the speech characterization code a first bit position of the variable length index code; k) means for determining how many candidate excitations are included in the subset determined by the means for determining the subset of candidate excitations which includes the selected candidate excitation; l) means for determining the minimum number of bits necessary to uniquely identify the candidate excitations included in the subset determined by the means for determining the subset of candidate excitations which includes the selected candidate excitation; m) means for reading, from the beginning bit position of the variable length index code in the speech characterization code, a number of bits equal to the minimum number of bits determined by the means for determining the minimum number of bits, the variable length index code comprising the bits read by the means for reading; and n) means for obtaining the candidate excitation selected by the means for selecting on the basis of the value of the index code.<br>15. An apparatus for encoding an input frame of speech based on a plurality of candidate excitations, each candidate excitation being associated with a fixed amount of spectral weights, the plurality of candidate excitations being subdivided into a plurality of subsets, each of the subsets including a predetermined amount of the plurality of candidate excitations, the apparatus comprising: a) means for determining a fundamental frequency of the input frame of speech; b) means for determining a first plurality of spectral weights based on the input frame of speech; c) means for generating a second plurality of spectral weights based on the first plurality of spectral weights, the second plurality of spectral weights having an amount of spectral weights equal to the fixed amount of spectral weights; d) means for selecting from the plurality of candidate excitations a candidate excitation most closely matching the input frame of speech on the basis of the second plurality of spectral weights; e) means for identifying the selected candidate excitation by a variable length index code having a data length based on the predetermined amount of candidate excitations included in the subset corresponding to the selected candidate excitation; and f) means for communicating a speech characterization code without communicating the selected candidate excitation, the speech characterization code including at least the variable index code, the fundamental frequency, and the first plurality of spectral weights determined by the means for determining the first plurality of spectral weights; g) means for receiving the speech characterization code communicated by the means for communicating the speech characterization code; h) determining the second plurality of spectral weights based on the received first plurality of spectral weights; and i) determining, based on the second plurality of candidate excitations, the subset of candidate excitations including the selected candidate excitation.<br>16. An apparatus for encoding an input frame of speech based on a plurality of candidate excitations, each candidate excitation being associated with a fixed amount of spectral weights, the plurality of candidate excitations being subdivided into a plurality of subsets, each of the subsets including a predetermined amount of the plurality of candidate excitations, the apparatus comprising: a) means for determining a fundamental frequency of the input frame of speech; b) means for determining a first plurality of spectral weights based on the input frame of speech; c) means for generating a second plurality of spectral weights based on the first plurality of spectral weights, the second plurality of spectral weights having an amount of spectral weights equal to the fixed amount of spectral weights; d) means for selecting from the plurality of candidate excitations a candidate excitation most closely matching the input frame of speech on the basis of the second plurality of spectral weights; e) means for identifying the selected candidate excitation by a variable length index code having a data length based on the predetermined amount of candidate excitations included in the subset corresponding to the selected candidate excitation; f) means for communicating a speech characterization code including at least the variable index code, the fundamental frequency, and the first plurality of spectral weights determined by the means for determining the first plurality of spectral weights; g) means for receiving the speech characterization code communicated by the means for communicating the speech characterization code; h) means for determining the second plurality of spectral weights based on the received first plurality of spectral weights; i) means for determining, based on the second plurality of spectral weights, the subset of candidate excitations including the selected candidate excitations; j) means for obtaining the selected candidate excitation from the subset determined by the means for determining the subset of candidate excitation on the basis of the variable length index code; k) means for generating a modified excitation based on the selected candidate excitation, the modified excitation corresponding to a number of frequency bands equal to the first plurality of spectral weights; and l) means for reconstructing the input frame of speech on the basis of the modified excitation, wherein each of the plurality of candidate excitations comprises a plurality of values, each of the plurality of values corresponding to one of a voiced decision and an unvoiced decision, and wherein each one of the frequency bands corresponding to the modified excitation includes one of the plurality of values.<br>17. An apparatus for encoding an input frame of speech based on a plurality of candidate excitations, the plurality of candidate excitations being subdivided into a plurality of subsets, each of the subsets including a predetermined amount of the plurality of candidate excitations, the apparatus comprising: a) a device including a spectral weight calculator for determining a plurality of spectral weights based on the input frame of speech; b) a device including a target excitation calculator for determining a target excitation based on the input frame of speech; c) a device including an adaptive searcher and a stochastic searcher for selecting from the plurality of candidate excitations the candidate excitation most closely matching the target excitation; d) a device including a spectral weight correlator for identifying the selected candidate excitation by a variable length index code having a data length based on the predetermined amount of candidate excitations included in the subset corresponding to the selected candidate excitation; e) a device including an encoder for communicating a speech characterization code without communicating the selected candidate excitation, the speech characterization code including at least the variable length index code and the plurality of the spectral weights calculated by the device including the spectral weight calculator; f) a device including a decoder for receiving the speech characterization code communicated by the device including the encoder; and g) a device including a cluster generator for determining, based on the plurality of spectral weights included in the speech characterization code, the subset of candidate excitations which includes the selected candidate excitation.<br>18. An apparatus for encoding an input frame of speech based on a plurality of candidate excitations, the plurality of candidate excitations being subdivided into a plurality of subsets, each of the subsets including a predetermined amount of the plurality of candidate excitations, the apparatus comprising: a) a device including a spectral weight calculator for determining a plurality of spectral weights based on the input frame of speech; b) a device including a target excitation calculator for determining a target excitation based on the input frame of speech; c) a device including an adaptive searcher and a stochastic searcher for selecting from the plurality of candidate excitations the candidate excitation most closely matching the target excitation; d) a device including a first spectral weight correlator for identifying the selected candidate excitation by a variable length index code having a data length based on the predetermined amount of candidate excitations included in the subset corresponding to the selected candidate excitation; e) a device including an encoder for communicating a speech characterization code, the speech characterization code including at least the variable length index code and the plurality of the spectral weights calculated by the device including the spectral weight calculator; f) a device including a decoder for receiving the speech characterization code communicated by the device including the encoder; g) a device including a cluster generator for determining, based on the plurality of spectral weights included in the speech characterization code, the subset of candidate excitations which includes the selected candidate excitation; h) a device including a second spectral weight correlator for obtaining the selected candidate excitation from the subset determined by the device including the cluster generator for determining the subset of candidate excitations which includes the selected candidate excitation by using the variable length index code; and i) a device including an LPC filter for reconstructing the input frame of speech based on the obtained candidate excitation, wherein the device including the second spectral weight correlator comprises: j) a device for determining within the speech characterization code a first bit position of the variable length index code; k) a device for determining how many candidate excitations are included in the subset determined by the device including the cluster generator; l) a device for determining the minimum number of bits necessary to uniquely identify the candidate excitations included in the subset determined by the device including the cluster generator; m) a device for reading, from the beginning bit position of the variable length index code in the speech characterization code, a number of bits equal to the minimum number of bits determined by the device for determining the minimum number of bits, the variable length index code comprising the bits read by the device for reading; and n) a device for obtaining the candidate excitation selected by the device including the adaptive searcher and the stochastic searcher on the basis of the value of the index code.<br>19. An apparatus for encoding an input frame of speech based on a plurality of candidate excitations, each candidate excitation being associated with a fixed amount of spectral weights, the plurality of candidate excitations being subdivided into a plurality of subsets, each of the subsets including a predetermined amount of the plurality of candidate excitations, the apparatus comprising: a) a device including a pitch frequency calculator for determining a fundamental frequency of the input frame of speech; b) a device including a spectral envelope generator for determining a first plurality of spectral weights based on the input frame of speech; c) a device including an in-band generator and an interpolator/decimator for generating a second plurality of spectral weights based on the first plurality of spectral weights, the second plurality of spectral weights having an amount of spectral weights equal to the fixed amount of spectral weights; d) a device including an excitation searcher for selecting from the plurality of candidate excitations a candidate excitation most closely matching the input frame of speech on the basis of the second plurality of spectral weights, wherein the excitation searcher identifies the selected candidate excitation by a variable length index code having a data length based on the predetermined amount of candidate excitations included in the subset corresponding to the selected candidate excitation; and e) a device including an encoder for communicating a speech characterization code including at least the variable index code, the fundamental frequency, and the first plurality of spectral weights determined by the device including the spectral envelope generator and excluding the selected candidate excitation.<br>20. An apparatus for encoding an input frame of speech based on a plurality of candidate excitations, each candidate excitation being associated with a fixed amount of spectral weights, the plurality of candidate excitations being subdivided into a plurality of subsets, each of the subsets including a predetermined amount of the plurality of candidate excitations, the apparatus comprising: a) a device including a pitch frequency calculator for determining a fundamental frequency of the input frame of speech; b) a device including a spectral envelope generator for determining a first plurality of spectral weights based on the input frame of speech; c) a device including an in-band generator and a first interpolator/decimator for generating a second plurality of spectral weights based on the first plurality of spectral weights, the second plurality of spectral weights having an amount of spectral weights equal to the fixed amount of spectral weights; d) a device including a first excitation searcher for selecting from the plurality of candidate excitations a candidate excitation most closely matching the input frame of speech on the basis of the second plurality of spectral weights, wherein the first excitation searcher identifies the selected candidate excitation by a variable length index code having a data length based on the predetermined amount of candidate excitations included in the subset corresponding to the selected candidate excitation; e) a device including an encoder for communicating a speech characterization code including at least the variable index code, the fundamental frequency, and the first plurality of spectral weights determined by the device including the spectral envelope generator; f) a device including a decoder for receiving the speech characterization code communicated by the device including the encoder; g) a device including a second interpolator/decimator for determining the second plurality of spectral weights based on the received first plurality of spectral weights; h) a device including a second excitation searcher for determining, based on the second plurality of spectral weights, the subset of candidate excitations including the selected candidate excitation, wherein the second excitation searcher obtains the selected candidate excitation from the subset determined by the second excitation searcher on the basis of the variable length index code; j) a device including a third interpolator/decimator for generating a modified excitation based on the selected candidate excitation, the modified excitation corresponding to a number of frequency bands equal to the first plurality of spectral weights; and k) a device including a synthesizer for reconstructing the input frame of speech on the basis of the modified excitation, wherein each of the plurality of candidate excitations comprises a plurality of values, each of the plurality of values corresponding to one of a voiced decision and an unvoiced decision, and wherein each one of the frequency bands corresponding to the modified excitation includes one of the plurality of values.</p></layer>
<layer id = "layer245"><p><b>US20020184017A1:Method and apparatus for performing real-time endpoint detection in automatic speech recognition</b><br>Methods and compounds for inducing immunosuppression in animals which need immunosuppressive treatment involving administration to animals of a therapeutically effective amount of a compound of the following formula ##STR1## where R is H, PO.sub.3.sup.=, alkyl of 1 to 12 carbon atoms substituted or unsubstituted, straight chain or branched, 0 to 6 double bonds, (CH.sub.2).sub.n morpholine where n=1-4, morpholinomethylphenyl, orthoaminophenyl, orthohydroxyphenyl, (CH.sub.2).sub.n COOR.sub.2 where n=1-4 where R.sub.2 is H, an alkalai metal salt, an alkaline earth metal salt, NH.sub.4.sup.+, N.sup.+ (R.sub.3).sub.4 where R.sub.3 is independently selected from the group consisting of H and alkyl of 1 to 4 carbon atoms, COR.sub.1 wherein R.sub.1 is selected from the group consisting of H, (CH.sub.2).sub.n CH.sub.3, where n=1-6, (CH.sub.2).sub.n COOR.sub.2 where n=1-4 and R.sub.2 is previously defined, (CH.sub.2).sub.n N.sup.+ (R.sub.3).sub.4 wherein n=1-4, and (CH.sub.2).sub.n SO.sub.3.sup.- where N=1-4, and pharmaceutically acceptable salts thereof.<br><b>Independant Claims</b><br>1. A method for performing real-time endpoint detection for use in automatic speech recognition applied to an input signal, the method comprising the steps of: extracting one or more features from said input signal to generate a sequence of extracted feature values; applying a filter to said sequence of extracted feature values to generate a sequence of filter output values; applying a state transition diagram to said sequence of filter output values to identify endpoints within said input signal.<br>15. An apparatus for performing real-time endpoint detection for use in automatic speech recognition applied to an input signal, the apparatus comprising: means for extracting one or more features from said input signal to generate a sequence of extracted feature values; a filter applied to said sequence of extracted feature values which generates a sequence of filter output values; a state transition diagram applied to said sequence of filter output values which identifies endpoints within said input signal.</p></layer>
<layer id = "layer246"><p><b>US3649765A:SPEECH ANALYZER-SYNTHESIZER SYSTEM EMPLOYING IMPROVED FORMANT EXTRACTOR</b><br>The present invention provides a method for diagnosing breast cancer comprising or consisting of the steps of (a) providing a sample to be tested; and (b) determining a biomarker signature of the test sample by measuring the presence and/or amount in the test sample of one or more biomarker selected from the group defined in Table A(i) and/or Table A(ii); wherein the presence and/or amount in the test sample of the one or more biomarker selected from the group defined in Table A(i) and/or Table A(ii) is indicative of the presence of breast cancer cells in the individual, corresponding uses, methods of treating breast cancer, together with arrays and kits for use in the same.<br><b>Independant Claims</b><br>7) What is claimed is: 
Apparatus for analyzing speech frequency signals, which comprises: means for counting the zero axis crossings of an applied speech signal, means for developing a signal representative of the cepstrum of said speech signal, and means responsive to said zero crossing count and to said cepstrum signal for determining therefrom the voiced-unvoiced character of said speech signal and, if voiced, the pitch period of said signal.<br>1) Speech analysis apparatus for locating formants of a voiced speech signal, which comprises: means supplied with a speech signal for developing a signal representative of a smoothed spectral envelope thereof, means supplied with said spectral envelope signal for developing signals representative of the location and amplitude of peaks within assigned frequency ranges in said speech signal, said ranges being selected to encompass a prescribed frequency range of said speech signal with predetermined segments of overlap and means responsive to said peak representative signals for selecting as formants of said speech signal the highest amplitude peaks according to location within said ranges.<br>2) Speech analysis apparatus for locating formants of voiced speech signals, which comprises: means for developing a signal representative of the cepstrum of an applied speech signal, means for developing from said cepstrum signal a signal representative of the spectral envelope of said speech signal, means for evaluating said spectral envelope signal along a contour close to the pole locations in the complex frequency plane thereby to produce a signal in which spectrum peaks are sharpened, means responsive both to said spectral envelope signal and selectively to said cepstrum signal for developing signals representative of the location and amplitude of all peaks in said spectral envelope signal, means responsive to said peak location signal for selecting and ordering in frequency the highest of said amplitude peaks, and means for identifying said selected and ordered peak location signals as formants of said applied signal.<br>3) Speech analysis apparatus for locating formants of a voiced speech signal, which comprises: means for developing a signal representative of the smoothed spectral envelope of an applied speech signal, means for locating all peaks in said spectral envelope signal, means for developing signals representative of the location and amplitude of each of said located peaks within assigned frequency ranges, said ranges being selected to encompass a selected frequency range of said applied signal with prescribed segments of overlap, means responsive to said peak location signals for selecting the highest amplitude peak in each of said ranges, means for identifying as formants of said applied signal said selected peaks which occur in nonoverlapping segments of said ranges, and means for identifying as formants of said applies signal the highest amplitude peaks according to their location, which occur in overlapping segments of said ranges.<br>5) Speech analysis apparatus for locating formants of voiced speech signals, which comprises: means for developing a signal representative of the pitch period of an applied speech signal, means for selectively weighting said applied speech signals with a symmetric window function of said pitch period signal, means supplied with said weighted speech signal for developing a signal representative of the smoothed spectral envelope of said applies speech signal, means for locating all peaks in said spectral envelope signal, means for developing signals representative of the location and amplitude of each of said located peaks within assigned frequency ranges, means responsive to said peak location signals for selecting the highest amplitude peak in each of said ranges, means for identifying as formants of said applied signal said selected peaks which occur in nonoverlapping segments of said ranges, and means for identifying as formants of said applied signal the highest amplitude peaks according to their location, which occur in overlapping segments of said ranges.<br>8) A speech signal analyzer system for producing coded signals from applied speech signals, which comprises: means for developing a signal representative of the smoothed spectrum of an applied speech signal, means for locating all peaks in said spectrum, means responsive to said located peaks and selectively to said spectrum for developing, during voiced intervals of said speech signal, control signals representative of the location of the highest of said spectrum peaks in a prescribed order as formants of said applied signal, means responsive to said spectrum for developing control signals representative of the level of said applied signal during voiced and unvoiced intervals, respectively, means for developing a signal representative of the cepstrum of said applied speech signal, means responsive to a count of zero axis crossings in said applied signal and to said cepstrum for developing a signal representative of the voicing character of said applied signal and the pitch period of voiced intervals thereof, means responsive to said peak signals for developing a signal representative of the pole and zero locations for unvoiced intervals of said applied signal, and means for utilizing all of said developed signals as a coded representation of said applied speech signal.<br>9) A speech signal analyzer-synthesizer system with reduced channel bandwidth requirements, which comprises: at an analyzer station, means for developing a signal representative of the smoothed spectrum of an applied speech signal, means for locating all peaks in said spectrum, means responsive to an indication of said located peaks and selectively to said spectrum signal for developing, during voiced intervals of said speech signal, control signals representative of the location of the highest of said amplitude peaks in a prescribed order as formants of said applied signal, means responsive to said spectrum signal for developing signals representative of the level of said applied signal during voiced and unvoiced intervals, respectively, means for developing a signal representative of the cepstrum of said applied signal, means responsive to a count of zero axis crossings in said applied signal and to said cepstrum signal for developing signals representative of the voicing character of said applied signal and the pitch period of voiced intervals thereof, means responsive to said peak signals for developing signals representative of the pole and zero locations for unvoiced intervals of said applied signal, and means responsive to all of said developed signals for delivering them to a synthesizer station, and at said synthesizer station, means responsive to received unvoiced level control signals for adjusting the level of a source of noise signals, a system of unvoiced resonant circuits energized by said adjusted noise signals, means for adjusting said resonant system with said pole and zero location signals to produce an unvoiced signal, generator means responsive to said pitch period control signal for developing pulses at pitch frequency, means for adjusting the amplitude of said pulses according to said level control signal during voiced signals of said applied signal, a system of resonant circuits energized by said control pulse signals and by said formant signals to produce a voiced signal, means for combining said voiced and unvoiced signals, means for shaping the spectrum of said combined signal, and means for utilizing said shaped spectrum signal as a replica of said applied speech signal.</p></layer>
<layer id = "layer247"><p><b>US6035048A:Method and apparatus for reducing noise in speech and audio signals</b><br>A portable display apparatus and method for transporting and displaying sample products along with an electronic device is disclosed. The portable display apparatus comprises a container, a platform, and a cover, wherein the cover is removably attached to the container. Removal of the cover allows for both a display portion and compartments within the container to be accessed. The present invention is useful in presenting a product to prospective customers at any location necessary.<br><b>Independant Claims</b><br>1. A method for enhancing, within a signal bandwidth, a corrupted audio-frequency signal having a signal component and a noise component, the method comprising: analyzing the corrupted signal into plural sub-band signals, each occupying a frequency sub-band smaller than the signal bandwidth; applying a respective signal gain function to the sub-band signal corresponding to each sub-band, thereby to yield respective gain-modified signals; and synthesizing the gain-modified signals into an enhanced signal of the signal bandwidth; wherein: (a) within each frequency sub-band, the step of applying a respective signal gain function to a corresponding sub-band signal comprises evaluating a function that is preferentially sensitive to energy in the signal component; (b) within each frequency sub-band, said applying step further comprises applying gain values to the corresponding sub-band signal, wherein said gain values are related to said preferentially sensitive function; and (c) the step of evaluating the preferentially sensitive function comprises measuring a relative amount of speech energy within the corresponding sub-band, and measuring a relative amount of speech energy within a frequency range greater than, but centered on, the corresponding sub-band.<br>11. A method for enhancing, within a signal bandwidth, a corrupted audio-frequency signal having a signal component and a noise component, the method comprising: analyzing the corrupted signal into plural sub-band signals, each occupying a frequency sub-band smaller than the signal bandwidth; applying a respective signal gain function to the sub-band signal corresponding to each sub-band, thereby to yield respective gain-modified signals; and synthesizing the gain-modified signals into an enhanced signal of the signal bandwidth, wherein: (a) within each frequency sub-band, the step of applying a respective signal gain function to a corresponding sub-band signal comprises evaluating a function that is preferentially sensitive to energy in the signal component; (b) within each frequency sub-band, the step of applying further comprises applying gain values to the corresponding sub-band signal, wherein the gain values are related to the preferentially sensitive function; (c) the step of evaluating the preferentially sensitive function comprises: measuring speech energy; and measuring noise energy within the corresponding sub-band; (d) the step of measuring noise energy comprises evaluating a noise estimate in response to a recursive function of a sampled sub-band input is updated if a test is satisfied at sampled intervals (e) such that an update of a current noise estimate is generated if a new sample of the corrupted signal is less than a product of a multiplier and the current noise estimate, and is prevented if the new sample exceeds the product.<br>12. A method for enhancing, within a signal bandwidth, a corrupted audio-frequency signal having a signal component and a noise component, the method comprising: analyzing the corrupted signal into plural sub-band signals, each occupying a frequency sub-band smaller than the signal bandwidth; applying a respective signal gain function to the sub-band signal corresponding to each sub-band, thereby to yield respective gain-modified signals; and synthesizing the gain-modified signals into an enhanced signal of the signal bandwidth, wherein: (a) within each frequency sub-band, the step of applying a respective signal gain function to a corresponding sub-band signal comprises evaluating a function that is preferentially sensitive to energy in the signal component; (b) within each frequency sub-band, the step of applying further comprises applying gain values to the corresponding sub-band signal, wherein the gain values are related to the preferentially sensitive function; (c) the step of evaluating the preferentially sensitive function comprises: measuring speech energy; and measuring noise energy within the corresponding sub-band; (d) the step of measuring noise energy comprises evaluating a noise estimate in response to a recursive function that is updated at least at sample intervals; (e) the value of the noise estimate is limited by an upper bound that is matched to the dynamic range of the corrupted signal to be enhanced; and (f) the gain values are derived from one or more ratios of a sub-band signal estimate to a sub-band signal noise estimate.</p></layer>
<layer id = "layer248"><p><b>US6044343A:Adaptive speech recognition with selective input data to a speech classifier</b><br>At a time Tp when a wafer W is transferred into either a load lock chamber LL<b>1 </b>or LL<b>2</b>, periods PSL for the load lock chambers LL<b>1 </b>and LL<b>2 </b>to get ready to permit a transfer of a next wafer W thereinto are calculated based on a timing for exchange of wafers W between the load lock chamber LL<b>1 </b>or LL<b>2 </b>and a loader module LM. When the periods PSL are calculated, a loader arm LA<b>1 </b>or LA<b>2 </b>selects a next wafer W having the shortest period to get ready to be transferable into the load lock chamber LL<b>1 </b>or LL<b>2</b>, from load ports LP<b>1 </b>to LP<b>3</b>. This improves transfer delay in a cluster tool provided with the load lock chambers.<br><b>Independant Claims</b><br>1. A speech recognition system comprising: a first speech signal preprocessor to receive first input data representing a speech input signal and having first speech input signal preclassifying output data; a second speech signal preprocessor to receive second input data representing the speech input signal and having second speech input signal preclassifying output data; a mixer to receive the first and second speech input signal preclassifying output data and having output data represented by a selected mix of the first and second speech input signal preclassifying output data; a selection control circuit coupled to the mixer to determine the selected mix of the first and second speech input signal preclassifying output data by determining an appropriate balance between speech recognition accuracy of the speech recognition system and a speech recognition processing speed of the speech recognition system; and a speech classifier to receive the selected mix and having output data to classify the speech input signal as recognized speech.<br>14. A speech recognition system comprising: a speech input signal feature extractor to provide parameters representing features of T groups of N speech input signal frames; a vocabulary of u words; a matrix quantizer to receive the parameters and to provide (i) a series of observation sequences for each of the T groups of the N speech input signal frames and (ii) distance measure output data between the parameters and u respective matrix codebooks; a plurality of u hidden Markov models coupled to the matrix quantizer to receive the observation sequences; a Viterbi algorithm module to receive the observation sequences and provide respective probabilities that the respective hidden Markov models produced a respective observation sequence; a selection control circuit to determine when the distance measure output, the probabilities, and a combination of the distance measure output and the probabilities are included in a plurality of selected mixes by determining an appropriate balance between speech recognition accuracy of the speech recognition system and a speech recognition processing speed of the speech recognition system; a mixer coupled to the matrix quantizer and the Viterbi algorithm module for mixing the distance measure output and the probabilities into one set of mixed output data based on the selected mixes; and a neural network coupled to the mixer to receive the mixed output data set and determine which of the u vocabulary words most probably represents the speech input signal.<br>20. A speech recognition system comprising: means for processing first speech input signal data to preclassify the speech input signal and produce first preclassification output data, wherein the first speech input signal data represents a speech input signal; means for processing second speech input signal data to preclassify the speech input signal and produce second preclassification output data; means, coupled to both means for processing, for determining when to include the first speech input signal, the second speech input signal, and a combination of the first and second speech input signals in a preferred mix of the preclassification output data by determining an appropriate balance between speech recognition accuracy of the speech recognition system and a speech recognition processing speed of the speech recognition system; means, coupled to the means for determining, for mixing the first and second preclassification output data in accordance with the determined preferred mix; means, coupled to the means for mixing, for classifying the speech input signal based on the preferred mix of preclassification output data.<br>22. A speech recognition method comprising the steps of: processing first speech input signal data to preclassify the speech input signal and produce first preclassification output data, wherein the first speech input signal data represents a speech input signal; processing second speech input signal data to preclassify the speech input signal and produce second preclassification output data; determining when to include the first speech input signal, the second speech input signal, and a combination of the first and second speech input signals in a preferred mix of the preclassification output data by determining at least an appropriate balance between speech recognition accuracy and a speech recognition processing speed; mixing the first and second preclassification output data in accordance with the preferred mix; and classifying the speech input signal based on the preferred mix of preclassification output data.<br>32. A speech recognition system comprising: a first speech signal preprocessor to receive first input data representing a speech input signal and having first speech input signal preclassifying output data; a second speech signal preprocessor to receive second input data representing the speech input signal and having second speech input signal preclassifying output data; a mixer to receive the first arid second speech input signal preclassifying output data and having output data represented by a selected mix of the first and second speech input signal preclassifying output data; a non-neural network selection control circuit coupled to the mixer to determine when to include the first speech input signal, the second speech input signal, and a combination of the first and second speech input signals in the selected mix; and a speech classifier to receive the selected mix and having output data to classify the speech input signal as recognized speech.<br>33. A speech recognition system comprising: a first speech signal preprocessor to receive first input data representing a speech input signal and having first speech input signal preclassifying output data; a second speech signal preprocessor to receive second input data representing the speech input signal and having second speech input signal preclassifying output data; a mixer to receive the first and second speech input signal preclassifying output data and having output data represented by a selected mix of the first and second speech input signal preclassifying output data; a selection control circuit coupled to the mixer to determine when to include the first speech input signal, the second speech input signal, and a combination of the first and second speech input signals in the selected mix; a speech classifier to receive the selected mix and having output data to classify the speech input signal as recognized speech; and a noise level detector to provide a noise level parameter output signal to the selection control circuit.</p></layer>
<layer id = "layer249"><p><b>US6032116A:Distance measure in a speech recognition system for speech recognition using frequency shifting factors to compensate for input signal frequency shifts</b><br>A time-interleaved bandpass delta-sigma modulator is developed which includes a first adder and a second adder and a comparator. An input signal is transmitted to the first adder according to the clock frequency of each channel block, and an n channel block output u<sub>n </sub>of the first adder is transmitted to the first adder and the second adder of an n+2 channel block, and an n block output v<sub>n </sub>of the second adder is transmitted to the second adder of an n+2 block, and an output y<sub>n </sub>that passes through an n block comparator is transmitted to the first adder and the second adder of an n+2 block. Therefore, a modulator sequentially receives output from the comparator of each block for generating the final output y.<br><b>Independant Claims</b><br>1. A speech recognition system comprising: a line spectral pair generator to generate line spectral pair frequencies from a speech input signal; and a first speech classifier comprising: a quantizer for determining a distance measure between an ith speech input signal line spectral pair frequency and an ith reference speech signal line spectral pair frequency, wherein the distance measure, for i=1 to N.sub.1, is proportional to (i) a difference between the ith speech input signal line spectral pair frequency and the ith reference speech signal line spectral pair frequency and (ii) a shift of the difference by an ith frequency shifting factor to at least partially compensate for frequency shifting of the ith speech input signal line spectral pair frequency by acoustic noise, wherein N.sub.1 is greater than or equal to one and less than or equal to P; wherein the first speech classifier is capable of receiving output data based on the distance measures and is capable of generating speech classification output data for classifying the speech input signal.<br>14. A speech recognition system comprising: means for generating P order line spectral pair frequencies for a speech input signal; means for determining a difference, for i=1 to N.sub.1, between the ith line spectral pair frequency and an ith line spectral frequency of a reference speech signal; means for shifting the difference by an ith frequency shifting factor, for i=1 to N.sub.1, to at least partially compensate for frequency shifting of the ith speech input signal line spectral pair frequency by acoustic noise; means for determining a difference, for i=N.sub.1 +1 to P, between ith speech input signal line spectral pair frequency and the ith reference speech signal line spectral pair frequency; means for weighting of the difference by an ith frequency weighting factor, for i=N.sub.1 +1 to P, wherein ith frequency shifting and weighting factor is the error power spectrum of the speech input signal and a predicted speech input signal at the ith line spectral pair frequency of the speech input signal; and means for utilizing the shifted difference to classify the speech input signal.<br>18. A method of generating a robust distance measure in a speech recognition system comprising the steps of: generating P order line spectral pair frequencies for a speech input signal; determining a difference, for i=1 to N.sub.1, between the ith line spectral pair frequency and an ith line spectral frequency of a reference speech signal; shifting the difference, for i=1 to N.sub.1, by an ith frequency shifting factor to at least partially compensate for frequency shifting of the ith speech input signal line spectral pair frequency by acoustic noise; and utilizing the shifted difference to classify the speech input signal.<br>23. A method of robust speech recognition in an automotive environment comprising the steps of: receiving a speech input signal; representing the speech input signal with a vector .function. of P line spectral pair frequencies; representing a codeword in a quantizer codebook as a vector .function. of P line spectral pair frequencies; and determining a distance measure between the vector .function. and the vector .function., wherein the distance measure, d(.function.,.function.), is defined by: ##EQU29## wherein the constants .alpha..sub.1, .alpha..sub.2, .beta..sub.1 and .beta..sub.2 are set to substantially minimize quantization error, and e.sub.i is the error power spectrum of the speech input signal and a predicted speech input signal at the ith line spectral pair frequency of the speech input signal.<br>27. An apparatus comprising: a quantizer that receives speech input signal line spectral pair frequencies, that includes at least one codebook having reference speech signal line specral pair frequencies, and that determines a distance measure between an ith speech input signal line spectral pair frequency and an ith reference speech signal line spectral pair frequency, wherein the distance measure, for i=1 to N.sub.1, is proportional to (i) a difference between the ith speech input signal line spectral pair frequency and the ith reference speech signal line spectral pair frequency and (ii) a subtraction from the difference of an ith frequency shifting factor to at least partially compensate for frequency shifting of the ith speech input signal line spectral pair frequency by acoustic noise, wherein N.sub.1 is greater that or equal to one and less than or equal to P.</p></layer>
<layer id = "layer250"><p><b>US6026356A:Methods and devices for noise conditioning signals representative of audio information in compressed and digitized form</b><br>2-Thioindoles (2-selenoindoles) and analogous 2-indolinethione (2-indolineselenone) and polysulfide (selenide) compounds, salts thereof, methods of production, intermediates in their production, pharmaceutical compositions containing said compounds, and methods for inhibiting protein kinase dependent disease in a mammal or treating aberrant cell growth in a mammal, using said compositions, are disclosed.<br><b>Independant Claims</b><br>1. A signal processing apparatus, comprising: a) an input for receiving a signal derived from audible sound, the signal conveying a plurality of successive data frames, each data frame being representative of audio information in digitized and compressed form, each data frame including: a coefficient segment; an excitation segment; b) an output; c) a detector coupled to said input for distinguishing data frames containing speech sounds from data frames containing non-speech sounds; d) a noise conditioning device; e) a selector device capable of acquiring two operative conditions, namely a first operative condition and a second operative condition, said selector device being responsive to said detector for switching between the two operative conditions, when said detector distinguishes a data frame as containing speech sounds said selector acquiring the first operative condition, in said first operative condition said selector device causing transfer of a data frame to said output substantially without altering the coefficient segment of the data frame, when said detector distinguishes a data frame as containing non-speech sounds said selector acquiring the second operative condition, to transfer the data frame to said noise conditioning device, said noise conditioning device being operative for processing the coefficient segment of the data frame received by the noise conditioning device in dependence upon parameters of preceding data frames applied to said input to derive a noise conditioned coefficient segment, the noise conditioned coefficient segment having an impulse response being characterized by a first frequency domain behavior, said noise conditioning device being further operative for low pass filtering the impulse response of the noise conditioned coefficient segment to derive an output coefficient segment having an impulse response characterized by a second frequency domain behavior different from said first frequency domain behavior, said noise conditioning device being further operative to transfer the output coefficient segment to said output.<br>12. A method for serially reducing background noise artifacts in a signal derived from audible sound, the signal conveying a succession of data frames, each data frame being representative of audio information in digitized and compressed form, each data frame including a coefficient segment and an excitation segment, said method comprising: a) receiving the signal derived from audible sound; b) classifying each data frame in the signal as containing either one of speech sounds and non-speech sounds; c) transferring the data frames classified as containing speech sounds to an output; d) processing each frame classified as containing non-speech sounds to alter the coefficient segment thereof in dependence of coefficient segments of preceding data frames to effect a reduction in background noise artifacts in the frame classified as containing non-speech sounds to derive a noise conditioned coefficient segment, the noise conditioned coefficient segment having an impulse response being characterized by a first frequency domain behavior; e) low pass filtering the impulse response characterized by the first frequency domain behavior of the noise conditioned coefficient segment to derive an output coefficient segment having an impulse response characterized by a second frequency domain behavior different from said first frequency domain behavior; f) upon completion of the processing at steps d and e, transferring the data frame with an output coefficient segment to said output.<br>20. A communication system including: a) an encoder including an input for receiving a signal derived from audible sound, said encoder being operative to convert the signal into a succession of data frames representative of audio information in digitized and compressed form, each data frame including a coefficient segment and an excitation segment; b) a decoder remote from said encoder, said decoder including an input for receiving data frames representative of audio information in digitized and compressed form to convert the data frames into an audio signal; c) a communication path between said encoder and said decoder, said communication path allowing data frames generated by said encoder to be transported to the input of said decoder; d) a signal processing apparatus in said communication path for reducing background noise artifacts in data frames transported from said encoder toward said decoder, said signal processing apparatus comprising: an input for receiving the succession of data frames from said encoder; an output for issuing a succession of data frames toward the input of said decoder; a detector coupled to the input of said signal processing apparatus for distinguishing data frames containing speech sounds from data frames containing non-speech sounds; a noise conditioning device; a selector device capable of acquiring two operative conditions, namely a first operative condition and a second operative condition, said selector device being responsive to said detector for switching between the two operative conditions, when said detector distinguishes a data frame as containing speech sounds said selector acquiring the first operative condition, in said first operative condition said selector device causing transfer of a data frame to said output substantially without altering the coefficient segment of the data frame, when said detector distinguishes a data frame as containing non-speech sounds said selector acquiring the second operative condition, to transfer the data frame to said noise conditioning device, said noise conditioning device being operative for processing the coefficient segment of the data frame received by the noise conditioning device in dependence upon parameters of preceding data frames applied to said input to derive a noise conditioned coefficient segment, the noise conditioned coefficient segment having an impulse response being characterized by a first frequency domain behavior, said noise conditioning device being further operative for low pass filtering the impulse response of the noise conditioned coefficient segment to derive an output coefficient segment having an impulse response characterized by a second frequency domain behavior different from said first frequency domain behavior, said noise conditioning device being further operative to transfer the output coefficient segment to said output.</p></layer>
<layer id = "layer251"><p><b>US5630016A:Comfort noise generation for digital communication systems</b><br>The invention relates to a method for producing an installation for implementing a method for cryogenic air separation, whereby at least one constituent of the air used is obtained as a product by means of a selected method variant. Said installation comprises at least one coldbox in which a module is arranged. The invention is characterized in that several classes are predefined, each class determining the dimensions of the coldbox pertaining thereto, and the coldbox of each class being large enough to hold the module for at least two different product quantity requirements and/or at least two different method variants. A coldbox of a certain class is selected and the module is arranged in the coldbox of said selected class.<br><b>Independant Claims</b><br>1. A method of generating background noise during voice inactivity intervals in a communication system having a transmitter with an encoder for encoding and transmitting audio data, and a receiver remote from the transmitter with a decoder for receiving and decoding the transmitted audio data, said method comprising the steps of: encoding audio data in the transmitter and transmitting the encoded audio data to the receiver; detecting in the transmitter voice activity and voice inactivity; continuing transmission of encoded audio data during a predetermined time interval following each detection of voice inactivity; discontinuing transmission of encoded audio data at the expiration of each of said predetermined time intervals; resuming transmission of encoded audio data upon detection in the transmitter of voice activity; decoding in the remote receiver the encoded audio data received from the transmitter; detecting in the remote receiver voice activity and voice inactivity at the transmitter; processing in the receiver the decoded audio data including data received during each of said predetermined time intervals after the detection of voice inactivity in the transmitter, said processing step further comprising the steps of: deriving a first series of output signals corresponding to an average loudness level of received noise; deriving a second series of output signals having spectral shape attributes corresponding to the received noise; and combining the first and second series of derived signals to generate audible analog audio of varying loudness level representing background noise; wherein the deriving of the first and second series of signals includes weighting each of the first and second series of signals successively to vary the loudness level and spectral shape during periods of voice inactivity, the weighting of each of the first and second series of signals comprising multiplying each of the first series of signals by a first weighting factor and each of the second series of signals by a second weighting factor, the first and second weighting factors being varied to vary the loudness level and spectral shape; wherein the weighting each of the first and second series of signals successively includes repeatedly incrementing the value of the first weighting factor in steps from a minimum value to a maximum value and then decrementing the value of the first weighting factor from the maximum value to the minimum value; and repeatedly generating audible analog audio representing background noise based upon the audio data processed during each of said predetermined time intervals until the resumption of transmission of the encoded audio data.<br>3. A system for generating comfort noise for a digital communication system during a period of voice inactivity immediately following a period of voice activity based on received data representing background noise during said period of voice activity, comprising: a synthesis codebook having a first table of values corresponding to long term estimates of background noise; an excitation codebook having a second table of values corresponding to long term estimates of spectrally flattened background noise; means including the received data during each said period of voice inactivity and values from the first table of synthesis codebook for producing a first series of signals having a loudness level averaged over a plurality of frames of data; means including the received data during said period of voice inactivity and the second table of values from the excitation codebook for producing a second series of signals having spectral shape attributes corresponding to the received data; and means for combining the first and second series of signals to generate the background noise of varying amplitude during said period of voice inactivity, wherein the means for producing the first and second series of signals includes means for weighting each of the signals of the first and second series of signals, using a first and a second weighting factor, respectively, to vary the spectral shape and loudness level of the background noise, and wherein the value of the first weighting factor is repeatedly incremented in steps from a minimum value to a maximum value and then decremented from the maximum value to the minimum value.</p></layer>
<layer id = "layer252"><p><b>US20030009326A1:Frequency domain postfiltering for quality enhancement of coded speech</b><br><b>Independant Claims</b><br>1. A method of postfiltering a speech signal using linear predictive coefficients of the speech signal for enhancing human perceptual quality of the speech signal, the method comprising the steps of: generating a postfilter by performing a non-linear transformation of the linear predictive coefficients spectrum in the frequency domain; applying the generated postfilter to the synthesized speech signal in the frequency domain; and transforming the filtered frequency domain synthesized speech signal into a speech signal in the time domain.<br>10. A computer-readable medium having computer-readable instructions for performing steps to postfilter a synthesized speech signal using the linear predictive coefficients spectrum of the speech signal comprising the steps of: computing the tilt of the linear predictive coefficients spectrum; compensating the linear predictive coefficients spectrum using the computed tilt; generating a postfilter by executing a non-linear transformation of the compensated linear predictive coefficients spectrum in the frequency domain; and applying the generated postfilter to the synthesized speech signal in the frequency domain.<br>17. An apparatus for postfiltering a speech signal using a plurality of linear predictive coefficients of the speech signal for enhancing human perceptual quality of the speech signal, the apparatus comprising: a Fourier transformation module operable for conducting a Fourier transformation; an inverse Fourier transformation module operable for conducting an inverse Fourier transformation; and a formant filter comprising formant filter gains, wherein the gains are calculated in the frequency domain by performing a non-linear transformation of the linear predictive coefficients.<br>23. An apparatus for use with a postfilter for processing linear predictive coefficients of a signal and providing a frequency domain formant filter gains for a formant filter, the apparatus comprising: a linear predictive coefficients tilt computation module for computing the tilt of the linear predictive coefficients; a linear predictive coefficients tilt compensation module for compensating the linear predictive coefficients spectrum according to the computed tilt of the linear predictive coefficients spectrum; and a formant filter gain computation module for calculating the frequency domain formant filter gains according to the linear predictive coefficients, wherein the gains include a magnitude and a phase response.</p></layer>
<layer id = "layer253"><p><b>US20030004718A1:Signal modification based on continous time warping for low bit-rate celp coding</b><br>A liquid crystal display unit produces image carrying light through a liquid crystal layer having a positive anisotropy of refractive index; an optically compensating layer with a negative anisotropy of refractive index is provided on an optical path of the image carrying light so as to compensate the optical anisotropy of the liquid crystal, and the image carrying light is incident onto an optically diffusing layer after the optical compensation so as to widen the viewing angle of the liquid crystal display unit without deterioration of image contrast.<br><b>Independant Claims</b><br>1. A method of preparing a frame of a digital speech signal for compression comprising the steps of: producing a linear prediction residual for the frame, the linear prediction residual having irregularly spaced dominant peaks; dividing the residual into a series of contiguous, non-overlapping sections, each section containing not more than one dominant peak; deriving an idealized signal having a series of regularly-spaced dominant peaks located in a series of sequential sections; associating each section of the residual with a corresponding section of the idealized signal; calculating a linear continuous warp contour for each residual section based on a subset of possible last sample lag values for each residual section within a subrange of possible last sample lag values for each residual section; and modifying the residual by applying the calculated warp contour to the sections of the residual so that any dominant peak in each section of the residual aligns with the dominant peak in the corresponding section of the idealized signal, whereby dominant pitch peaks of the modified residual are regularly spaced, and no portion of any section of the residual is omitted or repeated in the modified residual.<br>10. An apparatus for modifying a speech signal prior to coding the speech signal, the apparatus comprising: a linear prediction coefficient extraction module for receiving a digital speech signal and for producing a set of linear prediction coefficients; an inverse synthesis filter for receiving the digital speech signal and the linear prediction coefficients and for producing a residual signal; a residual modification module for time warping the residual signal based on a continuous linear warp contour selected from the set of all possible warp contours by calculating only a subset of all possible warp contours, whereby a modified residual signal having a regular rather than irregular array of dominant peaks is produced; and a synthesis filter for receiving the modified residual signal and the linear prediction coefficients for producing a modified digital speech signal suitable for low bit rate coding.<br>12. A computer readable medium having computer readable instructions for performing a method of preparing a frame of a digital speech signal for compression comprising the steps of: producing a linear prediction residual for the frame, the linear prediction residual having irregularly spaced dominant peaks; dividing the residual into a series of contiguous, non-overlapping sections, each section containing not more than one dominant peak; deriving an idealized signal having a series of regularly-spaced dominant peaks located in a series of sequential sections; associating each section of the residual with a corresponding section of the idealized signal; calculating a linear continuous warp contour for each residual section based on a subset of possible last sample lag values for each residual section within a subrange of possible last sample lag values for each residual section; and modifying the residual by applying the calculated warp contour to the sections of the residual so that any dominant peak in each section of the residual aligns with the dominant peak in the corresponding section of the idealized signal, whereby dominant pitch peaks of the modified residual are regularly spaced, and no portion of any section of the residual is omitted or repeated in the modified residual.</p></layer>
<layer id = "layer254"><p><b>US4776014A:Method for pitch-aligned high-frequency regeneration in RELP vocoders</b><br>Mounting arrangement for the mirror member of an outside rear view mirror assembly characterized in that a mounting plate is provided that includes a support surface to which the mirror member is fixedly connected and also includes a bracket which adjustably connects the mirror member to a tubular support.<br><b>Independant Claims</b><br>1. A method for the pitch-aligned high-frequency regeneration (PA-HFR) of a speech signal, decimated at a known decimation ratio N, in the receiver portion of a RELP vocoder, comprising the steps of: (a) providing at least one local carrier signal, each at a frequency which is an exact integer multiple of a baseband pitch estimate frequency f.sub.f recovered from received data; (b) amplitude modulating each of the local carrier signals with baseband residual data, recovered in the receiver portion, to provide partial spectrum data; (c) removing, only if the decimation ratio N is even, the lower sideband data from the lowest frequency local carrier signal to obtain partial spectrum data; and (d) adding the residual baseband data to the partial spectrum data obtained in step (b), if N is odd, or step (c), if N is even, to obtain PA-HFRed output data from which to reconstruct the speech signal.</p></layer>
<layer id = "layer255"><p><b>US4771465A:Digital speech sinusoidal vocoder with transmission of only subset of harmonics</b><br>A heating element protection apparatus for a mass-flow sensor may include a heating element disposed in a gas, a gas temperature sensor disposed in the gas to sense a temperature of the gas, a slope detector to measure a slope of the temperature as power is supplied to the heating element, and a heating element controller to supply power to the heating element to replace heat dissipated by the gas. The heating element controller may detect a temperature of the heating element and may supply power to the heating element based on the heating element temperature and the gas temperature, and the power may be switched off for a predetermined period of time if a magnitude of the slope is greater than a reference magnitude.<br><b>Independant Claims</b><br>1. A processing system for synthesizing voice from encoded information representing speech frames each having a predetermined number of evenly spaced samples of instantaneous amplitude of speech with said encoded information for each frame representing frame energy and a set of speech parameters and a fundamental frequency signal of the speech and offset signals representing the difference between the theoretical harmonic frequencies as derived from a fundamental frequency signal and a subset of the actual harmonic frequencies, said system comprising: means responsive to the offset signals and the fundamental frequency signal of one of said frames for calculating a subset of harmonic phase signals corresponding to said offset signals; means responsive to said fundamental frequency signal for computing the remaining harmonic phase signals for said one of said frames; means responsive to the frame energy and the set of speech parameters of said one of said frames for determining the amplitudes of said fundamental signal and said subset of said harmonic phase signals and said remaining harmonic phase signals; and means for generating replicated speech in response to said fundamental signal and said subset of said harmonic phase signals and said remaining harmonic phase signals and the determined amplitudes for said one of said frames.<br>14. A processing system for encoding human speech comprising: means for segmenting the speech into a plurality of speech frames, each having a predetermined number of evenly spaced samples of instantaneous amplitudes of speech and each of which overlaps by a predefined number of samples with the previous and subsequent frames; means for calculating a set of speech parameter signals defining a vocal tract for each frame; means for calculating the frame energy per frame of the speech samples; means for performing a spectral analysis of said speech samples of each frame to produce a spectrum for each frame; means for detecting the fundamental frequency signal for each frame from the spectrum corresponding to each frame; means for determining a subset of harmonic frequency signals for each frame from the spectrum corresponding to each frame; means for determining offset signals representing the difference between each of said harmonic frequency signals and multiples of said fundamental frequency signal; and means for transmitting encoded representations of said frame energy and said set of speech parameters and said fundamental frequency signal and said offset signals for subsequent speech synthesis.<br>19. A method for synthesizing voice from encoded information representing speech frames each having a predetermined number of evenly spaced samples of instantaneous amplitude of speech with said encoded information for each frame comprising frame energy and a set of speech parameters and a fundamental frequency of speech and offset signals representing the difference between the theoretical harmonic frequencies as derived from a fundamental frequency signals and a subset of actual harmonic frequencies, comprising the steps of: calculating a subset of harmonic phase signals corresponding to said offset signals; computing the remaining harmonic phase signals for said one of said frames from said fundamental frequency signal; determining the amplitudes of said fundamental signal and said subset of harmonic phase signals and said remaining harmonic phase signals from the frame energy and the set of speech parameters of said one of said frame; and generating replicated speech in response to said fundamental signal and said subset and remaining harmonic phase signals and said determined amplitudes for said one of said frames.</p></layer>
<layer id = "layer256"><p><b>US5351338A:Time variable spectral analysis based on interpolation for speech coding</b><br>The present invention pertains to a design for a carton blank for significantly enhancing the seal of a carton for packaging semi-liquids such as ice cream or the like without compromising the adaptability of the carton blank to mechanical folding devices. The carton blank includes front, bottom rear, and cover panels. A closure flap is hingedly connected to a top edge of the cover panel. The closure flap includes a tear strip for enabling a consumer to readily gain access to the contents of the carton. An end flap extends from each edge of the cover, rear, bottom and front panels. A cover or glue tab extends from each edge of the closure flap. A membrane extends from each of the front panel end flaps and the front panel for forming a substantially continuous lip about a potion of the outer periphery of the carton. The front panel membrane includes notches or recess at each end for receiving the corresponding ends of the front panel end flap membranes.<br><b>Independant Claims</b><br>1. A method of linear predictive coding analysis and interpolation of uninterpolated input signal frames using time variable spectral models, the method comprising the steps of: sampling a signal to obtain a series of discrete samples and constructing therefrom a series of frames; modeling the spectrum of said signal using a filter model utilizing interpolation of parameter signals between a previous, present and next frame for forming estimated parameters; calculating regressor signals from said estimated parameters; smoothing the spectrum by combining the regressor signals with a smoothing parameter to obtain smoothed regressor signals; combining said smoothed regressor signals with weighting factors to produce a first set of signals; combining parameter signals from the previous frame with said smoothed regressor signals, a signal sample and a weighting factor to produce a second set of signals; calculating parameter signals for the present frame and the next frame from the first and second set of signals; determining whether the filter model is stable after each frame; and stabilizing the filter model if the filter model is determined to be unstable.<br>35. A method of linear predictive coding analysis and interpolation of uninterpolated input signal frames using time variable spectral models, the method comprising: sampling a signal to obtain a series of discrete samples and constructing therefrom a series of frames; modeling the spectrum of said signal using a filter model utilizing interpolation of parameters between a previous, present and next frame for forming estimated parameters; calculating regressor signals from said estimated parameters; smoothing the spectrum by combining the regressor signals with a smoothing parameter to obtain smoothed regressor signals; combining said smoothed regressor signals with a weighting factor to produce a first set of signals; combining parameter signals from the previous frame with said smoothed regressor signals, a signal sample and a weighting factor to produce a second set of signals; calculating parameter signals for the present frame from the first and second set of signals; determining whether the filter model is stable after each frame; stabilizing the filter model if the filter model is determined to be unstable.<br>69. A method of signal coding, the method comprising: determining a first spectral analysis of signal frames using time variable spectral models and utilizing interpolation of spectral parameters between frames; determining a second spectral analysis using time invariant spectral models; comparing the first analysis to the second spectral analyses to determine which spectral analysis has the highest quality; and selecting the spectral analysis with the highest quality to code the signal.</p></layer>
<layer id = "layer257"><p><b>US20030074192A1:Phase excited linear prediction encoder</b><br>A screen assembly for a vibratory screening machine including a plurality of superimposed screens, channels on the edges of the screen assembly, and a plurality of hollow plastic channeling strips fused into the plurality of superimposed screens. The hollow channeling strips may have metal rods therein, and the plurality of superimposed screens may be bonded to an apertured plate. A method of fabricating a screen assembly for a vibratory screening machine including the steps of laying a plurality of plastic tubes into grooves of a fixture, superimposing the plurality of screens over the plastic tubes, and applying a heated platen to the screens to thereby cause the plastic tubes to fuse into the screens. The hollow plastic tubes may have metal rods therein, and the plurality of screens may be bonded to an apertured plate before the hollow plastic tubes are bonded to the screens.<br><b>Independant Claims</b><br>1. A speech encoder, comprising: a content extraction module including, a band pass filter that receives a speech input signal and generates a band limited speech signal, a first speech buffer connected to the band pass filter that stores the band limited speech signal, an LP analysis block connected to the first speech buffer that reads the stored speech signal and generates a plurality of LP coefficients therefrom, an LPC to LSF block connected to the LP analysis block for converting the LP coefficients to a line spectral frequency (LSF) vector, an LP analysis filter connected to the LPC to LSF block that extracts an LP residual signal from the LSF vector; and an LSF quantizer connected to the LPC to LSF block that receives the LSF vector and determines an LSF index therefor; a pitch detector connected to the LP analysis block of the content extraction module, the pitch detector classifying the band filtered speech signal as one of a voiced signal and an unvoiced signal; and a naturalness enhancement module connected to the content extraction module and the pitch detector, the naturalness enhancement module including, means for extracting parameters from the LP residual signal, wherein for an unvoiced signal the extracted parameters include pitch and gain and for a voiced signal the extracted parameters include pitch, gain and excitation level; and a quantizer for quantizing the extracted parameters and generating quantized parameters.<br>3. The speech encoder of claim 3, wherein the IIR filter includes a fourth order low-pass section and a fourth order high pass section.<br>7. The speech encoder of claim 7, wherein a bandwidth expansion block expands the plurality of LP coefficients to generate bandwidth expanded LP coefficients.<br>22. A content extraction module for a speech encoder, the content extraction module comprising: a band pass filter that receives a speech input signal and generates a band limited speech signal, a first speech buffer connected to the band pass filter that stores the band limited speech signal, an LP analysis block connected to the first speech buffer that reads the stored speech signal and generates a plurality of LP coefficients therefrom, an LPC to LSF block connected to the LP analysis block for converting the LP coefficients to a line spectral frequency (LSF) vector, an LP analysis filter connected to the LPC to LSF block that extracts an LP residual signal from the LSF vector; and an LSF quantizer connected to the LPC to LSF block that receives the LSF vector and determines an LSF index therefor.<br>30. A naturalness enhancement module for a speech encoder, wherein the speech encoder includes a pitch detector for determining whether an input speech signal is a voiced signal or an unvoiced signal and a content extraction module for generating an LP residual signal from the input speech signal, the naturalness enhancement module comprising: means for extracting parameters from the LP residual signal, wherein for an unvoiced signal the extracted parameters include pitch and gain and for a voiced signal the extracted parameters include pitch, gain and excitation level; and a quantizer for quantizing the extracted parameters and generating quantized parameters.<br>37. A pitch detector for a speech encoder, the pitch detector comprising: a first operation level for analyzing a speech signal and, based on a first predetermined ambiguity value of the speech signal, generating a first estimated pitch period; and a second operation level for analyzing the speech signal and, based on a second predetermined ambiguity value of the speech signal, generating a second estimated pitch period.<br>44. A speech signal preprocessor for preprocessing an input speech signal prior to providing said speech signal to a speech encoder, the preprocessor comprising: a band pass filter that receives said speech input signal and generates a band limited speech signal; and a scale down unit connected to the band pass filter for limiting a dynamic range of the band limited speech signal.<br>48. A method of encoding a speech signal, comprising the steps of: filtering the speech signal to limit a bandwidth thereof; fragmenting the filtered speech signal into speech segments; decomposing the speech segments into a spectral envelope and an LP residual signal, wherein the spectral envelope is represented by a plurality of LP filter coefficients (LPC); converting the LPC into a plurality of line spectral frequencies (LSF); classifying each speech segment as one of a voiced segment and an unvoiced segment based on a pitch of the segment; extracting parameters from the LP residual signal, wherein for an unvoiced segment the extracted parameters include pitch and gain and for a voiced segment the extracted parameters include pitch, gain and excitation level; and quantizing the extracted parameters and generating quantized parameters.</p></layer>
<layer id = "layer258"><p><b>US6122384A:Noise suppression system and method</b><br>A soldering iron including an insulator, a dissipator, and a hollow, cylindrical handle through which the electrical cable travels, and in which the wires, extending from the electrical cable and connected to the heater unit by individual plug and socket connectors, are able to move freely for making it easier to exchange the heating element but prevent the wires from being accidentally disconnected by pulling on the electrical cord during use. More specifically, a single electrical insulator body, which fits inside the dissipator, receives all of the electrical connectors. Furthermore, the insulator provides unidirectional strain relief by trapping the wires against an inside tapered portion of the dissipator when mounted within the dissipator and releases the wires in the opposite direction simply by the act of being removed from the dissipator. Furthermore, the electrical insulator together with a minimal contact area joining of the dissipator to the handle serves to achieve a cool handpiece while making it possible to limit the use of expensive, high temperature resistant, static dissipative materials to only the dissipator, it being suitable to use high temperature resistant plastics that are not static dissipative for the electrical insulator and low temperature resistant, static dissipative plastic for the handle.<br><b>Independant Claims</b><br>1. A noise suppressor for suppressing the background noise of an audio signal, comprising: a signal to noise ratio (SNR) estimator for generating channel SNR estimates for a first predefined set of frequency channels of said audio signal; a gain estimator for generating a gain factor for each of said frequency channels based on a corresponding one of said channel SNR estimates, wherein said gain factor is derived using a gain function which defines gain factor as an increasing function of SNR; a gain adjuster for adjusting the gain level of each of said frequency channels based on said corresponding gain factor; and a speech detector for determining the presence of speech in said audio signal, wherein said speech detector uses the SNR estimator and a rate decision element to detect the presence of speech.<br>13. A noise suppressor for suppressing the background noise of an audio signal, comprising: means for detecting an encoding rate associated with said audio signal, wherein said audio signal is already encoded in accordance with the encoding rate; means for determining the presence of speech in said audio signal in accordance with the encoding rate; means for generating channel signal to noise ratio (SNR) estimates for a predefined set of frequency channels of said audio signal; means for determining a gain factor for each of said frequency channels if said means for determining the presence of speech determines that speech is present, wherein a gain function is defined for each of a set of frequency bands, and for each said frequency band, gain factor is defined to increase with increasing SNR, so that for each of said frequency channels, a channel gain factor is determined based on the gain function for the frequency band whose range contains the frequency channel; and means for adjusting the gain level of each of said frequency channels based on said corresponding channel gain factor.<br>26. A method for suppressing the background noise of an audio signal, comprising the steps of: transforming said audio signal into a frequency representation of said audio signal; detecting an encoding rate associated with said audio signal; determining the presence of speech in said audio signal from the encoding rate of said audio signal; generating channel signal to noise ratio (SNR) estimates for a predefined set of frequency channels of said frequency representation; determining a gain factor for each of said frequency channels if speech is determined to be present in said audio signal, wherein a gain function is defined for each of a set of frequency bands, and for each said frequency band, gain is defined to increase with increasing SNR, so that for each of said frequency channels, a channel gain factor is determined based on the gain function for the frequency band whose range contains the frequency channel; adjusting the gain level of each of said frequency channels based on said corresponding channel gain factor; and inverse transforming said gain adjusted frequency representation to generate a noise suppressed audio signal.</p></layer>
<layer id = "layer259"><p><b>US6029133A:Pitch synchronized sinusoidal synthesizer</b><br>A COF flexible printed wiring board, used for a semiconductor device, contains an insulating layer, a wiring pattern formed of a conductor layer on one side of the insulating layer, on which a semiconductor chip is to be mounted, and a heat-resistant releasing layer, wherein the releasing layer is formed from a releasing agent and is provided on a surface of the insulating layer, which surface is opposite to the mounting side of the semiconductor chip, and the releasing layer and the insulating layer, as a whole, exhibit an optical transmittance of 50% or higher, excluding the area corresponding to the wiring pattern.<br><b>Independant Claims</b><br>1. A pitch synchronized sinusoidal synthesizer to produce excitation signals to artificially mimic human speech or acoustic signals from data, wherein said data comprises pitch frequencies of said human speech or acoustic signals for current and previous synthesizing frame samples, starting phase information for all harmonics of said human speech or acoustic signals within said current synthesizing frame sample, magnitudes for said harmonics, the voiced/unvoiced decisions for said harmonics, and an energy description of said synthesizing frame sample, comprising: a) a plurality of pitch interpolation means, wherein each pitch interpolation means receives said data and calculates a plurality of pitch period intervals of said human speech or acoustic signals within said synthesizing frame sample, an interpolated pitch frequency for each harmonic of said human speech or acoustic signals within said pitch period within each current synthesizing frame sample, an ending phase for each pitch period for said harmonics, a time period for each pitch period, and an interpolated magnitude of each harmonic during each pitch period; b) a plurality of resonator means coupled to said plurality of pitch interpolation means to produce a plurality of sinusoidal waveforms having the pitch frequency harmonics, time period and magnitude calculated by said pitch interpolation means for said human speech or acoustic signals; and c) a gain shaping means coupled to said plurality of resonator means to merge and amplify said plurality of sinusoidal waveforms according to said energy description, to produce said excitation signals for said human speech or acoustic signals.<br>9. A method for outputting speech by synthesizing excitation signals to artificially mimic human speech or acoustic signals from data, wherein said data comprises pitch frequencies of said human speech or acoustic signals for current and previous synthesizing frame samples, starting phase information for all harmonics of said human speech or acoustic signals within said current synthesizing frame sample, magnitudes for said harmonics, the voiced/unvoiced decisions for said harmonics, and an energy description of said synthesizing frame sample, comprising the steps of: a) receiving said data; b) interpolating pitch frequencies to create a plurality of pitch periods and pitch frequencies of said human speech or acoustic signals to prevent noise caused by sudden changes in data at synthesizing frame sample boundaries; c) interpolating magnitudes of each of the harmonics of said human speech or acoustic signals to prevent noise caused by sudden changes in magnitudes of harmonics for each pitch frequency; d) determining an end phase for each pitch frequency to allow smooth transition from a previous pitch frequency to a current pitch frequency; e) synthesizing a plurality of sinusoidal waveforms for said human speech or acoustic signals having the pitch frequency, harmonics, time period, and magnitude; f) merging and amplifying said plurality of sinusoidal waveforms according to said energy description to produce said excitation signals for said human speech or acoustic signals, and g) outputting the excitation signals to a transducer to reproduce said human speech or acoustic signals.</p></layer>
<layer id = "layer260"><p><b>US5913190A:Frame-based audio coding with video/audio data synchronization by audio sample rate conversion</b><br>An image reading device includes a plurality of photoelectric converting elements, a plurality of accumulating elements corresponding to each of the photoelectric converting elements, and switching circuitry for reading out the signals accumulated in the accumulating elements. Each of the photoelectric converting elements comprises a switching portion and a sensor portion. Driving circuitry is provided for driving the photoelectric converting elements by activating the switching portions to release the charges accumulated in the accumulating elements through the photoelectric converting elements in order to reset the accumulated elements.<br><b>Independant Claims</b><br>1. A method for processing an input audio signal comprising: receiving a signal conveying an input frame rate, receiving said input audio signal represented by samples at an input audio sample rate, generating an internal audio signal arranged in internal audio frames by converting the sample rate of said input audio signal to an internal audio sample rate that differs from said input audio sample rate, wherein said internal audio sample rate is equal to an internal frame rate multiplied by a quantity equal to an internal audio frame length less an internal audio frame overlap length, wherein said internal frame rate is equal to one-half of said input frame rate if said input frame rate is greater then 30 Hz and is equal to said input frame rate otherwise, said internal audio frame length is equal to said internal audio frame overlap length plus an integer multiple of a net block length, said net block length being equal to a block length less a block overlap length, generating an encoded audio signal arranged in a sequence of encoded audio frames, a respective encoded audio frame generated by encoding samples of a respective internal audio frame grouped into said integer number blocks each having said block length and overlapping one another by said block overlap length, and generating an output signal arranged in output signal frames by assembling information from a respective encoded audio frame into a respective output signal frame.<br>5. A method for signal processing comprising: receiving a signal conveying an input frame rate, receiving an input signal arranged in frames and obtaining from a respective frame of said input signal a frame of encoded audio information, generating an internal audio signal arranged in a sequence of internal audio frames at an internal audio sample rate, a respective internal audio frame generated by decoding a respective frame of encoded audio information, wherein said respective frame of encoded audio information comprises samples grouped into an integer number of blocks each having a block length and overlapping one another by a block overlap length, and wherein said respective internal audio frame has an internal audio frame length that is equal to an internal audio frame overlap length plus a product of said integer number and a net block length, said net block length being equal to said block length less said block overlap length, and generating an output audio signal by converting the sample rate of said internal audio signal to an output audio sample rate that differs from said internal audio sample rate that is equal to an internal frame rate multiplied by said internal audio frame length, wherein said internal frame rate is equal to one-half of said input frame rate if said input frame rate is greater then 30 Hz and is equal to said input frame rate otherwise.<br>9. A device for processing an input audio signal comprising: means for receiving a signal conveying an input frame rate, means for receiving said input audio signal represented by samples at an input audio sample rate, means for generating an internal audio signal arranged in internal audio frames by converting the sample rate of said input audio signal to an internal audio sample rate that differs from said input audio sample rate, wherein said internal audio sample rate is equal to an internal frame rate multiplied by a quantity equal to an internal audio frame length less an internal audio frame overlap length, wherein said internal frame rate is equal to one-half of said input frame rate if said input frame rate is greater then 30 Hz and is equal to said input frame rate otherwise, said internal audio frame length is equal to said internal audio frame overlap length plus an integer multiple of a net block length, said net bock length being equal to a block length less a block overlap length, means for generating an encoded audio signal arranged in a sequence of encoded audio frames, a respective encoded audio frame generated by encoding samples of a respective internal audio frame grouped into said integer number blocks each having said block length and overlapping one another by said block overlap length, and means for generating an output signal arranged in output signal frames by assembling information from a respective encoded audio frame into a respective output signal frame.<br>13. A device for signal processing comprising: means for receiving a signal conveying an input frame rate, means for receiving an input signal arranged in frames and obtaining from a respective frame of said input signal a frame of encoded audio information, means for generating an internal audio signal arranged in a sequence of internal audio frames at an internal audio sample rate, a respective internal audio frame generated by decoding a respective frame of encoded audio information, wherein said respective frame of encoded audio information comprises samples grouped into an integer number of blocks each having a block length and overlapping one another by a block overlap length, and wherein said respective internal audio frame has an internal audio frame length that is equal to an internal audio frame overlap length plus a product of said integer number and a net block length, said net block length being equal to said block length less said block overlap length, and means for generating an output audio signal by converting the sample rate of said internal audio signal to an output audio sample rate that differs from said internal audio sample rate that is equal to an internal frame rate multiplied by said internal audio frame length, wherein said internal frame rate is equal to one-half of said input frame rate if said input frame rate is greater then 30 Hz and is equal to said input frame rate otherwise.</p></layer>
<layer id = "layer261"><p><b>US6216103B1:Method for implementing a speech recognition system to determine speech endpoints during conditions with background noise</b><br>Creams formed from about 35% to about 50% fine particulates of certain poly(tetrafluoroethylene) (PTFE) resins dispersed in perfluorinated polyether oils having viscosities from about 20 cSt to about 350 cSt afford good protection against chemical warfare agents such as sulfur mustard (HD), lewisite (L), sulfur mustard/Lewisite mixtures (HL), pinacolyl methylphosphonofluoridate (soman or GD), thickened soman (TGD) and O-ethyl S-2-diisopropylaminoethyl methylphosphonothiolate (vx).<br><b>Independant Claims</b><br>1) A system for detecting endpoints of an event, comprising: a processor coupled to said system for receiving energy corresponding to said event; and an endpoint detector, responsive to said processor, for analyzing said energy to calculate threshold values and energy parameters, said endpoint detector comparing said threshold values with said energy parameters to identify a beginning point and an ending point of said event.<br>10) A system for detecting endpoints of an event, comprising: a processor coupled to said system for receiving energy corresponding to said event, said event being a spoken utterance and said energy being speech energy corresponding to said spoken utterance; and an endpoint detector, responsive to said processor, for analyzing said energy in sequential and contiguous frames which are each related to a corresponding sequential frame index to calculate threshold values and energy parameters which are short-term energy parameters corresponding to said frames of said speech energy, said endpoint detector comparing said threshold values with said energy parameters to identify a beginning point and an ending point of said event, said endpoint detector calculating a background noise value, said background noise value being equal to said short-term energy parameters during to a background noise period, said background noise period ending at least 250 milliseconds ahead of a reliable island and having a normalized deviation that is less than a predetermined value.<br>17) A system for detecting endpoints of an event, comprising: a processor coupled to said system for receiving energy corresponding to said event, said event being a spoken utterance and said energy being speech energy corresponding to said spoken utterance, an endpoint detector, responsive to said processor, for analyzing said energy in sequential and contiguous frames which are each related to a corresponding sequential frame index to calculate threshold values and short-term energy parameters corresponding to said frames of said speech energy, said speech energy including at least one reliable island in which said short-term energy parameters are greater than a starting threshold and a stopping threshold, said endpoint detector comparing said threshold values with said short-term energy parameters to identify a beginning point and an ending point of said event, and restart generation means to generate a restart signal for recalculating said starting threshold whenever a sequential energy ratio exceeds a predetermined constant value.<br>18) A system for implementing a speech recognition system, comprising: a feature extractor for receiving speech data corresponding to a spoken utterance and responsively generating channel energy and feature vectors; an endpoint detector for analyzing said channel energy to determine endpoints of said spoken utterance; and a recognizer for receiving said endpoints and said feature vectors and responsively generating a speech recognition result.<br>20) A system for implementing a speech recognition system, comprising: a feature extractor for receiving speech data corresponding to a spoken utterance and responsively generating channel energy and feature vectors, said feature extractor including a filter for band-passing said speech data to generate said channel energy; an endpoint detector for analyzing said channel energy to determine endpoints of said spoken utterance; a recognizer for receiving said endpoints and said feature vectors and responsively generating a speech recognition result; and restart generation means for generating a restart signal to said recognizer whenever a sequential energy ratio exceeds a predetermined constant value.<br>21) A method for detecting endpoints of an event, comprising the steps of: analyzing energy from said event to calculate threshold values and energy parameters; and comparing said threshold values with said energy parameters to identify a beginning point and an ending point of said event.<br>30) A method for detecting endpoints of an event, comprising the steps of: analyzing energy from said event using an endpoint detector to calculate threshold values and short-term energy parameters, said event being a spoken utterance and said energy being speech energy corresponding to said spoken utterance, said endpoint detector analyzing said speech energy in sequential and contiguous frames which are each related to a corresponding sequential frame index; and comparing said threshold values with said short-term energy parameters using said endpoint detector to identify a beginning point and an ending point of said event, said endpoint detector calculating a background noise value, said background noise value being equal to said short-term energy parameters during to a background noise period, said background noise period ending at least 250 millisecond ahead of a reliable island and having a normalized deviation that is less than a predetermined value.<br>37) A method for detecting endpoints of an event, comprising the steps of: analyzing energy from said event using an endpoint detector to calculate threshold values and short-term energy parameters, said event being a spoken utterance and said energy being speech energy corresponding to said spoken utterance, said speech energy including at least one reliable island in which said short-term energy parameters are greater than a starting threshold and a stopping threshold, said endpoint detector analyzing said speech energy in sequential and contiguous frames which are each related to a corresponding sequential frame index; comparing said threshold values with said short-term energy parameters using said endpoint detector to identify a beginning point and an ending point of said event; and using restart generation means for generating a restart signal to recalculate said starting threshold whenever an energy ratio exceeds a predetermined constant value.<br>38) A method for detecting endpoints of a spoken utterance, comprising the steps of: analyzing speech energy corresponding to said spoken utterance; calculating energy parameters in real time, said energy parameters corresponding to frames of said speech energy; determining a starting threshold corresponding to a reliable island in said speech energy; locating a starting point of said reliable island by comparing said energy parameters to said starting threshold; performing a refinement procedure to identify a beginning point for said spoken utterance; determining a stopping threshold corresponding to said reliable island in said speech energy; determining an ending threshold corresponding to said spoken utterance; comparing said energy parameters to said stopping threshold and to said ending threshold; and performing a refinement procedure to identify an ending point for said spoken utterance.<br>41) A method for implementing a speech recognition system, comprising the steps of: receiving speech data corresponding to a spoken utterance and responsively generating channel energy and feature vectors; analyzing said channel energy to determine endpoints of said spoken utterance; and receiving said endpoints and said feature vectors and responsively generating a speech recognition result.<br>43) A method for implementing a speech recognition system, comprising the steps of: receiving speech data corresponding to a spoken utterance and responsively generating channel energy and feature vectors; analyzing said channel energy to determine endpoints of said spoken utterance; receiving said endpoints and said feature vectors and responsively generating a speech recognition result; using a filter that band-passes said speech data to generate said channel energy; and using restart generation means for generating a restart signal whenever a sequential energy ratio exceeds a predetermined constant value.<br>44) A computer-readable medium comprising program instructions for detecting endpoints of an event by performing the steps of: analyzing energy from said event to determine threshold values and energy parameters; and comparing said threshold values with said energy parameters to identify a beginning point and an ending point of said event.<br>45) A computer-readable medium comprising program instructions for implementing a speech recognition system by performing the steps of: receiving speech data corresponding to a spoken utterance and responsively generating channel energy and feature vectors; analyzing said channel energy to determine endpoints of said spoken utterance; and receiving said endpoints and said feature vectors and responsively generating a speech recognition result.<br>46) A system for detecting endpoints of an event, comprising: means for analyzing energy from said event to determine threshold values and energy parameters; and means for comparing said threshold values with said energy parameters to identify a beginning point and an ending point said event.<br>47) A system for implementing a speech recognition system, comprising: means for receiving speech data corresponding to a spoken utterance and responsively generating channel energy and feature vectors; means for analyzing said channel energy to determine endpoints of said spoken utterance; and means for receiving said endpoints and said feature vectors and responsively generating a speech recognition result.</p></layer>
<layer id = "layer262"><p><b>US6070136A:Matrix quantization with vector quantization error compensation for robust speech recognition</b><br>In a method for controlling an induction motor <b>14</b>, in which the speed of the induction motor <b>14 </b>is controlled, by an inverter <b>21</b>, to move and stop an actuator <b>22 </b>at a predetermined position, a speed command <b>23 </b>to be input to the inverter <b>21 </b>is switched to an intermittent pulse signal <b>27 </b>when the actuator <b>22 </b>reaches a position B, a predetermined distance before, the predetermined position C. Thus, the system can be constructed at low cost, and sufficient practical positioning and stopping accuracy can be easily obtained.<br><b>Independant Claims</b><br>1. A speech recognition system comprising: a vector quantizer to receive first parameters of an input signal and generate a first quantization observation sequence; a first speech classifier to receive the first quantization observation sequence from the vector quantizer and generate first respective speech classification output data; a matrix quantizer to receive second parameters of the input signal and generate a second quantization observation sequence; a second speech classifier to receive the second quantization observation sequence from the matrix quantizer and generate second respective speech classification output data; and a hybrid decision generator to combine corresponding first and second respective speech classification data to generate third respective speech classification data and to recognize the input signal from the third respective speech classification data.<br>16. A speech recognition system comprising: a vector quantizer to receive line spectral pair input data corresponding to an input speech signal and to generate a first quantization observation sequence; first hidden Markov models to receive the first quantization observation sequence from the vector quantizer and generate first respective speech recognition probabilities from each of the first hidden Markov models; a matrix quantizer to receive temporally associated line spectral pair input data corresponding to the input speech signal and to generate a second quantization observation sequence; second hidden Markov models to receive the second quantization observation sequence from the matrix quantizer and generate second respective speech recognition probabilities from each of the second hidden Markov models; and a hybrid decision generator to utilize the first and second respective speech recognition probabilities to combine corresponding first and second speech recognition probabilities and to recognize the input signal from the combined corresponding first and second speech recognition probabilities.<br>20. An apparatus comprising: a first speech classifier to operate on first parameters of an input signal and provide first output data relating the input signal to reference data, wherein the input signal parameters include frequency and time domain parameters, wherein the first speech classifier further includes a first set of hidden Markov models; a second speech classifier to operate on second parameters of the input signal and to provide second output data relating the input signal to the reference data, wherein the second parameters of the input signal include the frequency domain parameters, the second speech classifier further includes a second set of hidden Markov models; and a hybrid decision generator to combine the first output data and the second output data so that the second output data compensates for errors in the first output data and to generate third output data to classify the input signal.<br>28. A method comprising: processing first parameters of an input signal using a first speech classifier, wherein the parameters include frequency and time domain parameters; providing first output data relating the input signal to reference data, wherein the first output data is provided from the first speech classifier to a second speech classifier; processing the first output data using the second speech classifier; providing second output data from the second speech classifier; processing second parameters of the input signal using a third speech classifier, wherein the parameters include frequency domain parameters; providing third output data relating the input signal to the reference data, wherein the third output data is provided from the third speech classifier to a fourth speech classifier; processing the third output data using the fourth speech classifier; providing fourth output data from the fourth speech classifier; combining the third output data and fourth output data to compensate for speech classification errors in the third output data; and classifying the input signal as recognized speech.<br>34. A method of recognizing speech comprising: receiving an input signal; determining parameters of the input signal; vector quantizing the parameters of the input signal to obtain first quantization output data; classifying the first quantization output data; matrix quantizing the parameters of the input signal to obtain second quantization output data; classifying the second quantization output data; and generating an identification of the input signal as recognized speech based upon the classification of the first and second quantization output data.<br>43. A method of recognizing speech comprising the steps of: receiving an input signal; determining P order line spectral pairs for TO frames of the input signal, wherein P and TO are integers; vector quantizing the P order line spectral pairs for each of the TO frames; classifying the input signal using the vector quantization of the P order line spectral pairs; matrix quantizing the P order line spectral pairs for T matrices of frames of the input signal, wherein T is defined as int(TO/N), and N is the number for input signal frames represented in each of the T matrices; classifying the input signal using the matrix quantization of the P order line spectral pairs; combining the classifications of the input signal to generate a combination of the classifications; and recognizing the input signal as particular speech from the combination of the classifications.</p></layer>
<layer id = "layer263"><p><b>US6067515A:Split matrix quantization with split vector quantization error compensation and selective enhanced processing for robust speech recognition</b><br>A book that is capable of displaying one or more coins related to its theme, including a front cover and a back cover. At least one book cover defines one or more apertures that are capable of receiving coins. The book theme is displayed on at least one of the book covers. The book may optionally include one or more caps that may be inserted into and removed from the coin-receivable apertures. These caps will preferably display images that are related to the theme of the book. The invention provides a coin specific display that stores and displays one or more coins in an appealing manner, and that also conveys or provides additional information about the theme displayed on the coin.<br><b>Independant Claims</b><br>1. A speech recognition system comprising: a split vector quantizer to receive first parameters of an input signal, to partition the first parameters into S.sub.1 partitions, and to generate a first quantization observation sequence; a first speech classifier to receive the first quantization observation sequence from the split vector quantizer and generate first respective speech classification output data; a split matrix quantizer to receive second parameters of the input signal, to partition the second parameters into S.sub.2 partitions, and generate a second quantization observation sequence; a second speech classifier to receive the second quantization observation sequence from the split matrix quantizer and generate second respective speech classification output data; and a hybrid decision generator to combine corresponding first and second respective speech classification data to generate third respective speech classification data and to recognize the input signal from the third respective speech classification data.<br>20. A speech recognition system comprising: a split vector quantizer to receive first parameters of an input signal, to partition the first parameters into S.sub.1 partitions to generate first quantization output data, wherein the first quantization output data includes a first observation sequence; a first speech classifier to receive the first quantization observation sequence from the split vector quantizer and generate first respective speech classification output data; a split matrix quantizer to receive second parameters of the input signal, to partition the second parameters into S.sub.2 partitions to generate second quantization output data, wherein the second quantization output data includes a second observation sequence; and a second speech classifier to receive the second quantization observation sequence from the split matrix quantizer and generate second respective speech classification output data; and a hybrid decision generator to combine corresponding first and second respective speech classification data to generate third respective speech classification data and to recognize the input signal from the third respective speech classification data.<br>24. A speech recognition system comprising: a split vector quantizer to receive line spectral pair input data corresponding to an input speech signal and to generate a first quantization observation sequence; first hidden Markov models to receive the first quantization observation sequence from the split vector quantizer and generate first respective speech recognition probabilities from each of the first hidden Markov models; a split matrix quantizer to receive temporally associated line spectral pair input data corresponding to the input speech signal and to generate a second quantization observation sequence; second hidden Markov models to receive the second quantization observation sequence from the split matrix quantizer and generate second respective speech recognition probabilities from each of the second hidden Markov models; and a hybrid decision generator to utilize the first and second respective speech recognition probabilities to generate input signal recognition information and to recognize the input speech signal from the input signal recognition information.<br>27. An apparatus comprising: a first speech classifier to operate on S.sub.1 partitions of first parameters of an input signal and to provide first output data relating the input signal to first reference data, wherein the input signal parameters include frequency and time domain parameters, wherein S.sub.1 is an integer greater than one and the first speech classifier further includes a first set of hidden Markov models; a second speech classifier to operate on S.sub.2 partitions of second parameters of the input signal and to provide second output data relating the input signal to second reference data, wherein the second parameters of the input signal include the frequency domain parameters, wherein S.sub.2 is an integer greater than one and the second speech classifier further includes a second set of hidden Markov models; and a hybrid decision generator to combine the first output data and the second output data so that the second output data compensates for errors in the first output data and to generate third output data to classify the input signal.<br>37. A method comprising: partitioning first parameters of an input signal into S.sub.1 partitions, wherein the parameters include frequency and time domain parameters; processing the partitioned first parameters of the input signal using a first speech classifier to relate the partitioned first parameters to first reference data; providing first output data relating the input signal to first reference data, wherein the first output data is provided from the first speech classifier to a second speech classifier; processing the first output data using the second speech classifier; providing second output data from the second speech classifier; partitioning second parameters of the input signal into S.sub.2 partitions, wherein the parameters include frequency domain parameters; processing the partitioned second parameters of the input signal using a third speech classifier to relate the partitioned second parameters to second reference data; providing third output data relating the input signal to the second reference data, wherein the third output data is provided from the third speech classifier to a fourth speech classifier; processing the third output data using the fourth speech classifier; providing fourth output data from the fourth speech classifier; combining the third output data and fourth output data to compensate for speech classification errors in the third output data; and classifying the input signal as recognized speech.<br>47. A method of recognizing speech comprising: receiving an input signal; determining parameters of the input signal; split vector quantizing the parameters of the input signal to obtain first quantization output data; classifying the first quantization output data using a first probabilistic process; split matrix quantizing the parameters of the input signal to obtain second quantization output data; classifying the second quantization output data using a second probabilistic process; and generating an identification of the input signal as recognized speech based upon the classification of the first and second quantization output data.<br>57. A method of recognizing speech comprising: receiving an input signal; determining D order line spectral pairs for TO frames of the input signal, wherein D and TO are integers; determining parameters related to the energy of the input signal, wherein the parameters related to the energy of the input signal include the input signal energy and a first derivative of the input signal energy; split vector quantizing the D order line spectral pairs for each of the TO frames and the parameters related to the input signal energy; classifying the input signal using the split vector quantization of the D order line spectral pairs; split matrix quantizing the D order line spectral pairs and the parameters related to the input signal energy for T matrices of frames of the input signal, wherein T is defined as int(TO.vertline.N), and N is the number for input signal frames represented in each of the T matrices; classifying the input signal using the split matrix quantization of the D order line spectral pairs and parameters related to the input signal energy; combining the classifications of the input signal to generate a combination of the classifications; and recognizing the input signal as particular speech from the combination of the classifications.</p></layer>
<layer id = "layer264"><p><b>US20030065506A1:Perceptually weighted speech coder</b><br><b>Independant Claims</b><br>1. A method of coding speech using perceptual weighting, the method comprising the steps of: sampling a speech signal; determining a pitch of the speech signal; characterizing the voiced quality of the speech signal; training a Lloyd-Max quantizer with the pitch values of those speech signals from the determining step characterized as being substantially fully voiced in the characterizing step; and quantizing the pitch values from the training step and the pitch values of those speech signals from the determining step not characterized as being substantially fully voiced in the characterizing step.<br>12. A method of coding speech using perceptual weighting, the method comprising the steps of: sampling a speech signal buffering the speech signal for a multiple of frames to be block quantized in subsequent steps, wherein the number of frames of speech being buffered is increased during periods of substantially voiced speech as determined in the subsequent steps; determining a pitch of the speech signal; characterizing the voiced quality of the speech signal; training a Lloyd-Max quantizer with the pitch values of those speech signals from the determining step characterized as being substantially fully voiced in the characterizing step; quantizing the pitch values from the training step and the pitch values of those speech signals from the determining step not characterized as being substantially fully voiced in the characterizing step; and synthesizing speech, wherein a substantially fully voiced speech signal is synthesized using a pitch periodic excitation train and a speech signal that is not substantially fully voiced is synthesized using a lowpass filtered pitch periodic excitation signal mixed with highpass white noise.<br>15. An apparatus for coding speech using perceptual weighting, the apparatus comprising: a buffer, the buffer inputs a speech signal and stores samples thereof; a pitch detector coupled to the buffer, the pitch detector determines a pitch of the speech signal; a voicing analyzer coupled to the pitch detector; the voicing analyzer characterizes the speech signal as to whether it is substantially fully voiced; and a Lloyd-Max quantizer coupled to the voicing analyzer and pitch detector, the quantizer is trained with and quantizes the pitch values of those speech signals from the voicing analyzer characterized as being substantially fully voiced, the quantizer also quantizes the pitch values of those speech signals from the pitch detector not characterized as being substantially fully voiced.</p></layer>
<layer id = "layer265"><p><b>US5528727A:Adaptive pitch pulse enhancer and method for use in a codebook excited linear predicton (Celp) search loop</b><br>Disclosed are processes and apparatus utilizing, choke means at least partially providing restriction to passage of material and measurement of magnitude of force(s) exterted on said choke means by passage of material, to provide: (1) an indication of characteristics of the material, and/or; (2) control of said passage of material and/or control or processes or apparatus associated with said passage of material in response to the magnitude of the measured force(s).<br><b>Independant Claims</b><br>1. An encoder for coding an input signal, comprising: adaptive codebook means for storing a variable set of excitation vectors; fixed codebook means for storing a fixed set of excitation vectors; codebook searching means for searching said adaptive codebook means to determine an optimal adaptive codebook excitation vector, and for searching said fixed codebook means to determine an optimal fixed codebook excitation vector; total excitation vector producing means for producing a total excitation vector from said optimal adaptive codebook excitation vector and said optimal fixed codebook excitation vector; voicing measure determining means for determining a voicing measure of said input signal, said voicing measure being voiced when said input signal includes voiced speech and said voicing measure being unvoiced when said input signal does not include voiced speech; and modifying means for modifying said total excitation vector by raising said total excitation vector to an exponent determined in accordance with said voicing measure of said input signal.<br>7. An adaptive pitch pulse enhancer for use in an encoder, the encoder including an adaptive codebook having a variable set of excitation vectors stored therein, a fixed codebook having a fixed set of excitation vectors stored therein, an adaptive codebook searching means for searching the adaptive codebook to determine an optimal adaptive codebook excitation vector, and a fixed codebook searching means for searching the fixed codebook to determine an optimal fixed codebook excitation vector, wherein said encoder produces a total excitation vector from the optimal adaptive codebook excitation vector and the optimal fixed codebook excitation vector, the adaptive pitch pulse enhancer comprising: voicing measure determining means for determining a voicing measure of an input signal, said voicing measure being voiced when said input signal includes voiced speech and said voicing measure being unvoiced when said input signal does not include voiced speech; and modifying means for modifying said total excitation vector by raising said total excitation vector to an exponent determined in accordance with said voicing measure of said input signal.<br>11. A method of coding an input signal comprising the steps of: storing a variable set of excitation vectors in an adaptive codebook; storing a fixed set of excitation vectors in a fixed codebook; searching said adaptive codebook to determine an optimal adaptive codebook excitation vector; searching said fixed codebook to determine an optimal fixed codebook excitation vector; producing a total excitation vector from said optimal adaptive codebook excitation vector and said optimal fixed codebook excitation vector; determining a voicing measure of said input signal, said voicing measure being voiced when said input signal includes voiced speech and said voicing measure being unvoiced when said input signal does not include voiced speech; and modifying said total excitation vector by raising said total excitation vector to an exponent determined in accordance with said voicing measure of said input signal.<br>18. In an encoder including an adaptive codebook having a variable set of excitation vectors stored therein, a fixed codebook having a fixed set of excitation vectors stored therein, an adaptive codebook searching means for searching the adaptive codebook to determine an optimal adaptive codebook excitation vector, and a fixed codebook searching means for searching the fixed codebook to determine an optimal fixed codebook excitation vector, said encoder producing a total excitation vector from the optimal adaptive codebook excitation vector and the optimal fixed codebook excitation vector, a method of enhancing a pitch pulse structure of the adaptive codebook comprising the steps of: determining a voicing measure of said input signal, said voicing measure being voiced when said input signal includes voiced speech and said voicing measure being unvoiced when said input signal does not include voiced speech; and modifying said total excitation vector by raising said total excitation vector to an exponent determined in accordance with said voicing measure of said input signal.<br>19. An encoder for coding an input signal, comprising: a first memory for storing an adaptive codebook of a variable set of excitation vectors; a second memory for storing a fixed codebook of a fixed set of excitation vectors; a search processor in communication with said first and said second memories for searching said adaptive codebook to determine an optimal adaptive codebook excitation vector, for searching said fixed codebook to determine an optimal fixed codebook excitation vector, and for producing a total excitation vector from said optimal adaptive codebook excitation vector and said optimal fixed codebook excitation vector; a voicing measurer for determining a voicing measure of said input signal, said voicing measure being voiced when said input signal includes voiced speech and said voicing measure being unvoiced when said input signal does not include voiced speech; and a filter in communication with said voicing measurer for modifying said total excitation vector by raising said total excitation vector to an exponent determined in accordance with said voicing measure of said input signal.</p></layer>
<layer id = "layer266"><p><b>US20030093278A1:Method of bandwidth extension for narrow-band speech</b><br>A double-sided circuit board of which a solder conductor is prevented from deformation in a cycling test so as to maintain high connection reliability, comprises an insulating layer <b>2 </b>made of an organic high molecular weight resin and a circuit <b>3 </b>provided on each side of the insulating layer <b>2, </b>the circuits <b>3 </b>on both sides being electrically connected through via-holes filled with a conductor <b>4 </b>made of solder having a metal powder <b>6 </b>dispersed therein.<br><b>Independant Claims</b><br>1. A method of producing a wideband signal from a narrowband signal, the method comprising: computing Mnb area coefficients from the narrowband signal; interpolating the Mnb area coefficients into Mwb area coefficients; generating a highband signal using the Mwb area coefficients; and combining the highband signal with the narrowband signal interpolated to the highband sampling rate to form the wideband signal.<br>8. A method of bandwidth extension of a narrowband signal, the method comprising: computing Mnb log-area coefficients from the narrowband signal; interpolating the Mnb log-area coefficients into Mwb log-area coefficients; generating a highband signal using the interpolated Mwb log-area coefficients; and combining the highband signal with the narrowband signal interpolated to the highband sampling rate to generate a wideband signal.<br>14. A method of extending the bandwidth of a narrowband signal, a preprocessing of the narrowband signal producing narrowband partial correlation coefficients (parcors), the method comprising: (1) computing Mnb area coefficients from the narrowband parcors; (2) computing Mnb log-area coefficients from the Mnb area coefficients; (3) obtaining Mwb log-area coefficients from the Mnb log-area coefficients; (4) computing Mwb area coefficients from the Mwb log-area coefficients; (5) computing wideband parcors from the Mwb area coefficients; (6) generating a highband signal using the wideband parcors; and (7) combining the highband signal with the narrowband signal interpolated to the highband sampling rate.<br>16. A method of producing a wideband signal from a narrowband signal, the method comprising: (1) computing narrowband linear predictive coefficients (LPCs) from the narrowband signal; (2) computing narrowband parcors ri associated with the narrowband LPCs; (3) computing Mnb area coefficients Ainb, i=1, 2, . . . , Mnb using the following: 27Ai=1+ri1-ri⁢Ai+1;i=Mnb,Mnb-1,…⁢ ,1, i=Mnb, Mnb−1, . . . , 1, where A1 corresponds to a cross-section at lips, AMnb+1 and corresponds to a cross-section of a vocal tract at a glottis opening; (4) extracting Mwb area coefficients from the Mnb area coefficients using interpolation; (5) computing wideband parcors using the Mwb area coefficients according to the following: 28riwb=Aiwb-Ai+1wbAiwb+Ai+1wb,i=1,2,…⁢ ,Mwb; (6) computing wideband LPCs aiwb, i=1, 2, . . . , Mwb, from the wideband parcors; and (7) synthesizing a wideband signal ywb using the wideband LPCs and an excitation signal.<br>25. A method of extending the bandwidth of a narrowband signal, the method comprising: (1) computing narrowband linear predictive coefficients (LPCs) from the narrowband signal; (2) computing narrowband parcors associated with the narrowband LPCs; (3) computing Mnb area coefficients using the narrowband parcors; (4) extracting Mwb area coefficients from the Mnb area coefficients using shifted-interpolation; (5) converting the Mwb area coefficients into wideband LPCs; and (6) synthesizing a wideband signal ywb using the wideband LPCs and an excitation signal.<br>30. A method of extending the bandwidth of a narrowband signal, the method comprising: (1) computing narrowband linear predictive coefficients (LPCs) from the narrowband signal; (2) computing Mnb area coefficients using the narrowband LPCs; (3) extracting Mwb area coefficients from the Mnb area coefficients using interpolation; (4) converting the Mwb area coefficients into wideband LPCs; and (5) synthesizing a wideband signal ywb using the wideband LPCs and highpass filtered white noise in the higher band of an excitation signal and a linear prediction residual signal in the lower band of the excitation signal.<br>32. A method of producing a wideband signal from a narrowband signal, the method comprising: (1) producing a wideband excitation signal from the narrowband signal; (2) computing partial correlation coefficients ri (parcors) from the narrowband signal; (3) computing Mnb area coefficients according to the following equation: 29Ai=1+ri1-ri⁢Ai+1;i=Mnb,Mnb-1,…⁢ ,1, where A1 corresponds to the cross-section at lips and AMnb+1 corresponds to the cross-section at a glottis opening; (4) extracting Mwb area coefficients from the Mnb area coefficients using interpolation; (5) computing wideband parcors riwb from the interpolated Mwb area coefficients according to the following: 30riwb=Aiwb-Ai+1wbAiwb+Ai+1wb,i=1,2,…⁢ ,Mwb; (6) computing wideband linear predictive coefficients (LPCs) aiwb from the wideband parcors riwb; (7) synthesizing a wideband signal ywb from the wideband LPCs aiwb and the wideband excitation signal; (8) highpass filtering the wideband signal ywb to produce a highband signal; and (9) generating a wideband signal Ŝwb by summing the highband signal and the narrowband signal interpolated to the wideband sampling rate.<br>34. A method of producing a wideband signal from a narrowband signal, the method receiving data associated with a narrowband signal, the method comprising: (1) computing Mnb area coefficients using the narrowband data; (2) extracting Mwb area coefficients from the Mnb area coefficients using interpolation; and (3) synthesizing a wideband signal ywb using wideband coefficients processed from data associated with the Mnb area coefficients and an excitation signal.<br>36. A method of producing a wideband signal from a narrowband signal, the method comprising: (1) computing Mnb area coefficients from the narrowband signal; (2) computing Mnb log-area coefficients from the Mnb area coefficients; (3) interpolating the Mnb log-area coefficients into Mwb log-area coefficients; (4) converting the Mwb log-area coefficients into Mwb area coefficients; and (5) synthesizing a wideband signal ywb using the Mwb area coefficients and an excitation signal.<br>44 A method of generating a wideband signal from a narrowband signal, the method comprising: (1) producing a wideband excitation signal from the narrowband signal; (2) computing partial correlation coefficients ri (parcors) from the narrowband signal; (3) computing Mnb area coefficients according to the following equation: 32Ai=1+ri1-ri⁢Ai+1; ⁢i=Mnb,Mnb-1,…,1, where A1 corresponds to the cross-section at lips and AMnb+1 corresponds to the cross-section at a glottis opening; (4) computing Mnb log-area coefficients by applying a log operator to the Mnb area coefficients; (5) extracting Mwb log-area coefficients from the Mnb log-area coefficients using shifted-interpolation; (6) converting the Mwb log-area coefficients into Mwb area coefficients; (7) computing wideband parcors riwb from the Mwb area coefficients according to the following: 33riwb=Aiwb-Ai+1wbAiwb+Ai+1wb, ⁢i=1,2,…,Mwb; (8) computing wideband linear predictive coefficients (LPCs) aiwb from the wideband parcors riwb; and (9) synthesizing a wideband signal ywb from the wideband LPCs aiwb and the wideband excitation signal.<br>47. A method of producing a wideband signal from a narrowband signal, the method comprising: computing Mnb area coefficients from the narrowband signal; interpolating the Mnb area coefficients into Mwb area coefficients; and generating the wideband signal using the Mwb area coefficients.<br>49. A method of producing a wideband signal from a narrowband signal, the method comprising: computing Mnb log-area coefficients by applying a log operator to Mnb area coefficients generated from the narrowband signal; extracting Mwb log-area coefficients from the Mnb log-area coefficients using interpolation; and generating a wideband signal using Mwb area coefficients generated from the Mwb log-area coefficients.</p></layer>
<layer id = "layer267"><p><b>US8595001B2:System for bandwidth extension of narrow-band speech</b><br>Multiple-tier omnidirectional solid-state emission source capable of dispersing light in flexible distributions or custom-intensity distributions which throw more light forward, to the side alternatively, or in all directions. This optical light control requires multiple-surface manipulation of the directions of the light energy bundles emerging from solid-state light sources. Producing uniform light up to 325 degrees in the vertical direction through the combined implementation of multi-stage light guiding for remote source elongation and multiple-tiers of TIR, refraction, and scatter for remote source emission and control. Combining the efficient light production of an LED chip with that of a directly coupled optic results in high efficiency custom distribution to direct light where required. The optical light manipulator consists of a dielectric or reflector collector section, spline light-pipe section used to clear the cross-sectional area of a thermal dissipation device and a section which either externally, internally, or combinatorially feeds multiple-tier TIR/refractor elements.<br><b>Independant Claims</b><br>1) A method comprising: computing, via a processor, linear predictive coefficients from a received signal; recursively computing partial correlation coefficients based on the linear predictive coefficients; computing narrow area coefficients from the partial correlation coefficients; computing wide area coefficients via interpolation of the narrow area coefficients; and synthesizing a wideband signal using the wide area coefficients.<br>15) A computer-readable storage device having instructions stored which, when executed by a computing device, cause the computing device to perform operations comprising: computing linear predictive coefficients from a received signal; recursively computing partial correlation coefficients based on the linear predictive coefficients; computing narrow area coefficients from the partial correlation coefficients; computing wide area coefficients via interpolation of the narrow area coefficients; and synthesizing a wideband signal using the wide area coefficients.<br>8) A system comprising: a processor; and a computer-readable storage medium having instructions stored which, when executed by the processor, cause the processor to perform operations comprising: computing linear predictive coefficients from a received signal; recursively computing partial correlation coefficients based on the linear predictive coefficients; computing narrow area coefficients from the partial correlation coefficients; computing wide area coefficients via interpolation of the narrow area coefficients; and synthesizing a wideband signal using the wide area coefficients.</p></layer>
<layer id = "layer268"><p><b>US6192134B1:System and method for a monolithic directional microphone array</b><br>An x-ray imaging system according to the present invention comprising a stepped scanning-beam x-ray source and a multi-detector array. The output of the multi-detector array is input to an image reconstruction engine which combines the outputs of the multiple detectors over selected steps of the x-ray beam to generate an x-ray image of the object. A collimating element, preferably in the form of a perforated grid containing an array of apertures, interposed between the x-ray source and an object to be x-rayed. A maneuverable positioner incorporating an x-ray sensitive marker allowing the determination of the precise position coordinates of the maneuverable positioner.<br><b>Independant Claims</b><br>1) A system for a directional microphone, said system comprising: (a) a plurality of monolithic detection units for detecting sound information and performing local signal processing on said sound information, wherein each of said plurality of monolithic detection units includes: (i) an integrated transducer for receiving acoustic waves, and responsive thereto, for generating a signal representing sound information of said waves; (ii) a processor, coupled to the transducer, for receiving the sound information and performing local digital signal processing on the sound information by generating a spatially directed virtual array directed to focus on at least one of a certain frequency bandwidth or sound information emanating from a specific spatial location to generate locally processed sound information; (b) a base unit, coupled to the plurality of monolithic detection units, for receiving a pre-processed local sound information from at least one of said plurality of monolithic detection units and forperforming global signal processing on the pre-processed local sound information, said base unit including a processor for receiving the pre-processed local sound information and performing global digital signal processing on the pre-processed local sound information by generating a global virtual array directed to focus on at least one of a certain frequency bandwidth or sound information emanating from a specific spatial location to generate globally processed sound information; and (c) a communication means for communicating between said plurality of monolithic detection units and said base unit, each of said detection units being capable of communicating with another detection unit and said base unit, said base unit being capable of transmitting instructions to each of said detection units.<br>23) A method of detecting audio signals generated by an audio sources, comprising the steps of: (a) receiving sound information; (b) responsive to the sound information, generating an electrical signal representative of the sound information; (e) performing local signal processing at a local detection unit on the electrical signal by generating a spatially directed virtual array directed to focus on at least one of a certain frequency bandwidth or sound information emanating from a specific spatial location to generate globally processed sound information; (f) communicating the pre-processed local sound information from said local detection unit to a base unit; (g) performing global signal processing on the pre-processed local sound information by generating a global virtual array directed to focus on at least one of a certain frequency bandwidth or sound information emanating from a specific spatial location to generate globally processed digital sound information; and (h) communicating local processing instructions from said base unit to said local detection unit.</p></layer>
<layer id = "layer269"><p><b>US20030101048A1:Suppression system of background noise of voice sounds signals and the method thereof</b><br>A transmission system includes multiple network elements for the transmission of a plurality of data units from at least one network element having a data source, to at least one further network element that has a data sink and a data buffer. Transmission systems of this kind are used for the composition of news items in a news broadcast studio or for the remote transmission of video sequences. Very strict requirements are then imposed on the data transmission, notably as regards the temporal control of the data transmission, in order to achieve real-time, interference-free data output via the data sink. Therefore, means is provided for temporal control of the data transmission from the data source to the data buffer, and for the temporal control, independently of the former, of the data transmission from the data buffer (<b>11</b>) to the data sink.<br><b>Independant Claims</b><br>1. A suppression method of the voice sounds signals wherein analog voice sounds signals first pass through a sampler to be transformed from analog signals to digital signals comprising the steps of: a. utilizing 32 KHz sampling frequency to sample and represent the acquired digital signals with 12 bits pulse code modulation; b. passing a low-pass filter after sampling; c. removing unnecessary signals outside the bandwidth of the voice sounds signals wherein the digital signals from the first low-pass filter are sent into the adaptive speech analysis unit, pitch detection unit and the background noise suppression filter unit, respectively, to proceed the next-step process; In adaptive speech analysis unit, the voice sounds signals are estimated by utilizing the N'th order all-pole adaptive filter wherein the coefficient of the all-pole adaptive filter is al(k), i=1,2 . . . N, which represents i'th filter coefficient, these N filter coefficients of which to be determined to represent the unique characteristics of the voice sounds signals will be sent to the background suppression filter unit; on the other hand it will be sent to the pitch detection unit to estimate the pitch periods of the voice sounds wherein each pitch period of samples of the voice sounds will be estimated and be sent to the background noise suppression filter unit to proceed the next-step suppression of the background noise. In the background noise suppression filter, the background noise suppression filter is designed by utilizing the speech characteristics coefficients and the voice sounds pitch periods and next by utilizing one high-frequency booster to compensate for the attenuated components of its high frequency in the voice sounds signals, finally by utilizing one low-pass filter to remove the noise outside the bandwidth of the voice sounds signals.<br>2. A suppression system of the background noise of the voice sounds signals wherein unnecessary background noise would be deleted by means of suitably adjustment of the signals according to the variation of the voice sounds signals by means of the long time and the short time statistic characteristics of voice sounds comprising: An oversampling unit, to transform the analog voice sounds signals into the digital ones; A first low-pass filter, to remove the unnecessary parts in the digital voice sounds signals of the output from the oversampling unit; An adaptive speech analysis unit, to analyze the characteristics of the digital voice sounds signals output from said first low-pass filter; A pitch detection unit which is used to estimate the pitch periods of the digital voice sounds signals output from said first low-pass filter; A background noise suppression filter which is used to remove the background noise according to the characteristic of the voice sounds analyzed by the adaptive speech analysis unit and the voice sounds pitch periods estimated from the pitch detection unit; A high-frequency booster which is used to compensate for the attenuation of the digital voice sounds signals caused by the background noise suppression filter; A second low-pass filter which is used to remove the unnecessary parts of the output of the high frequency booster. By means of the above-mentioned component, the unnecessary background noise within the voice sounds signals is suppressed.</p></layer>
<layer id = "layer270"><p><b>US5455888A:Speech bandwidth extension method and apparatus</b><br>The present invention provides an automatic cut off switch which grounds the magneto-spark plug circuit of a small gasoline engine shutting the engine down when the quantity of lubricating oil within the sump falls below a predetermined quantity. The switch is operated by a balance beam float assembly housed within a protective shroud. The protective shroud acts to collect a relatively stable pool of oil, representative of the quantity of oil remaining in the sump, for activation of the balance beam float. Upon refilling of the oil sump the switch automatically resets thereby permitting re-start of the engine.<br><b>Independant Claims</b><br>1. Speech bandwidth extension apparatus comprising: an input for receiving a narrowband speech signal sampled at a first rate; LPC analysis means for determining, for a speech frame having a predetermined duration of the speech signal, LPC parameters a.sub.i ; inverse filter means for filtering each speech frame in dependence upon the LPC parameters for the frame to produce a narrowband excitation signal frame; excitation extension means for producing a wideband excitation signal sampled at a second rate in dependence upon pitch and power of the narrowband excitation signal; lowband shape means for determining a lowband shape vector in dependence upon the LPC parameters; voiced/unvoiced means for determining voiced and unvoiced speech frames; gain and shape vector quantizer means for selecting predetermined highband shape and gain parameters in dependence upon the lowband shape vector for voiced speech frames and selecting fixed predetermined values for unvoiced speech frames; filter bank means responsive to the selected highband shape and gain parameters for filtering the wideband excitation signal to produce a highband speech signal; interpolation means for producing a lowband speech signal sampled at the second rate from the narrow band speech signal; and adder means for combining the highband speech signal and the lowband speech signal to produce a wideband speech signal.<br>10. A method of speech bandwidth extension comprising the steps of: analyzing a narrowband speech signal, sampled at a first rate, to obtain a spectral shape of the narrowband speech signal and an excitation signal of the narrowband speech signal; extending the excitation signal to a wideband excitation signal, sampled at a second, higher rate in dependence upon an analysis of pitch of the narrowband excitation signal; correlating the narrowband spectral shape with one of a plurality of predetermined highband shapes and one of a plurality of highband gains; filtering the wideband excitation signal in dependence upon the predetermined highband shape and gain to produce a highband signal; interpolating the narrowband speech signal to produce a lowband speech signal sampled at the second rate; and adding the highband signal and the lowband signal to produce a wideband signal sampled at the second rate.</p></layer>
<layer id = "layer271"><p><b>US20030097260A1:Speech model and analysis, synthesis, and quantization methods</b><br>The invention relates to an article, in particular a glove, a condom, or the like, which is comprised of a flexible rubber and/or plastic, is embodied having at least one section of the surface intended contact or rest against human skin, which article is provided with a slip coating in a section of the surface. This slip coating is comprised of a polymeric material and at least in sections, has repeating shape deviations of the surface that are recessed in relation to a raised, net-like structure. The ratio of the average spacings between the shape deviations to their depth in relation to the raised, net-like structure is between 500:1 and 5:1 and the average roughness depth is between 0.5 and 100 μm, preferably between 1 and 40 μm.<br><b>Independant Claims</b><br>1. A method of analyzing a digitized signal to determine model parameters for the digitized signal, the method comprising: receiving a digitized signal; determining a voiced strength for the digitized signal by evaluating a first function; and determining a pulsed strength for the digitized signal by evaluating a second function.<br>18. A method of synthesizing a signal, the method comprising: determining a voiced signal; determining a voiced strength; determining a pulsed signal; determining a pulsed strength; dividing the voiced signal and the pulsed signal into two or more frequency bands; and combining the voiced signal and the pulsed signal based on the voiced strength and the pulsed strength.<br>20. A method of synthesizing a signal, the method comprising: determining a voiced signal; determining a voiced strength; determining a pulsed signal; determining a pulsed strength; determining an unvoiced signal; determining an unvoiced strength; dividing the voiced signal, pulsed signal, and unvoiced signal into two or more frequency bands; and combining the voiced signal, the pulsed signal, and the unvoiced signal based on the voiced strength, the pulsed strength, and the unvoiced strength.<br>21. A method of quantizing speech model parameters, the method comprising: determining the voiced error between a voiced strength parameter and quantized voiced strength parameters; determining the pulsed error between a pulsed strength parameter and quantized pulsed strength parameters; combining the voiced error and the pulsed error to produce a total error; and selecting the quantized voice strength and the quantized pulsed strength which produce the smallest total error.<br>22. A method of quantizing speech model parameters, the method comprising: determining a quantized voiced strength; determining a quantized pulsed strength; and quantizing a fundamental frequency based on the quantized voice strength and the quantized pulsed strength.<br>24. A method of quantizing speech model parameters, the method comprising: determining a quantized voiced strength; determining a quantized pulsed strength; and quantizing a pulse position based on the quantized voiced strength and the quantized pulsed strength.<br>26. A computer software system for analyzing a digitized signal to determine model parameters for the digitized signal comprising: a voiced analysis unit operable to determine a voiced strength for the digitized signal by evaluating a first function; and a pulsed analysis unit operable to determine a pulsed strength for the digitized signal by evaluating a second function.<br>41. A method of analyzing a digitized signal to determine model parameters for the digitized signal, the method comprising: receiving a digitized signal; and evaluating an error criterion with reduced sensitivity to time shifts to determine pulse parameters for the digitized signal.</p></layer>
<layer id = "layer272"><p><b>US20030101050A1:Real-time speech and music classifier</b><br>An engine cycle that is carried out in a reciprocating piston/cylinder engine consists of a working stroke in which exothermic decomposition of at least one liquid compound is caused to occur without combustion so as to produce a gaseous product of the decomposition that drives the piston along the cylinder in one direction and an exhaust stroke in which the products of the decomposition are exhausted from the cylinder upon return movement of the piston.<br><b>Independant Claims</b><br>1. A method of classifying a current coding frame in a sequence of audio data frames in real-time for switching a multi-mode audio coding system operated in a current coding mode between different modes, the method comprising: recording the sequence of audio data frames; extracting at least one long-term feature and at least one short-term feature relative to each audio data frame, wherein the features substantially exhibit distinct values for different signal types; detecting a potential switch point according to the at least one short-term feature of the current frame and the current coding mode; and determining whether to switch the current coding mode of the coding system at the potential switch point based on the at least one long-term feature.<br>11. A method for switching an audio encoder between a speech mode and a music mode for coding a sequence of audio data frames, the method comprising: recording the sequence of frames in a buffer; extracting at least one long-term feature and at least one short-term feature relative to each frame, wherein the features substantially exhibit distinct values for speech and music frames; detecting a potential switch point according to the at least one short-term feature; defining a feature space by the at least one long-term feature of each frame; generating a feature point in the feature space for each frame in the buffer, wherein a set of feature points defines a feature pattern; classifying each frame via pattern recognition relative to the feature pattern; and determining whether to switch the mode of the audio encoder according to the classification and a pre-defined switch criterion.<br>14. A classifier for use in a coder having at least a speech coding mode and a music coding mode for switching the coder between the speech and music coding modes, the classifier comprising: a look-ahead buffer for storing a received sequence of frames; a feature extractor for extracting one or more long-term features and one or more short-term features for each frame in the buffer, wherein the long-term features and short-term features are capable of distinguishing a frame comprising speech data from a frame comprising music data, and for outputting the extracted long-term features and short-term features; and a classification module for receiving the long-term and short-term features from the feature extractor and classifying each frame according to its long-term features and indicating a switching time for the coder to change its coding mode according to the short-term features.<br>16. A coder system for coding a sequence of audio frames composed of speech data frames and music data frames, the coder system comprising: an encoder having multiple operating modes, at least one of which is for encoding speech data and another of which is for encoding music data; and an encoding classifier in communication with the encoder, wherein the encoding classifier is adapted for determining a potential switching time for the encoder to switch its operating mode based on one or more extracted short-term features of a frame, classifying each frame in the sequence according to one or more long-term features extracted from the frame, determining whether to switch a current operating mode of the encoder based on the one or more long-term features according to a predefined criterion, and providing a set of classification information classifying at least one frame as a speech data or music data frame.<br>18. A method of classifying a current coding frame in a sequence of audio data frames in real-time for switching a multi-mode audio coding system operated in a current coding mode between different modes, the method comprising: recording the sequence of audio data frames; extracting at least one long-term feature and at least one short-term feature relative to each audio data frame, wherein the features substantially exhibit distinct values for different signal types; determining whether to switch the current coding mode of the coding system based on the at least one extracted long-term feature; and if it is determined to switch the current coding mode of the coding system, detecting a switch point according to the at least one short-term feature of the current frame and the current coding mode, at which to switch the current coding mode of the coding system.<br>19. A method of classifying a current coding frame in a sequence of audio data frames in real-time for switching a multi-mode audio coding system operated in a current coding mode between different modes, the method comprising: recording the sequence of audio data frames; extracting at least one long-term feature relative to each audio data frame, wherein the at least one feature substantially exhibits distinct values for different signal types; detecting a potential switch point according to the at least one long-term feature of the current frame and the current coding mode; and determining whether to switch the current coding mode of the coding system at the current switch point based on the at least one long-term feature.<br>20. A method of classifying a current coding frame in a sequence of audio data frames in real-time for switching a multi-mode audio coding system operated in a current coding mode between different modes, the method comprising: recording the sequence of audio data frames; extracting at least one short-term feature relative to each audio data frame, wherein the at least one feature substantially exhibits distinct values for different signal types; detecting a potential switch point according to the at least one short-term feature of the current frame and the current coding mode; and determining whether to switch the current coding mode of the coding system at the current switch point based on the at least one short-term feature.</p></layer>
<layer id = "layer273"><p><b>US20030083886A1:Audio coding</b><br>An electronic assembly that may include a two-phase material that absorbs heat generated by an integrated circuit. The heat may be transferred from the integrated circuit to the two-phase material by a heat pipe. The two-phase material can absorb heat in an isothermal process utilizing the latent heat of the material. The isothermal process allows the two-phase material to absorb heat generated by the integrated circuit without raising the temperature of the assembly.<br><b>Independant Claims</b><br>1. A method of encoding (1) an audio signal (x), the method comprising the steps of: providing a respective set of sampled signal values for each of a plurality of sequential segments; analysing (130) the sampled signal values to generate one or more sinusoidal components (fk,fk+1) for each of the plurality of sequential segments; providing an indicator (ai,P1k) of the frequency variation of said sinusoidal components within each of the plurality of sequential segments; linking sinusoidal components across a plurality of sequential segments according to the difference in frequencies (δ4,δ6) of sinusoidal components to which respective indicators (ai,P1k) are applied; generating sinusoidal codes (CS) comprising tracks of linked sinusoidal components for each of the plurality of sequential segments; and generating (15) an encoded audio stream (AS) including said sinusoidal codes (CS).<br>6. A method according to claim 6 wherein the maximum number of last amplitude parameters is four.<br>17. Method of decoding an audio stream, the method comprising the steps of: reading an encoded audio stream (AS′) including sinusoidal codes (CS) comprising tracks of linked sinusoidal components for each of the plurality of sequential segments; and employing (32) an indicator (ai, P1k) of the frequency variation of said sinusoidal components within each of the plurality of sequential segments and said sinusoidal codes to synthesize said audio signal including re-constructing sinusoidal components across a plurality of sequential segments according to the difference in frequencies (δ4, δ6) Of sinusoidal components to which respective indicators have been applied.<br>23. Audio coder (1) arranged to process a respective set of sampled signal values for each of a plurality of sequential segments of an audio signal (x), said coder comprising: an analyser (130) for analysing the sampled signal values to generate one or more sinusoidal components (fk,fk+1) for each of the plurality of sequential segments; a component for determining an indicator (ai,P1k) of the frequency variation of said sinusoidal components within each of the plurality of sequential segments; a linker for linking sinusoidal components across a plurality of sequential segments according to the difference in frequencies (δ4,δ6) of sinusoidal components to which respective indicators (ai,P1k) are applied; a component for generating sinusoidal codes (CS) comprising tracks of linked sinusoidal components for each of the plurality of sequential segments; and a bit stream generator for generating (15) an encoded audio stream (AS) including said sinusoidal codes (CS).<br>24. Audio player (3), comprising: means for reading an encoded audio stream (AS′) including sinusoidal codes (CS) comprising tracks of linked sinusoidal components for each of the plurality of sequential segments; and a synthesizer (32) arranged to employ an indicator (ai,P1k) of the frequency variation of said sinusoidal components within each of a plurality of sequential segments and said sinusoidal codes to synthesize said audio signal including re-constructing sinusoidal components across a plurality of sequential segments according to the difference in frequencies (δ4,δ6) of sinusoidal components to which respective indicators have been applied.<br>26. Audio stream (AS) comprising sinusoidal codes (CS) representative of at least a component of an audio signal, said codes comprising tracks of linked sinusoidal components, said sinusoidal components being linked across said plurality of sequential segments according to the difference in frequencies (δ4, δ6) of said sinusoidal components to which respective indicators (a1,P1k) of the frequency variation of said sinusoidal components within each of a plurality of sequential segments of said audio signal have been applied.</p></layer>
<layer id = "layer274"><p><b>US6199035B1:Pitch-lag estimation in speech coding</b><br>A transfer case is provided and includes a first output shaft driven by a powertrain and operably interconnected with a first pair of wheels, a second output shaft selectively driven by the first output shaft and operably interconnected with a second pair of wheels and a transfer gear assembly operably disposed between the first output shaft and the second output shaft for transferring drive torque from the first output shaft to the second output shaft. The transfer gear assembly includes a first transfer gear in selective drive connection with the first output shaft, a second transfer gear in meshed engagement with the first transfer gear, a third transfer gear in drive connection with the second transfer gear and the second output shaft. A clutch pack is operably disposed between the first output shaft and the first transfer gear for selectively establishing drive connection therebetween.<br><b>Independant Claims</b><br>1) A method of speech coding a sampled signal using a pitch-lag parameter for each of a series of frames of the signal, the method comprising for each frame: determining the autocorrelation function for the frame within the signal, between predefined maximum and minimum delays; weighting the autocorrelation function to emphasise the function for delays in the neighborhood of the pitch-lag parameter determined for a previous frame; and identifying the delay corresponding to the maximum of the weighted autocorrelation function as the pitch-lag parameter for the frame.<br>4) Apparatus for speech coding a sampled signal using a pitch-lag parameter for each of a series of frames of the signal, the apparatus comprising: means for determining for each frame the autocorrelation function of the frame within the signal between predetermined maximum and minimum delays; weighting means for weighting the autocorrelation function to emphasize the function for delays in the neighborhood of the pitch-lag parameter determined for a previous frame; and means for identifying the delay corresponding to the maximum of the weighted autocorrelation function as the pitch-lag parameter for the frame.<br>7) A method of speech coding a sampled signal using a pitch-lag parameter for each of a series of frames of the sampled signal, the method comprising for each frame: determining an autocorrelation function for at least one frame within the series of frames within the sampled signal, between predefined maximum and minimum delays; weighting the autocorrelation function to emphasize the autocorrelation function for delays in the neighborhood of a median value of a plurality of pitch-lag parameters determined for respective previous frames within the series of frames; and identifying a delay corresponding to the maximum of the weighted autocorrelation function as the pitch-lag parameter for the at least one frame.<br>11) Apparatus for speech coding a sampled signal using a pitch-lag parameter for each of a series of frames of the sampled signal, the apparatus comprising: means for determining for at least one frame within the series of frames an autocorrelation function between predetermined maximum and minimum delays; weighting means for weighting the autocorrelation function to emphasize the autocorrelation function for delays in the neighborhood of a median value of a plurality of pitch-lag parameters determined for respective previous frames; and means for identifying a delay corresponding to the maximum of the weighted autocorrelation function as the pitch-lag parameter for the at least one frame.<br>14) A method of speech coding a sampled signal using a pitch-lag parameter for each of a series of frames of the signal, the method comprising for each frame: determining the autocorrelation function for the frame within the signal, between predefined maximum and minimum delays; weighting the autocorrelation function with a weighting function to emphasize the function for delays in the neighborhood of the pitch-lag parameter determined for a previous frame, wherein the weighting function has the form: Wd(d)=(═Told−d═+dL)log2Knw  where Told is the pitch lag of said previous frame, dL is said minimum delay, and Knw is a tuning parameter defining the neighborhood weighting; and identifying the delay corresponding to the maximum of the weighted autocorrelation function as the pitch-lag parameter for the frame.<br>16) A method of speech coding a sampled signal using a pitch-lag parameter for each of a series of frames of the sampled signal, the method comprising for each frame: determining the autocorrelation function for the frame within the signal, between predefined maximum and minimum delays; weighting the autocorrelation function to emphasize the function for delays in the neighborhood of the pitch-lag parameter determined for a previous frame, wherein the autocorrelation function is weighted to emphasize the function for delays in the neighborhood of the median value of a plurality of pitch lags determined for respective previous frames; and identifying the delay corresponding to the maximum of the weighted autocorrelation function as the pitch-lag parameter for the frame.<br>21) A method of speech coding a sampled signal using a pitch-lag parameter for each of a series of frames of the signal, the method comprising for each frame: classifying the frame into one of a voiced and a non-voiced frame; determining the autocorrelation function for the frame within the signal, between predefined maximum and minimum delays; weighting the autocorrelation function to emphasize the function for delays in the neighborhood of the pitch-lag parameter determined for a respective previous frame, wherein said previous frame is the most recent voiced frame; and identifying the delay corresponding to the maximum of the weighted autocorrelation function as the pitch-lag parameter for the frame, wherein, if said previous frame, or the most recent previous frame, is not the most recent frame, the weighting is reduced.<br>22) A method of speech coding a sampled signal using a pitch-lag parameter for each of a series of frames of the signal, the method comprising for each frame: classifying the frame into one of a voiced and a non-voiced frame; determining the autocorrelation function for the frame within the signal, between predefined maximum and minimum delays; weighting the autocorrelation function to emphasize the function for delays in the neighborhood of the pitch-lag parameter determined for a respective previous frame, wherein said previous frame is the most recent voiced frame; and identifying the delay corresponding to the maximum of the weighted autocorrelation function as the pitch-lag parameter for the frame, wherein, after a sequence of consecutive non-voiced frames is received, the weighting is reduced, substantially in proportion to the number of frames in the sequence.<br>23) A method of speech coding a sampled signal using a pitch-lag parameter for each of a series of frames of the signal, the method comprising for each frame: determining the autocorrelation function for the frame within the signal, between predefined maximum and minimum delays; weighting the autocorrelation function with a weighting function to emphasize the function for delays in the neighborhood of the pitch-lag parameter determined on the basis of at least one previous frame, wherein the weighting function has the form: Wd(d)=(═Tprev−d═+dL)log2Knw  where Tprev is the pitch lag determined on the basis of at least one previous frame, dL is said minimum delay, and Knw is a tuning parameter defining the neighborhood weighting; and identifying the delay corresponding to the maximum of the weighted autocorrelation function as the pitch-lag parameter for the frame.</p></layer>
<layer id = "layer275"><p><b>US5809455A:Method and device for discriminating voiced and unvoiced sounds</b><br><b>Independant Claims</b><br>1. A method for discriminating a digital speech sound comprising dividing digital speech signals into signal blocks each including a predetermined number of samples, and making a decision for each of said signal blocks as to whether the speech sound is voiced, said method further comprising the steps of: transforming signals of each of said signal blocks into data on the frequency scale, finding low frequency range energies based on said data on the frequency scale, finding high frequency range energies based on said data on the frequency scale, finding a mean signal level of each of said signal blocks from low frequency range energies and high frequency range energies, dividing signals of each of said signal blocks into plural sub-blocks, analyzing said sub-blocks to find statistical characteristics of each of said sub-blocks, calculating a bias of said statistical characteristics of said signals in the time domain, and, deciding whether or not said signal blocks are voiced by comparing said mean signal level with a first predetermined threshold and by further comparing said bias of said statistical characteristics in the time domain with a second predetermined threshold.<br>7. A method for discriminating a digital speech sound comprising dividing digital speech signals into signal blocks each including a predetermined number of samples, and making a decision as to whether or not the speech sound is voiced for each of said signal blocks, said method further comprising the steps of: finding an effective value of signals in each of a plurality of sub-blocks divided from each of said signal blocks, finding a standard deviation and a mean value of said signals of each signal block based on the effective value as found for each of said sub-blocks, finding a normalized standard deviation in the time domain based on said standard deviation and said mean value, frequency-analyzing signals of each of said signal blocks to find spectral intensities at a plurality of frequencies, finding an energy distribution based on said spectral intensity at each of said plurality of frequencies, finding a mean signal level of signals of each of said signal blocks from said energy distribution, and, making a decision as to whether or not said signal blocks are voiced by comparing said normalized standard deviation, said energy distribution and said mean signal level with each corresponding predetermined threshold.<br>10. An apparatus for discriminating a digital speech sound by dividing digital speech signals into signal blocks each including a predetermined number of samples, and making a decision for each of said signal blocks, as to whether or not the speech sound is voiced, said apparatus comprising: frequency data calculating means for transforming signals of each of said signal blocks into frequency-domain data, means for finding low frequency range energies based on said frequency-domain data, means for finding high frequency range energies based on said frequency-domain data, means for finding a mean signal level of each of said signal blocks from said low frequency range energies and said high range energies, means for dividing signals of said signal block into plural sub-blocks, means for analyzing said sub-blocks for finding statistical characteristics of each of said sub-blocks, means for calculating a bias of said statistical characteristics of said signals in the time domain, and, decision means for making a decision as to whether or not said signal blocks are voiced by comparing said mean signal level with a first predetermined threshold and by further comparing said bias of said statistical characteristics in the time domain with a second predetermined threshold.<br>16. An apparatus for discriminating a digital speech sound by dividing digital speech signals into signal blocks each including a predetermined number of samples, and making a decision for each of said signal blocks as to whether or not the speech sound is voiced, said apparatus comprising: means for finding an effective value of signals in each of a plurality of sub-blocks divided from each of said signal blocks, means for finding a standard deviation and a mean value of said signals of each signal block based on an effective value as found for each of said sub-blocks, means for finding a normalized standard deviation in the time domain based on said standard deviation and said mean value, means for frequency-analyzing signals of each of said signal blocks to find spectral intensities at a plurality of frequencies, means for finding energy distribution based on said spectral intensity at each of said plurality of frequencies, means for finding a mean signal level of signals of each of said signal blocks from said energy distribution, and, decision means for deciding whether or not said signal blocks are voiced by comparing said normalized standard deviation, said energy distribution and said mean signal level with each corresponding predetermined threshold.</p></layer>
<layer id = "layer276"><p><b>US20010000190A1:Background noise/speech classification method, voiced/unvoiced classification method and background noise decoding method, and speech encoding method and apparatus</b><br>An uninterruptible power system has a transformer with a primary connected to input terminals, a secondary connected to output terminals, a static switch connected between the input terminals and the primary, and an auxiliary primary connected to an inverter which is supplied by a battery to provide output voltage to the output terminals when a main AC power system connected to the input terminals has failed. The primary has multiple taps at different voltage levels and a buck-boost winding. The taps of the transformer are switched and the buck-boost winding is controlled to provide either buck, boost, or pass-by to allow control of the output voltage from the transformer to within a few percent of a desired voltage level despite large changes in the input voltage. A battery charger coupled to the auxiliary primary operates as a boost converter to provide current to charge the battery at a current level which tracks the input voltage from the AC power system, thereby providing a substantially unity power factor to the AC power system. The voltage control of the output voltage also controls the voltage at the output of the auxiliary primary to which the battery charger is connected, whereby the voltage applied to the charger is substantially regulated and the output power of the charger itself is substantially regulated. The charger can be operated in programmable modes to provide a desired charge configuration for the battery. Detection of faults in the AC power system is enhanced by accurate detection of the zero crossings of the input voltage from the AC power system, and by comparison of the AC input power waveform with an adaptive reference.<br><b>Independant Claims</b><br>1. A background noise/speech classification method comprising the steps of: calculating power information and spectral information of an input signal as feature amounts; and comparing the calculated feature amounts with estimated feature amounts constituted by estimated power information and estimated spectral information in a background noise period, thereby deciding whether the input signal belongs to speech or background noise.<br>4. A background noise/speech classification method comprising the steps of: calculating power information and spectral information of an input signal as feature amounts; comparing the calculated feature amounts with estimated feature amounts constituted by estimated power information and estimated spectral information in a background noise period, thereby analyzing power and spectral fluctuation amounts; and when a result obtained by analyzing the power and spectral fluctuation amounts indicates background noise, deciding that the input signal belongs to background noise, and otherwise, deciding that the input signal belongs to speech.<br>9. A voiced/unvoiced classification method comprising the steps of: preparing a voiced appearance probability table and an unvoiced appearance probability table in which voiced and unvoiced appearance probabilities are respectively written in correspondence with speech feature amounts; obtaining voiced and unvoiced probabilities by referring to said voiced appearance probability table and said unvoiced appearance probability table by using a feature amount calculated from input speech as a key; and deciding on the basis of the voiced and unvoiced probabilities whether the input speech belongs to voice or unvoice.<br>10. A background noise decoding method comprising the steps of: extracting a decoded excitation signal parameter, a gain decoded parameter, and a decoded synthesis filter parameter from decoded parameters obtained by decoding encoded data; decoding an excitation signal and a gain from the decoded excitation signal parameter and the gain decoded parameter; smoothing the gain such that the gain changes smoothly; and generating a synthesized signal by using a signal obtained by multiplying the excitation signal by the smoothed gain and synthesis filter characteristic information based on the decoded synthesis filter parameter.<br>12. A speech encoding method comprising the steps of: dividing an input speech signal into frames each having a predetermined length; obtaining a pitch period of a future frame with respect to a current frame to be encoded; and encoding the pitch period.<br>13. A speech encoding method comprising the steps of: dividing an input speech signal into frames each having a predetermined length, and further dividing a speech signal of each frame into subframes; obtaining a predictive pitch period of a subframe in a current frame by using pitch periods of at least two frames of the current frame to be encoded and past and future frames with respect to the current frame; and obtaining a pitch period of a subframe in the current frame by using the predicted pitch period.<br>16. A speech encoding method comprising the steps of: preparing an adaptive codebook storing a plurality of adaptive vectors generated by repeating a past excitation signal series at a period included in a predetermined range; dividing an input speech signal into frames each having a predetermined length, and further dividing a speech signal of each frame into subframes; obtaining a predicted pitch period of a subframe in a current frame by using pitch periods of at least two frames of the current frame to be encoded and past and future frames with respect to the current frame; and determining a search range for subframes in the current frame by using the predicted pitch period to select an adaptive vector with a period that minimizes an error between a target vector and a signal obtained by filtering an adaptive vector extracted from said adaptive codebook through a perceptually weighted synthesis filter.<br>20. A speech encoding apparatus comprising: means for dividing an input speech signal into frames each having a predetermined length; means for obtaining a pitch period of a future frame with respect to a current frame to be encoded; and means for encoding the pitch period obtained by said means for obtaining the pitch period.<br>21. A speech encoding apparatus comprising: a divider section for dividing an input speech signal into frames each having a predetermined length, and further dividing a speech signal of each frame into subframes; a predicted subframe pitch period calculation section for obtaining a predicted pitch period of a subframe in a current frame by using pitch periods; of at least two frames of the current frame to be encoded and past and future frames with respect to the current frame; and a subframe pitch period calculation section for obtaining a pitch period of a subframe in the current frame by using the predicted pitch period.<br>22. A speech encoding apparatus comprising: an adaptive codebook storing a plurality of adaptive vectors generated by repeating a past excitation signal series at a period included in a predetermined range; a divider section for dividing an input speech signal into frames each having a predetermined length, and further dividing a speech signal of each frame into subframes; a predicted subframe pitch period calculation section for obtaining a predictive pitch period of a subframe in a current frame by using pitch periods of at least two frames of the current frame to be encoded and past and future frames with respect to the current frame; and a search range determination section for determining a search range for subframes in the current frame by using the predicted pitch period to select an adaptive vector with a period that minimizes an error between a target vector and a signal obtained by filtering an adaptive vector extracted from said adaptive codebook through a perceptually weighted synthesis filter.<br>23. A recording medium on which a program is recorded, said program being used to execute processing of dividing an input speech signal into frames each having a predetermined length, and obtaining a pitch period of a future frame with respect to a current frame to be encoded, and processing of encoding the pitch period.<br>24. A recording medium on which a program is recorded, said program being used to execute processing of dividing an input speech signal into frames each having a predetermined length, further dividing a speech signal of each frame into subframes, and obtaining a predicted pitch period of a subframe in a current frame by using pitch periods of at least two frames of the current frame to be encoded and past and future frames with respect to the current frame, and processing of obtaining a pitch period of a subframe in the current frame by using the predicted pitch period.<br>25. A computer-readable recording medium on which a program for performing speech encoding processing is recorded, the program being used to execute processing of dividing an input speech signal into frames each having a predetermined length, further dividing a speech signal of each frame into subframes, and obtaining a predicted pitch period of a subframe in a current frame by using pitch periods of at least two frames of the current frame to be encoded and past and future frames with respect to the current frame, and processing of determining a search range for subframes in the current frame by using the predicted pitch period to select an adaptive vector with a period that minimizes an error between a target vector and a signal obtained by filtering an adaptive vector extracted from an adaptive codebook through a perceptually weighted synthesis filter, said adaptive codebook storing a plurality of adaptive vectors generated by repeating a past excitation signal series at a period included in a predetermined range.</p></layer>
<layer id = "layer277"><p><b>US5633980A:Voice cover and a method for searching codebooks</b><br>The present invention provides an antistatic composition comprising a binder, a cyclic phosphazene, and a salt that complexes with the cyclic phosphazene. The cyclic phosphazene has the general formula ##STR1## wherein x is 3 or 4.<br><b>Independant Claims</b><br>1. A voice coder comprising: masking calculating means for calculating masking threshold values from supplied discrete voice signals based on auditory sense masking characteristics; auditory sense weighting means for calculating filter coefficients based on said masking threshold values and weighting input signals based on said filter coefficients; a codebook which includes a plurality of code vectors; and searching means for searching for a code vector in the codebook that minimizes error signal power between an output signal of said auditory sense weighting means and the code vectors in said codebook.<br>7. A voice coder comprising: dividing means for dividing supplied discrete voice signals into first pre-set time length frames; subframe generating means for generating subframes by dividing said frames into second pre-set time length divisions; regenerating means for regenerating said voice signals for said subframes based on an adaptive codebook; masking calculating means for calculating masking threshold values for each of said subframes from said voice signals based on auditory sense masking characteristics; an auditory sense weighting means for calculating filter coefficients based on said masking threshold values and performing auditory sense weighting to a difference signal formed as a difference between a signal regenerated with said regenerating means and said voice signal based on said filter coefficients; an excitation codebook which includes a plurality of code vectors; and searching means for searching for a code vector in said excitation codebook that minimizes an error signal power between said auditory sense weighting means and the code vectors in said excitation codebook.<br>13. A voice coder comprising: dividing means for dividing supplied discrete voice signals into pre-set time length frames; subframe generating means for generating subframes by dividing said frames into pre-set time length divisions; masking calculating means for calculating masking threshold values for each of said subframes form said voice signals based on auditory sense masking characteristics; auditory sense weighting means for calculating filter coefficients based on said masking threshold values and performing auditory sense weighting to said voice signals based on said filter coefficients; adaptive codebook means for calculating an adaptive code vector that minimizes power of a difference signal formed as a difference between a response signal and a voice signal weighted with said auditory sense weighting means; an excitation codebook which includes a plurality of excitation code vectors; and searching means for searching for a code vector in said excitation codebook that minimizes an error signal power between an output signal generated from said adaptive codebook means and said difference signal.<br>18. A voice coder comprising: dividing means for dividing supplied discrete voice signals into pre-set time length frames; subframe generating means for generating subframes by dividing said frames into pre-set time length divisions; regenerating means for regenerating said voice signals for each of said subframes based on an adaptive codebook; masking calculating means for calculating masking threshold values from said voice signals based on auditory sense masking characteristics; auditory sense weighting means for calculating filter coefficients based on said masking threshold values and performing auditory sense weighting to an error signal formed as a difference between said voice signal and a signal regenerated with said regenerating means based on said filter coefficients; and calculating means for calculating a multi-pulse that minimizes an error signal power between an output signal of said auditory sense weighting means and said code vectors in said adaptive codebook.<br>21. A method for searching a codebook used for coding discrete voice signals, using signals weighted with masking threshold values calculated from said voice signals based on auditory sense masking characteristics, the method comprising the steps of: (a) dividing said voice signals into preset time length frames; (b) generating subframes by dividing said frames into pre-set time length divisions; (c) regenerating said voice signals for each of said subframes based on an adaptive codebook; (d) calculating masking threshold values from said voice signals based on auditory sense masking characteristics; (e) calculating filter coefficients based on said masking threshold values and performing auditory sense weighting to an error signal between a signal regenerated in the step (c) and said voice signal, based on said filter coefficients; and (f) searching for an excitation code vector in an excitation code book that minimizes the error signal power weighted in the step (e).<br>25. The method for searching a codebook of used for coding discrete voice signals, using signals weighted with masking threshold values calcualted from said voice signals based on auditory sense masking characteristics, the method comprising the steps of: (1) dividing said voice signals into preset time length frames; (2) generating subframes by dividing said frames into pre-set time length divisions; (3) calculating masking threshold values from said voice signals based on auditory sense masking characteristics; (4) calculating filter coefficients based on said masking threshold value and performing auditory sense weighting to said voice signal based on said filter coefficients; (5) calculating, for each of said subframes and using a difference signal formed as a difference between a response signal and a voice signal weighted in the step (4), an adaptive code vector that minimizes a power of said difference signal, and regenerating said voice signal; and (6) searching for an excitation code vector in an excitation code book that minimizes an error signal power between a signal regenerated in the step (5) and said voice signal.<br>29. A voice coder comprising: dividing means for dividing supplied discrete voice signals into frames of a first pre-set time length and further dividing said frames into subframes of a second pre-set time length smaller than said first pre-set time length; masking calculating means for calculating masking threshold values from said voice signals based on auditory sense masking characteristics; a plurality of codebooks of which bit numbers are different from each other; bit number allocating means for allocating a number of bits of said codebooks based on said masking threshold values; and searching means for searching a code vector by switching said codebooks for each of said subframes based on the allocated number of bits.<br>35. A voice coder comprising: dividing means for dividing supplied discrete voice signals into frames of a preset time length; masking calculating means for calculating masking threshold values from said voice signals based on auditory sense masking characteristics; pitch calculating means for calculating pitch parameters so as to make signals regenerated based on said adaptive codebooks made of past excitation signals approximate, for each of said subframes, said voice signals; auditory sense weighting means for calculating filter coefficients based on said masking threshold values and conducting auditory sense weighting to error signals between signals regenerated with said pitch calculating means and said voice signals based on said filter coefficients; a plurality of excitation codebooks of which bit numbers are different from each other; bit allocating means for allocating a bit number of said excitation codebooks for each of said subframes based on said masking threshold values; and searching means for switching said excitation codebooks for each of said subframes based on the allocated number of bits and searching for an excitation code vector minimizing an error signal power between an output signal generated from said auditory sense weighting means and code vectors in a switched excitation codebook.<br>38. A voice coder comprising: dividing means for dividing supplied discrete voice signals into frames of a first pre-set time length and further dividing said frames into subframes of a second pre-set time length smaller than said first pre-set time length; masking calculating means for calculating masking threshold values from said voice signals based on auditory sense masking characteristics; deciding means for deciding a number of multipulses for each of said subframes based on said masking threshold values; and means for representing excitation signals of said voice signals in a form of multipulse using the number of multipulses decided for each of said subframes.<br>41. A voice coder comprising: dividing means for dividing supplied discrete voice signals into frames of a first pre-set time length; means for generating subframes by dividing said frames into divisions of a second pre-set time length; masking calculating means for calculating masking threshold values form said voice signals based on auditory sense masking characteristics; pitch calculating means for calculating pitch parameters so as to make signals regenerated based on said adaptive codebooks made of past excitation signals approximate, for each of said subframes, said voice signals; auditory sense weighting means for calculating filter coefficients based on said masking threshold values and conducting auditory sense weighting to error signals between signals regenerated with said pitch calculating means and said voice signals based on said filter coefficients; deciding means for deciding a number of multipulses for each of said subframes based on said masking threshold values; and means for calculating a multipulse minimizing said error signal power using the number of multipulses decided for each of said subframes and representing excitation signals of said voice signals using said multipulse.<br>42. A method of searching codebooks comprising the steps of: (a) dividing supplied discrete voice signals into frames of a first pre-set time length and further dividing said frames into subframes of a second pre-set time length; (b) calculating masking threshold values from said voice signals based on auditory sense masking characteristics; (c) allocating a bit number of a codebook to each of said subframes; and (d) searching for a code vector for each of said subframes using a codebook having the allocated bit number.<br>47. A multipulse calculating method comprising the steps of: (a) dividing and subbanding supplied discrete voice signals into frames of a first pre-set time length and further dividing said frames into subframes of a second pre-set time length; (b) calculating masking threshold values from said voice signals based on audtory sense masking characteristics, and dividing supplied discrete voice signals into frames of the first pre-set time length and further dividing said frames into subframes of the second pre-set time length; (c) deciding a number of multipulses for each of said subframes based on said masking threshold values; and (d) calculating a multipulse minimizing said error signal power usign a number of multipulses decided for each of said subframes and representing excitation signals of said voice signals using said multipulse.</p></layer>
<layer id = "layer278"><p><b>US4850022A:Speech signal processing system</b><br>A method and apparatus that makes it possible to have a single unified network where the devices at the edge are able to handle both wired and wireless traffic. Separate devices are not required to handle wired and wireless traffic. Instead the whole enterprise network comprises devices that are agnostic to the nature of the traffic and have all the features required by both wired and wireless traffic.<br><b>Independant Claims</b><br>1. A speech signal processing system comprising: an input terminal for receiving successive sample values of a speech waveform S(n) at successive time points n, where n=0, 1, 2, . . . ; inverse-filter means connected to said input terminal for obtaining successive sample values of a prediction residual waveform e(n) by removing a short-time correlation from the speech waveform S(n); phase-equalizing filter means connected to said input terminal for receiving the speech waveform S(n) therefrom and producing successive samples of a phase-equalized speech waveform Sp(n) in the time domain by zero-phasing a prediction residual waveform component in the speech waveform in accordance with successive sets of M+1 phase-equalizing filter coefficients h(m,n) supplied thereto as filter coefficients thereof, where m=0, 1, 2, . . . , M, and M is a positive integer; and filter coefficient determining means connected to the output of said inverse-filter means for determining said phase-equalizing filter coefficients h(m,n) on the basis of said prediction residual waveform e(n), said filter coefficient determining means including voiced/unvoiced sound discriminator means connected to the output of said inverse-filter means for discriminating whether said speech waveform is a voiced sound or an unvoiced sound based on whether a computed value of an auto-correlation function on said prediction residual waveform during an analysis window of a length N at said filter coefficient determining means is above or below a threshold value, pitch position detecting means connected to the outputs of said inversefilter means and said voiced/unvoiced sound discriminator means for detecting, when said speech waveform is discriminated as a voiced sound, pitch positions n.sub.l from said prediction residual waveform e(n), and filter coefficient computing means connected to the outputs of said inverse-filter means, said voiced/unvoiced sound discriminator means and said pitch position detecting means, respectively, for computing, when said speech waveform is discriminated as a voiced sound, a set of the M+1 phase-equalizing filter coefficients h(m,n) for a time point n of each pitch position n=n.sub.l by solving the following simultaneous equations given for K=0, 1, . . . M, ##EQU26## where L is the number of the pitch positions n.sub.l in the analysis window and V(m) is an auto-correlation function of said prediction residual waveform e(n) given by: ##EQU27## and for setting, when said speech waveform is discriminated as an unvoiced sound, a particular one order of coefficient of said phase-equalizing filter coefficients to a certain value and the other orders thereof to zero; the output of said filter coefficient determining means being connected to said phase-equalizing filter means so that successive sets of said phase-equalizing filter coefficients h(m,n.sub.l) determined by said filter coefficient determining means are supplied to said phase-equalizing filter means as the filter coefficients thereof, whereby said phase-equalizing filter means outputs the phaseequalized speech waveform Sp(n) as the output of said system representing the input speech waveform.<br>11. A speech signal processing system comprising: an input terminal for receiving successive sample values of a speech waveform S(n) at successive time points n, where n=0, 1, 2, . . . ; inverse-filter means connected to said input terminal for obtaining successive sample values of a prediction residual waveform e(n) by removing a short-time correlation from the speech waveform S(n); phase-equalizing filter means connected to the output of said inverse-filter means for obtaining a phase-equalized residual waveform ep(n) in the time domain by zero-phasing the prediction residual waveform e(n) from said inverse-filter means in accordance with successive sets of M+1 phase-equalizing filter coefficients h(m,n) supplied thereto as filter coefficients thereof, where m=0, 1, 2, . . . , M and M is a positive integer; and filter coefficient determining means connected to the output of said inverse-filter means for determining said phase-equalizing filter coefficients h(m,n) on the basis of said prediction residual waveform e(n), said filter coefficient determining means including voiced/unvoiced sound discriminator means connected to the output of said inverse-filter means for discriminating whether said speech waveform is a voiced sound or unvoiced sound based on whether a computed value of an auto-correlation function on said prediction residual waveform during an analysis window of a length N at said filter coefficient determining means is above or below a threshold value, pitch position detecting means connected to the outputs of said inverse-filter means and said voiced/unvoiced sound discriminator means for detecting, when said speech waveform is discriminated as a voiced sound, pitch positions n.sub.l from said prediction residual waveform e(n), and filter coefficient computing means connected to the outputs of said inverse-filter means, said voiced/unvoiced sound discriminator means and said pitch position detecting means, respectively, for computing, when said speech waveform is discriminated as a voiced sound, a set of the M+1 phase-equalizing filter coefficients h(m,n) for a time point n of each pitch position n=n.sub.l by solving the following simultaneous equations given for k=0, 1, . . . M, ##EQU29## where L is the number of the pitch positions n.sub.l in the analysis window and V(m) is an auto-correlation function of said prediction residual waveform e(n) given by: ##EQU30## and for setting, when said speech waveform is discriminated as an unvoiced sound, a particular one order of coefficient of said phase-equalizing filter coefficients to a certain value and the other orders thereof to zero; the output of said filter coefficient determining means being connected to said phase-equalizing means so that successive set of said phase-equalizing filter coefficients h(m,n.sub.l) determined by said filter coefficient determining means are supplied to said phase-equalizing filter means as filter coefficients thereof, whereby said phase-equalizing filter means outputs the phase-equalized prediction residual waveform ep(n) as the output of said system representing the input speech waveform.</p></layer>
<layer id = "layer279"><p><b>US5488704A:Speech codec</b><br>A handheld gum massaging device of the type which includes a wand with a movable distal dip zone and a handle connected to the wand which includes means to move the distal tip zone of the wand in a massaging action. The distal tip zone carries an element of absorbent material for receiving and applying a charge of medicament so that when the wand tip zone is moving, the element not only massages the gums but, simultaneously, delivers the medicament topically to the gums.<br><b>Independant Claims</b><br>1. A speech codec, comprising: pitch extracting means for extracting a pitch-scale on the basis of a signal of an inputted speech; voiced sound/unvoiced sound determinating means for determinating whether said inputted speech is one of a voiced sound speech and unvoiced sound speech on the basis of the signal of said inputted speech; drive sound source generating means for generating a drive sound source signal on the basis of said pitch-scale and a determination result of said voiced sound/unvoiced sound determinating means, said drive sound source generating means including drive voiced sound source generating means for generating drive voiced sound source signal when said inputted speech is the voiced sound speech, and unvoiced sound source generating means for generating a drive unvoiced sound source signal when said inputted speech is the unvoiced sound speech, wherein said drive voiced sound source generating means includes pulse pattern generating means for generating a pulse pattern signal corresponding to said pitch-scale; first adaptive code book means for storing drive voiced sound source signals within a predetermined past time period; first noise code book means for storing in advance a noise signal; and first generating means for generating the drive voiced sound source signal on the basis of said pulse pattern signal, an output of said first adaptive code book means and an output of said first noise code book means; speech synthesizing means for outputting a synthesized speech signal on the basis of one of said drive voiced sound source signal and said drive unvoiced sound source signal generated by said drive sound source generating means; and code outputting means for selectively outputting a code corresponding to one of said drive voiced sound source signal and said drive unvoiced sound source signal at a timing that an error between said synthesized speech signal and the signal of said inputted speech becomes minimum by comparing the synthesized speech signal and the signal of said inputted speech.<br>9. A speech codec, comprising: pitch extracting means for extracting pitch-scale on the basis of a signal of an inputted speech; analyzing means for analyzing a parameter of said inputted speech; first speech synthesizing means for synthesizing a voiced sound synthesized speech signal on the basis of said pitch-scale and said parameter, wherein said first speech synthesizing means includes pulse pattern generating means for generating a pulse pattern signal in response to said pitch-scale; first adaptive code book means for storing a drive voiced sound source signal within a predetermined past time period; first noise code book means for storing in advance a noise signal; and first generating means for generating said voiced sound synthesized speech signal on the basis of said pulse pattern signal, an output of said first adaptive code book means and an output of said first noise code book means; second speech synthesizing means for synthesizing an unvoiced sound synthesized speech signal on the basis of the signal of said inputted speech and said parameter; similarity determining means for determining that which one of said voiced sound synthesized speech signal and unvoiced sound synthesized speech signal is similar to said inputted speech; selecting means for selecting one of said voiced sound synthesized speech signal and said unvoiced sound synthesized speech signal in response to an output of said similarity determining means; and multiplexer means for multiplexing one of said voiced sound synthesized speech signal and said unvoiced sound synthesized speech signal selected by said selecting means and said parameter.</p></layer>
<layer id = "layer280"><p><b>US20010044727A1:Audio signal compression method, audio signal compression apparatus, speech signal compression method, speech signal compression apparatus, speech recognition method, and speech recognition apparatus</b><br>An input value x of floating-point representation is added up with an input value offset by a floating point adder, to be translated to a region where an exponent part is constant. On the basis of an output from the floating point adder, an address decoder generates an address for a lookup table. The lookup table stores only mantissa data in accuracy required for a function value of a necessary nonlinear function. A bit expansion circuit converts a function value read from the lookup table to corresponding numeric data of floating-point representation. The floating point adder subtracts an output value offset and outputs a nonlinear function value of floating-point representation for translating the numeric data received from the bit expansion circuit to its original region. A nonlinear function generator is provided which can efficiently implement nonlinear conversion processing in a digital electronic circuit at a high speed.<br><b>Independant Claims</b><br>1. An audio signal compression method for compressively coding an input audio signal, including the steps of: calculating a spectrum envelope having different resolutions for different frequencies, from the input audio signal, using a weighting function on frequency based on human auditory characteristics; and flattening the input audio signal for each frame using the calculated spectrum envelope.<br>4. An audio signal compression method for compressively coding an input audio signal, including the steps of: transforming the input signal into a frequency-warped signal with an all-pass filter, using a weighting function on frequency based on human auditory characteristics; obtaining a spectrum envelope having different resolutions for different frequencies, by performing linear predictive analysis of the frequency-warped signal; and flattening the input audio signal for each frame using the spectrum envelope.<br>5. An audio signal compression method for compressively coding an input audio signal, including the steps of: performing mel-linear predictive analysis including frequency warping in a prediction model, thereby obtaining a spectrum envelope having different resolutions for different frequencies, from the input audio signal, using a weighting function on frequency based on human auditory characteristics; and flattening the input audio signal for each frame using the spectrum envelope.<br>6. An audio signal compression method for compressively coding an input audio signal, said method having the step of performing mel-linear predictive analysis including frequency warping in a prediction model, thereby calculating a spectrum envelope having different resolutions for different frequencies, from the input audio signal, using a weighting function on frequency based on human auditory characteristics; and said mel-linear predictive analysis comprising the steps of: cutting out an input signal of a specific time length from the input audio signal, and filtering the signal of the time length using multiple stages of all-pass filters to obtain output signals from the respective filters; obtaining an autocorrelation function on a mel-frequency axis by performing a product-sum operation between the input signal and the output signal from each filter, which product-sum operation is performed within a range restricted to the time length of the input signal as represented by the following formula, 23φ⁡(i, ⁢j)=∑n=0N-1⁢ ⁢x⁡[n]&CenterDot;y(i-j)⁡[n] wherein φ(i,j) is the autocorrelation function, x[n] is the input signal, and y(i−j)[n] is the output signal from each filter; obtaining mel-linear predictive coefficients from the autocorrelation function on the mel-frequency axis; and using the mel-linear predictive coefficients as a spectrum envelope, or obtaining a spectrum envelope from the mel-linear predictive coefficients.<br>8. An audio signal compression apparatus for compressively coding an input audio signal, comprising: time-to-frequency transformation means for transforming the input audio signal to a frequency domain signal; spectrum envelope calculation means for calculating a spectrum envelope having different resolutions for different frequencies, from the input audio signal, using a weighting function on frequency based on human auditory characteristics; normalization means for normalizing the frequency domain signal using the spectrum envelope to obtain a residual signal; power normalization means for normalizing the residual signal by the power; auditory weighting calculation means for calculating weighting coefficients on frequency, based on the spectrum of the input audio signal and human auditory characteristics; and multi-stage quantization means having plural stages of vector quantizers connected in series, to which the normalized residual signal is input, and at least one of the vector quantizers quantizing the residual signal using the weighting coefficients.<br>9. An audio signal compression apparatus for compressively coding an input audio signal, comprising: mel-parameter calculation means for calculating mel-linear predictive coefficients on a mel-frequency axis which represents a spectrum envelope having different resolutions for different frequencies, from the input audio signal, using a weighting function on frequency based on human auditory characteristics; parameter transformation means for transforming the mel-linear predictive coefficients to parameters representing a spectrum envelope, such as linear predictive coefficients on a linear frequency axis; envelope normalization means for normalizing the input audio signal by inversely filtering it with the parameters representing the spectrum envelope, to obtain a residual signal; power normalization means for normalizing the residual signal using the maximum value or mean value of the power to obtain a normalized residual signal; and vector quantization means for vector-quantizing the normalized residual signal using a residual code book to transform the residual signal into residual codes.<br>16. A speech signal compression method for compressively coding an input speech signal, said method having the step of performing mel-linear predictive analysis including frequency warping in a prediction model, thereby calculating a spectrum envelope having different resolutions for different frequencies, from the input speech signal, using a weighting function on frequency based on human auditory characteristics; and said mel-linear predictive analysis comprising the steps of: cutting out an input signal of a specific time length from the input speech signal, and filtering the signal of the time length using multiple stages of all-pass filters to obtain output signals from the respective filters; obtaining an autocorrelation function on a mel-frequency axis by performing a product-sum operation between the input signal and the output signal from each filter, which product-sum operation is performed within a range restricted to the time length of the input signal as represented by the following formula, 25φ⁡(i, ⁢j)=∑n=0N-1⁢ ⁢x⁡[n]&CenterDot;y(i-j)⁡[n] wherein φ(i,j) is the autocorrelation function, x[n] is the input signal, and y(i−j)[n] is the output signal from each filter; obtaining mel-linear predictive coefficients from the autocorrelation function on the mel-frequency axis; and using the mel-linear predictive coefficients as a spectrum envelope, or obtaining a spectrum envelope from the mel-linear predictive coefficients.<br>18. A speech signal compression apparatus for compressively coding an input audio signal, comprising: mel-parameter calculation means for calculating mel-linear predictive coefficients on a mel-frequency axis which represents a spectrum envelope having different resolutions for different frequencies, from the input speech signal, using a weighting function on frequency based on human auditory characteristics; parameter transformation means for transforming the mel-linear predictive coefficients to parameters representing a spectrum envelope, such as linear predictive coefficients on a linear frequency axis; envelope normalization means for normalizing the input signal by inversely filtering it with the parameters representing the spectrum envelope, to obtain a residual signal; power normalization means for normalizing the residual signal using the maximum value or mean value of the power to obtain a normalized residual signal; and vector quantization means for vector-quantizing the normalized residual signal using a residual code book to transform the residual signal into residual codes.<br>23. A speech recognition method wherein: parameters corresponding to a spectrum envelope are calculated from an input speech, by a linear predictive analysis method for calculating a spectrum envelope having different resolutions for different frequencies, using a weighting function on frequency based on human auditory characteristics; and the input speech is recognized using the parameters.<br>26. A speech recognition method including a method for obtaining a spectrum envelope based on human auditory characteristics from an input speech, said method comprising the steps of: transforming the input speech into a frequency-warped speech signal using an all-pass filter; and subjecting the frequency-warped speech signal to linear predictive analysis to obtain parameters corresponding to a spectrum envelope having different resolutions for different frequencies; wherein said input speech is recognized using the parameters obtained.<br>27. A speech recognition method employing a mel-linear predictive analysis method including frequency warping in a prediction model, as a method for obtaining parameters corresponding to a spectrum envelope based on human auditory characteristics from an input speech; and recognizing the input speech using the parameters.<br>28. A speech recognition method employing the following steps as a method for obtaining parameters corresponding to a spectrum envelope based on human auditory characteristics from an input speech: cutting out an input signal of a specific time length from an input speech, and filtering the signal of the time length using multiple stages of all-pass filters to obtain output signals from the respective filters; obtaining an autocorrelation function on a mel-frequency axis by performing a product-sum operation between the input signal and the output signal from each filter, which product-sum operation is performed within a range restricted to the time length of the input signal as represented by the following formula, 27φ⁡(i, ⁢j)=∑n=0N-1⁢ ⁢x⁡[n]&CenterDot;y(i-j)⁡[n] wherein φ(i,j) is the autocorrelation function, x[n] is the input signal, and y(i−j)[n] is the output signal from each filter; and obtaining mel-linear predictive coefficients from the autocorrelation function on the mel-frequency axis; wherein the input speech is recognized using the mel-linear predictive coefficients, or cepstrum coefficients obtained from the mel-linear predictive coefficients.<br>30. A speech recognition apparatus comprising: mel-linear predictive analysis means for calculating mel-linear predictive coefficients corresponding to a spectrum envelope having different resolutions for different frequencies, from an input speech, using a weighting function on frequency based on human auditory characteristics; cepstrum coefficient calculation means for calculating cepstrum coefficients from the mel-linear predictive coefficients obtained by the mel-linear predictive analysis means; and a speech recognition means for calculating distances between plural frames of the cepstrum coefficients and plural standard models or plural standard patterns, and deciding which one of the standard models or patterns is similar to the input speech.</p></layer>
<layer id = "layer281"><p><b>US6377915B1:Speech decoding using mix ratio table</b><br>A method and a device for the draw expansion of metal tubes of oval cross-section uses expansion elements drawn unidirectionally through metal tubes by means of draw elements. The expansion elements are fastened to the draw elements by suspension devices which have a hammer-like contour. The draw elements are preferably made of a rod-shaped material. An apparatus of the invention is an apparatus for mechanically expanding metallic tubes, in particular tubes in heat exchangers. Each individual tube to be expanded is held in at least one holding device and passed through by a drawing mandrel with an expanding element. To prevent jamming of the expanding element in one of the holding devices, the holding devices are provided with lateral guides which are resiliently compliant outward in the radial direction. When the expanding element passes through the metallic tube, the tube is expanded in the radial direction. The forces occurring thereby in the axial direction are absorbed by the holding device, since the tube is seated on a stop in the holding device.<br><b>Independant Claims</b><br>1) A speech decoding method for reproducing a speech signal from a speech information bit stream which is a coded output of the speech signal that has been encoded by a linear prediction analysis and synthesis type speech encoder, said speech decoding method comprising the steps of: separating spectral envelope information, voiced/unvoiced discriminating information, pitch period information and gain information from said speech information bit stream, whereby forming a plurality of separated informations, and decoding each separated information; obtaining a spectral envelope amplitude from said spectral envelope information, and identifying a frequency band having a largest spectral envelope amplitude among a predetermined number of frequency bands each having a predetermined frequency bandwidth divided on a frequency axis for generating a mixed excitation signal; determining a mixing ratio for each of said predetermined number of frequency bands, based on said identified frequency band and said voiced/unvoiced discriminating information and using said mixing ratio to mix a pitch pulse generated in response to said pitch period information and white noise with reference to a predetermined mixing ratio table that has previously been stored; producing a mixing signal for each of said predetermined number of frequency bands based on said determined mixing ratio, and then producing said mixed excitation signal by summing all of said mixing signals of said predetermined number of frequency bands; and producing a reproduced speech by adding said spectral envelope information and said gain information to said mixed excitation signal.<br>2) A speech decoding method for reproducing a speech signal from a speech information bit stream, including spectral envelope information, low-frequency band voiced/unvoiced discriminating information, high-frequency band voiced/unvoiced discriminating information, pitch period information and gain information, which is a coded output of the speech signal encoded by a linear prediction analysis and synthesis type speech encoder, said speech decoding method comprising the steps of: separating said spectral envelope information, low-frequency band voiced/unvoiced discriminating information, high-frequency band voiced/unvoiced discriminating information, pitch period information and gain information from said speech information bit stream whereby forming a plurality of separated informations, and decoding each separated information; determining a mixing ratio of the low-frequency band based on said low-frequency band voiced/unvoiced discriminating information, using said mixing ratio to mix a pitch pulse generated in response to said pitch period information and white noise for the low-frequency band, and producing a mixing signal for the low-frequency band; obtaining a spectral envelope amplitude from said spectral envelope information, and identifying a frequency band having a largest spectral envelope amplitude among a predetermined number of high-frequency bands each having a predetermined frequency bandwidth divided on a frequency axis for generating a mixed excitation signal; determining a mixing ratio for each of said predetermined number of high-frequency bands based on said identified frequency band and said high-frequency band voiced/unvoiced discriminating information, using said mixing ratio to mix the pitch pulse generated in response to said pitch period information and white noise for each of said high-frequency bands with reference to a predetermined mixing ratio table that has previously been stored, producing a mixing signal of each of said predetermined number of high-frequency bands, and producing a mixing signal for the high-frequency band corresponding to a summation of all of the mixing signals of said predetermined number of high-frequency bands; producing said mixed excitation signal by summing said mixing signal for the low-frequency band and said mixing signal for the high-frequency band; and producing a reproduced speech by adding said spectral envelope information and said gain information to said mixed excitation signal.<br>6) A speech decoding method for reproducing a speech signal from a speech information bit stream, including spectral envelope information, low-frequency band voiced/unvoiced discriminating information, high-frequency band voiced/unvoiced discriminating information, pitch period information and gain information, which is a coded output of a tile speech signal encoded by a linear prediction analysis and synthesis type speech encoder, said speech decoding method comprising the steps of: separating each of said spectral envelope information, said low-frequency band voiced/unvoiced discriminating information, said high-frequency band voiced/unvoiced discriminating information, said pitch period information and said gain information from said speech information bit stream into a plurality of separated informations, and decoding each separated information; determining a mixing ratio of the low-frequency band based on said low-frequency band voiced/unvoiced discriminating information, using said mixing ratio to mix a pitch pulse generated in response to said pitch period information being linearly interpolated in synchronism with the pitch period and white noise for the low-frequency band; obtaining a spectral envelope amplitude from said spectral envelope information, and identifying a frequency band having a largest spectral envelope amplitude among a predetermined number of high-frequency bands each having a predetermined frequency bandwidth divided on a frequency axis for generating a mixed excitation signal; determining a mixing ratio for each of said predetermined number of high-frequency bands based on said identified frequency band and said high-frequency band voiced/unvoiced discriminating information, using said mixing ratio to mix the pitch pulse generated in response to said pitch period information being linearly interpolated in synchronism with the pitch period and white noise for each of said predetermined number of high-frequency bands with reference to a predetermined mixing ratio table that had previously been stored; linearly interpolating said spectral envelope information, said pitch period information, said gain information, said mixing ratio of the low-frequency band, said mixing ratio of each of said predetermined number of high-frequency bands, in synchronism with the pitch period; producing a mixing signal for the low-frequency band by mixing said pitch pulse and said white noise with reference to the interpolated mixing ratio of the low-frequency band; producing a mixing signal of each of said predetermined number of high-frequency bands by mixing said pitch pulse and said white noise with reference to the interpolated mixing ratio for each of said predetermined number of high-frequency bands, and then producing a mixing signal for the high-frequency band corresponding to a summation of all of the mixing signals of said predetermined number of high-frequency bands; producing a mixed excitation signal by summing said mixing signal for the low-frequency band and said mixing signal for the high-frequency band; and producing a reproduced speech by adding said interpolated spectral envelope information and said interpolated gain information to said mixed excitation signal.</p></layer>
<layer id = "layer282"><p><b>US4531228A:Speech recognition system for an automotive vehicle</b><br>A carriage and drive mechanism for use in mines in which the drive engages a continuous chain and moves the carriage along a rack; including a chain deflecting device and chain guide members.<br><b>Independant Claims</b><br>1. A speech recognition system for an automotive vehicle for activating an actuator in response to a spoken instruction inputted through a microphone which comprises: (a) first smoothing means for smoothing the spoken instruction signal inputted through the microphone; (b) second smoothing means for smoothing the spoken instruction signal inputted through the microphone, said second smoothing means having a time constant longer than that of said first smoothing means; (c) signal level increasing means for increasing the spoken instruction signal voltage level smoothed by said second smoothing means; (d) threshold level outputting means for outputting a first threshold level for detecting the start of the spoken instruction and a second threshold level for detecting the end of spoken instruction in dependence upon the signal voltage level increased by said signal level increasing means, the second threshold level being equal to or higher than the first threshold level; (e) means for comparing the spoken instruction signal voltage level smoothed by said first smoothing means with the first and second threshold levels outputted from said threshold level outputting means with respect to voltage level and signal duration, and for outputting a spoken instruction start command signal when the spoken instruction signal voltage level smoothed by said first smoothing means exceeds the first threshold level for more than a reference start time and a spoken instruction end command signal when the spoken instruction signal voltage level smoothed by said first smoothing means drops below the second threshold level for more than a reference end time; and (f) a speech recognizer for starting recognizing the spoken instruction signal inputted through the microphone in response to the start command signal and stopping recognizing the same signal in response to the end command signal.<br>4. A speech recognition system for an automotive vehicle for activating an actuator in response to a spoken instruction inputted through a microphone which comprises: (a) a spectrum normalizing amplifier connected to said microphone for amplifying and spectrum-normalizing the spoken instruction signal transduced by the microphone; (b) a rectifier connected to said spectrum normalizing amplifier for rectifying the amplified spoken instruction signal; (c) a first smoother connected to said rectifier for smoothing the rectified spoken instruction signal and outputting a first smoothed signal; (d) a second smoother connected to said rectifier for smoothing the rectified spoken instruction signal at a time constant longer than that of said first smoother and outputting a second smoothed signal; (e) a multiplier connected to said second smoother for multiplying the second smoothed spoken instruction signal; (f) a holding circuit connected to said multiplier for passing the multiplied spoken instruction signal as a reference start threshold level when a holding signal is not applied thereto but holding the multiplied spoken instruction signal as a reference end threshold level when the holding signal is applied thereto, and outputting the held signal thereafter; (g) a level comparator one input terminal of which is connected to said first smoother and the other input terminal of which is connected to said holding circuit for comparing the first smoothed spoken instruction signal with the reference start threshold level when the holding signal is not applied to said holding circuit and outputting a H-voltage level signal when the first smoothed signal exceeds the reference start threshold level and for comparing the first smoothed spoken instruction signal with the reference end threshold level when the holding signal is applied to said holding circuit and outputting a L-voltage level signal when the first smoother signal drops below the reference end threshold level; (h) a duration comparator connected to said level comparator and said holding circuit for comparing the pulse width of the H-voltage level signal with a reference start time and outputting a spoken instruction start command signal when the H-voltage level pulse width exceeds the reference start time and for comparing the pulse width of the L-voltage level signal with a reference end time and outputting a spoken instruction end command signal when the L-voltage level pulse width exceeds the reference end time, the H-voltage level signal from said duration comparator being applied to said holding circuit as the holding signal; and (i) a speech recognizer connected to said duration comparator for starting recognizing the spoken instruction signal inputted through the microphone in response to the start command signal and stopping recognizing the same signal in response to the end command signal.<br>6. A speech recognition system for an automotive vehicle for activating an actuator in response to a spoken instruction inputted through a microphone which comprises: (a) a level detector connected to the microphone for detecting the voltage level of the spoken instruction signal for each sampling time interval; (b) a threshold calculator connected to said level detector for calculating the first start threshold levels on the basis of a calculation expression in dependence upon the spoken instruction signal voltage levels outputted from said level detector; (c) a start comparator connected to said level detector and said threshold calculator for comparing the sampled spoken instruction signal voltage level data from said level detector with the first start threshold level from said threshold calculator with respect to voltage level and number of sampled data and outputting a spoken instruction start command signal when the sampled signal level data of more than a reference start number exceeds the first calculated start threshold level continuously, (d) a timer unit connected to said start comparator for outputting a timer signal for a predetermined time period in response to the spoken instruction start command signal; (e) an OR gate one input terminal of which is connected to said start comparator and the other input terminal of which is connected to said timer unit for outputting an ORed signal; (f) a memory unit connected to said level detector and said OR gate for storing the spoken instruction voltage level data from said level detector in response to the spoken instruction start command signal from said start comparator and outputting the voltage level data stored in said memory unit, in the reverse order, when said timer unit stops outputting the timer signal; (g) a threshold corrector connected to said threshold calculator and said timer unit for correcting the first start threshold level calculated by said threshold calculator to a higher second end threshold level when said timer unit stops outputting the timer signal; (h) an end comparator connected to said threshold corrector and said memory unit for comparing the spoken instruction signal level data read from said memory unit in the reverse order with the second end threshold level corrected by said threshold level corrector with respect to voltage level and number of sampled data when said timer unit stops outputting the timer signal and outputting a spoken instruction end command signal when the read signal level data of more than a reference end number exceeds the second corrected end threshold level continuously; and (i) a speech recognizer connected to said start comparator and said end comparator for starting recognizing the spoken instruction signal inputted through the microphone in response to the start command signal and stopping recognizing the same signal in response to the end command signal.<br>12. A method of detecting the start and end of a spoken instruction inputted through a microphone to activate an actuator by a speech recognition system for an automotive vehicle, which comprises the following steps of: (a) sampling spoken instruction signal voltage levels Sn for each sampling time interval; (b) calculating first start threshold levels En in dependence upon the sampled signal voltage level data Sn on the basis of an expression; (c) comparing the sampled signal voltage levels Sn with the calculated start threshold level En; (d) if a sampled signal voltage level Sn exceeds the calculated start threshold level En, counting the number M.sub.1 of signal level data Sn exceeding the threshold level En; (e) comparing the counted number M.sub.1 with a reference start number W.sub.1 ; (f) if the counted number M.sub.1 exceeds the reference start number W.sub.1, outputting a spoken instruction start command signal M.sub.3 and storing the sampled signal voltage level data Sn in a memory sequentially; (g) if the counted number M.sub.1 does not exceed the reference start number W.sub.1 in step (f) above, returning to step (a) above; (h) comparing the counted number M.sub.1 with a reference number L; (i) if the counted number M.sub.1 is equal to the reference number L, correcting the first start threshold level E obtained when the start is detected to a higher second end threshold level E'; (j) reading the spoken instruction voltage level data Xm stored in the memory in the reverse order; (k) comparing the read data Xm with the second corrected end threshold level E'; (l) if a read data Xm exceeds the second end threshold level E', counting the number V of the read data Xm exceeding the second end threshold level E'; (m) comparing the counted number V of read data Xm with a reference end-detection number W.sub.3 ; (n) if the counted number V of read data Xm exceeding the second end threshold level E' exceeds the reference end-detection number W.sub.3, outputting a spoken instruction end detection command signal; and (o) if the read data Xm do not exceed the second end threshold level E' in step (k) above or if the counted number V of read data Xm exceeding the second end threshold level E' does not exceed the reference end-detection number W.sub.3 in step (m) above, returning to step (j) above.</p></layer>
<layer id = "layer283"><p><b>US5765127A:High efficiency encoding method</b><br>A multi-purpose water pressure plunger employs a source of pressurized water to dislodge clogs in bathroom drainage pipes and the like. The plunger is fashioned of a resilient cone-shaped cup, a rigid handle, an adjustable valve, and a means of connection to a pressurized source of water. Sealing against and partially extending into a drain opening, the cup permits full thrust of pressurized water into a drainage pipe without a backflow of water. The cup consists of an upper, deformable portion, and a solid, occlusive bottom portion defining a nipple-shaped end and a heightened center region opposite the nipple-shaped end surrounded by a concave recess. A flow of pressurized water is supplied to the cup through an elongated and ridged handle with a lengthwise aperture therethrough. An adjustable valve including a ball component and a regulating lever controls the flow of water into the handle, and thus, to the clogged drain. As another embodiment, the water pressure plunger comprises a compressible cup defining an interior cavity and including a solid upper portion and a barrel-like bottom which defines a circumferential orifice, the upper portion defining a central passage therethrough ending in a nipple-shaped end positioned within the interior cavity of the compressible cup. A firm elongated handle defining a lengthwise aperture attaches to the compressible cup opposite the nipple-shaped end.<br><b>Independant Claims</b><br>1. A high efficiency encoding method, comprising the steps of: determining an M-dimensional vector by dividing an input audio signal on a block-by-block basis and performing time domain to frequency domain conversion on at least one block of the signal; determining an S-dimensional vector from the M-dimensional vector, where S<M, by dividing the components of the M-dimensional vector into plural groups and finding a representative value for each of said groups; processing the S-dimensional vector in accordance with a first vector quantization; finding a corresponding S-dimensional code vector by inversely quantizing output data of the first vector quantization; generating an expanded M-dimensional vector by expanding the S-dimensional code vector; determining data expressing a relation between the expanded M-dimensional vector and the original M-dimensional vector, and performing a second vector quantization on said data.<br>17. A high efficiency encoding method comprising the steps of: determining an M-dimensional vector on the basis of data obtained by dividing an input audio signal on a block-by-block basis thus generating blocks each comprising a variable number of parameter data, performing time domain to frequency domain conversion on one of the blocks of the signal to generate frequency domain data, and generating from the frequency domain data a fixed number of data determining the M-dimensional vector; and processing the M-dimensional vector in accordance with vector quantization.<br>22. A high efficiency encoding method comprising the steps of: determining an M-dimensional vector for each block of an input audio signal by dividing the input audio signal on a block-by-block basis, performing time domain to frequency domain conversion on each block of the signal to generate frequency domain data, and performing an inter-block difference operation on the frequency domain data; and processing each said M-dimensional vector in accordance with vector quantization.<br>27. A high efficiency encoding method comprising the steps of: determining an M-dimensional vector by dividing an input voice signal on block-by-block basis, performing time domain to frequency domain conversion on at least one block of the signal thus generating frequency domain data, and performing non-linear compression on the frequency domain data; determining an S-dimensional vector from the M-dimensional vector, where S<M, by dividing the data of the M-dimensional vector into plural groups and finding an average value for each of the groups; processing the S-dimensional vector in accordance with a first vector quantization; finding a corresponding S-dimensional code vector by inversely quantizing output data of the first vector quantization; expanding the S-dimensional code vector to an expanded M-dimensional vector; and processing, in accordance with second vector quantization, data indicative of a difference between the expanded M-dimensional vector and the M-dimensional vector.<br>28. A high efficiency encoding method comprising the steps of: determining M-dimensional vectors by dividing an input audio signal on a block-by-block basis and performing time domain to frequency domain conversion on each block of the audio signal to generate frequency domain data for said each block, wherein the audio signal is a voice signal; and performing quantization, by using a vector quantizer having plural codebooks according to a state of the input audio signal to process each said M-dimensional vector in accordance with vector quantization, and by changing over the plural codebooks in accordance with a parameter indicating characteristics of said each block of the voice signal, wherein a first one of the codebooks is employed to process at least one of the M-dimensional vectors for which the parameter indicates that a corresponding portion of the voice signal is voiced, and a second one of the codebooks is employed to process at least one of the M-dimensional vectors for which the parameter indicates that a corresponding portion of the voice signal is unvoiced.</p></layer>
<layer id = "layer284"><p><b>US4720865A:Multi-pulse type vocoder</b><br>A tuning device including a conductive housing in which are suspended a dielectric substrate. A pair of first and second resonant circuits is disposed on the substrate in parallel with each other. Each resonant circuit is formed by an elongated conductive film and a capacitive element. A grounded conductive strip film is provided between the transmission lines of the first and second resonant circuits to reduce the interstage coupling between the two transmission lines with a resultant decrease in spacing between them.<br><b>Independant Claims</b><br>1. A multi-pulse type vocoder comprising: first means for extracting spectrum information of an input speech signal X(n) in an analysis frame; second means for developing an impulse response h(n) of a filter specified by said spectrum information; third means for developing a cross-correlation series .phi..sub.hx (mi) between said input speech signal X(n) and said impulse response h(n) at a time lag mi within a predetermined time range, n representing a sampling time point; fourth means for developing an auto-correlation series R.sub.hh (n) of said impulse response h(n) and a normalized auto-correlation series R.sub.hh,(n) normalized by a power of the auto-correlation series R.sub.hh(n) ; fifth means for determining the most similar portion of said cross-correlation series .phi..sub.hx to the auto-correlation series R.sub.hh(n) ; sixth means for developing a similarity between the cross-correlation series .phi..sub.hx(n) and the normalized auto-correlation series R.sub.hh '.sub.(n) ; and seventh means for providing a pulse having the maximum similarity value and a time position thereat of the most similar portion of said cross-correlation series .phi..sub.hx as one of said multi-pulses.</p></layer>
<layer id = "layer285"><p><b>US4701955A:Variable frame length vocoder</b><br>An orthopedic prosthetic device, formed of interlocking links, which allows for full motion in the plan of articulation, yet which resists, lateral forces applied to the joint, and tendencies of the joint to dislocate in a lateral direction. The interlocking links having adjustable stops so that motion in the plane of articulation may be restricted if desired.<br><b>Independant Claims</b><br>1. A variable frame length vocoder comprising: means for obtaining a feature vector from an output speech signal at every given frame; means for storing the feature vectors in a given section having a predetermined number of frames; means for approximating a change in said feature vectors in said given section with a given number of flat sections indicating the period of time with little or no change in the feature vectors, and inclined sections connecting said neighboring flat sections with inclined lines and indicating period of time with abrupt transitions in the feature vectors, said flat section length being variable, said inclined section length being constant, said inclined line representing the change of the feature vectors; means for outputting the feature vector of a given frame in each flat section as a representative vector of said flat section; means for outputting the number of frames present in said flat section as a repeat signal; and, on a synthesis side, means for producing the feature vector in each of said inclined sections by interpolating between the representative vectors of the flat sections present on both sides of said inclined section.</p></layer>
<layer id = "layer286"><p><b>US5717829A:Pitch control of memory addressing for changing speed of audio playback</b><br><b>Independant Claims</b><br>1. An audio signal processing apparatus comprising: memory means for storing an input audio signal; memory address control means; pitch extracting means for calculating an audio pitch and power information from the audio signal read out from said memory means; address phase management means receiving a zero pitch and a fixed pitch for use in outputting a memory address sample set providing an auto-correlation peak in a selected time duration of the audio signal in response to the audio pitch and the power information from said pitch extracting means and including pitch detecting means for detecting whether the audio pitch from said pitch extracting means is a final pitch formed of a number of samples for use in memory address correction in response to a memory address from said memory address control means for outputting a second memory address sample set based upon the results of detection and pitch selection means for selecting a final memory address sample set output from the address phase management means to the memory address control means using the second memory address sample set from said pitch detecting means; and wherein said memory address control means calculates a memory address for said memory means using the memory address sample set from said address phase management means.</p></layer>
<layer id = "layer287"><p><b>US5701344A:Audio processing apparatus</b><br>A projection lens enlarges and projects optical images in a matrix type light valve onto a screen. The projection lens includes a front lens group of the retrofocusing type; a rear lens with aspherical surfaces whose radii of curvature in the peripheral portion are shorter than that in the central portion; and a reflecting mirror which is positioned between the front lens group and the rear lens and diverts the optical axis. This projection lens enables the optical images in the light valve to be projected with a high contrast and a wide field angle. A projection system is provided which includes a light source; a light valve; a converging optical apparatus; a transmission type screen; diverting place mirrors; and a projection lens to enlarge and project the optical images in the light valve onto the screen. Since the projection lens has a wide field angle and has the reflecting mirror provided therein, the projection system can be very compact.<br><b>Independant Claims</b><br>1. An audio processing apparatus for processing an audio signal, comprising: a) a first input terminal arranged to receive a left-side audio signal composed mainly of an audio signal corresponding to a sound coming from a left side; b) a second input terminal arranged to receive a right-side audio signal composed mainly of an audio signal corresponding to a sound coming from a right side; c) first delay means for delaying the left-side audio signal received by said first input terminal to output a resultant signal; d) second delay means for delaying the right-side audio signal received by said second input terminal to output a resultant signal; e) first subtraction means for subtracting the signal outputted from said second delay means from the left-side audio signal received by said first input terminal to output a resultant signal; f) second subtraction means for subtracting the signal outputted from said first delay means from the right-side audio signal received by said second input terminal to output a resultant signal; g) first frequency band signal extraction means for extracting from the signal outputted from said first subtraction means a first low frequency band signal and a first high frequency band signal to output the first low frequency band signal and the first high frequency band signal; h) second frequency band signal extraction means for extracting from the signal outputted from said second subtraction means a second low frequency band signal and a second high frequency band signal to output the second low frequency band signal and the second high frequency band signal; i) first addition means for adding together the first low frequency band signal outputted from said first frequency band signal extraction means and the second low frequency band signal outputted from said second frequency band signal extraction means to output a resultant signal; j) second addition means for adding together the first high frequency band signal outputted from said first frequency band signal extraction means and the signal outputted from said first addition means to output a resultant signal; and k) third addition means for adding together the second high frequency band signal outputted from said second frequency band signal extraction means and the signal outputted from said first addition means to output a resultant signal.<br>3. An audio processing apparatus for processing an audio signal, comprising: a) a first input terminal arranged to receive a left-side audio signal composed mainly of an audio signal corresponding to a sound coming from a left side; b) a second input terminal arranged to receive a right-side audio signal composed mainly of an audio signal corresponding to a sound coming from a right side; c) first delay means for delaying the left-side audio signal received by said first input terminal to output a resultant signal; d) second delay means for delaying the right-side audio signal received by said second input terminal to output a resultant signal; e) first subtraction means for subtracting the signal outputted from said second delay means from the left-side audio signal received by said first input terminal to output a resultant signal; f) second subtraction means for subtracting the signal outputted from said first delay means from the right-side audio signal received by said second input terminal to output a resultant signal; g) first frequency band signal extraction means for extracting from the signal outputted from said first subtraction means a first low frequency band signal and a first high frequency band signal to output the first low frequency band signal and the first high frequency band signal; h) second frequency band signal extraction means for extracting from the signal outputted from said second subtraction means a second low frequency band signal and a second high frequency band signal to output the second low frequency band signal and the second high frequency band signal; i) first addition means for adding together the first low frequency band signal outputted from said first frequency band signal extraction means and the second low frequency band signal outputted from said second frequency band signal extraction means to output a resultant signal; j) variable addition means for adding together, in a variable arbitrary addition ratio, the first low frequency band signal outputted from said first frequency band signal extraction means and the signal outputted from said first addition means to output a first variable addition signal and for adding together, in a variable arbitrary addition ratio, the second low frequency band signal outputted from said second frequency band signal extraction means and the signal outputted from said first addition means to output a second variable addition signal; k) second addition means for adding together the first high frequency band signal outputted from said first frequency band signal extraction means and the first variable addition signal outputted from said variable addition means to output a resultant signal; and l) third addition means for adding together the second high frequency band signal outputted from said second frequency band signal extraction means and the second variable addition signal outputted from said variable addition means to output a resultant signal.<br>5. An audio processing apparatus for processing an audio signal, comprising: a) a first input terminal arranged to receive a left-side audio signal composed mainly of an audio signal corresponding to a sound coming from a left side; b) a second input terminal arranged to receive a right-side audio signal composed mainly of an audio signal corresponding to a sound coming from a right side; c) first delay means for delaying the left-side audio signal received by said first input terminal to output a resultant signal; d) second delay means for delaying the right-side audio signal received by said second input terminal to output a resultant signal; e) first subtraction means for subtracting the signal outputted from said second delay means from the left-side audio signal received by said first input terminal to output a resultant signal; f) second subtraction means for subtracting the signal outputted from said first delay means from the right-side audio signal received by said second input terminal to output a resultant signal; g) first frequency band signal extraction means for extracting from the signal outputted from said first subtraction means a first low frequency band signal and a first high frequency band signal to output the first low frequency band signal and the first high frequency band signal; h) second frequency band signal extraction means for extracting from the signal outputted from said second subtraction means a second low frequency band signal and a second high frequency band signal to output the second low frequency band signal and the second high frequency band signal; i) first addition means for adding together the first low frequency band signal outputted from said first frequency band signal extraction means and the second low frequency band signal outputted from said second frequency band signal extraction means to output a resultant signal; j) selective output means for selecting one of the first low frequency band signal outputted from said first frequency band signal extraction means and the signal outputted from said first addition means to output the selected one as a first selection signal and for selecting one of the second low frequency band signal outputted from said second frequency band signal extraction means and the signal outputted from said first addition means to output the selected one as a second selection signal; k) second addition means for adding together the first high frequency band signal outputted from said first frequency band signal extraction means and the first selection signal outputted from said selective output means to output a resultant signal; and l) third addition means for adding together the second high frequency band signal outputted from said second frequency band signal extraction means and the second selection signal outputted from said selective output means to output a resultant signal.</p></layer>
<layer id = "layer288"><p><b>US5819212A:Voice encoding method and apparatus using modified discrete cosine transform</b><br>In driving a color liquid crystal panel having red, green and blue color filters, a color liquid crystal display apparatus sets signal electrodes of these three colors in a no-bias status during a non-display period of an image signal in such a manner as to permit at least two colors of the signal electrodes have mutually different effective voltages. The effective voltages in the no-bias state are set at values which provide the optimum value for .DELTA.n.multidot.d (.DELTA.n: birefringence) in accordance with cell gaps d on the signal electrodes, thereby minimizing the height difference between the color filters.<br><b>Independant Claims</b><br>1. A signal encoding method comprising the steps of: splitting an input signal into a plurality of frequency bands; encoding signals of said each of the plurality of frequency bands in respective manners depending on signal characteristics of said each of the plurality of frequency bands; splitting the input speech signal into a first frequency band and a second frequency band, said second frequency band being lower on the frequency spectrum than the first frequency band; performing a short-term prediction on the signals of the second frequency band for finding short-term prediction residuals; performing a long-term prediction on the short-term prediction residuals for finding long-term prediction residuals; and orthogonal-transforming the long-term prediction residuals using a modified discrete cosine transform for the orthogonal transform step with a predetermined transform length selected to be a power of 2.<br>6. A signal encoding apparatus comprising: band-splitting means for splitting an input signal into a plurality of frequency bands to provide a plurality of split frequency bands; and encoding means for encoding signals of each of said plurality of frequency bands in respective manners responsive to respective signal characteristics of each of the plurality of frequency bands and for multiplexing a first signal of one of the plurality of split frequency bands and a portion of a second signal of another of the plurality of split frequency bands that is not in common with said first signal; wherein said encoding means includes: means for finding short-term prediction residuals by a short-term prediction performed on a signal of a lowest one of said plurality of frequency bands; means for finding long-term prediction residuals by performing a long-term prediction on the short-term prediction residuals; and orthogonal transform means for orthogonal-transforming the long-term prediction residuals, wherein said input signal is a broad-band input signal and said band-splitting means splits said broad-band input signal into at least a signal of a telephone frequency band and a signal in a frequency band higher on the frequency spectrum than said telephone frequency band.<br>7. A portable radio terminal apparatus including an antenna, the apparatus comprising: first amplifier means for amplifying an input speech signal to provide a first amplified signal; A/D conversion means for A/D converting the first amplified signal; speech encoding means for encoding an output of said A/D conversion means to provide an encoded signal; transmission path encoding means for channel-coding said encoded signal; modulation means for modulating an output of said transmission path encoding means to provide a modulated signal; D/A conversion means for D/A converting said modulated signal; and second amplifier means for amplifying a signal from said D/A conversion means to provide a second amplified signal and for supplying the second amplified signal to the antenna; wherein said speech encoding means includes: band-splitting means for splitting the output of said A/D conversion means into a plurality of frequency bands, wherein the plurality of frequency bands include a first frequency band and a second frequency band, said second frequency band being lower on the frequency spectrum than the first frequency band; and encoding means for encoding signals of each of said plurality of frequency bands in respective manners responsive to signal characteristics of said each of the plurality of frequency bands and for multiplexing a first signal of one of the plurality of frequency bands and a portion of a second signal of another of the plurality of frequency bands that is not in common with said first signal; means for finding short-term prediction residuals by a short-term prediction performed on a signal of a lowest one of said plurality of frequency bands; means for finding long-term prediction residuals by performing a long-term prediction on the short-term prediction residuals; and orthogonal transform means for orthogonal-transforming the long-term prediction residuals using a modified discrete cosine transform for the orthogonal transform with a predetermined transform length selected to be a power of 2.<br>8. A method for multiplexing an encoded signal comprising the steps of: encoding an input signal with a first encoding employing a first bit rate for producing a first encoded signal; encoding said input signal with a second encoding for producing a second encoded signal, said second encoded signal having a first portion in common with a portion of said first encoded signal and a second portion not in common with said first encoded signal, said second encoding employing a second bit rate different from said first bit rate; and multiplexing said first encoded signal and the second portion of said second encoded signal not in common with said first encoded signal; wherein said step of encoding said input signal with a second encoding includes splitting the input signal into a first signal with a frequency band approximately equal to that of a telephone signal and a second signal with a frequency band higher on a frequency spectrum than said first signal and said common portion is the encoded signal derived from linear prediction parameters of the input signal.<br>10. A portable radio terminal apparatus including an antenna, the apparatus comprising: first amplifier means for amplifying an input speech signal to provide a first amplified signal; A/D conversion means for A/D converting the amplified signal; speech encoding means for encoding an output of said A/D conversion means to provide an encoded signal; transmission path encoding means for channel-coding said encoded signal; modulation means for modulating an output of said transmission path encoding means to provide a modulated signal; D/A conversion means for D/A converting said modulated signal; and second amplifier means for amplifying a signal from said D/A conversion means to provide a second amplified signal and for supplying the second amplified signal to the antenna; wherein said speech encoding means comprises: means for multiplexing a first encoded signal obtained by a first encoding of the output of said A/D conversion means employing a first bit rate and a second encoded signal obtained by a second encoding of the output of said A/D conversion means, said second encoded signal having a first portion in common with a portion of said first encoded signal and a second portion not in common with said first encoded signal, said second encoding employing a second bit rate different from the first bit rate; band-splitting means for splitting the output of said A/D conversion means into a plurality of frequency bands, wherein the plurality of frequency bands include a first frequency band and a second frequency band, said second frequency band being lower on the frequency spectrum than the first frequency band; and encoding means for encoding signals of each of said plurality of frequency bands in respective manners responsive to signal characteristics of said each of the plurality of frequency bands; means for finding short-term prediction residuals by a short-term prediction performed on a signal of the second frequency band; means for finding long-term prediction residuals by performing a long-term prediction on the short-term prediction residuals; orthogonal transform means for orthogonal-transforming the long-term prediction residuals using a modified discrete cosine transform for the orthogonal transform with a predetermined transform length selected to be a power of 2; and means for multiplexing said first encoded signal and the second portion of the second encoded signal not in common with said first encoded signal.</p></layer>
<layer id = "layer289"><p><b>US5974375A:Coding device and decoding device of speech signal, coding method and decoding method</b><br>1,1,1.Trifluoro-2-fluoroethane (HFC 134A), respectively 1,1,1-trifluoro-2, 2-dichloroethane (HCFC 123) 1,1,1-trifluoro-2-chloro, 2-fluoroethane (HCFC 124) and pentafluoroethane (HFC 125), are purified from impurities respectively consisting of 1,1-difluoro-2-chloroethylene (HCFC 1122) and of difluorodichloroethylene (CFC 1112A and CFC 1112), by reacting in the liquid state respectively HFC 134A or HCFC 123, HCFC 124 and HFC 125 containing the relative impurities, with elemental fluorine, at temperatures ranging from -80.degree. to -40.degree. C.<br><b>Independant Claims</b><br>1. A coding device for coding an input speech vector including voice frames and unvoice frames, said coding device comprising: a codebook, including a quantification table stored in said codebook, operable for coding the speech vector, during the voice frames of the speech vector, by selecting a code, from said quantification table, most suitable to a characteristic of the speech vector; a codebook renewal circuit operable to determine a correlative value between the speech vector and the code selected by said codebook, determine a most-frequently-selected code as a code of the quantification table which is selected most frequently, generate a renewal code based on the correlative value, and replace the most-frequently-selected code with the renewal code in said quantification table of said codebook; wherein said coding device is operable to transmit the renewal code in a surplus bit portion of an unvoice frame of information sent from said coding device.<br>3. A coding device as claimed in claim wherein said codebook renewal circuit is operable to determine the most-frequently-selected code as a code of the quantification table which has been selected most frequently since a previous renewal of a code by said codebook renewal circuit.<br>18. A coding device for coding an input speech vector including voice frames and unvoice frames, said coding device comprising: a codebook, including a quantification table stored in said codebook, operable for coding the speech vector, during the voice frames of the input speech vector, by selecting a code, from said quantification table, most suitable to a characteristic of the speech vector; a codebook renewal circuit operable to determine a correlative value between the speech vector and the code selected by said codebook, determine an oldest code as a renewable code of said quantification table having a longest passage of time since being renewed, generate a renewal code based on the correlative value, and replace the oldest code with the renewal code in said quantification table of said codebook; wherein said coding device is operable to transmit the renewal code in a surplus bit portion of an unvoice frame of information sent from said coding device.<br>34. A decoding device for decoding a received speech vector including voice frames and unvoice frames, said decoding device comprising: a receiving circuit operable to pick up most-appropriate-code information from the voice frames of the received speech vector and a renewal code from a surplus bit portion of an unvoice frame of the received speech vector; a codebook, including a quantification table stored in said codebook, operable to perform a decoding procedure in order to decode the received speech vector during the voice frames of the received speech vector by selecting a code corresponding to the most-appropriate-code information from the quantification table, and operable to perform a renewal procedure by replacing the code selected by said codebook with the renewal code received by said receiving circuit.<br>45. A coding method for coding an input speech vector including voice frames and unvoice frames, said method comprising: coding the input speech vector during the voice frames by selecting a code most appropriate to a characteristic of the input speech vector from a quantification table; determining a correlative value between the speech vector and the selected code; determining a most-frequently-selected code as a code of the quantification table which is selected most frequently; generating a renewal code based on the correlative value; replacing the most-frequently-selected code with the renewal code in the quantification table; and transmitting the renewal code in a surplus bit portion of an unvoice frame of sent information.<br>57. A coding method for coding an input speech vector including voice frames and unvoice frames, said method comprising: coding the input speech vector during the voice frames by selecting a code most appropriate to a characteristic of the input speech vector from a quantification table; determining a correlative value between the speech vector and the selected code; determining an oldest code as a renewable code of the quantification table having a longest passage of time since being renewed; generating a renewal code based on the correlative value; replacing the oldest code with the renewal code in the quantification table; and transmitting the renewal code in a surplus bit portion of an unvoice frame of sent information.<br>68. A decoding method for decoding a received speech vector including voice frames and unvoice frames, for use with a quantification table, said decoding method comprising: receiving most-appropriate-code information from the voice frames of the received speech vector and a renewal code from a surplus bit portion of an unvoice frame of the received speech vector; decoding the received speech vector during the voice frames of the received speech vector by selecting a code corresponding to the most-appropriate-code information from the quantification table; replacing a specified code of a voice characteristic in the quantification table with the renewal code.<br>79. A machine-readable data signal embodied in a transmission signal on a transmission channel for use with a decoding device including a quantification table containing codes for speech characteristics, said machine-readable data signal comprising: a voice frame including characteristics of transmitted speech; and an unvoice frame including a surplus bit portion containing a renewal code for replacing a code of a voice characteristic in the quantification table of the decoding device.</p></layer>
<layer id = "layer290"><p><b>US20030033141A1:Voice data processing device and processing method</b><br>Apparatus for measuring electrical characteristics of biological tissues includes an autonomous capsule with an external surface having openings, a plurality of electrodes located within the openings, and a processor in communication with the plurality of electrodes for generating electrical characteristics. A method for measuring electrical characteristics of biological tissues includes the steps of introducing into the digestive tract an autonomous electrode configuration, selecting sets of electrodes for measurement, introducing a current into the selected electrodes, collecting electrical data from the selected electrodes, and calculating electrical characteristics from the collected data.<br><b>Independant Claims</b><br>1. A data processing device for carrying out speech processing in which prediction taps for finding prediction values of the speech of high sound quality are extracted from the synthesized sound obtained on affording linear prediction coefficients and residual signals, generated from a preset code, to a speech synthesis filter, said speech of high sound quality being higher in sound quality than said synthesized sound, and in which said prediction taps are used along with preset tap coefficients to perform preset predictive calculations to find said prediction values of said speech of high sound quality, said device comprising: prediction tap extracting means for extracting from said synthesized sound said prediction taps used for predicting said speech of high sound quality, as target speech, the prediction values of which are to be found; class tap extraction means for extracting a class tap, used for sorting said target speech to one of a plurality of classes, from said code, by way of classification; classification means for finding the class of said target speech based on said class tap; acquisition means for acquiring said preset tap coefficients associated with the class of said target speech from among a plurality of tap coefficients as found on learning from class to class; and prediction means for finding said prediction values of said target speech using said prediction taps and said preset tap coefficients associated with said class of said target speech.<br>8. A data processing method for carrying out speech processing of extracting prediction taps for finding prediction values of the speech of high sound quality from the synthesized sound obtained on affording linear prediction coefficients and residual signals, generated from a preset code, to a speech synthesis filter, said speech of high sound quality being higher in sound quality than said synthesized sound, and of performing preset predictive calculations using prediction taps along with preset tap coefficients to find said prediction values of said speech of high sound quality, said method comprising: a prediction tap extracting step of extracting from said synthesized sound said prediction taps used for predicting said speech of high sound quality, as target speech, the prediction values of which are to be found; a class tap extraction step of extracting a class tap, used for sorting said target speech to one of a plurality of classes, by way of classification, from said code; a classification step of finding the class of said target speech based on said class tap; an acquisition step of acquiring said tap coefficients associated with the class of said target speech from among said tap coefficients as found on learning from class to class; and a prediction step of finding said prediction values of said target speech using said prediction taps and said tap coefficients associated with said class of said target speech.<br>9. A recording medium having recorded thereon a program for having a computer execute speech processing of extracting prediction taps for finding prediction values of the speech of high sound quality from the synthesized sound obtained on affording linear prediction coefficients and residual signals, generated from a preset code, to a speech synthesis filter, said speech of high sound quality being higher in sound quality than said synthesized sound, and of performing preset predictive calculations using said prediction taps along with preset tap coefficients to find said prediction values of said speech of high sound quality, said method comprising: a prediction tap extracting step of extracting from said synthesized sound said prediction taps used for predicting said speech of high sound quality, as target speech, the prediction values of which are to be found; a class tap extraction step of extracting class taps, used for sorting said target speech to one of a plurality of classes, by way of classification, from said code; a classification step of finding the class of said target speech based on said class taps; an acquisition step of acquiring said tap coefficients associated with the class of said target speech from among said tap coefficients as found on learning from class to class; and a prediction step of finding said prediction values of said target speech using said prediction taps and said tap coefficients associated with said class of said target speech.<br>10. A learning device for learning preset class taps usable for finding, by preset predictive calculations, prediction values of the speech of high sound quality from the synthesized sound obtained on affording linear prediction coefficients and residual signals, generated from a preset code, to a speech synthesis filter, said speech of high sound quality being higher in sound quality than said synthesized sound, said learning device comprising: class tap extraction means for extracting class taps from said code, said class taps being used for classifying said speech of high sound quality, as target speech, the prediction values of which are to be found; classification means for finding a class of said target speech based on said class taps; and learning means for carrying out learning so that the prediction errors of the prediction values of the speech of high sound quality obtained on carrying out predictive calculations using said tap coefficients and the synthesized sound will be statistically minimum, to find said tap coefficients from class to class.<br>14. A learning method for learning preset class taps usable for finding, by preset predictive calculations, prediction values of the speech of high sound quality from the synthesized sound obtained on affording linear prediction coefficients and residual signals, generated from a preset code, to a speech synthesis filter, said speech of high sound quality being higher in sound quality than said synthesized sound, said learning device comprising: a class tap extraction step of extracting class taps from said code, said class taps being used for classifying said speech of high sound quality, as target speech, the prediction values of which are to be found; a classification step of finding a class of said target speech based on said class taps; and a learning step of carrying out learning so that the prediction errors of the prediction values of the speech of high sound quality obtained on carrying out predictive calculations using said tap coefficients and the synthesized sound will be statistically minimum, to find said tap coefficients from class to class.<br>15. A recording medium having recorded thereon a program for having a computer execute learning processing of learning preset class taps usable for finding, by preset predictive calculations, prediction values of the speech of high sound quality from the synthesized sound obtained on affording linear prediction coefficients and residual signals, generated from a preset code, to a speech synthesis filter, said speech of high sound quality being higher in sound quality than said synthesized sound, said learning device comprising: a class tap extraction step of extracting class taps from said code, said class taps being used for classifying said speech of high sound quality, as target speech, the prediction values of which are to be found; a classification step of finding a class of said target speech based on said class taps; and a learning step of carrying out learning so that the prediction errors of the prediction values of the speech of high sound quality obtained on carrying out predictive calculations using said tap coefficients and the synthesized sound will be statistically minimum, to find said tap coefficients from class to class.<br>16. A data processing device for generating, from a preset code, filter data to be afforded to a speech synthesis filter adapted for synthesizing the speech based on linear prediction coefficients and a preset input signal, comprising: code decoding means for decoding said code to output decoded filter data; acquisition means for acquiring preset tap coefficients as found by carrying out learning; and prediction means for carrying out preset predictive calculations, using said tap coefficients and the decoded filter data, to find prediction values of said filter data, to send the so found prediction values to said speech synthesis filter.<br>27. A data processing method for generating, from a preset code, filter data to be afforded to a speech synthesis filter adapted for synthesizing the speech based on linear prediction coefficients and on a preset input signal, comprising: a code decoding step of decoding said code to output decoded filter data; an acquisition step of acquiring preset tap coefficients as found by carrying out learning; and a prediction step of carrying out preset predictive calculations, using said tap coefficients and the decoded filter data, to find prediction values of said filter data, to send the so found prediction values to said speech synthesis filter.<br>28. A recording medium having recorded thereon a program for having a computer execute data processing of generating, from a preset code, filter data to be afforded to a speech synthesis filter adapted for synthesizing the speech based on linear prediction coefficients and a preset input signal, comprising: a code decoding step of decoding said code to output decoded filter data; an acquisition step of acquiring preset tap coefficients as found by carrying out learning; and a prediction step of carrying out preset predictive calculations, using said tap coefficients and the decoded filter data, to find prediction values of said filter data, to send the so found prediction values to said speech synthesis filter.<br>29. A learning device for learning preset tap coefficients usable for finding, by predictive calculations from a code associated with filter data to be applied to a speech synthesis filter which synthesizes the speech based on linear prediction coefficients and a preset input signal, prediction values of said filter data, comprising: code decoding means for decoding the code corresponding to filter data to output decoded filter data; and learning means for carrying out learning so that prediction errors of prediction values of said filter data obtained on carrying out predictive calculations using said tap coefficients and decoded filter data will be statistically smallest to find said tap coefficients.<br>37. A learning method for learning preset tap coefficients usable for finding, by predictive calculations from a code associated with filter data to be applied to a speech synthesis filter which synthesizes the speech based on linear prediction coefficients and a preset input signal, prediction values of said filter data, comprising: a code decoding step of decoding the code corresponding to filter data to output decoded filter data; and a learning step of carrying out learning so that the prediction errors of prediction values of said filter data obtained on carrying out predictive calculations using said tap coefficients and decoded filter data will be statistically smallest to find said tap coefficients.<br>38. A recording medium having recorded thereon a program for having a computer execute learning processing of learning preset tap coefficients usable for finding, by predictive calculations from a code associated with filter data to be applied to a speech synthesis filter which synthesizes the speech based on linear prediction coefficients and a preset input signal, prediction values of said filter data, comprising: a code decoding step of decoding the code corresponding to filter data to output decoded filter data; and a learning step of carrying out learning so that the prediction errors of prediction values of said filter data obtained on carrying out predictive calculations using said tap coefficients and decoded filter data will be statistically smallest to find said tap coefficients.<br>39. A speech processing device for finding prediction values of the speech of high sound quality from the synthesized sound obtained on affording linear prediction coefficients and residual signals, generated from a preset code, to a speech synthesis filter, said speech of high sound quality being higher in sound quality than said synthesized sound, comprising: prediction tap extraction means for extracting prediction taps usable for predicting the speech of high sound quality, as target speech, the prediction values of which are to be found, class tap extraction means for extracting class taps, usable for sorting the target speech to one of a plurality of classes, by way of classification, from said synthesized sound, said code or the information derived from said code; acquisition means for acquiring said tap coefficients associated with the class of said target speech from the tap coefficients as found on learning from one class to another; and prediction means for finding the prediction values of said target speech using said prediction taps and said tap coefficients associated with the class of said target speech.<br>46. A speech processing method for finding prediction values of the speech of high sound quality from the synthesized sound obtained on affording linear prediction coefficients and residual signals, generated from a preset code, to a speech synthesis filter, said speech of high sound quality being higher in sound quality than said synthesized sound, comprising: a prediction tap extraction step of extracting prediction taps usable for predicting the speech of high sound quality, as target speech, the prediction values of which are to be found, from said synthesized sound, said code or the information derived from said code; a class tap extraction step of extracting a class tap, usable for sorting the target speech to one of a plurality of classes, by way of classification, from said synthesized sound, said code or the information derived from said code; a classification step of finding the class of said target speech based on said class tap; an acquisition step of acquiring said tap coefficients associated with the class of said target speech from the tap coefficients as found on learning from one class to another; and a prediction step of finding the prediction values of said target speech using said prediction taps and said tap coefficients associated with the class of said target speech.<br>47. A recording medium having recorded thereon a program for having a computer execute speech processing of finding prediction values of the speech of high sound quality from the synthesized sound obtained on affording linear prediction coefficients and residual signals, generated from a preset code, to a speech synthesis filter, said speech of high sound quality being higher in sound quality than said synthesized sound, comprising: a prediction tap extraction step of extracting prediction taps usable for predicting the speech of high sound quality, as target speech, the prediction values of which are to be found, a class tap extraction step of extracting class taps, usable for sorting the target speech to one of a plurality of classes, by way of classification, from said synthesized sound, said code or the information derived from said code; an acquisition step of acquiring said tap coefficients associated with the class of said target speech from the tap coefficients as found on learning from one class to another; and a prediction step of finding the prediction values of said target speech using said prediction taps and said tap coefficients associated with the class of said target speech.<br>48. A learning device for learning preset tap coefficients usable for finding, by preset predictive calculations, prediction values of the speech of high sound quality, from the synthesized sound obtained on affording linear prediction coefficients and residual signals, generated from a preset code, to a speech synthesis filter, said speech of high sound quality being higher in sound quality than said synthesized sound, comprising: prediction tap extraction means for extracting prediction taps usable in predicting the speech of high sound quality, as target speech, the prediction values of which are to be found, from said synthesized sound, said code or the information derived from said code; class tap extraction means for extracting class taps usable for sorting the target speech to one of a plurality of classes, by way of classification, from said synthesized sound, said code or the information derived from said code; classification means for finding the class of said target speech based on said class taps; and learning means for carrying out learning so that the prediction errors of prediction values of said speech of high sound quality, obtained on carrying out predictive calculations using said tap coefficients and said prediction taps, will be statistically smallest.<br>52. A learning method for learning preset tap coefficients usable for finding, by preset predictive calculations, prediction values of the speech of high sound quality, from the synthesized sound obtained on affording linear prediction coefficients and residual signals, generated from a preset code, to a speech synthesis filter, said speech of high sound quality being higher in sound quality than said synthesized sound, comprising: a prediction tap extraction step of extracting prediction taps usable in predicting the speech of high sound quality, as target speech, the prediction values of which are to be found, from said synthesized sound, said code or the information derived from said code; a class tap extraction step of extracting a class tap usable for sorting the target speech to one of a plurality of classes, by way of classification, from said synthesized sound, said code or the information derived from said code; a classification step of finding the class of said target speech based on said class tap; and a learning step of carrying out learning so that the prediction errors of prediction values of said speech of high sound quality, obtained on carrying out predictive calculations using said tap coefficients and said prediction taps, will be statistically smallest, to find said tap coefficients.<br>53. A recording medium having recorded thereon a program for having a computer execute learning processing of learning preset tap coefficients usable for finding, by preset predictive calculations, prediction values of the speech of high sound quality, from the synthesized sound obtained on affording linear prediction coefficients and residual signals, generated from a preset code, to a speech synthesis filter, said speech of high sound quality being higher in sound quality than said synthesized sound, comprising: prediction tap extraction step of extracting prediction taps usable in predicting the speech of high sound quality, as target speech, the prediction values of which are to be found, from said synthesized sound, said code or the information derived from said code; a class tap extraction step of extracting a class tap usable for sorting the target speech to one of a plurality of classes, by way of classification, from said synthesized sound, said code or the information derived from said code; a classification step of finding the class of said target speech based on said class tap; and a learning step of carrying out learning so that the prediction errors of prediction values of said speech of high sound quality, obtained on carrying out predictive calculations using said tap coefficients and said prediction taps, will be statistically smallest, to find said tap coefficients.</p></layer>
<layer id = "layer291"><p><b>US20020138268A1:Speech bandwidth extension</b><br>A surface mountable electrical connector (20) includes an insulating housing (22) having a coaxial subassembly receiving cavity (54) extending thereinto to a cavity bottom (56) proximate the mounting face (28); a coaxial subassembly 60) having center and outer conductors (66, 76); and first and second contacts (82, 92) along the mounting face and extending into the housing to resilient inner ends (84, 94) exposed proximate the cavity bottom. The resilient inner ends are engaged by portions of the center and outer conductors (66, 76) at the insertion end of the coaxial subassembly (60) upon full insertion into the cavity. The first and second contacts (82, 92) include outer contact sections (88, 98) adapted to be surface mounted to a circuit board. The arrangement incorporates a coaxial contact into a multiple contact hybrid connector (20) fully surface mountable to a circuit board.<br><b>Independant Claims</b><br>1. A method of generating a wide-band speech signal from a first narrow-band speech signal, the method comprising: analyzing the first narrow-band speech signal to generate one or more parameters; synthesizing a lower frequency-band signal based on at least one of the one or more parameters; and combining the synthesized lower frequency-band signal with a second narrow-band speech signal that is derived from the first narrow-band speech signal, wherein: the one or more parameters include a pitch frequency parameter; and synthesizing the lower frequency-band signal based on at least one of the one or more parameters comprises generating continuous sine tones that are based on the pitch frequency parameter.<br>11. An apparatus for generating a wide-band speech signal from a first narrow-band speech signal, the apparatus comprising: logic that analyzes the first narrow-band speech signal to generate one or more parameters; logic that synthesizes a lower frequency-band signal based on at least one of the one or more parameters; and logic that combines the synthesized lower frequency-band signal with a second narrow-band speech signal that is derived from the first narrow-band speech signal, wherein: the one or more parameters include a pitch frequency parameter; and the logic that synthesizes the lower frequency-band signal based on at least one of the one or more parameters comprises logic that generates continuous sine tones that are based on the pitch frequency parameter.</p></layer>
<layer id = "layer292"><p><b>US20020128839A1:Speech bandwidth extension</b><br>Plastic injection-compression multi-cavity molding of flash-free improved-cleanliness thermoplastic spectacle lenses are suitable to be robotically dip hardcoated. Special spring-loaded molds having variable-volume mold cavities are used in an injection-compression molding process to form, without parting line flash, pairs of a wide range of differing optical power of polycarbonate Rx spectacle lenses. These pairs have special molded-on design features which are specially suited for full automation, starting with a novel way for ejection out of the mold into a takeout robot which is integrated via full automation with subsequent dip hardcoating. A molded-on tab with each pair of lenses is specially suited for manipulation by SCARA type robot. This combination produces micro-clean hardcoated paired molded lens made entirely within a single continuous cleanroom air enclosure surrounding the lenses, without any human operators therein, nor requiring any cutting or trimming of the molded paired lens or runner system before hardcoating, nor use of Freon (tm) CFC nor aqueous cleaning protocols before dipcoating. An extension of this cleanroom enclosure and robotic handling scheme may optionally provide in-line continuous-product-flow automatic inspection of optical power and lens cosmetic quality, and/or may optionally provide in-line continuous-product-flow anti-reflective thin film vacuum coating, before the molded-and-hardcoated polycarbonate lenses exit out of the continuous cleanroom air enclosure and/or receive any manual handling.<br><b>Independant Claims</b><br>1. A method of generating a wide-band speech signal from a first narrow-band speech signal, the method comprising: analyzing the first narrow-band speech signal to generate one or more parameters; synthesizing a first higher frequency-band signal based on at least one of the one or more parameters; generating a second higher frequency-band signal by amplifying the first higher-frequency band signal by a gain amount that is based, at least in part, on one or more spectral amplitude peaks in the first narrow-band speech signal; and combining the second higher frequency-band signal with a second narrow-band speech signal that is derived from the first narrow-band speech signal.<br>23. An apparatus for generating a wide-band speech signal from a first narrow-band speech signal, the method comprising: logic that analyzes the first narrow-band speech signal to generate one or more parameters; logic that synthesizes a first higher frequency-band signal based on at least one of the one or more parameters; logic that generates a second higher frequency-band signal by amplifying the first higher-frequency band signal by a gain amount that is based, at least in part, on one or more spectral amplitude peaks in the first narrow-band speech signal; and logic that combines the second higher frequency-band signal with a second narrow-band speech signal that is derived from the first narrow-band speech signal.</p></layer>
<layer id = "layer293"><p><b>US5054072A:Coding of acoustic waveforms</b><br>There is provided a one-part structural adhesive composition having satisfactory adhesive to plane surfaces and oily surface-adhesion properties. The adhesive composition comprises substantial amounts of a hydroxyl-containing polymerizable methacrylate represented by a certain general formula and a polymerizable methacrylate having 2 or more methacrylic groups as well as small amounts of a polymerizable organic phosphate represented by a certain general formula, tetrahydroquinoline salt of o-benzoic sulfimide, an organic hydroperoxide and water; the amounts of the above-mentioned components in the composition being within defined ranges.<br><b>Independant Claims</b><br>1. A method of coding speech for digital transmission, the method comprising: sampling the speech to obtain a series of discrete samples and constructing therefrom a series of frames, each frame spanning a plurality of samples; analyzing each frame of samples to extract a set of variable frequency components having individual amplitudes and phases which, in summation, approximate the waveform of the speech frame; estimating a pitch for each frame of samples; coding data representative of the analyzed speech frame and the pitch for digital transmission; synthesizing a set of reconstruction frequency components from the encoded data; and establishing a pitch onset time at which the frequency components come into phase synchrony.<br>7. A method of coding speech for digital transmission, the method comprising: sampling the speech to obtain a series of discrete samples and constructing therefrom a series of frames, each frame spanning a plurality of samples; analyzing each frame of samples to extract a set of variable frequency components having individual amplitudes and phases; estimating the pitch for each frame of samples; constructing a spectral envelope from the amplitudes of the frequency components; sampling the envelope based upon the pitch estimate to obtain a set of amplitude values at variable channel frequencies, the location of which vary with the pitch; coding the amplitude values for digital transmission; and synthesizing a set of reconstruction frequency components from the encoded values.<br>10. A speech coding device comprising: sampling means for sampling a speech waveform to obtain a series of discrete samples and constructing therefrom a series of frames, each frame spanning a plurality of samples; analyzing means for analyzing each frame of samples by Fourier analysis to extract a set of variable frequency components having individual amplitude and phase values; estimating means for estimating the pitch for each frame of samples; coding means for coding data representative of the analyzed speech frame and a pitch for each frame; synthesizing means for synthesizing a set of reconstruction frequency components from the encoded data; and means for establishing a pitch onset time at which the frequency components come into phase synchrony.<br>16. A speech coding device comprising: sampling means for sampling a speech waveform to obtain a series of discrete samples and constructing therefrom a series of frames, each frame spanning a plurality of samples; analyzing means for analyzing each frame of samples by Fourier analysis to extract a set of variable frequency components having individual amplitude and phase values; estimating means for estimating the pitch of the waveform; envelope construction means for constructing a spectral envelope from the amplitudes of the frequency components; envelope sampling means for sampling the envelope based upon the pitch estimate to obtain a set of amplitude values at variable channel frequencies, the number and spacing of which vary based upon the pitch; coding means for coding the amplitude values for digital transmission; and synthesizing means for synthesizing a set of reconstruction frequency components from the encoded values.<br>19. A system for processing an acoustic waveform comprising: analyzing means for decomposing the waveform into a set of sinusoidal components having individual amplitudes which in sum approximate the waveform over an analysis frame; pitch estimating means for estimating the pitch of the waveform for the analysis frame; and synthesis means for generating a synthetic reproduction of the waveform from the data representative of the analyzed waveform and the pitch, including means for summing a set of sinusoidal reconstruction components and means for establishing a pitch onset time for each analysis frame at which time the phases of the sinusoidal reconstruction components come into synchrony.</p></layer>
<layer id = "layer294"><p><b>US6456965B1:Multi-stage pitch and mixed voicing estimation for harmonic speech coders</b><br>An external mirror includes an indicator light and a case with a protruding portion whose outer face is arranged more outside than an outer face of the indicator light. Even when the external mirror hits or bumps against an obstacle, the protruding portion is the first and likely only portion which hits or bumps against the obstacle thereby preventing the indicator light from being damaged. Therefore, the indicator light will have to be replaced less frequently, thereby reducing a burden on the user. Typically, the protruding portion is provided below the indicator light. Accordingly, the indicator light can be strongly protected with respect to the contact from a lower side of the external mirror, where there are generally a relatively large number/percentage of obstacles. Preferably, the indicator light has a convex surface lens which protrudes toward outside of the external mirror. Preferably, the protruding portion has a ridge line between an upper face and a lower face of the protruding portion.<br><b>Independant Claims</b><br>1) A method of estimating the pitch of a segment of a speech signal, comprising the steps of: selecting a set of initial pitch candidates by dividing the pitch range into sub-ranges, applying a pitch cost function to input samples, and selecting a pitch candidate for each said sub-range for which the pitch cost function is maximized, determining an input pitch period using at least one previously calculated pitch value from prior segments of said speech signal; determining whether said determined pitch period from prior segments is short or long; and for each pitch candidate, if said average pitch period is short having just a few harmonics such that it is easier to match time domain waveforms, using a time domain pitch estimation process to evaluate each said pitch candidate, or if said average pitch period is long being more than a few harmonics and not easier to match time domain waveforms, using a frequency domain pitch estimation process to evaluate each said pitch candidate.</p></layer>
<layer id = "layer295"><p><b>US20010001140A1:Modular approach to speech enhancement with an application to speech coding</b><br>A method and apparatus for testing an integrated circuit device. An integrated circuit device undergoes testing in at least two different stages of the manufacturing process. At one stage, the semiconductor wafer containing multiple chip dice is probed by a probe tester that tests each of the dice individually. At another stage, after an individual chip die has been encapsulated in a package, a package tester tests and exercises the functions of the chip.<br><b>Independant Claims</b><br>1. An apparatus for enhancing and coding speech, comprising: a speech coder that receives digitized speech; a spectrum signal processor within the speech coder determining spectrum components of the digitized speech; an excitation signal processor within the speech coder determining excitation signal components of the digitized speech; a first speech enhancement system within the speech coder processing the spectrum components; and a second speech enhancement system within the speech coder processing the excitation signal components.<br>5. A method for enhancing and coding speech, comprising the steps of: receiving digitized speech; and enhancing the digitized speech to extract component parts of the digitized speech; wherein the digitized speech is enhanced differently for each of the component parts.<br>13. A method for enhancing and coding speech, comprising the steps of: receiving digitized speech; performing a first speech enhancement process as part of a spectrum analysis of the digitized speech; performing a second speech enhancement process as part of a residual processing of the digitized speech; and producing encoded speech based on the resulting outputs from the first speech enhancement process and the second speech enhancement process.<br>14. A speech coder, comprising: a first means for enhancing and extracting a first set of features characterizing a digital speech signal; and a second means for enhancing and extracting a second set of features characterizing the digital speech signal.</p></layer>
<layer id = "layer296"><p><b>US20020002455A1:CORE ESTIMATOR AND ADAPTIVE GAINS FROM SIGNAL TO NOISE RATIO IN A HYBRID SPEECH ENHANCEMENT SYSTEM</b><br>The present invention provides an aqueous metallic coating composition comprising (A) 100 parts, based on solids, of a film-forming aqueous acrylic polymer obtained by neutralizing a copolymer having a number average molecular weight of 2,000 to 200,000, an acid value of 10 to 110 mg KOH/g and a hydroxyl value of 20 to 100 mg KOH/g, the copolymer being obtained by copolymerizing (a) 10 to 35 wt. % of styrene, (b) 5 to 25 wt. % of C.sub.6-18 alkyl (meth)acrylate, (c) 0.1 to 10 wt. % of phosphoric ester group-containing polymerizable unsaturated monomer represented by the general formula ##STR1## wherein X is a hydrogen atom or methyl, and m is an integer of 1 to 3, (d) 2 to 10 wt. % of carboxyl-containing polymerizable unsaturated monomer, (e) 5 to 20 wt. % of hydroxyl-containing polymerizable unsaturated monomer, and (f) 0 to 77.9 wt. % of other polymerizable unsaturated monomer, and (B) 2 to 100 parts by weight of a metallic flake pigment; and a method for forming a topcoat using the composition.<br><b>Independant Claims</b><br>1. A speech enhancement system, comprising: a noise adaptation module receiving noisy speech, the noisy speech being characterized by spectral coefficients spanning a plurality of frequency bins and containing an original noise, the noise adaptation module segmenting the noisy speech into noise-only frames and signal-containing frames, and the noise adaptation module determining a noise estimate and a probability of signal absence in each frequency bin; a signal-to-noise ratio estimator coupled to the noise adaptation module, the signal-to-noise ratio estimator determining a first signal-to-noise ratio and a second signal-to-noise ratio based on the noise estimate; and a core estimator coupled to the signal-to-noise ratio estimator and receiving the noisy speech, the core estimator applying to the spectral coefficients of the noisy speech a first set of gains in the frequency domain without discarding the noise-only frames to produce speech that contains a residual noise, wherein the first set of gains is determined based, at least in part, on the second signal-to-noise ratio and a level of aggression, and wherein the core estimator is operative to maintain the spectral density of the spectral coefficients of the residual noise below a proportion of the spectral density of the spectral coefficients of the original noise.<br>8. A method for enhancing speech, comprising the steps of: receiving noisy speech, wherein the noisy speech is characterized by spectral coefficients spanning a plurality of frequency bins and contains an original noise; segmenting the speech into noise-only frames and signal-containing frames; determining a noise estimate and a probability of signal absence in each frequency bin; determining a first signal-to-noise ratio and a second signal-to-noise ratio based on the noise estimate; determining a first set of gains based, at least in part, on the second signal-to-noise ratio and a level of aggression; and applying the first set of gains to the spectral coefficients of the noisy speech without discarding the noise-only frames to produce speech that contains a residual amount of noise, such that the spectral density of the spectral coefficients of the residual noise is maintained below a proportion of the spectral density of the spectral coefficients of the original noise.</p></layer>
<layer id = "layer297"><p><b>US6415253B1:Method and apparatus for enhancing noise-corrupted speech</b><br>A communication cable, which has a cable core provided in the center as well as outside cladding and strain relief elements applied in the region of the outside cladding, has at least one optical transmission element which includes at least one light waveguide, provided in the region of the strain relief elements.<br><b>Independant Claims</b><br>1) A noise suppression device for suppressing noise in a noise-corrupted signal, said device comprising: a voice activity detector which receives said noise-corrupted signal, and generates a control signal in accordance with a likelihood of existence of speech in said noise-corrupted signal, wherein said voice activity detector includes a state machine; wherein said state machine has an intermediate state between a silence state where said speech is determined not to exist in said noise-corrupted signal, and a speech state where said speech is determined to exist in said noise-corrupted signal, wherein said state machine has a primary detect flag, and a speech detect flag; and said voice activity detector sets said primary detect flag and said speech detect flag, so that a state transition directly from said silence state to said speech state occurs, if an energy ratio of said speech is larger than a first threshold; and wherein said voice activity detector sets said primary detect flag and said speech detect flag, so that a state transition from said silence state to said speech state via said intermediate state occurs, if an energy ratio of said speech is larger than a second threshold; and a smoothing module which filters said noise-corrupted signal based on a window whose size is determined based on said control signal, wherein said size of said window has at least two values in accordance with said likelihood that said speech exists in said noise-corrupted signal, wherein the largest value of said at least two values is provided when said speech is determined not to exist in said noise-corrupted signal, and wherein the smallest value of said at least two values is provided when said speech is determined to exist in said noise-corrupted signal; wherein said smoothing module further comprises a Wiener filter; and wherein nulls of filter coefficients of said Wiener filter are removed.<br>8) A method for suppressing noise in a noise-corrupted signal, comprising the steps of: receiving said noise-corrupted signal; generating a control signal in accordance with a likelihood of existence of speech in said noise-corrupted signal, wherein said control signal is generated based on a state machine; and said state machine has an intermediate state between a silence state where said speech is determined not to exist in said noise-corrupted signal, and a speech state where said speech is determined to exist in said noise-corrupted signal, wherein said state machine has a primary detect flag, and a speech detect flag; and wherein said voice activity detector sets said primary detect flag and said speech detect flag, so that a state transition directly from said silence state to said speech state occurs, if an energy ratio of said speech is larger than a first threshold; determining a size of a window based on said control signal, wherein said size of said window has at least two values in accordance with said likelihood that said speech exists in said noise-corrupted signal, wherein the largest value of said at least two values is provided when said speech is determined not to exist in said noise-corrupted signal, and wherein the smallest value of said least two values is provided when said speech is determined to exist in said noise-corrupted signal; and filtering said noise-corrupted signal based on said window; wherein said filtering step further comprises a step of applying a Wiener filter to said noise-corrupted signal; and wherein nulls of filter coefficients of said Wiener filter are removed.</p></layer>
<layer id = "layer298"><p><b>US20030040908A1:Noise suppression for speech signal in an automobile</b><br>A method for controlling printing of pixels corresponding to multi-level image data includes determining, based on multi-level image data for a target pixel and multi-level image data for pixels adjacent to the target pixel, whether the target pixel should be printed using a dye-based ink or whether the target pixel should be printed using a pigment-based ink. In a case that it is determined that the target pixel should be printed using the dye-based ink, a printer is instructed to print the target pixel using the dye-based ink. On the other hand, in a case that it is determined that the target pixel should be printed using the pigment-based ink, the printer is instructed to print the target pixel using the pigment-based ink.<br><b>Independant Claims</b><br>1. A signal processing system used in automobile to suppress noise from a speech signal comprising: a first signal detector configured to provide a first signal comprised of a desired component plus an undesired component, wherein the desired component includes speech; a second signal detector configured to provide a second signal comprised mostly of an undesired component; a signal processor operatively coupled to the first and second signal detectors and configured to receive and process the first and second signals based on at least one noise suppression technique to provide an output signal having a substantial portion of the desired component and a large portion of the undesired component removed.<br>19. A signal processing system comprising: a first signal detector configured to provide a first signal comprised of a desired component plus an undesired component; a second signal detector configured to provide a second signal comprised mostly of an undesired component; an adaptive canceller configured to receive the first and second signals, and to remove a portion of the undesired component in the first signal that is correlated with the undesired component in the second signal to provide an intermediate signal; a voice activity detector configured to receive the intermediate signal and provide a control signal indicative of non-active time periods whereby the desired component is detected to be absent from the intermediate signal; and a noise suppression unit configured to receive the intermediate and second signals, and to suppress the undesired component in the intermediate signal based on a spectrum modification technique to provide an output signal having a substantial portion of the desired component and a large portion of the undesired component removed.<br>29. A voice activity detector for use in a noise suppression system, comprising: a first unit configured to receive and transform an input signal to provide a transformed signal comprised of a sequence of blocks of M elements for M frequency bins, one block for each time instant, and wherein M is two or greater; a second unit configured to provide a power value for each element of the transformed signal; a third unit configured to receive power values for the M frequency bins and provide a reference value for each of the M frequency bins, wherein the reference value for each frequency bin is a smallest power value received within a particular time window for the frequency bin plus a particular offset; a fourth unit configured to compare the power value for each frequency bin against the reference value for the frequency bin and provide a corresponding output value; and a fifth unit configured to provide a control signal indicative of activity in the input signal based on output values for the M frequency bins.<br>34. A method for suppressing noise in an automobile, comprising: detecting via a first signal detector a first signal comprised of a desired component plus an undesired component; detecting via a second signal detector a second signal comprised mostly of an undesired component; removing a portion of the undesired component in the first signal that is correlated with the undesired component in the second signal based on adaptive cancellation; and removing an additional portion of the undesired component in the first signal based on spectrum modification to provide an output signal having a substantial portion of the desired component and a large portion of the undesired component removed.<br>35. A method for detecting activity in an input signal, comprising: transforming the input signal to provide a transformed signal comprised of a sequence of blocks of M elements for M frequency bins, one block for each time instant, and wherein M is two or greater; deriving a power value for each element of the transformed signal; deriving a reference value for each of the M frequency bins, wherein the reference value for each frequency bin is a smallest power value received within a particular time window for the frequency bin plus a particular offset; comparing the power value for each frequency bin against the reference value for the frequency bin to provide a corresponding output value; and providing a control signal indicative of activity in the input signal based on output values for the M frequency bins.</p></layer>
<layer id = "layer299"><p><b>US6453289B1:Method of noise reduction for speech codecs</b><br>The circuit for controlling the threshold voltage in the flash memory cell according to the present invention comprises a circuit for generating a first voltage depending on the amount of a drain current in the memory cell; a first element for comparing the first voltage with a reference voltage and for generating a second voltage; and a second element for supplying a control gate voltage for the control gate of the memory cell depending on the second voltage.<br><b>Independant Claims</b><br>1) A method of reducing noise in an input speech signal having digitized samples comprising the steps of: dividing said input speech signal into segments comprising a selected number of said samples using a selected window function; processing said segments using a Fourier analysis to obtain input noisy speech spectra of said input speech signal; estimating the noise spectral magnitude of said samples to generate a noise spectral estimate; smoothing said noise spectral estimate and said input noisy speech spectra; computing a gain function using said noise spectral estimate and said input noisy speech spectra which have been smoothed; generating speech signal spectra using said input noisy speech spectra and said gain function; and performing an inverse Fourier process on said speech signal spectra to obtain a reduced noise speech signal.<br>18) A method of determining whether speech is present in a frame of an input signal characterized by a plurality of frames, wherein the input signal can comprise additive background noise, the method comprising the steps of: performing a noise reduction process on said input signal to generate an enhanced input signal; computing pitch lag using said enhanced input signal; determining a representation of said noise in said input signal; selecting a threshold corresponding to an energy level of said input signal at which said input signal is determined to comprise speech; obtaining autocorrelation function coefficients corresponding to said frame of said input signal; updating at least one of said representation of said noise and said threshold using a threshold adaptation process involving at least one of a plurality of characteristics of said input signal comprising tone, pitch, predictor values and said autocorrelation function coefficients, said pitch being determined via periodicity detection using said pitch lag; adaptively filtering said autocorrelation function coefficients using said representation of said noise to generate an input signal energy parameter; and comparing said input signal energy parameter with said threshold.<br>24) A voice activity detector for determining whether speech is present in a frame of an input signal, wherein the input signal can comprise additive background noise, comprising: a long-term voice activity detector operable to detect speech during a portion of said input signal; a short-term voice activity detector operable to detect speech during an initial predetermined number of frames of said input signal; and a logical OR device for using an output generated via said short-term voice activity detector during said initial predetermined number of frames of said input signal and said long-term voice activity detector thereafter, said short-term voice activity detector and said long-term voice activity detector each being operable to generate an indication for when said speech is present as said output.<br>25) A speech encoder with integrated noise reduction comprising: a voice activity detection module; a frame delay device; an encoder operable to receive signals from said voice activity detection module and to provide delayed pitch lag to said voice activity detection module; a noise reduction module; and a high-pass filter and scale module for receiving and processing input speech signals and providing input signals to said voice activity detection module and to said noise reduction module, said voice activity detection module processing said input signals and generating a first output signal as an input to said noise reduction module to indicate the presence of voice in said input signal, said noise reduction module being operable to process said input signals and generate a first output signal for input to said encoder; said voice activity detection module being operable to receive autocorrelation function coefficients, to determine line spectral frequencies from said autocorrelation function coefficients, and to perform at least one of a plurality of functions comprising using line spectral frequencies comprising tone detection, predictor values computation and spectral comparison; said noise reduction module being operable to generate enhanced input speech signals by processing said input signals to reduce noise therein and to provide enhanced pitch lag to said voice activity detection module via said frame delay device, said encoder determining said enhanced pitch lag from said enhanced input speech signals.<br>27) A speech encoder with integrated noise reduction comprising: a voice activity detection module; a frame delay device; a noise reduction module; an encoder operable to receive signals from said noise reduction module and to provide delayed pitch lag to said voice activity detection module; and a high-pass filter and scale module for receiving and processing input speech signals and providing an output signal to said voice activity detection module and to said noise reduction module, said voice activity detection module being operable to process said output signal and generate an output signal as input to said noise reduction module, said noise reduction module being operable to process said output signal and generate an output signal as input to said encoder, said voice activity detection module generating a second output signal as an input to said noise reduction module to indicate the presence of noise in said input speech signals; said noise reduction module being operable to generate a noise spectral estimate of said noise, to obtain noisy speech spectra from said input speech signals, to smooth said noise spectral estimate and said noisy speech spectra, to compute a gain using the smooth said noisy speech spectra, to smooth said gain, and to generate noise reduced speech signal spectra using said noisy speech spectra and said gain.<br>32) A speech decoding apparatus with integrated noise reduction for decoding encoded signals comprising: a decoder for decoding said encoded signals to generate decoded output signals; a voice activity detection module operable to generate a first indicator signal indicating the presence of voice in decoded said output signals, said first indicator signal being used to generate a second indicator signal to indicate when decoded said output signals comprise noise; a noise reduction module operable to receive said output signals from said decoder and said second indicator signal from said voice activity module, and to process said output signals to reduce noise therein and generate enhanced speech signals, said noise reduction module being operable to generate a noise spectral estimate and to update said noise spectral estimate using said second indicator signal, to generate noisy speech spectra using said output signals, to smooth said noisy speech spectra and said noise spectral estimate, to compute a gain using the smoothed noisy speech spectral, to smooth said gain and to generate said enhanced speech signals using said gain and said noisy speech spectra, said enhanced speech signals being provided to said decoder for high-pass filtering and scaling.<br>38) A speech decoding apparatus with integrated noise reduction for decoding encoded signals comprising: a decoder for decoding said encoded signals to generate output signals; a voice activity detection module operable to receive pitch lag data and line spectral frequencies from said decoder, said voice activity module being operable to perform periodicity detection using said pitch lag data and at least one of a plurality of functions comprising tone detection, predictor values computation and spectral comparison using said line spectral frequencies to generate a first indicator signal indicating the presence of voice in said encoded signals; a noise reduction module operable to receive said output signals from said decoder and said first indicator signal from said voice activity module, and to process said output signals to reduce noise therein and generate enhanced speech signals, said enhanced speech signals being provided to said decoder for high-pass filtering and scaling.</p></layer>
<layer id = "layer300"><p><b>US6453285B1:Speech activity detector for use in noise reduction system, and methods therefor</b><br>According to an embodiment of the invention, a method and apparatus for image segmentation are described. An embodiment of a method comprises inserting a state comprising a set of image segmentations into a queue, the queue being ordered by priority, the set of image segmentations having a priority representing a bound for a quality of the segmentations; extracting the state in the queue having the highest priority; if the extracted state is a terminal state, halting and outputting the extracted state as a solution; if the extracted state is not a terminal state refining the extracted state into a plurality of sets of segmentations, each of the plurality of sets having a priority, inserting the plurality of sets of segmentations into the queue, and iteratively repeating the extraction of the state in the queue having the highest priority.<br><b>Independant Claims</b><br>1) A speech activity detector for detecting whether speech signals are present in individual time frames of an input signal, the speech activity detector comprising: a speech detector that receives as input the input signal and examines the input signal in order to generate a plurality of statistics that represent characteristics indicative of the presence or absence of speech in a time frame of the input signal, and generates an output based on the plurality of statistics representing a likelihood of speech presence in a current time frame, the plurality of statistics further comprising: a speech energy change statistic representing a change in energy within speech frequency bands between a first group of one or more time frames and a second group of one or more time frames; and a spectral deviation change statistic representing a change in the spectral shape of speech frequency bands of the input signal between a first group of one or more time frames and a second group of one or more time frames; and a state machine coupled to the speech detector and having a plurality of states, the state machine receiving as input the output of the speech detector and transitioning between the plurality of states based on a state at a previous time frame and the output of the speech detector for the current time frame, the state machine generating as output a speech activity status signal based on the state of the state machine which provides a measure of the likelihood of speech being present during the current time frame, the plurality of states comprising: a reset state representing identification of a change in background noise level; and one or more speech present states, wherein each of the one or more speech present states has an associated likelihood of speech being present during the current time frame.<br>14) A method of detecting speech activity in individual time frames of an input signal, comprising steps of: generating a plurality of statistics from the input signal, the statistics representing characteristics indicative of the presence or absence of speech in the time frame of the input signal, the plurality of statistics further comprising: a speech energy change statistic representing a change in energy within speech frequency bands between a first group of one or more time frames and a second group of one or more time frames; and a spectral deviation change statistic representing a change in the spectral shape of speech frequency bands of the input signal between a first group of one or more time frames and a second group of one or more time frames; and defining a plurality of states of a state machine, the plurality of states comprising: a reset state representing identification of a change in background noise level; and one or more speech present states, wherein each of the one or more speech present states has an associated likelihood of speech being present during the current time frame; transitioning between states of the state machine based on a set of rules dependent on the plurality of statistics for a current time frame and the state of the state machine at a previous time frame; and generating a speech activity status signal based on the state of the state machine,</p></layer>
<layer id = "layer301"><p><b>US6188980B1:Synchronized encoder-decoder frame concealment using speech coding parameters including line spectral frequencies and filter coefficients</b><br>A data memory system includes a non-spare area having a plurality of memory cell blocks and containing pages, a spare area having a plurality of spare memory cell blocks in which data items are previously set to a certain value and containing pages, and a determination circuit which detects a data error of at least two bits when data is read out from the page of the non-spare area and determines the number of error bits in the readout page for each readout page. When the result of determination by the determination circuit indicates two or more bits, the contents of the readout page are error-corrected and programmed into the page of the spare area.<br><b>Independant Claims</b><br>1) A speech encoding system using an analysis by synthesis approach on a speech signal, the speech encoding system comprising: an encoder that generates a series of line spectral frequencies, some of the line spectral frequencies are produced out of order; the encoder determines the number of line spectral frequencies that are produced out of order; the encoder selectively applies a first of a plurality of correction techniques to process the series of line spectral frequencies that are produced out of order if the number of line spectral frequencies that is produced out of order exceeds a first predetermined threshold; the encoder selectively applies a second of the plurality of correction techniques to process the series of line spectral frequencies that are produced out of order if the number of line spectral frequencies that is produced out of order exceeds a second predetermined threshold; and the second of the plurality of correction techniques comprises reordering the series of line spectral frequencies that are produced out of order.<br>8) A speech codec using an analysis by synthesis approach on a speech signal, the speech encoding system comprising: an encoder processing circuit that generates a series of filter coefficients, some of the filter coefficients is produced out of order; the encoder processing circuit determines the number of filter coefficients that are produced out of order; and the encoder processing circuit selectively applies one of a plurality of techniques to accommodate the production of the series of filter coefficients that are produced out of order if the number of filter coefficients that is produced out of order exceeds a predetermined threshold.<br>16) A method used by a speech encoder that operates on a speech signal, the method comprising: producing from the speech signal a series of line spectral frequencies, at least one of the line spectral frequencies being produced out of order; determining the number of line spectral frequencies that are produced out of order; and deciding either to reorder the series of line spectral frequencies that are produced out of order, or to replace at least a portion of the series of line spectral frequencies that are produced out of order using at least a portion of one previous series of line spectral frequencies if the number of line spectral frequencies that is produced out of order exceeds a predetermined threshold.</p></layer>
<layer id = "layer302"><p><b>US6507814B1:Pitch determination using speech classification and prior pitch estimation</b><br><b>Independant Claims</b><br>1) A speech encoding system for encoding a speech signal including a previous pitch lag and a current pitch lag, the speech encoding system comprising: an adaptive codebook for storing excitation vectors associated with corresponding pitch lag candidates; and an encoder processing circuit for identifying the pitch lag candidates for at least one of a frame and a sub-frame of the speech signal; the encoder processing circuit selecting a preferential one of the pitch lag candidates as the current pitch lag based on at least two of the following: a first timing relationship, a second timing relationship, and voiced classification; the first timing relationships concerning a temporal relationship between the previous pitch lag and at least one of the pitch lag candidates, the second timing relationship concerning a temporal relationship between at least two of the pitch lag candidates, the voiced classification pertaining to an interval of the speech signal.<br>8) A speech encoding system for encoding a speech signal that has a current pitch lag, the speech encoding system comprising: an adaptive codebook; an encoder processing circuit that identifies a plurality of pitch lag candidates; and the encoder processing circuit applying an adaptive weighting factor to a pitch correlation to favor selection of at least one of the pitch lag candidates over at least one other of the pitch lag candidates if at least one of a first timing relationship and a second timing relationship is detected; the first timing relationship associated with one of the pitch lag candidates and the second timing relationship being between at least two of the pitch lag candidates; the encoder processing circuit selecting one of the pitch lag candidates as the current pitch lag by comparing the weighted pitch correlation to another pitch correlation.<br>16) A method for speech encoding, the method comprising: identifying a plurality of pitch lag candidates; using an adaptive weighting factor applied to a pitch correlation to favor at least one of the pitch lag candidates over at least one other of the pitch lag candidates if at least one of a first timing relationship and a second timing relationship is detected; the first timing relationship associated with one of the pitch lag candidates and the second timing relationship being between at least two of the pitch lag candidates; and selecting one of the plurality of the pitch lag candidates as a current pitch lag estimate by comparing the weighted pitch correlation to another pitch correlation.<br>21) A method of encoding a speech signal, the method comprising the steps of: identifying a plurality of pitch lag candidates for a present interval of the speech signal; determining if a previous interval, with respect to the present interval, contains a voiced component; comparing the identified pitch lag candidates to at least one previous pitch lag value for a previous interval; to identify at least one favored one of the pitch lag candidates that falls within a temporal neighborhood of the previous pitch lag value if the previous interval contains a generally voiced component; and favoring selection of the at least one favored one of the pitch lag candidates as a preferential one of the pitch lag candidates by weighting a pitch correlation for at least one favored candidate differently than a remainder of the pitch lag candidates.<br>27) A method of encoding a speech signal, the method comprising the steps of: identifying a plurality of pitch lag candidates for a present interval of the speech signal; determining if a previous interval, with respect to the present interval, contains a voiced component; comparing identified pitch lag candidates to each other; detecting a timing relationship if the compared pitch lag candidates have pitch lags related approximately by an integer multiple of each other; and favoring selection of at least one favored one of the pitch lag candidates with the timing relationship as a preferential one of the pitch lag candidates by weighting a pitch correlation for the at least one favored candidate differently than a remainder of the pitch lag candidates.<br>28) A method of encoding a speech signal, the method comprising: identifying a plurality of regions of the pitch lag; determining a local maximum correlation between a target speech signal and a synthesized speech signal within each of the identified regions to provide a set of local maximum correlations; and selecting a global maximum correlation among the determined local maximum correlations to facilitate selection of a pitch lag for a present interval of a speech signal.</p></layer>
<layer id = "layer303"><p><b>US6449590B1:Speech encoder using warping in long term preprocessing</b><br>A low-pressure mercury vapor discharge lamp according to the invention is provided with a discharge vessel (10) which encloses a discharge space (11) containing mercury and a rare gas in a gaslight manner. The discharge vessel (10) has a light-transmitting tubular portion (12) and a first and a second end portion (13A, 13B). Current supply conductors (20A, 20A'; 20B, 20B') issue through each end portion (13A, 13B) to respective electrodes (21A, 21B) arranged in the discharge space (11). The lamp is further provided with a main amalgam (30) for stabilizing the mercury vapour pressure in the discharge space (11) during normal operation, and with an auxiliary amalgam (31A, 31B) for quickly releasing mercury into the discharge space (11) after switching-on of the lamp. In an equilibrium state at room temperature (25.degree. C.), the mass (m.sub.Hg in mg) of the quantity of mercury absorbed in auxiliary amalgam (31A, 31B) is at most 20 times the mercury vapour pressure (P.sub.E in Pa) prevalent in the discharge space (11) in the equilibrium state. Only comparatively small brightness differences between lamp zones occur in the lamp according to the invention after switching-on.<br><b>Independant Claims</b><br>1) A speech encoder for encoding a speech signal, the speech encoder comprising: an adaptive codebook comprising excitation vectors to support formation of a synthesized speech signal representative of the speech signal; an encoder processing circuit generating a pitch lag contour of the speech signal by using estimates of a previous pitch lag and a current pitch lag of the speech signal; and a long-term preprocessor of the encoder processing circuit warping the speech signal by temporally deforming a weighted speech signal, derived from the speech signal, to conform to the pitch lag contour.<br>7) A speech encoder for encoding a speech signal, the speech encoder comprising: an adaptive codebook comprising excitation vectors to support formation of a synthesized speech signal representative of the speech signal; an encoder processing circuit for estimating a pitch lag of the speech signal and deriving a weighted speech signal from the speech signal; and a long-term preprocessor of the encoder processing circuit applying continuous warping of the speech signal by temporally deforming the weighted speech signal to conform to the estimated pitch lag.<br>11) A speech signal encoder for encoding a speech signal, the speech encoder comprising: an adaptive codebook comprising excitation vectors to support formation of a synthesized speech signal; an encoder processing circuit for estimating a target contour of the speech signal and deriving a weighted speech signal from the speech signal; and a long-term preprocessor of the encoder processing circuit searching for a best local delay of the weighted speech signal, the searching using linear time weighting for warping or temporally differential deformation of the weighted speech signal to conform to the estimated target contour.</p></layer>
<layer id = "layer304"><p><b>US6480822B2:Low complexity random codebook structure</b><br>The method for mounting a semiconductor chip comprises disposing conductive thermoplastic polyimide as a bonding material between an inner lead of the TAB tape and an external connecting electrode of the semiconductor chip, applying pressure to the conductive thermoplastic polyimide by a wedge with heating by a hot stage via the semiconductor chip. The semiconductor chip comprises the external connecting electrode adhered the conductive thermoplastic polyimide. The method for fabricating the semiconductor chip comprises forming a signal line and a protective film, forming an electrode pad on the signal line not provided the protective film, forming a conductive thermoplastic polyimide layer on the semiconductor wafer by spin coating, forming a resist on the conductive thermoplastic polyimide layer and performing an etching with using the resist as a mask. The inner lead of the TAB tape is made of conductive thermoplastic polyimide, not gilded. The flip-chip mounting substrate comprises a semiconductor chip connecting electrode comprising a signal line made of conductive thermoplastic polyimide, a protective film protecting the signal line, and adhering conductive thermoplastic polyimide on the signal line not providing the protective film. The microwave device comprises mounting the semiconductor chip in the inner lead of the TAB tape by adhering the external connecting electrode of the semiconductor chip to the inner lead of the TAB tape. Therefore, it is not required using high cost material for mounting the semiconductor chip, so that reducing in cost is accomplished.<br><b>Independant Claims</b><br>1) A speech encoder using a system of codebook vectors as an excitation signal in speech coding, the speech encoder comprising: a codebook having a comb-structure comprising a first plurality of codevectors and a second plurality of codevectors, each of the plurality of codevectors defining a plurality of elements; and an encoder processing circuit coupled to the codebook, that rearranges the plurality of elements in each of the first plurality of codevectors to generate a third plurality of codevectors.<br>5) A speech encoder using a system of codebook vectors as an excitation signal in speech coding, the speech encoder comprising: a starting codebook having a comb-structure comprising a first plurality of codevectors and a second plurality of codevectors, each of the plurality of codevectors defining a plurality of elements; a plurality of resultant codevectors; and an encoder processing circuit that accesses the starting codebook to generate the plurality of resultant codevectors by rearranging the plurality of elements in each of the first plurality of codevectors to generate a third plurality of codevectors.<br>9) A method used by a speech encoder, the method comprising: selecting a codebook having a comb-structure comprising a first plurality of codevectors and a second plurality of codevectors, the codevectors each being set to a normalized energy level of one and comprising a plurality of elements; generating a plurality of additional codevectors by rearranging the elements of the first plurality of codevectors.</p></layer>
<layer id = "layer305"><p><b>US6823303B1:Speech encoder using voice activity detection in coding noise</b><br>An IOL insertion apparatus including a cartridge with an IOL-receiving chamber, a handpiece into which the cartridge is loaded, and a plunger rod that extends through a lumen in the cartridge to reliably engage the IOL therein. The chamber has a recess in one wall that creates a space adjacent the proximal edge of the IOL positioned therein. A lip or projection on the plunger rod is aligned with the space to extend underneath the proximal edge of the IOL. The plunger rod may define a forked end with a groove into which the proximal edge of the IOL is captured. The cartridge may be of the type that folds the IOL therein. The recess may continue the entire length of the cartridge to guide the plunger rod therethrough. The cartridge lumen may converge so that the IOL is further compressed therealong. An inwardly-directed wall portion in the cartridge may help guide the lip of the plunger rod into the recess.<br><b>Independant Claims</b><br>1) A speech encoding system using an analysis by synthesis approach on a speech signal having varying characteristics, the speech encoding system comprising: an encoder processing circuit that selectively applies a first or a second encoding scheme upon identification of varying characteristics of the speech signal; where the varying characteristics are utilized to classify the speech signal as having one of active voice content and inactive voice content; the first encoding scheme utilizes a first analysis-by-synthesis speech coding approach on a speech signal classified as active voice content; and the second encoding scheme utilizes a second analysis-by-synthesis speech coding approach on a speech signal classified as inactive voice content, the inactive voice content comprising background noise.<br>6) A speech encoding system for processing a speech signal having varying characteristics, the speech encoding system comprising: an encoder processing circuit that selectively applies a first or a second analysis-by-synthesis encoding scheme based upon at least one of the varying characteristics of the speech signal; the encoder processing circuit applies the first analysis-by-synthesis encoding scheme following identification of an active voice frame of the speech signal; and the encoder processing circuit applies the second analysis-by-synthesis encoding scheme following identification of an inactive voice frame of the speech signal, the inactive voice frame comprising background noise.<br>16) A method of encoding a speech signal comprising: classifying the speech signal as having one of active voice content and inactive voice content, the inactive voice content comprising background noise; applying a first encoding scheme comprising analysis-by-synthesis when the speech signal is classified as having active voice content; and applying a second encoding scheme comprising analysis-by-synthesis when the speech signal is classified as having inactive voice content.</p></layer>
<layer id = "layer306"><p><b>US5617508A:Speech detection device for the detection of speech end points based on variance of frequency band limited energy</b><br>Disclosed is an image data transmission apparatus which includes an image reading unit for reading the original image, and a transmission apparatus main body. The main body includes a memory for storing the image data read by the image reading unit and transmits the content of the memory. The image reading unit is detachably mounted on the transmission apparatus main body. The transmission apparatus main body is further provided with a conveying device for conveying the original in a state in which the image reading unit is mounted on the transmission apparatus main body to thereby read the original. The image reading unit may also scan the original to read an original image, in a state in which the image reading unit is dismounted from the transmission apparatus main body. Further, a sheet element made of a material of a low coefficient of friction, as opposed to the original, may be disposed at a position corresponding to the mounted state of the image reading unit on the transmission apparatus main body. Further, an image data transmission apparatus is disclosed which possesses the telephone function and copy function, and is also provided with, as desired, a facsimile function by mounting a detachable facsimile processing device in the transmission apparatus main body. Further, the operation panel may be, in order to use it as the original stacker, disposed angularly dislocatably around the axial line crossing with the original inserting direction.<br><b>Independant Claims</b><br>1. A device for detecting speech in an input signal comprising: first determining means for determining a plurality of values representative of a plurality of frequency band limited energy within the signal, wherein the signal is sampled at a predetermined sampling rate in a single frequency band over a first plurality of frames, wherein each frame comprises a plurality of samples; second determining means for receiving the plurality of values from said first determining means, and determining a variance of the frequency band limited energy of the signal in the single frequency band over a second plurality of frames; third determining means for determining beginning and ending points of speech within the signal using the variance of the frequency band limited energy; and a signal recording device including: means for receiving the signal; means for storing the most recent m seconds of the received signal; and means for selecting the portion of the stored signal that corresponds to the start and the end points determined by said third determining means.<br>4. A device for detecting speech in an input signal comprising: first determining means for determining a plurality of values representative of a plurality of frequency band limited energy within the signal, wherein the signal is sampled at a predetermined sampling rate in a single frequency band over a first plurality of frames, wherein each frame comprises a plurality of samples, said first determining means including: means for calculating the energy of the frequency band limited signal; and means for applying a smoothing function to energy of the frequency band limited signal to generate the frequency band limited energy; second determining means for receiving the plurality of values from said first determining means, and determining a variance of the frequency band limited energy of the signal in the single frequency band over a second plurality of frames; and third determining means for determining beginning and ending points of speech within the signal using the variance of the frequency band limited energy.</p></layer>
<layer id = "layer307"><p><b>US6424938B1:Complex signal activity detection for improved speech/noise classification of an audio signal</b><br>There is provided a cold cathode including a substrate, a plurality of electron emitting electrodes formed on the substrate, a first insulating layer formed on the substrate and formed with a plurality of first cavities in which the electron emitting electrodes are disposed, a gate electrode formed on the first insulating layer and formed with a plurality of first openings which are in communication with the first cavities, a second insulating layer formed on the gate electrode and formed with a plurality of second cavities which are in communication with the first openings, and a focusing electrode formed on the second insulating layer and formed with a plurality of second openings which are in communication with the second cavities. At least one of central axes of the second openings and central axes of the first openings is eccentric with central axes of the electron emitting electrodes. Eccentricity between at least one of the central axes of the second openings and the central axes of the first openings, and the central axes of the electron emitting electrodes is oriented outwardly, and a degree of the eccentricity is set greater at a location more remote from a centrally located electron emitting electrode.<br><b>Independant Claims</b><br>1) A method of preserving perceptually relevant non-speech information in an audio signal during encoding of the audio signal, comprising: making a first determination of whether the audio signal is considered to comprise speech or noise information; making a second determination of whether the audio signal includes non-speech information that is perceptually relevant to a listener; and selectively overriding said first determination in response to said second determination.<br>9) A method of preserving perceptually relevant information in an audio signal, comprising: for each of a plurality of frames into which the audio signal is divided, finding a highest normalized correlation value of a high pass filter version of the audio signal by using an open-loop long term prediction correlation analysis; producing a first sequence of said normalized correlation values; determining a second sequence of representative values to represent respectively the normalized correlation values of the fist sequence; and comparing the representative values to a threshold value to obtain an indication of whether the audio signal contains perceptually relevant non-speech information.<br>13) An apparatus for use in an audio signal encoder to preserve perceptually relative non-speech information contained in an audio signal, comprising: a classifier for receiving the audio signal and making a first determination of whether the audio signal is considered to comprise speech or noise information; a detector for receiving the audio signal and making a second determination of whether the audio signal includes non-speech information that is perceptually relevant to a listener; and logic coupled to said classifier and said detector, said logic having an output for indicating whether the audio signal includes perceptually relevant information, said logic operable to selectively provide at said output information indicative of said first determination, and also responsive to said second determination for selectively overriding at said output said information indicative of said first determination.</p></layer>
<layer id = "layer308"><p><b>US6289309B1:Noise spectrum tracking for speech enhancement</b><br>A sealing clip strip structure which is an integrated strip plate with a predetermined length. The sealing clip strip is formed with a lengthwise folding groove along a central line of the sealing clip strip, which divides the sealing clip strip into an upper and a lower clip plates. On the edges of the upper and lower clip plates are respectively formed corresponding latch section and hook section, whereby the upper and lower clip plates are folded toward each other about the folding groove to make the latch section latched by the hook section so as to clip and seal an opening of a bag body. At least one end section of the sealing clip strip is obliquely cut into a slope end, whereby after the upper and lower clip plates are folded to clip the opening of the bag body, the end section becomes a disaligned extension section in order to facilitate the opening operation of the sealing clip strip.<br><b>Independant Claims</b><br>1) A speech enhancement method which processes an input signal including both speech components and noise components to produce a noise-reduced output signal, the speech enhancement method comprising the steps of: receiving the input signal; segmenting the input signal into frames; applying a spectral transformation to the input signal to obtain respective spectral representations of each frame of the input signal; identifying frames that include speech components; estimating respective noise components of the respective spectral representations of the frames of the input signal using a time-varying forgetting factor that reduces any contribution to the estimated noise components from data frames that exhibit rapid changes in signal power relative to earlier received data frames; wherein the spectral representations of the frames of the input signal used to estimate the respective noise components exclude the frames that include speech components; reducing, in magnitude, the spectral representations of each frame by the estimated noise components to produce noise-reduced spectral representations of each frame.<br>10) A computer-usable carrier including a computer program that controls a computer to perform speech enhancement, the computer program causing the computer to process an input signal including both speech components and noise components to produce a noise-reduced output signal, by causing the computer to perform the steps of: receiving the input signal; segmenting the input signal into frames; applying a spectral transformation to the input signal to obtain respective spectral representations of each frame of the input signal; identifying frames that include speech components; estimating respective noise components of the respective spectral representations of the frames of the input signal using a time-varying forgetting factor that reduces any contribution to the estimated noise components from data frames that exhibit rapid changes in signal power relative to earlier received data frames; wherein the spectral representations of the frames of the input signal used to estimate the respective noise components exclude the frames that include speech components; reducing, in magnitude, the spectral representations of each frame by the estimated noise components to produce noise-reduced spectral representations of each frame.</p></layer>
<layer id = "layer309"><p><b>US20020052734A1:Apparatus and quality enhancement algorithm for mixed excitation linear predictive (MELP) and other speech coders</b><br>A sofa sleeper foldable sofa bed assembly having pivotally interconnected head, body, intermediate and foot frame sections each including a pair of opposed side rails. The frame sections are extendable to form a bed and foldable to form a sofa seat. The frame is supported laterally by at least one generally U-shaped cross brace which is biased in an upwardly raised position by at least one resilient member.<br><b>Independant Claims</b><br>1. A method of enhancing the speech quality of a speech coder comprising the steps of: digitally sampling speech to create a speech waveform over a multiplicity of frames; using a sliding-sample window to locate a frame position with the highest pitch correlation; and formulating at least one synthesized voice parameter in response to the speech waveform within the located frame position.<br>10. A speech coder comprising: means for sampling a speech waveform to generate a discrete representation of the speech waveform over a multiplicity of frames; and means for locating a pitch-analysis window over that frame position with the highest pitch correlation.</p></layer>
<layer id = "layer310"><p><b>US6633841B1:Voice activity detection speech coding to accommodate music signals</b><br>This invention relates to retroreflective devices and systems incorporating such devices; the term “retroreflective devices” as used herein being intended to encompass generally optical components used for returning radiation automatically from a remote location toward an optical source. In one aspect, an embodiment of the invention is a retroreflective device comprising a lens having a non-planar outer surface; and a liquid crystal cell having a non-planar layer comprising liquid crystal material, said non-planar layer having a shape corresponding with that of the non-planar outer surface of the lens. The device includes a reflective part arranged to retroreflect a radiation beam passing through the lens, and the liquid crystal cell is arranged to modulate one or more characteristics of said retroreflected radiation beam. Embodiments of the invention are advantageous for use in applications that require thin, transmissive modulators that are compatible with non-planar retroreflecting devices. Liquid crystals offer a useful modulation action for optical path lengths of 1 mm and less, and, since the local orientation of their molecular symmetry axes can be controlled by the fabrication process so as to vary with position, they can be made to be locally optimum over the whole of the reflecting surface of the non-planar retroreflecting device. In addition, liquid crystal devices are associated with low power requirements, which make them advantageous for use in power-limited applications.<br><b>Independant Claims</b><br>1) An extended signal codec that performs signal coding of a speech signal, the extended signal codec comprising: a background noise speech signal coding module; a music speech signal coding module; a voice activity detection module configured to generate a decision signal, wherein the decision signal is of a first type if the voice activity detection module detects no voice activity in the speech signal or of a second type if the voice activity detection module detects voice activity in the speech signal, and wherein the first type is associated with selection of the background noise speech signal coding module and the second type is associated with selection of the music speech signal coding module; and a voice activity detection correction and supervision module configured to receive the decision signal, wherein if the voice activity module generates the decision signal of the first type, the voice activity detection correction and supervision module overrides the decision signal of the first type and generates a new decision signal of the second type if the voice activity detection correction and supervision module detects at least one characteristic of the speech signal indicative of a music signal in the speech signal.<br>9) A signal processor that performs correction and supervision of a voice activity detection decision, the signal processor comprising: an encoder circuitry that analyzes a signal, the encoder circuitry also performs forward linear prediction coding and backward linear prediction coding on the signal; the signal processor computes a plurality of parameters corresponding to the signal, the plurality of parameters comprising a pitch parameter, a spectral difference parameter, and a background noise energy parameter, the signal processor also statistically analyzes the plurality of parameters corresponding to the signal and compares the statistical analysis of the plurality of parameters corresponding to the signal to at least one predetermined threshold, the at least one predetermined threshold is stored in the encoder circuitry; and the signal processor overrides a voice activity detection decision when the statistical analysis of the plurality of parameters meets the at least one predetermined threshold.<br>15) A method that performs correction and supervision of a voice activity detection decision, the method comprising: analyzing a signal; performing forward linear prediction coding and backward linear prediction coding on the signal; computing a plurality of parameters corresponding to the signal, the plurality of parameters comprising a pitch parameter, a spectral difference parameter, and a background noise energy parameter; statistically analyzing the plurality of parameters corresponding to the signal; comparing the statistical analysis of the plurality of parameters corresponding to the signal to at least one predetermined threshold; and overriding a voice activity detection decision when the statistical analysis of the plurality of parameters meets the at least one predetermined threshold.<br>21) A signal processor that performs correction and supervision of a voice activity detection decision that is made on a signal, the signal processor comprising: a signal processor that analyzes a signal, the signal having a plurality of frames, the signal processor generates a voice activity detection decision upon analysis of the signal; the signal processor performs statistical analysis using a predetermined number of frames of the signal, the predetermined number of frames of the signal are selected from the plurality of frames of the signal; the signal processor updates at least one running, mean upon performing the statistical analysis of the predetermined number of frames of the signal using at least one characteristic corresponding to the signal; and a voice activity detection correction and supervision circuitry that overrides a voice activity detection decision when the statistical analysis of the plurality of parameters meets at least one predetermined threshold.</p></layer>
<layer id = "layer311"><p><b>US4933973A:Apparatus and methods for the selective addition of noise to templates employed in automatic speech recognition systems</b><br>In a device for mounting a liquid crystal display (LCD) to a circuit board, a holder is positioned between the LCD and the circuit board and a cover member positioned around the LCD and holder is secured to the board. The LCD is recessed slightly within the cover member and is exposed through the cover at a display opening. To compensate for the recess of the LCD within the cover member, an optically clear lens is positioned with its lower surface in contact with the LCD and upper surface extending outwardly through the display opening. An image of the alphanumeric characters displayed by the LCD is projected on the outer surface of the lens of create an optical illusion of the display characters at the surface of the cover.<br><b>Independant Claims</b><br>1. In a speech recognition system of the type including a storage for storing initial templates representing spectral values of recognizable speech in the absence of noise, a spectrum analyzer for providing spectral values of utterances of an incoming signal representing speech in the presence of noise at an output thereof, and a recognition module for comparing operational templates with the output spectral values from said spectrum analyzer to provide an output upon a favorable comparison indicative of the presence of recognized speech in said utterances, the improvement therewith of apparatus for generating said operation templates, comprising: first means coupled to said spectrum analyzer for providing an estimated noise signal indicative of the noise in the incoming signal, and second means coupled to said first means and responsive to said estimated noise signal to generate said operational templates which are modified from said initial templates according to said estimated noise signal, wherein said first means includes a speech and noise level tracking means having a speech tracking portion operative to detect a speech signal in the presence of noise in said utterances and to provide at one output thereof a first signal indicative of an average power of the speech signal in the presence of noise which is a scalar speech level value associated with the speech signal, and a noise tracking portion operative to detect noise in said utterances and to provide a given time period of said utterances which is a vector of spectral values representing an estimate of the noise, and wherein said second means generates said operational templates by adjusting the speech level of said initial templates in accordance with said first signal and by adding spectral values of the estimate of the noise in accordance with said second signal to said initial templates, whereby the operational templates have the estimated noise of and the same signal-to-noise ratio as the utterances of the incoming signal in order to obtain an improved speech recognition performance of said recognition module.<br>12. A method of forming operational templates for use in a speech recognition system for recognizing speech in the presence of noise in utterances of an incoming signal based upon comparison of spectral values thereof to the operational templates, comprising the steps of: providing an estimated noise signal by detecting a speech signal in the presence of noise in the incoming signal and providing a first signal indicative of an average power of the speech signal in the presence of noise which is a scalar speech level value associated with the speech signal, and detecting noise in said utterances and providing a second signal indicative of an average power of the noise over a given time period of said utterances which is a vector of spectral values representing an estimate of the noise, and modifying initial templates representing recognizable speech in the absence of noise by adjusting the speech level of said initial templates in accordance with said first signal and by adding spectral values of the estimate of the noise in accordance with said second signal to said initial templates, in order to form said operational templates having the estimated noise of and the same signal-to-noise ratio as the utterances of the incoming signal for obtaining an improved speech recognition performance.</p></layer>
<layer id = "layer312"><p><b>US20010044722A1:System and method for modifying speech signals</b><br>In addition to removing noil from a combing machine, the lap pieces which occur during a lap change operation are suctioned off and recycled into the combing process so as to reduce the amount of waste generated by the combing process. The noil and lap pieces can be removed from the combing heads through a common suction tube and conveyed separately via connecting pipes to separate points. The lap pieces which have been separated can be transported into a drum separator with the fiber material of the lap pieces being separated and recycled for the production of new laps.<br><b>Independant Claims</b><br>1. A method for processing a speech signal, comprising the steps of: analyzing a received, narrowband signal to determine synthetic upper band content; reproducing a lower band of the speech signal using the received, narrowband signal; and combining the reproduced lower band with the determined, synthetic upper band to produce a wideband speech signal having a synthesized component.<br>9. A system for processing a speech signal, comprising: means for analyzing a received, narrowband signal to determine synthetic upper band content; means for reproducing a lower band of the speech signal using the received, narrowband signal; and means for combining the reproduced lower band with the determined, synthetic upper band to produce a wideband speech signal having a synthesized component.<br>17. A system for processing a narrowband speech signal at a receiver, comprising: an upsampler that receives the narrowband speech signal and increases the sampling frequency to generate an output signal having an increased frequency spectrum; a parametric spectral analysis module that receives the output signal from the upsampler and analyzes the output signal to generate parameters associated with a speech model and a residual error signal; a pitch decision module that receives the residual error signal from the parametric spectral analysis module and generates a pitch signal that represents the pitch of the speech signal and an indicator signal that indicates whether the speech signal represents voiced speech or unvoiced speech; a residual extender and copy module that receives and processes the residual error signal and the pitch signal to generate a synthetic upper band signal component.</p></layer>
<layer id = "layer313"><p><b>US20010033652A1:Electrolaryngeal speech enhancement for telephony</b><br><b>Independant Claims</b><br>1. A method for processing an acoustic signal to separate the acoustic signal into a voiced (V) component corresponding to an electrolaryngeal source and an unvoiced (U) component corresponding to a turbulence source, the method comprising the steps of: digitizing the acoustic signal to produce an original stream of numerical values; extracting a segment of consecutive values from the original stream of numerical values to produce a first group of values covering two or more periods of the electrolaryngeal source; performing a discrete Fourier transform on the first group of values to produce a discrete Fourier transform result; extracting a second group of values from components of the discrete Fourier transform result which correspond to an electrolaryngeal fixed repetition rate, F0, and harmonics thereof; inverse-Fourier transforming the second group of values, to produce a representation of a segment of the V component; concatenating multiple V component segments to form a V component sample stream; and determining the U component by subtracting the V component sample stream from the original stream of numerical values.<br>6. A method for processing an acoustic signal to separate the acoustic signal into inter-word and non-inter-word segments, the method comprising the steps of: digitizing the acoustic signal to produce an original stream of numerical values; extracting a segment of consecutive values from the original stream of numerical values to produce a group of values; determining an average power level for the group of values; and if the average power level of the group of values is below a threshold value, determining that the group of values corresponds to an inter-word segment of the acoustic signal.</p></layer>
<layer id = "layer314"><p><b>US20020035470A1:Speech coding system with time-domain noise attenuation</b><br>A communications system includes a plurality of recipient processors located at geographically remote locations with respect to each other and connected for communication with an information provider processor, over the communications network. The provider and recipient processors may comprise respective computers coupled for communication on the internet or world-wide-web. The provider processor is capable of providing information from any suitable source, by communicating such information over a communications network. However, access to the information by the recipient processors is controlled, based on the geographic location or region of the recipient processors. Each recipient processor is operably associated with a positioning system for providing geographic location information corresponding to the location or region in which the positioning system is located, such as a global positioning system GPS. The geographic position information is used to determine whether or not the processor requesting the information is within a restricted (or limited) or non-restricted region. This determination may be made comparing the geographic information provided by the recipient processor and positioning system with a list of non-restricted or non-limited (or restricted) geographic locations or regions.<br><b>Independant Claims</b><br>1. A noise attenuation system for speech coding comprising; an encoder disposed to receive a digitized signal, the encoder to provide a bitstream based upon a speech coding of the digitized signal; where the speech coding determines at least one gain scaling a portion of the digitized signal; and where the encoder adjusts the at least one gain as a function of noise characteristic.<br>16. A noise attenuation system for speech coding comprising; a decoder disposed to receive a bitstream, the decoder to provide a reconstructed signal based upon a speech decoding of the bitstream; where the speech decoding determines at least one gain scaling a portion of the reconstructed signal; and where the encoder adjusts the at least one gain as a function of noise characteristic.<br>30. A noise attenuation system for speech coding comprising: an encoder disposed to receive a digitized signal, the encoder to provide a bitstream based upon a speech coding of the digitized signal, where the speech coding determines at least one gain scaling a portion of the digitized signal, and where the encoder adjusts the at least one gain as a function of noise characteristic; and a decoder operatively connected to receive the bitstream from the encoder, where the decoder provides a reconstructed signal based upon a speech decoding of the bitstream, where the speech decoding reconstructs the at least one gain scaling the portion of the digitized signal, and where the decoder adjusts the at least one gain as a function of noise characteristic.<br>45. A method of attenuating noise in a speech coding system, comprising: (a) segmenting a digitized signal into at least one portion; (b) determining at least one gain scaling the digitized signal within the one portion; (c) adjusting the at least one gain as a function of noise characteristic; and (d) quantizing the at least one gain into a group of at least one bit for a bitstream.<br>55. A method of attenuating noise in a speech coding system, comprising: (a) decoding at least one gain from a group of at least one bit in a bitstream; (b) adjusting the at least one gain as a function of noise characteristic; and (c) assembling the at least one gain into a portion of a reconstructed speech signal.<br>63. A method of attenuating noise in a speech coding system, comprising: (a) segmenting a digitized signal into at least one portion; (b) determining at least one gain representing the digitized signal within the one portion; (c) pre-adjusting the at least one gain as a function of noise characteristic; (d) quantizing the at least one gain into a group of at least one bit for a bitstream. (e) decoding the at least one gain from the group of at least one bit in the bitstream; (f) post-adjusting the at least one gain as a function of noise characteristic; and (g) assembling the at least one gain into a reconstructed speech signal.</p></layer>
<layer id = "layer315"><p><b>US20020123888A1:System for an adaptive excitation pattern for speech coding</b><br>A wagering game apparatus and method is provided which permits the random selection of prizes for games such as blackjack, poker, and electronic games. A side wager is placed in a receptacle or designated area which indicates to the dealer that the player wishes to participate in the random jackpot selection portion of the game. If a random event occurs, such as the player being dealt a preselected combination of cards, the player or dealer may activate the random prize selection process. The random prize selection is performed by a computer which uses a random generated number to select a prize from a pay table. The prize may be displayed on or near the gaming table. The player is then awarded the random jackpot amount.<br><b>Independant Claims</b><br>1. A communications system comprising: an encoder to encode a digitized speech signal; a communication link communicatively coupled to the encoder; a decoder communicatively coupled to the encoder via the communication link; and a short term excitation enhancement circuit in communication with the encoder and the decoder.<br>11. A communications system comprising: a short term excitation enhancement circuit that improves the perceptual quality of speech data for reproduction.<br>19. A method to perform excitation enhancement on speech data, the method comprising: analyzing a coded signal; and performing short term excitation enhancement in accordance with the analyzed coded signal.</p></layer>
<layer id = "layer316"><p><b>US20020143527A1:Selection of coding parameters based on spectral content of a speech signal</b><br>In accordance with the present invention, there are provided novel G-protein-coupled receptor proteins (CRF-R) characterized by having sufficient binding affinity for corticotropin releasing factor (CRF) such that concentrations of .ltoreq.10 nM of CRF occupy .gtoreq.50% of the binding sites of said receptor protein. Nucleic acid sequences encoding such receptors, assays employing same, as well as antibodies derived therefrom, are also disclosed. The invention CRF-R can be employed in a variety of ways, such as, for example, in bioassays, for production of antibodies thereto, in therapeutic compositions containing such proteins and/or antibodies.<br><b>Independant Claims</b><br>1. A method for coding of a speech signal, the method comprising the steps of: accumulating samples of the speech signal over at least a minimum sampling duration; evaluating the accumulated samples associated with the minimum sampling period to obtain a representative sample; determining whether a slope of the representative sample of the speech signal conforms to a defined characteristic slope stored in a reference database of spectral characteristics; and selecting a value of a coding parameter for application to the speech signal for the coding based on the determination on the spectral slope of the representative sample.<br>24. A system for coding a speech signal, the system comprising: a buffer memory for accumulating samples of the speech signal over at least a minimum sampling duration; an averaging unit for evaluating the accumulated samples associated with the minimum sampling period to obtain a representative sample; a storage device adapted to store spectral characteristics for classifying the speech signal as a closest one of a defined characteristic slope and a flat speech signal; an evaluator adapted to determine whether a slope of the representative sample of the speech signal conforms to a defined characteristic slope stored in the storage device; and a selector for selecting a preferential one of a first coding parameter value and a second coding parameter value for application to the speech signal for the coding based on the determination on the slope of the representative sample.</p></layer>
<layer id = "layer317"><p><b>US5146539A:Method for utilizing formant frequencies in speech recognition</b><br>A corrosion-resistant storage body for a regenerator includes a multiplicity of carbon shapes having profiles formed thereon, the shapes being stacked together with the profiles spacing the shapes apart defining canals between the shapes passing through the storage body, and a frame holding the stacked shapes together.<br><b>Independant Claims</b><br>1. A method for recognizing speech signals organized into a sequence of frames, said method comprising: storing a plurality of reference frames of formant frequencies representative of linguistic units providing a vocabulary of words; generating a plurality of format frequency candidates for each frame of the speech signals desired to be recognized; creating a plurality of all possible subsets of optimum formant frequencies for each frame based upon the plurality of formant frequency candidates generated for the respective frame, wherein each subset comprises some but not all of the formant frequency candidates generated for that frame; comparing each subset of the plurality of all possible subsets of optimum formant frequencies for each frame of the speech signals to be recognized with each of the plurality of reference frames of formant frequencies; selecting one subset from said plurality of all possible subsets of optimum formant frequencies for each frame from said formant frequency candidates which best matches the stored formant frequencies of a corresponding reference frame of formant frequencies in accordance with predetermined criteria; and recognizing said speech signals in response to the selected one subset of optimum formant frequencies for respective frames.<br>7. A method for recognizing speech signals organized into a sequence of frames, said method comprising: storing a plurality of reference frames of formant frequencies representative of linguistic units providing a vocabulary of words in which each reference frame contains a predetermined number of primary formant frequencies; generating a plurality of format frequency candidates for each frame of the speech signals desired to be recognized; grouping the formant frequency candidates for each frame into all possible combinations of subsets thereof having the same predetermined number of formant frequencies of each of the plurality of reference frames, wherein each subset comprises some but not all of the formant frequency candidates generated for that frame; comparing each of the possible combinations of subsets of formant frequency candidates for each frame of the speech signals to be recognized with the formant frequencies contained in each of the plurality of reference frames; selecting one subset of all possible subsets of optimum formant frequencies for each frame from said formant frequency candidates for the respective frame which best matches the stored formant frequencies of a respective reference frame in accordance with predetermined criteria; and recognizing said speech signals in response to the selected optimum formant frequencies comprising the selected subset of formant frequencies for each respective frame.</p></layer>
<layer id = "layer318"><p><b>US4885790A:Processing of acoustic waveforms</b><br>Lubricating oils, which in aqueous media are useful hydraulic fluids and the like, contain a metal hydrocarbyl dithiophosphate and a system of other additives which solubilize the dithiophosphates in the aqueous oils.<br><b>Independant Claims</b><br>1. A method of processing an acoustic waveform, the method comprising: sampling the waveform to obtain a series of discrete samples and constructing therefrom a series of frames, each frame spanning a plurality of samples; analyzing each frame of samples to extract a set of variable frequency components having individual amplitudes; matching said variable components from one frame to a next frame such that a component in one frame is matched with a component in a successive frame that has a similar value regarless of shifts in frequency and spectral energy; and interpolating the matched values of the components from the one frame to the next frame to obtain a parametric representation of the waveform whereby a synthetic waveform can be constructed by generating a set of sine waves corresponding to the interpolated values of the parametric representation.<br>32. A device for processing an acoustic waveform, the device comprising: sampling means for sampling the waveform to obtain a series of discrete samples and constructing therefrom a series of frames, each frame spanning a plurality of samples; analyzing means for analyzing each frame of samples to extract a set of variable frequency components having individual amplitudes; matching means for matching said variable components from one frame to a next frame such that a component in one frame is matched with a component in a successive frame that has a similar value regardless of shifts in frequency and spectral energy; and interpolating means for interpolating the matched values of the components from the one frame to the next frame to obtain a parametric representation of the waveform whereby a synthetic waveform can be constructed by generating a set of sine waves corresponding to the interpolated values of the parametric representation.<br>51. A coded speech transmission system comprising: sampling means for sampling a speech waveform to obtain a series of discrete samples and for constructing therefrom a series of frames, each frame spanning a plurality of samples; analyzing means for analyzing each frame of samples by Fourier analysis to extract a set of variable frequency components having individual amplitude values; coding means for coding the component values; decoding means for decoding the coded values after transmission and for reconstituting the variable components; matching means for matching the reconstituted, variable components from one frame to a next frame such that a component is one frame is matched with a component in a successive frame that has a similar value regardless of shifts in frequency and spectral energy; and interpolation means for interpolating the values of the frequency components from the one frame to the next frame to obtain a representation of the waveform whereby synthetic speech can be constructed by generating a set of sine waves corresponding to the interpolated values of the parametric representation.<br>58. A device for altering the time-scale of an audible waveform, the device comprising: sampling means for sampling the waveform to obtain a series of discrete samples and constructing therefrom a series of frames, each frame spanning a plurality of samples; analyzing means for analyzing each frame of samples to extract a set of variable frequency components having individual amplitudes; matching means for matching said variable components from one frame to a next frame such that a component in one frame is matched with a component in a successive frame that has a similar value regardless of shifts in frequency and spectral energy; interpolating means for interpolating the amplitude and frequency values of the components from the one frame to the next frame to obtain a representation of the waveform whereby a synthetic waveform can be constructed by generating a set of sine waves corresponding to the interpolated representation; interpolation rate adjusting means for altering the rate of interpolation; and synthesizing means for constructing a time-scaled synthetic waveform by generating a series of constituent sine waves corresponding in frequency and amplitude to the extracted components, the sine waves being generated at said alterable interpolation rate.</p></layer>
<layer id = "layer319"><p><b>US4935963A:Method and apparatus for processing speech signals</b><br><b>Independant Claims</b><br>1. A method of enhancing pitch detection in sampled speech signals by performing time domain speech envelope flattening, comprising the steps of: receiving a sampled time domain speech signal; deriving a time domain speech envelope from said sampled speech signal by performing the steps of: detecting peak signal levels in said sampled time domain speech signal, and filtering said detected peak signal levels to produce said time domain speech envelope signal from said peak signal levels of said speech signal; creating a sampled amplitude function by performing the steps of: sampling said time domain speech envelope at a sampling rate lower than a sampling rate for said sampled time domain speech signal to produce subrate samples; computing a plurality of interpolated points by interpolating values between adjacent ones of said subrate samples to produce interpolated values; generating a sampled amplitude function having a sample point corresponding to each sample of said sampled speech signal by assigning said subrate samples to corresponding amplitude function samples and assigning said interpolated values to each sample point located between said sample points; and normalizing said sampled time domain speech signal to produce time domain speech envelope flattening by performing a point by point division of said time domain speech signal samples by said corresponding amplitude function samples.<br>3. A method of enhancing pitch detection in sampled speech signals by performing time domain speech envelope flattening, comprising the steps of: receiving a sampled time domain speech signal; deriving a time domain speech envelope from said sampled speech signal; creating a sampled amplitude function by performing the steps of: sampling said time domain speech envelope at a sampling rate lower than a sampling rate for said sampled time domain speech signal to produce subrate samples; computing a plurality of interpolated points by interpolating values between adjacent ones of said subrate samples to produce interpolated values; generating a sampled amplitude function having a sample point corresponding to each sample of said sampled speech signal by assigning said subrate samples to corresponding amplitude function samples and assigning said interpolated values to each sample point located between said sample points; and normalizing said sampled time domain speech signal with the sampled amplitude function; and to produce time domain speech envelope flattening.<br>7. A method of enhancing pitch detection in sampled speech signals by performing time domain speech envelope flattening, comprising the steps of: receiving a sampled time domain speech signal; deriving a time domain speech envelope from said sampled speech signal by sampling said time domain speech envelope at a rate lower than a sampling rate for said sampled time domain speech signal; creating a sampled amplitude function having a sample point corresponding to each sample of said sampled speech signal by assigning said subrate samples to corresponding amplitude function samples and assigning interpolated values to each sample point located between said sample points; and normalizing said sampled time domain speech signal with the sampled amplitude function to produce time domain speech envelope flattening.<br>8. A method of enhancing pitch detection in sampled speech signals by performing time domain speech envelope flattening, comprising the steps of: receiving a sampled time domain speech signal; deriving a time domain speech envelope from said sampled speed signal by performing the steps of: detecting peak signal levels in said sampled time domain speech signal, and low pass filtering said detected peak signal levels with a low pass filter having a cutoff frequency between approximately 25 and 300 Hz to produce said time domain speech envelope signal from said peak signal levels of said speech signal; creating a sampled amplitude function by performing the steps of: sampling said time domain speech envelope at a sampling rate between approximately 100 and 1000 Hz to produce subrate samples; computing a plurality of interpolated points by linear interpolating values between adjacent ones of said subrate samples using a low pass filter to produce interpolated values; generating a sampled amplitude function having a sample point corresponding to each sample of said sampled speech signal by assigning said subrate samples to corresponding amplitude function samples and assigning said interpolated values to each sample point located between said sample points; normalizing said sampled time domain speech signal to produce time domain speech envelope flattening by performing a point by point division of said time domain speech signal samples by said corresponding amplitude function samples; and pitch detecting said normalized signals.</p></layer>
<layer id = "layer320"><p><b>US5012518A:Low-bit-rate speech coder using LPC data reduction processing</b><br>A printing hammer assembly for use in impact printers includes a printing hammer which has an impact surface and an armature and which is supported to be movable in a reciprocating manner along its longitudinal axis, a driving solenoid which drives to move the printing hammer forward when energized against the force of a coil spring which normally applies a biasing force to the printing hammer in the backward direction and a yoke leading a magnetic flux produced by said solenoid to the armature of printing hammer. A pair of magnets are disposed such that they are magnetically repulsive to each other with one of them fixed in position and the other movable over a predetermined distance thereby allowing to absorb the rebounding energy of the hammer when it returns to its home position.<br><b>Independant Claims</b><br>1. In a speech coder system of the type having an encoder for converting input speech signals into spectral coefficients in successive frames, and for encoding said spectral coefficients into quantized vector indexes, an improvement comprising a codebook for storing a vocabulary of codewords in the form of respectively defined vector indexes corresponding to words to be spoken as input speech signals to said encoder, and means for comparing the quantized vector indexes output from said encoder to the codewords of said codebook and outputting the defined vector indexes corresponding thereto with a minimum distortion for transmission,</p></layer>
<layer id = "layer321"><p><b>US5388181A:Digital audio compression system</b><br>A magnetic recording playback head and a method for producing the same having an improved wear resistance and resistance to chipping as well as an improved production rate. The head is formed from a pair of magnetic cores joined through a gap-forming film. The lateral sides of the gap are flat, except for the surface repair to contact the tape, which have a width equal to the track width. The flat sides are coated with a nonmagnetic thin hard film of a material such as alumina or titanium nitride.<br><b>Independant Claims</b><br>1. A method of processing a wideband digital audio signal and for storing the processed signal on a data storage medium comprising: dividing said wideband digital audio signal into signal blocks each block having a maximum signal value; scaling each signal block by a constant value selected such that the maximum absolute signal value in each block equals a predetermined value within a preset range and setting a scale factor equal to said constant value for each signal block; transforming each said signal block into transform blocks comprising a plurality of transform values representative of the audio signal in its associated signal block; quantizing said transform blocks; and recording said quantized transform blocks and said scale factors as digital data on the data storage medium.<br>6. A method of processing a wideband digital audio signal and for storing the processed signal on a data storage medium comprising: dividing said wideband digital audio signal into signal blocks; dividing said signal blocks into a plurality of subblocks; detecting transients in said subblocks and setting a transient flag associated with said signal block to a predetermined value if a transient greater than a predetermined threshold is detected; if the transient flag is set to said predetermined value, scaling each subblock in accordance with transients detected to produce processed signal blocks and generating a scale factor for each subblock; said scaling step further comprising the step of scaling at least one subblock occurring a predetermined time before a detected transient differently than scaling the subblock containing the transient; transforming said processed signal blocks into transform blocks each comprising a plurality of transform values representative of the audio signal in its associated block; quantizing said transform blocks; and recording said quantized transform blocks, transient flags and scale factors as digital data on the data storage medium.<br>11. A method of processing a wideband digital audio signal and for storing the processed signal on a data storage medium comprising; dividing said wideband digital audio signal into signal blocks; detecting if a transient occurs in each signal block and setting a transient flag to a predetermined value when a transient is detected; when said transient flag equals said predetermined value, dividing said signal blocks into a plurality of subblocks; scaling each subblock in accordance with transients detected to produce processed signal blocks and generating a scale factor for each subblock; said scaling step further comprising the step of scaling at least one subblock occurring a predetermined time before a detected transient differently than scaling the subblock containing the transient; transforming said processed signal blocks into transform blocks each comprising a plurality of transform values representative of the magnitude and phase of the audio signal as a function of frequency in its associated block; quantizing said transform blocks; and recording said quantized transform blocks, transient flags and scale factors as digital data on a data storage medium.<br>12. A method of processing a wideband digital audio signal and for storing the processed signal on a dam storage medium comprising; dividing said wideband digital audio signal into signal blocks; Fourier transforming said signal blocks into transformed blocks representative of the magnitude and phase of the audio signal in its associated block as a function of frequency; extracting from said transformed blocks magnitude data blocks and phase data blocks as a function of frequency; grouping said magnitude data blocks and phase data blocks into a plurality of adjacent frequency bands, said frequency bands extending from low frequency bands to high frequency bands; applying a first quantization process upon said magnitude data blocks in each frequency band to develop quantized magnitude blocks; applying a second quantization process upon said phase dam blocks in each frequency band to develop quantized phase blocks, said second quantization process developing higher precision quantization in said low frequency bands than in said high frequency bands; recording said quantized magnitude blocks and said quantized phase blocks as digital data on the data storage medium wherein said first quantization process includes two-stage vector quantization of said magnitude data blocks.<br>22. A method of processing a wideband digital audio signal and for storing the processed signal in a data storage medium comprising the steps of: dividing said wideband audio signal into signal blocks, Fourier transforming each said block into transform blocks representative of the magnitude and phase of the audio signal as a function of frequency in its associated block, grouping said transform blocks into a plurality of adjacent frequency bands, each frequency band having a predetermined magnitude quantizer factor and predetermined phase quantizer factors, said quantizer factors determining the degree of precision of a subsequent quantization, quantizing the magnitudes and phases of each transform block in each frequency band in accordance with its respective quantizer factor to develop quantized magnitude blocks and quantized phase blocks, and recording said quantized magnitude blocks and quantized phase blocks as digital data on the data storage medium.<br>25. A method of processing a wideband digital audio signal and for storing the processed signal on a data storage medium comprising: dividing said wideband digital audio signal into signal blocks; dividing said signal blocks into a plurality of subblocks; detecting transients in said subblocks and setting a transient flag associated with said signal block to a predetermined value if a transient greater than a predetermined threshold is detected; if the transient flag is set to said predetermined value, scaling each subblock in accordance with transients detected to produce processed signal blocks and generating a scale factor for each subblock; said scaling step further comprising the step of scaling at least one subblock occurring a predetermined time after a detected transient differently than scaling the subblock containing the transient; transforming said processed signal blocks into transform blocks each comprising a plurality of transform values representative of the audio signal in its associated block; quantizing said transform blocks; and recording said quantized transform blocks, transient flags and scale factors as digital data on the data storage medium.<br>26. A method of processing a wideband digital audio signal and for storing the processed signal on a data storage medium comprising; dividing said wideband digital audio signal into signal blocks; detecting if a transient occurs in each signal block and setting a transient flag to a predetermined value when a transient is detected; when said transient flag equals said predetermined value, dividing said signal blocks into a plurality of subblocks; scaling each subblock in accordance with transients detected to produce processed signal blocks and generating a scale factor for each subblock; said scaling step further comprising the step of scaling at least one subblock occurring a predetermined time after a detected transient differently than scaling the subblock containing the transient; transforming said processed signal blocks into transform blocks each comprising a plurality of transform values representative of the magnitude and phase of the audio signal as a function of frequency in its associated block; quantizing said transform blocks; and recording said quantized transform blocks, transient flags and scale factors as digital data on a data storage medium.<br>27. A method of processing a wideband digital audio signal and for storing the processed signal on a data storage medium comprising: dividing said wideband digital audio signal into signal blocks; Fourier transforming said signal blocks into transformed blocks representative of the magnitude and phase of the audio signal in its associated block as a function of frequency; extracting from said transformed blocks magnitude data blocks and phase data blocks as a function of frequency; grouping said magnitude data blocks and phase data blocks into a plurality of adjacent frequency bands, said frequency bands extending from low frequency bands to high frequency bands; applying a first quantization process upon said magnitude data blocks in each frequency band to develop quantized magnitude blocks; applying a second quantization process upon said phase data blocks in each frequency band to develop quantized phase blocks, said second quantization process developing higher precision quantization in said low frequency bands than in said high frequency bands; recording said quantized magnitude blocks and said quantized phase blocks as digital data on the data storage medium wherein said first quantization process includes tree-structured vector quantization of said magnitude data blocks.<br>29. A method of processing a wideband digital audio signal and for storing the processed signal on a data storage medium comprising: dividing said wideband digital audio signal into signal blocks; Fourier transforming said signal blocks representative of the magnitude and phase of the audio signal in its associated block as a function of frequency; extracting from said transformed blocks magnitude data blocks and phase data blocks as a function of frequency; grouping said magnitude data blocks and phase data blocks into a plurality of adjacent frequency bands, said frequency bands extending from low frequency bands to high frequency bands; applying a first quantization process upon said magnitude data blocks in each frequency band to develop quantized magnitude blocks; applying a second quantization process upon said phase data blocks in each frequency band to develop quantized phase blocks, said second quantization process developing higher precision quantization in said low frequency bands than in said high frequency bands; recording said quantized magnitude blocks and said quantized phase blocks as digital data on the data storage medium wherein each phase data block comprises a plurality of phase coefficients and wherein said second quantization process comprises the step of applying a scalar quantizer to each phase coefficient with a level spacing inversely proportional to the frequency of each coefficient.<br>30. A method of processing a wideband digital audio signal and for storing the processed signal on a data storage medium comprising: dividing said wideband digital audio signal into signal blocks; Fourier transforming said signal blocks into transformed block representative of the magnitude and phase of the audio signal in its associated block as a function of frequency; extracting from said transformed blocks magnitude data blocks and phase data blocks as a function of frequency; grouping said magnitude data blocks and phase data blocks into a plurality of adjacent frequency bands, said frequency banks extending from low frequency bands to high frequency bands; applying a first quantization process upon said magnitude data blocks in each frequency band to develop quantized magnitude blocks; applying a second quantization process upon said phase data blocks in each frequency band to develop quantized phase blocks, said second quantization process developing higher precision quantization in said low frequency bands than in said high frequency bands; recording said quantized magnitude blocks and said quantized phase blocks as digital data on the data storage medium; detecting a transient in said transformed blocks and, when detected, decreasing the level spacing with respect to said second quantization process.<br>32. A method of processing a wideband digital audio signal and for storing the processed signal on a data storage medium comprising; dividing said wideband digital audio signal into signal blocks; Fourier transforming said signal blocks into transformed blocks representative of the magnitude and phase of the audio signal in its associated block as a function of frequency; extracting from said transformed blocks magnitude data blocks and phase data blocks as a function of frequency; grouping said magnitude data blocks and phase data blocks into a plurality of adjacent frequency bands, said frequency bands extending from low frequency bands to high frequency bands; scaling each said frequency band by a constant value selected such that the energy of the frequency band equals a predetermined value within a preset range; applying a first quantization process upon said magnitude data blocks in each frequency band to develop quantized magnitude blocks; applying a second quantization process upon said phase data blocks in each frequency band to develop quantized phase blocks, said second quantization process developing higher precision quantization in said low frequency bands than in said high frequency bands; recording said quantized magnitude blocks said constant values and said quantized phase blocks as digital data on the data storage medium wherein said first quantization process includes two-stage vector quantization of said magnitude data blocks.</p></layer>
<layer id = "layer322"><p><b>US5216747A:Voiced/unvoiced estimation of an acoustic signal</b><br>A data acquisition system for use in an aircraft flight data recorder receives multiple analog and discrete signals representative of various aircraft parameters. A single address command from the flight data recorder central processing unit (CPU) causes a first multiplexer to select a set of analog signals. Each selected analog signal is amplified by a gain factor under CPU control and passed to track-and-hold circuitry which holds a level of the amplified analog signal upon receipt of a suitable command. The held analog signal levels are passed to a second multiplexer which also receives a set of discrete signals selected by a third multiplexer in response to a CPU address command. A control sequencer sequentially passes each signal at the input of the second multiplexer through an analog-to-digital converter, with the resultant digital signal being loaded into memory. After either all the selected and processed analog signals or the selected discrete signals have been analog-to-digital converted and stored in memory, the control sequencer issues an interrupt signal to the CPU.<br><b>Independant Claims</b><br>1. A method for encoding an acoustic signal, the method comprising the steps of: A. breaking the signal into segments, each of the segments representing one of a succession of time intervals; B. breaking each of said segments into a plurality of frequency bands; and C. considering in turn each of the segments as the current segment, and for each of a plurality of said frequency bands of the current segment making a voiced/unvoiced decision by a method comprising the steps of: evaluating a voicing measure for said frequency band; making the voiced/unvoiced decision for said frequency band based upon a comparison between the voicing measure and a threshold; determining an energy measure of the current segment; determining a measure of the signal energy of one or more recent prior segments; comparing the energy measure of the current segment to the measure of the signal energy of the one or more recent prior segments; and adjusting the threshold to make a voiced decision more likely when the energy measure of the current segment is greater than the measure of the signal energy of the one or more recent prior segments.<br>2. A method for encoding an acoustic signal, the method comprising the steps of: A. breaking the signal into segments, each of the segments representing one of a succession of time intervals; B. breaking each of said segments into a plurality of frequency bands; and C. considering in turn each of the segments as the current segment, and for each of a plurality of said frequency bands of the current segment making a voiced/unvoiced decision by a method comprising the steps of: evaluating a voicing measure for said frequency band; making the voiced/unvoiced decision for said frequency band based upon a comparison between the voicing measure and a threshold; determining an energy measure of the current segment; determining a measure of the signal energy of one or more recent prior segments; comparing the energy measure of the current segment to the measure of the signal energy of the one or more recent prior segments; and adjusting the threshold to make an unvoiced decision more likely when the energy measure of the current segment is less than the measure of the signal energy of the one or more recent prior segments.<br>7. A method for encoding an acoustic signal, the method comprising the steps of: A. breaking the signal into segments, each of the segments representing one of a succession of time intervals; B. considering in turn each of the segments as the current segment, and making a voiced/unvoiced decision for at least a frequency band of the current segment by a method comprising the steps of: evaluating a voicing measure for said frequency band; making the voiced/unvoiced decision for said frequency band based upon a comparison between the voicing measure and a threshold; determining an energy measure of the current segment; determining a measure of the signal energy of one or more consecutive preceding segments; comparing the energy measure of the current segment to the measure of the signal energy of the consecutive preceding segments; adjusting the threshold to make a voiced decision more likely when the energy measure of the current segment is greater than the measure of the signal energy of the consecutive preceding segments.<br>8. A method for encoding an acoustic signal, the method comprising the steps of: A. breaking the signal into segments, each of the segments representing one of a succession of time intervals; B. considering in turn each of the segments as the current segment, and making a voiced/unvoiced decision for at least a frequency band of the current segment by a method comprising the steps of: evaluating a voicing measure for said frequency band; making the voiced/unvoiced decision for said frequency band based upon a comparison between the voicing measure and a threshold; determining an energy measure of the current segment; determining a measure of the signal energy of one or more consecutive preceding segments; comparing the energy measure of the current segment to the measure of the signal energy of the consecutive preceding segments; adjusting the threshold to make a voiced decision less likely when the energy measure of the current segment is less than the measure of the signal energy of the consecutive preceding segments.</p></layer>
<layer id = "layer323"><p><b>US5293449A:Analysis-by-synthesis 2,4 kbps linear predictive speech codec</b><br>The traveler has a car movable on an athwartship track. The mainsheet is connected to the car. Two oppositely facing hooks are pivotally mounted on the car for similar, simultaneous movement between a latching position and an inoperative position. A spring biases the hooks to latching position. Control lines are connected to each end of a bar which has sliding engagement with the hooks. When a control line is tensioned, the bar moves towards the line and actuates the hooks to inoperative position. When both lines are slack, the hooks are in operative position to engage stop pins positioned on either side of the center of the track.<br><b>Independant Claims</b><br>1. A linear predictive speech codec arrangement for performing a closed loop analysis-by-synthesis operation, comprising: an excitation model means for generating a plurality of excitation signals comprising voiced excitation generator means in the form of a codebook for providing a plurality of possible pulse trains for use as an excitation signal; and Gaussian noise generator means in the form of a codebook for providing a plurality of possible random sequences for use as an excitation signal, wherein said voiced excitation generator means and said Gaussian noise generator means are provided in parallel arrangement; sequencing means, coupled to an output of said voiced excitation generator means and said Gaussian noise generator means, for providing all possible pulse trains and random sequences in sequence as possible excitation signals; spectrum synthesizer means, coupled to said sequencing means, for providing reconstructed speech generation in response to each of said plurality of excitation signals; distortion analyzer means, coupled to an output of said spectrum synthesizer means, for comparing said reconstructed speech with original speech, and providing a distortion analysis signal for each of said excitation signals; and means for comparing the distortion analysis signal for each of said excitation signals and selecting the excitation signal that produces the reconstructed speech with a minimum distortion analysis signal so as to provide optimal reconstructed speech.<br>6. A linear predictive speech codec arrangement for performing a closed loop analysis-by-synthesis operation, comprising: an excitation model means for generating a plurality of excitation signals comprising voiced excitation generator means in the form of a first order pitch synthesizer for providing a plurality of possible voiced excitation signals for use as an excitation signal; and Gaussian noise generator means in the form of a codebook for providing a plurality of possible random sequences for use as an excitation signal, wherein said voiced excitation generator means and said gaussian noise generator means are provided in parallel arrangement; sequencing means, coupled to an output of said voiced excitation generator means and said Gaussian noise generator means, for providing all possible pulse trains and random sequences in sequence as possible excitation signals; spectrum synthesizer means, coupled to said sequencing means, for providing reconstructed speech generation in response to each of said plurality of excitation signals; distortion analyzer means, coupled to an output of said spectrum synthesizer means, for comparing said reconstructed speech with original speech, and providing a distortion analysis signal for each of said excitation signals; and means for comparing the distortion analysis signal for each of said excitation signals and selecting one of said possible random sequences, or selecting a pitch value and pitch filter coefficient of said first order pitch synthesizer so as to provide optimal reconstructed speech.<br>8. A linear predictive speech codec arrangement for performing a closed loop analysis-by-synthesis operation, comprising: an excitation model means for generating a plurality of excitation signals comprising voiced excitation generator means in the form of a first order pitch synthesizer for providing a plurality of possible voice excitation signals for use as an excitation signal; and Gaussian noise generator means in the form of a codebook for providing a plurality of possible random sequences for use as an excitation signal, wherein said voice excitation generator means and said Gaussian noise generator means are provided in parallel arrangement; sequencing means, coupled to an output of said voiced excitation generator means and said Gaussian noise generator means, for providing all possible pulse trains and random sequences in sequence as possible excitation signals; spectrum synthesizer means, coupled to said sequencing means, for providing reconstructed speech generation in response to each of said plurality of excitation signals; distortion analyzer means, coupled to an output of said spectrum synthesizer means, for comparing said reconstructed speech with original speech, and providing a distortion analysis signal for each of said excitation signals; and means for comparing the distortion analysis signal for each of said excitation signals and selecting one of said possible random sequences and a pitch value and pitch filter coefficient of said first order pitch synthesizer, and computing a summation of excitation signals according to the selected random sequence and pitch value and pitch filter coefficient so as to provide optimal reconstructed speech.</p></layer>
<layer id = "layer324"><p><b>US5630011A:Quantization of harmonic amplitudes representing speech</b><br>An automatic food frying and vending system having a refrigerated storage chamber for storing food material to be fried and a frying chamber for frying material in cooking oil are installed in the main body of the automatic food frying and vending system in discrete sections designated for their respective purposes. The refrigrated chamber includes a stocker unit for receiving and keeping a number of packed containers, each sealed by a lid. A feeding device is provided with a holder for receiving from a conveying device the sealed container and inverting the container. The holder and a cutter is disposed on a movable table which moves in a substantially horizontal direction, so that, when the container is transferred to the holder, the holder is positioned in the vicinity of the storage chamber, and, when the sealed lid of the container is opened, the cutter is positioned over a frying basket in the frying chamber to enable the food material to be dropped by their own weight into the frying basket simultaneously with the opening of the sealed lid. A guide member covers the top of a cup supported on a placement table. After filling with the cooked food, the table moves downwardly for removal of the filled cup from a takeout port.<br><b>Independant Claims</b><br>1. A method for predicting speech signal parameters for use in encoding or decoding speech, comprising: representing segments of a speech signal by frames of a data signal that each comprise a fundamental frequency and multiple spectral harmonics; reconstructing speech signal parameters that characterize a first segment of speech from a first frame; reconstructing a first control parameter that characterizes the first segment using a first digitally encoded signal, wherein all digital bits of the first digitally encoded signal that represent the first control parameter are protected by an error protection code; reconstructing a second control parameter that characterizes a second segment of speech from a second frame using a second digitally encoded signal, wherein all digital bits of the second digitally encoded signal that represent the second control parameter are protected by an error protection code; and predicting speech signal parameters that characterize the second segment based on the reconstructed speech signal parameters and the first and second control parameters.<br>12. A method for predicting speech signal parameters for use in encoding or decoding speech, comprising: representing segments of a speech signal by frames of a data signal that each comprise a fundamental frequency and multiple spectral harmonics; reconstructing speech signal parameters that characterize a first segment of speech from a first frame; reconstructing a first control parameter that characterizes the first segment; reconstructing a second control parameter that characterizes a second segment of speech from a second frame; predicting speech signal parameters that characterize the second segment based on the reconstructed speech signal parameters and the first and second control parameters; computing a scale factor from the first and second control parameters; and applying the scale factor to the predicted speech signal parameters to produce modified predicted speech signal parameters.<br>17. A method for predicting speech signal parameters for use in encoding or decoding speech, comprising: representing segments of a speech signal by frames of a data signal that each comprise a fundamental frequency and multiple spectral harmonics; reconstructing speech signal parameters that characterize a first segment of speech from a first frame; reconstructing a first control parameter that characterizes the first segment; reconstructing a second control parameter that characterizes a second segment of speech from a second frame; predicting speech signal parameters that characterize the second segment based on the reconstructed speech signal parameters and the first and second control parameters; and removing the mean value of the predicted speech signal parameters from the predicted speech signal parameters to produce modified predicted speech signal parameters.</p></layer>
<layer id = "layer325"><p><b>US5369724A:Method and apparatus for encoding, decoding and compression of audio-type data using reference coefficients located within a band of coefficients</b><br>A logic circuit communicating to and from an input/output port in a variety of input modes and in a variety of output modes. The circuit may be configured to have a dedicated, registered, or latched input; and in the output mode to have a registered, combinatorial or latched output. A register/latch, in conjunction with a programmable input select multiplexer, can function as an input, output or buried register or as a transparent latch. A programmable clock select multiplexer selects between a clock/latch enable signal applied at an external pin or a product term generated internally. Clock polarity control is also provided. Asynchronous reset and preset of the register/latch is provided along with polarity control therefor. Dedicated and programmable feedback paths are provided. An output inverter can selectably be enabled from internal signals or from an external pin. The logic circuit can be deployed in banks, each bank electably receiving the same or a different clock. The register/latch can be preloaded via an internally-generated signal or from the external pins.<br><b>Independant Claims</b><br>1. A method for encoding a selected aspect of a signal that is defined by signal elements that are discrete in at least one dimension, said method comprising the steps of: a. dividing the signal into at least one band, at least one of said at least one band(s) having a plurality of adjacent signal elements; b. in at least one band, identifying a signal element having a magnitude with a preselected size relative to other signal elements in said at least one band(s) and designating said signal element as a "yardstick" signal element for said at least one band(s), at least one of said yardstick signal elements having a magnitude that is the closest to the median of the magnitudes of all of the signal elements in its respective band; c. encoding the location of at least one yardstick signal element(s) with respect to its position along said at least one dimension in which said signal elements are discrete within its respective band; and d. quantizing the magnitude of said at least one yardstick signal element(s) for which the location was encoded.<br>2. A method for encoding a selected aspect of a signal that is defined by signal elements that are discrete in at least one dimension, said method comprising the steps of: a. dividing the signal into at least one band, at least one of said at least one band(s) having a plurality of adjacent signal elements: b. in at least one band, identifying a signal element having a magnitude with a preselected size relative to other signal elements in said at least one band(s) and designating said signal element as a "yardstick" signal element for said at least one band(s), at least one of said yardstick signal elements having a magnitude that is the closest to the average of the magnitudes of all of the signal elements in its respective band; c. encoding the location of at least one yardstick signal element(s) with respect to its position along said at least one dimension in which said signal elements are discrete within its respective band; and d. quantizing the magnitude of said at least one yardstick signal element(s) for which the location was encoded.<br>3. A method for encoding a selected aspect of a signal that is defined by signal elements that are discrete in at least one dimension, said method comprising the steps of: a. dividing the signal into at least one band, at least one of said at least one band(s) having a plurality of adjacent signal elements; b. in at least one band, identifying a signal element having a magnitude with a preselected size relative to other signal elements in said at least one band(s) and designating said signal element as a "yardstick" signal element for said at least one band(s); c. encoding the location of at least one yardstick signal element(s) with respect to its position along said at least one dimension in which said signal elements are discrete within its respective band; d. allocating a first yardstick bit allocation to at least one of said yardstick signal elements; e. quantizing the magnitude of said at least one yardstick signal element(s) using said first yardstick bit allocation; f. allocating a second yardstick bit allocation to said at least one said yardstick signal element(s); and g. encoding the magnitude of said at least one yardstick signal element(s) using said second yardstick bit allocation and said encoded location of said at least one yardstick signal element(s) to refine the quantization of said at least one yardstick signal element(s).<br>4. A method for encoding a selected aspect of a signal that is defined by signal elements that are discrete in at least one dimension, said method comprising the steps of: a. dividing the signal into at least one band, at least one of said at least one band(s) having a plurality of adjacent signal elements; b. in at least one band, identifying a signal element having a magnitude with a preselected size relative to other signal elements in said at least one band(s) and designating said signal element as a "yardstick" signal element for said at least one band(s); c. encoding the location of at least two yardstick signal element(s) with respect to the position of each along said at least one dimension in which said signal elements are discrete within its respective band; d. quantizing the magnitude of at least two said yardstick signal element(s) for which the location was encoded; e. selecting a signal element in a band including one of said at least two yardstick signal elements, the magnitudes of which have been quantized; and f. allocating to said selected signal element a signal element bit allocation that is a function of the quantized magnitudes of said at least two yardstick signal elements.<br>5. A method for encoding a selected aspect of a signal that is defined by signal elements that are discrete in at least one dimension, said method comprising the steps of: a. dividing the signal into at least one band, at least one of said at least one band(s) having a plurality of adjacent signal elements; b. in at least one band, identifying a signal element having a magnitude with a preselected size relative to other signal elements in said at least one band(s) and designating said signal element as a "yardstick" signal element for said at least one band(s); c. encoding the location of at least one yardstick signal element(s) with respect to its position along said at least one dimension in which said signal elements are discrete within its respective band; and d. quantizing the magnitude of said at least one yardstick signal element(s) for which the location was encoded: and e. encoding the sign of said at least one yardstick signal element(s) for which the location has been encoded.<br>6. A method for decoding a code representing a selected aspect of a signal that is defined by signal elements that are discrete in at least one dimension, which code has been encoded by a method comprising the steps of: a. dividing the signal into at least one band, at least one of said at least one band(s) having a plurality of adjacent signal elements; b. in at least one band, identifying a signal element having a magnitude with a preselected size relative to other signal elements in said at least one band(s) and designating said signal element as a "yardstick" signal element for said at least one band(s); c. encoding the location of at least one yardstick signal element(s) with respect to its position along said at least one dimension in which said signal elements are discrete within its respective band; d. quantizing the magnitude(s) of said at least one yardstick signal element(s) for which the location was encoded; e. using a function of said encoded location(s) and magnitude(s) of said at least one yardstick signal element(s) to encode said selected aspect of said signal; f. quantizing the magnitude of said at least one yardstick signal element(s) for which the location was encoded and of at least one additional yardstick signal element: g. selecting a signal element in a band that includes said at least one yardstick signal elements for which the location was encoded; and h. allocating to said selected signal element a signal element bit allocation that is a function of the quantized magnitudes of said at least two yardstick signal elements for which the magnitudes have been quantized; said method of decoding comprising the step of translating said code based on: i. a function that is appropriately inversely related to said function of the location(s) and magnitude(s) used to encode said code; and ii. a function of said signal element bit allocation.<br>10. A method for decoding a code representing a selected aspect of a signal that is defined by signal elements that are discrete in at least one dimension, which code has been encoded by a method comprising the steps of: a. dividing the signal into at least one band, at least one of said at least one band(s) having a plurality of adjacent signal elements; b. in at least one band, identifying a signal element having a magnitude with a preselected size relative to other signal elements in said at least one band(s)and designating said signal element as a "yardstick" signal element for said at least one band(s); c. encoding the location of at least one yardstick signal element(s) with respect to its position along said at least one dimension in which said signal elements are discrete within its respective band; d. allocating a first yardstick bit allocation to said located at least one of said yardstick signal element(s); e. quantizing the magnitude of at least one of said located yardstick signal element(s) using said first yardstick bit allocation; f. allocating a second yardstick bit allocation said at least one located and quantized yardstick signal element(s); g. encoding the magnitude of said at least one located and quantized yardstick signal element(s) using said second yardstick bit allocation and said encoded location of said at least one yardstick signal element(s) to refine the quantization of said at least one yardstick signal element(s); and h. using a function of said encoded location(s) and magnitude(s) of said at least one yardstick signal element(s) to encode said selected aspect of said signal; said method of decoding comprising the step of translating said code based on a function that is appropriately inversely related to said function of the location(s) and magnitude(s) used to encode said code.<br>11. An apparatus for decoding a code representing a selected aspect of a signal that is defined by signal elements that are discrete in at least one dimension, which code has been encoded by a method comprising the steps of: a. dividing the signal into at least one band, at least one of said at least one band(s) having a plurality of adjacent signal elements; b. in at least one band, identifying a signal element having a magnitude with a preselected size relative to other signal elements in said at least one band(s) and designating said signal element as a "yardstick" signal element for said at least one band(s); c. encoding the location of at least one yardstick signal element(s) with respect to its position along said at least one dimension in which said signal elements are discrete within its respective band; d. quantizing the magnitudes of said at least one yardstick signal element(s) for which the locations was encoded and of at least one additional yardstick signal element; e. selecting a signal element in a band that includes said at least one yardstick signal elements for which the location was encoded; f. allocating to said selected signal element a signal element bit allocation that is a function of the quantized magnitudes of said at least two yardstick signal elements for which the magnitudes have been quantized; and g. using a function of said encoded location and magnitude of said at least one yardstick signal element(s) to encode said selected aspect of said signal; said decoding apparatus comprising means for translating said code that is based on said signal element bit allocation and that is appropriately inversely related to said function of the location and magnitude used to encode said selected aspect of said signal.</p></layer>
<layer id = "layer326"><p><b>US5978759A:Apparatus for expanding narrowband speech to wideband speech by codebook correspondence of linear mapping functions</b><br>The device comprises a gripper (15) whose arms (16, 17) hold at their free end an on-loading mechanism (18, 19) designed to engage a load (13) by gripping accessories (14). Two connecting rods (21, 22) constitute a deformable diamond with the upper part of the gripper (15). The lower ends of connecting rods (21, 22) are hinged to a shoulder (27) of a guide column (28) on which moves a slide (29) forming the head of the gripper (15). Two jacks (45, 46) control the opening and closing of the gripper (15). A connector arm (30) links the shoulder of column (28) to a turning grappling rope (10) and allows the center of gravity to be corrected by a jack (52). This gripping device is intended for use with raising devices such as turret slewing cranes.<br><b>Independant Claims</b><br>1. An apparatus for recovering wideband speech from narrowband speech, said apparatus comprising: a linear predictive coding analyzer for performing a linear predictive coding analysis on an inputted narrowband digital speech signal to thereby obtain a set of narrowband spectral envelope parameters and a residual signal; a spectral envelope codebook having a plurality of spectral envelope codes, wherein each of the plurality of spectral envelope codes is a predefined set of narrowband spectral envelope parameters; a linear mapping function codebook having a plurality of linear mapping functions for linearly mapping the set of narrowband envelope parameters to a set of wideband spectral envelope parameters which correspond to the plurality of spectral envelope codes on a one-to-one basis; a selection means for selecting one linear mapping function from said linear mapping function codebook which provides a minimum distance to the set of narrowband spectral envelope parameters of the inputted narrowband speech signal; a linear mapping function calculation means for calculating a set of wideband spectral envelope parameters using the selected one linear mapping function and the set of narrowband spectral envelope parameters directly obtained from said linear predictive coding analyzer; a residual converter for converting the residual signal into a wideband residual signal; and a linear predictive coding synthesizer for synthesizing the set of wideband spectral envelope parameters calculated and the wideband residual signal so as to obtain a wideband digital speech signal.<br>9. An apparatus for recovering wideband speech from narrowband speech, said apparatus comprising: a linear predictive coding analyzer for performing a linear predictive coding analysis on an inputted narrowband digital speech signal to thereby obtain a set of narrowband spectral envelope parameters and a residual signal; a spectral envelope codebook having a plurality of spectral envelope codes, wherein each of the plurality of spectral envelope codes is a predefined set of narrowband spectral envelope parameters; a linear mapping function codebook having a plurality of linear mapping functions for linearly mapping the set of narrowband envelope parameters to a set of wideband spectral envelope parameters which correspond to the plurality of spectral envelope codes on a one-to-one basis; a distance calculation means for calculating a distance between the set of narrowband spectral envelope parameters and each of the plurality of spectral envelope codes contained in said spectral envelope codebook; a weights calculations means for calculating weights for the spectral parameters based on, and corresponding to, each of the distances calculated by said distance calculations means; a linear mapping function calculation means for calculating a plurality of sets of wideband spectral envelope parameters using each of the plurality of linear mapping functions contained in said linear mapping codebook and the set of narrowband spectral envelope parameters directly obtained from said linear predictive coding analyzer; a linear map result adder for weighing the plurality of sets of wideband spectral envelope parameters using the weights calculated by said weights calculation means and for summing the weighted sets of transformed spectral envelope parameters to obtain a set of wideband spectral envelope parameters; a residual converter for converting the residual signal into a wideband residual signal; and a linear predictive coding synthesizer for synthesizing the set of wideband spectral envelope parameters and the wideband residual signal so as to obtain a wideband digital speech signal.</p></layer>
<layer id = "layer327"><p><b>US5568559A:Sound processing apparatus</b><br><b>Independant Claims</b><br>1. A sound processing apparatus comprising: (A) a plurality of audio signal output means which convert sounds generated from a sound source into audio signals and output the audio signals; (B) a detection means which receives two audio signals output from at least two of said audio signal output means, detects whether the polarities of the two input audio signals are in agreement or not, and outputs a detection signal that indicates whether their polarities are in agreement or not; and (C) a comparator means which compares a period in which the polarities of the two input audio signals are in agreement with a period in which they are not in agreement at predetermined intervals depending upon the detection signal output from the detection means, and outputs a signal indicating the result of comparison.<br>2. A sound processing apparatus comprising: (A) a plurality of audio signal output means which convert sounds generated from a sound source into audio signals and output the audio signals; (B) a detection means which receives two audio signals output from at least two of said audio signal output means, detects whether the polarities of the two input audio signals are in agreement or not at intervals of a predetermined period, and outputs a detection signal that indicates a period in which the polarities are in agreement; and (C) a comparator means which compares the length of a period indicated by the detection signal output from said detection means with a reference value, and outputs a signal indicating the result of comparison.<br>3. A sound processing apparatus comprising: (A) a plurality of audio signal output means which convert sounds generated from a sound source into audio signals and output the audio signals; (B) a detection means which receives two audio signals output from at least two of said audio signal output means, detects whether the polarities of the two input audio signals are in agreement or not at predetermined intervals, and outputs a detection signal that indicates a period in which the polarities are not in agreement; and (C) a comparator means which compares the length of a period indicated by the detection signal output from said detection means with a reference value, and outputs a signal indicating the result of comparison.<br>4. A sound processing apparatus comprising: (A) a plurality of audio signal output means which convert sounds generated from a sound source into audio signals and output the audio signals; (B) a detection means which receives two audio signals output from at least two of said audio signal output means, detects whether the polarities of the two input audio signals are in agreement or not, and outputs a detection signal that indicates whether the polarities are in agreement or not; (C) a smoothing means which smoothes the detection signal output from said detection means and outputs the smoothed signal; and (D) a comparator means which compares a period in which the polarities of the two input audio signals are in agreement with a period in which the polarities are not in agreement according to the detection signal smoothed by said smoothing means at predetermined intervals, and outputs a signal indicating the result of comparison.<br>5. A sound processing apparatus comprising: (A) a plurality of audio signal output means which convert sound generated from a sound source into audio signals and output the audio signals; (B) a detection means which inputs two audio signals output from at least two of said audio signal output means, detects whether the polarities of the two input audio signals are in agreement or not at predetermined intervals, and outputs a detection signal that indicates whether the polarities are in agreement or not; (C) a smoothing means which smoothes the detection signal output from said detection means and outputs the smoothed signal; and (D) a comparator means which compares the length of a period indicated by the smoothed signal from said smoothing means with a reference value, and outputs a signal representing the result of comparison.<br>6. A sound processing apparatus comprising: (A) a plurality of audio signal output means which convert sounds generated from a sound source into audio signals and output the audio signals; (B) a detection means which receives two audio signals output from at least two of said audio signal output means, detects whether the polarities of the two input audio signals are in agreement or not at predetermined intervals, and outputs a detection signal that indicates a period in which the polarities are not in agreement; (C) a smoothing means which smoothes the detection signal output from said detection means and outputs the smoothed signal; and (D) a comparator means which compares the length of a period indicated by the smoothed signal from said smoothing means with a reference value, and outputs a signal representing the result of comparison.<br>7. A sound processing apparatus comprising: (A) a plurality of audio signal output means which convert sounds generated from a sound source into audio signals and output the audio signals; (B) a multiplier means which receives two audio signals output from at least two of said audio signal output means, multiplies the two input audio signals and output a multiplication signal indicating the result of multiplication; and (C) a comparator means which compares a period in which the multiplication signal output from said multiplier means has positive polarity with a period in which the multiplication signal has negative polarity at predetermined intervals, and outputs a signal indicating the result of comparison.<br>8. A sound processing apparatus comprising: (A) a plurality of audio signal output means which convert sound generated from a sound source into audio signals and output the audio signals; (B) a multiplier means which receives two audio signals output from at least two of said audio signal output means, multiplies the two input audio signals and outputs a multiplication signal indicating the result of multiplication; and (C) a comparator means which detects a period in which a signal output from said multiplier means has positive polarity or a period in which the signal has negative polarity at predetermined intervals, compares the length of the period in which the signal has positive polarity with a reference value, and outputs a signal indicating the result of comparison.<br>9. A sound processing apparatus comprising: (A) a plurality of audio signal output means which convert sounds generated from a sound source into audio signals and output the audio signals; (B) a multiplier means which receives two audio signals output from at least two of said audio signal output means, multiplies the two input audio signals and outputs a multiplication signal indicating the result of multiplication; and (C) a comparator means which detects a period in which a signal output from said multiplier means has positive polarity or a period in which the signal has negative polarity at predetermined intervals, compares the length of the period in which the signal has negative polarity with a reference value, and outputs a signal indicating the result of comparison.<br>10. A sound processing apparatus comprising: (A) a plurality of audio signal output means which convert sounds generated from a sound source into audio signals and output the audio signals; (B) a multiplier means which receives two audio signals output from at least two of said audio signal output means, multiplies the two input audio signals and outputs a multiplication signal indicating the result of multiplication; (C) a smoothing means which smoothes the multiplication signal output from said multiplication means and outputs the smoothed multiplication signal; and (D) a comparator means which compares a period in which the multiplication signal smoothed by said smoothing means has positive polarity with a period in which the multiplication signal has negative polarity at predetermined intervals, and outputs a signal indicating the result of comparison.<br>11. A sound processing apparatus comprising: (A) a plurality of audio signal output means which convert sounds generated from a sound source into audio signals and output the audio signals; (B) a multiplier means which receives two audio signals output from at least two of said audio signal output means, multiplies the two input audio signals and outputs a multiplication signal indicating the result of multiplication; (C) a smoothing means which smoothes the multiplication signal output from said multiplication means and outputs the smoothed multiplication signal; and (D) a comparator means which compares the length of a period in which the multiplication signal smoothed by said smoothing means has positive polarity with a reference value at predetermined internals, and outputs a signal indicating the result of comparison.<br>12. A sound processing apparatus comprising: (A) a plurality of audio signal output means which convert sounds generated from a sound source into audio signals and output the audio signals; (B) a multiplier means which receives two audio signals output from at least two of said audio signal output means, multiplies the two input audio signals and outputs a multiplication signal indicating the result of multiplication; (C) a smoothing means which smoothes the multiplication signal output from said multiplication means and outputs the smoothed multiplication signal; and (D) a comparator means which compares the length of a period in which the multiplication signal smoothed by said smoothing means has negative polarity with a reference value at predetermined internals, and outputs a signal indicating the result of comparison.</p></layer>
<layer id = "layer328"><p><b>US5864798A:Method and apparatus for adjusting a spectrum shape of a speech signal</b><br>A method of compensating a direct-current offset coupled into a receiving path of a receiver, the receiving path having at least one gain factor adjustable by a gain control, which method first determines an amount of a direct-current offset present at a selected end point in the receiving path. A compensation quantity is set accordingly. In case of a forthcoming adjustment of the at least one gain factor by the gain control, the compensation quantity is then scaled with a scaling factor to prevent a direct-current step at the selected end point due to this forthcoming adjustment. The final compensation quantity is fed at a selected summing node into the receiving path. The invention is also directed to a corresponding receiver, an electronic device comprising such a receiver, a hardware component for such a receiver and to a corresponding software program product.<br><b>Independant Claims</b><br>1. A method for adjusting a spectrum shape of an input speech signal, comprising the steps of: cascade-connecting a first filter having a first pole-zero transfer function for subjecting said input speech signal to a spectrum envelop emphasis and a second filter having a second pole-zero transfer function for compensating a spectral tilt of the spectrum shape of the input speech signal caused by the first filter; independently deriving two filter coefficients used in the second filter from the first pole-zero transfer function of said first filter; and compensating the spectral tilt using the derived filter coefficients, wherein the second pole-zero transfer function in a z transform domain comprises at least a first-order pole-zero transfer function expressed by (1-.mu..sub.z Z.sup.-1)/(1-.mu..sub.p Z.sup.-1), where .mu..sub.z and .mu..sub.p are filter coefficients whose absolute values are smaller than 1 and which are independent from each other, and said step of deriving the filter coefficients derives said .mu..sub.z from a zero transfer function of the first filter and derives said .mu..sub.z from a pole transfer function of the first filter.<br>8. An apparatus for adjusting a spectrum shape of an input speech signal, comprising: a first filter having a pole-zero transfer function which subjects said input speech signal to a spectrum envelop emphasis; and a second filter which compensates a spectral tilt of the spectrum shape of the input speech signal caused by said first filter, the second filter including: a calculator which independently derives two filter coefficients from the pole-zero transfer function of said first filter; and a filter section which subjects a speech signal output from said first filter to a filtering process using the derived filter coefficients and which compensates the spectral tilt caused by the first filter, wherein said calculator calculates a first parameter corresponding to a first-order partial autocorrelation coefficient which is approximated to a spectrum envelop of a zero transfer function of said first filter and a second parameter corresponding to a first-order partial autocorrelation coefficient which is approximated to a spectrum envelop of a pole transfer function of said first filter, said calculator inputs the first parameter and the second parameter to said filter section, and said filter section includes a transfer function which uses the first parameter and the second parameter to compensate the spectral tilt caused by the first filter.<br>11. An apparatus for adjusting a spectrum shape of an input speech signal, comprising: a first filter having a pole-zero transfer function which subjects said input speech signal to a spectrum envelop emphasis; and a second filter which compensates a spectral tilt of the spectrum shape of the input speech signal caused by said first filter, the second filter including: a calculator which independently derives two filter coefficients from the pole-zero transfer function of said first filter; and a filter section which subjects a speech signal output from said first filter to a filtering process using the derived filter coefficients and which compensates said spectral tilt caused by the first filter, wherein said calculator calculates a first parameter corresponding to multiple-order partial autocorrelation coefficients which are approximated to a spectrum envelop of a zero transfer function of said first filter and a second parameter corresponding to multiple-order partial autocorrelation coefficients which are approximated to a spectrum envelop of a pole transfer function of said first filter, said calculator inputs the first parameter and the second parameter to said filter section, and said filter section includes a transfer function which uses the first parameter and the second parameter to compensate the spectral tilt caused by said first filter.<br>12. An apparatus for adjusting a spectrum shape of an input speech signal, comprising: a synthesis filter which analyzes said input speech signal to output synthesis filter data; a calculator which calculates weighting filter data and a pole-zero transfer function using the synthesis filter data output from the synthesis filter; and a weighting filter which filters the input speech signal using the calculated weighting filter data and the calculated pole-zero transfer function, the weighting filter including a first filter having a first pole-zero transfer function and a second filter having a second pole-zero transfer function, said second filter compensates a spectral tilt of the spectrum shape of the input speech signal caused by the first filter, wherein the second filter has a function of a first-order zero filter having a z domain transfer function expressed by 1-.mu..sub.z Z.sup.-1 and a function of a first-order pole filter having a z domain transfer function expressed by 1/(1-.mu..sub.p z.sup.-1), where an absolute value of .mu..sub.p is smaller than 1.<br>14. An apparatus for adjusting a spectrum shape of an input speech signal, comprising: a first filter having a pole-zero transfer function represented by transfer functions A(z)/B(z); a second filter cascade-connected to the first filter and having a first parameter and a second parameter, said second filter compensates characteristics of said first filter; and parameter deriving means for individually deriving the first parameter and the second parameter from the transfer functions A(z) and B(z), wherein the parameter deriving means includes a first parameter output section for predicting characteristics of at least one of 1) the transfer function A(z) and 2) an inverse transfer function 1/A(z) to derive a first predictive coefficient and to output the first predictive coefficient as the first parameter; and a second parameter output section for predicting characteristics of at least one of 1) the transfer function B(z) and 2) an inverse transfer function 1/B(z) to derive a second predictive coefficient and to output the second predictive coefficient as the second parameter.<br>15. A method for adjusting a spectrum shape of an input speech signal, comprising the steps of: preparing a first filter having a pole-zero transfer function represented by A(z)/B(z) and a second filter for compensating characteristics of the first filter, the second filter having a first-order transfer function represented by (1-.mu..sub.z Z.sup.-1)/(1-.mu..sub.p Z.sup.-1), where .mu..sub.z and .mu..sub.p are respective filter coefficients whose absolute values are smaller than 1; and filtering the speech signal by means of the first and second filters.<br>20. A method for adjusting a spectrum shape of an input speech signal, comprising the steps of: preparing a first filter having a pole-zero transfer function represented by transfer functions A(z)/B(z) and a second filter for compensating characteristics of the first filter, the second filter having a first-order transfer function represented by (1-.mu..sub.z Z.sup.-1)/(1-.mu..sub.p Z.sup.-1), where .mu..sub.z and .mu..sub.p are respective filter coefficients whose absolute values are smaller than 1; deriving two parameters used in the second filter from the transfer functions A(z) and B(z) individually; and filtering the speech signal by means of the first and second filters.</p></layer>
<layer id = "layer329"><p><b>US6539355B1:Signal band expanding method and apparatus and signal synthesis method and apparatus</b><br>A system and method for loading and unloading a data cartridge includes a data cartridge processor having a loader tray for loading and unloading a data cartridge into and from the data cartridge processor. The data cartridge processor records data to or receives data from the data cartridge. A cartridge loader is provided for actuating the loader tray to lower the data cartridge or raise the loader tray to unload the data cartridge into and from the data cartridge processor. An accessor is provided for activating the cartridge loader driven by an actuator for effecting movement of the accessor.<br><b>Independant Claims</b><br>1) A bandwidth expanding method for expanding a bandwidth by estimating outside-band components from narrow-band signals or from parameters allowing for synthesizing the narrow-band signals comprising the steps of: first adjusting frequency characteristics of said outside-band components by pre-set alterable parameter values; and subsequently adding said outside-band components having adjusted frequency characteristics to said narrow-band signals.<br>4) A bandwidth expanding method for expanding a bandwidth by estimating outside-band components from narrow-band signals or from parameters allowing for synthesizing the narrow-band signals comprising the steps of: adding said outside-band components to said narrow-band signals; and adjusting frequency characteristics of said outside-band components after addition thereof to said narrow-band signals by pre-set alterable parameter values.<br>6) A bandwidth expanding apparatus for expanding the bandwidth by estimating outside-band components from narrow-band signals or from parameters allowing for synthesizing the narrow-band signals, comprising: frequency characteristics adjustment means for adjusting frequency characteristics of said outside-band components by pre-set alterable parameter values; and addition means for adding the outside-band components having frequency characteristics adjusted by said frequency characteristics adjustment means to said narrow-band signals.<br>11) A bandwidth expanding apparatus for expanding the bandwidth by estimating outside-band components from narrow-band signals or from parameters allowing for synthesizing the narrow-band signals comprising: addition means for adding said outside-band components to said narrow-band signals; and frequency characteristics adjustment means for adjusting frequency characteristics of said outside-band components of an addition output of said addition means by pre-set alterable parameters.<br>14) A signal processing method for adding signals of a main system to signals of a subsidiary system, comprising the steps of prior to adding the signals of said subsidiary system to the signals of said main system, adjusting a gain of a given sample of the signals of said subsidiary system and adjusting a gain of samples following said given sample based on a presence or absence of an overflow determined from an amount of the addition.<br>17) A signal processing apparatus for signals of a main system and signals of a subsidiary system, comprising: addition means for summing the signals of the subsidiary system to the signals of the main system; overflow detection means for detecting a presence or absence of an overflow based on an amount of addition from said addition means; gain adjustment means for adjusting a gain for a given sample and for following samples of the signals of said subsidiary system based on detected results from said overflow detection means; and multiplication means for multiplying said given sample and said following samples of the signals of the subsidiary system by an adjustment gain from said gain adjustment means.<br>20) A bandwidth expanding method for expanding the bandwidth by estimating outside-band components from narrow-band signals or from parameters allowing for synthesizing the narrow-band signals, comprising the steps of: prior to adding said outside-band components to said narrow-band signals, adjusting a gain of said outside-band components based on a presence or absence of an overflow determined from an amount of addition.<br>22) A bandwidth expanding apparatus for expanding the bandwidth by estimating outside-band components from narrow-band signals or from parameters allowing for synthesizing the narrow-band signals, comprising: addition means for summing said outside-band components to said narrow-band signals; overflow detection means for detecting a presence or absence of an overflow that can be verified from an amount of addition from said addition means; gain adjustment means for adjusting a gain for a given sample and following samples of the outside-band components based on detected results from said overflow detection means; and multiplication means for multiplying said given sample and following samples of the outside-band components by an adjustment gain from said gain adjustment means.<br>24) A speech synthesis method comprising: a first parameter prediction step for predicting parameters that allow for representation of a number of broad band formants not larger than a number of narrow band formants from narrow band parameters representing an input narrow band speech and which allow for representation of the input narrow band speech; a parameter extraction step for extracting parameters that allow representation of the narrow-band formant information from the input narrow band speech; a second parameter prediction step for predicting a parameter that allows representation of a number of broad band formants not larger than the number of the produced narrow-band formants; and a synthesis step for synthesizing the broad-band speech from a parameter that allows for representation of the produced broad band formants.<br>26) A speech synthesis apparatus comprising: first parameter prediction means for predicting parameters that allow for representation of a number of broad band formants not larger than a number of narrow band formants from narrow band parameters representing an input narrow band speech and which allow for representation of the input narrow band speech; parameter extraction means for extracting parameters that allow representation of the narrow-band formant information from the input narrow band speech; second parameter prediction means for predicting a parameter that allows representation of a number of broad band formants not larger than the number of the produced narrow-band formants; and synthesis means for synthesizing the broad-band speech from a parameter that allows for representation of the produced broad-band formants.</p></layer>
<layer id = "layer330"><p><b>US20080027720A1:Method and apparatus for speech data</b><br>A process for improving the melt characteristics of polyethylene resins is provided. The process involves contacting a polyethylene resin powder with a low level of free radical initiator at a temperature below the melting point of the resin.<br><b>Independant Claims</b><br>1-15. (canceled)<br>2) 1-15. (canceled)<br>3) 1-15. (canceled)<br>4) 1-15. (canceled)<br>1-15. (canceled)<br>6) 1-15. (canceled)<br>7) 1-15. (canceled)<br>8) 1-15. (canceled)<br>9) 1-15. (canceled)<br>10) 1-15. (canceled)<br>11) 1-15. (canceled)<br>12) 1-15. (canceled)<br>13) 1-15. (canceled)<br>14) 1-15. (canceled)<br>1-15. (canceled)<br>16. A data processing device for generating, from a preset code, filter data to be afforded to a speech synthesis filter adapted for synthesizing the speech based on linear prediction coefficients and a preset input signal, comprising: code decoding means for decoding said code produced by encoding original filter data, to output decoded filter data; acquisition means for acquiring preset tap coefficients as found by carrying out learning, said tap coefficients being used to predict the original filter data from said decoded filter data; and prediction means for carrying out preset predictive calculations, using said tap coefficients and the decoded filter data, to find prediction values of said filter data, to send the so found prediction values to said speech synthesis filter for use as linear prediction coefficients in said speech syntheses filter.<br>27. A data processing method for generating, from a preset code, filter data to be afforded to a speech synthesis filter adapted for synthesizing the speech based on linear prediction coefficients and on a preset input signal, comprising: a code decoding step of decoding said code to output decoded filter data; an acquisition step of acquiring preset tap coefficients as found by carrying out learning; and a prediction step of carrying out preset predictive calculations, using said tap coefficients and the decoded filter data, to find prediction values of said filter data, to send the so found prediction values to said speech synthesis filter for use as linear prediction coefficients in said speech syntheses filter.<br>28. A recording medium having recorded thereon a program for having a computer execute data processing of generating, from a preset code, filter data to be afforded to a speech synthesis filter adapted for synthesizing the speech based on linear prediction coefficients and a preset input signal, said program comprising: a code decoding step of decoding said code to output decoded filter data; an acquisition step of acquiring preset tap coefficients as found by carrying out learning; and a prediction step of carrying out preset predictive calculations, using said tap coefficients and the decoded filter data, to find prediction values of said filter data, to send the so found prediction values to said speech synthesis filter for use as linear prediction coefficients in said speech syntheses filter.<br>29. A learning device for learning preset tap coefficients usable for finding, by predictive calculations from a code associated with filter data to be applied to a speech synthesis filter which synthesizes the speech based on linear prediction coefficients and a preset input signal, prediction values of said filter data, comprising: code decoding means for decoding the code corresponding to filter data to output decoded filter data; and learning means for carrying out learning so that prediction errors of prediction values of said filter data obtained on carrying out predictive calculations using said tap coefficients and decoded filter data will be statistically smallest to find said tap coefficients.<br>37. A learning method for learning preset tap coefficients usable for finding, by predictive calculations from a code associated with filter data to be applied to a speech synthesis filter which synthesizes the speech based on linear prediction coefficients and a preset input signal, prediction values of said filter data, comprising: a code decoding step of decoding the code corresponding to filter data to output decoded filter data; and a learning step of carrying out learning so that prediction errors of prediction values of said filter data obtained on carrying out predictive calculations using said tap coefficients and decoded filter data will be statistically smallest to find said tap coefficients.<br>38. A recording medium having recorded thereon a program for having a computer execute learning processing of learning preset tap coefficients usable for finding, by predictive calculations from a code associated with filter data to be applied to a speech synthesis filter which synthesizes the speech based on linear prediction coefficients and a preset input signal, prediction values of said filter data, said program comprising: a code decoding step of decoding the code corresponding to filter data to output decoded filter data; and a learning step of carrying out learning so that prediction errors of prediction values of said filter data obtained on carrying out predictive calculations using said tap coefficients and decoded filter data will be statistically smallest to find said tap coefficients.<br>39-53. (canceled)<br>40) 39-53. (canceled)<br>41) 39-53. (canceled)<br>42) 39-53. (canceled)<br>43) 39-53. (canceled)<br>44) 39-53. (canceled)<br>45) 39-53. (canceled)<br>46) 39-53. (canceled)<br>47) 39-53. (canceled)<br>48) 39-53. (canceled)<br>49) 39-53. (canceled)<br>50) 39-53. (canceled)<br>51) 39-53. (canceled)<br>52) 39-53. (canceled)<br>39-53. (canceled)<br>54. A data processing device for generating, from a preset code, filter data to be afforded to a speech synthesis filter adapted for synthesizing the speech based on linear prediction coefficients and a preset input signal, comprising: a decoder configured to decode said code produced by encoding original filter data, to output decoded filter data; an acquisition unit configured to acquire preset tap coefficients as found by carrying out learning, said tap coefficients being used to predict the original filter data from said decoded filter data; and a predictor configured to carry out preset predictive calculations, using said tap coefficients and the decoded filter data, to find prediction values of said filter data, to send the so found prediction values to said speech synthesis filter for use as linear prediction coefficients in said speech syntheses filter.</p></layer>
<layer id = "layer331"><p><b>US5960389A:Methods for generating comfort noise during discontinuous transmission</b><br><b>Independant Claims</b><br>1. A method for producing comfort noise (CN) in a digital mobile terminal that uses a discontinuous transmission, comprising the steps of: in response to a speech pause, calculating random excitation spectral control (RESC) parameters; transmitting the RESC parameters to a receiver together with predetermined ones of CN parameters; receiving the RESC parameters; and shaping the spectral content of an excitation using the received RESC parameters prior to applying the excitation to a synthesis filter.<br>16. Apparatus for generating comfort noise (CN) in a system having a digital mobile terminal that uses a discontinuous transmission to a network, comprising: means in said digital mobile terminal that is responsive to a speech pause for calculating random excitation spectral control (RESC) parameters and for transmitting the RESC parameters together with predetermined ones of CN parameters to a receiver in said network; and means in said network for shaping the spectral content of an excitation using received RESC parameters prior to applying the excitation to a synthesis filter.<br>31. A method for generating comfort noise (CN) in a digital mobile terminal that uses a discontinuous transmission, comprising the steps of: in response to a speech pause, buffering a set of speech coding parameters; within an averaging period, replacing speech coding parameters of the set that are not representative of background noise with speech coding parameters that are representative of the background noise; and averaging the set of speech coding parameters.<br>51. Apparatus for generating comfort noise (CN) in a system having a digital mobile terminal that uses a discontinuous transmission to a network, comprising: data processing means in said digital mobile terminal that is responsive to a speech pause for buffering a set of speech coding parameters and, within an averaging period, for replacing speech coding parameters of the set that are not representative of background noise with speech coding parameters that are representative of the background noise, said data processing means averaging the set of speech coding parameters and transmitting the averaged set of speech coding parameters to the network.<br>56. A method for producing comfort noise (CN), comprising the steps of: in response to a speech pause, transmitting CN parameters to a receiver; and shaping the spectral content of an excitation by steps of, forming an excitation from a white noise excitation sequence; scaling the white noise excitation sequence to produce a scaled white noise excitation sequence; and processing the scaled white noise excitation sequence in a synthesis filter having fixed coefficients that are optimized to provide at least one of a desired comfort noise quality or to cause the frequency response of the synthesis filter to resemble that of a random excitation spectral control (RESC) filter having transmitted coefficients.</p></layer>
<layer id = "layer332"><p><b>US6006174A:Multiple impulse excitation speech encoder and decoder</b><br>A signal detector, having a light receiving element, in which a plurality of electrodes are arranged opposite to the surface of the light receiving element through which light is received. The electrode opposite to the position of incidence of received light is cut off to form two electrode regions on either side of the electrode cut off and to thereby set a virtual division line. The need for the provision of a structural division line on the light receiving element used for focusing control is thereby eliminated. There is therefore no need for strict adjustment of the attachment position and, hence, no need for an error adjustment circuit to be separately provided.<br><b>Independant Claims</b><br>1. A method for encoding speech, comprising the steps of: sampling an original speech signal; producing spectral coefficients from said samples; interpolating the spectral coefficients; and subjecting interpolated spectral coefficients to pitch analysis to obtain a spectral residual signal.<br>4. An apparatus for encoding speech, comprising: means for sampling an original speech signal; means for producing spectral coefficients from said sample; means for interpolating the spectral coefficients; and means for performing a pitch analysis of the interpolated spectral coefficients to obtain a spectral residual signal.<br>6. An improved method for encoding a digitized speech signal comprising the steps of: a) defining a filter with coefficients based upon selected interpolated parameters of the digitized speech signal; b) perceptually weighting said digitized speech signal; c) selectively pulsing said filter to create a synthetic speech signal which is an approximation of said perceptually weighted digitized speech signal; d) comparing said synthetic speech signal to said perceptually weighted digitized speech signal to determine the difference between the two signals; e) selectively pulsing the filter to create a correction signal which approximates said difference; and f) combining said correction signal with said synthetic speech signal to provide a modified synthetic speech signal which is a better approximation of said perceptually weighted digitized speech signal.</p></layer>
<layer id = "layer333"><p><b>US20020007280A1:Wideband speech coding system and method</b><br><b>Independant Claims</b><br>1. A method of wideband speech encoding, comprising: (a) partitioning a frame of digital speech into a lowband and a highband; (b) encoding said lowband; (c) encoding said highband using a linear prediction excitation from noise modulated by a portion of said lowband; and (d) combining said encoded lowband and said encoded highband to form an encoded wideband speech.<br>2. A method of wideband speech decoding, comprising: (a) decoding a first portion of an input signal as a lowband speech signal; (b) decoding a second portion of an input signal as a noise-modulated excitation of a linear prediction encoding wherein said noise modulated excitation is noise modulated by a portion of the results of said decoding as a lowband speech signal of preceding step (a); and (c) combining the results of foregoing steps (a) and (b) to form a decoded wideband speech signal.<br>3. A wideband speech encoder, comprising: (a) a lowband filter and a highband filter for digital speech; (b) a first encoder with input from said lowband filter; (c) a second encoder with input from said highband filter and said lowband filter, said second encoder using an excitation from noise modulated by a portion of output from said lowband filter; and (d) a combiner for the outputs of said first encoder and said second encoder to output encoded wideband speech.<br>4. A wideband speech decoder, comprising: (a) a first speech decoder with an input for encoded narrowband speech; (b) a second speech decoder with an input for encoded highband speech and an input for the output of said first speech decoder, said second speech decoder using excitation of noise modulated by a portion of the output of said first speech decoder; and (c) a combiner for the outputs of said first and second speech decoders to output decoded wideband speech.</p></layer>
<layer id = "layer334"><p><b>US5142656A:Low bit rate transform coder, decoder, and encoder/decoder for high-quality audio</b><br>An integrated power combiner is disclosed. The power combiner includes a first circular geometry primary winding having one or more inductive elements, such as an active winding with one or more driver stages. A circular geometry secondary winding is disposed adjacent to the first primary winding, such as an active winding with one or more driver stages. A second circular geometry primary winding is disposed adjacent to the secondary winding and has one or more inductive elements. One or more connections are provided between one or more of the inductive elements of the first circular geometry primary winding and one or more of the inductive elements of the second circular geometry primary winding.<br><b>Independant Claims</b><br>1. An encoder for the encoding of digital information, said digital information comprising signal sample blocks representing analog audio signals, comprising means for generating subband information blocks, each subband information block comprising a set of digital words generated in response to a signal sample block, said means comprising means for applying a discrete transform function to each of said signal sample blocks, and means for quantizing with a fixed number of bits one or more digital words corresponding to at least the lowest frequency spectral component of said analog audio signals, but not quantizing all digital words with a fixed number of bits.<br>2. An encoder for the encoding of digital information, said digital information comprising signal sample blocks representing analog audio signals, comprising means for defining subbands and for generating subband information blocks, each subband information block comprising a set of digital words generated in response to a signal sample block, and means for quantizing with a fixed number of bits one or more digital words corresponding to at least the lowest frequency spectral component of said analog audio signals, and for quantizing one or more digital words with a fixed number of bits and an adaptive number of bits.<br>6. A decoder for the recovery of digital information from a coded signal, said digital information representing analog audio signals, comprising means for reconstructing digital words from said coded signal, said means reconstructing with a fixed number of bits one or more digital words corresponding to at least the lowest frequency spectral component of said analog audio signals, but not reconstructing all digital words with a fixed number of bits, and means for generating signal sample blocks in response to said digital words, said means comprising means for applying an inverse discrete transform function to the reconstructed digital words.<br>7. A decoder for the recovery of digital information from a coded signal, said digital information representing analog audio signals, comprising means for reconstructing digital words from said coded signal, said means reconstructing with a fixed number of bits one or more digital words corresponding to at least the lowest frequency spectral component of said analog audio signals, and for reconstructing one or more digital words with a fixed number of bits and an adaptive number of bits, and means for generating signal sample blocks in response to said digital words.<br>13. An encoding method for the encoding of digital information, said digital information comprising signal sample blocks representing analog audio signals, comprising generating subband information blocks, each subband information block comprising a set of digital words generated in response to a signal sample block, by applying a discrete transform function to each of said signal sample blocks, and quantizing with a fixed number of bits one or more digital words corresponding to at least the lowest frequency spectral component of said analog audio signals, but not quantizing all digital words with a fixed number of bits.<br>14. An encoding method for the encoding of digital information, said digital information comprising signal sample blocks representing analog audio signals, comprising defining subbands and generating subband information blocks, each subband information block comprising a set of digital words generated in response to a signal sample block, and quantizing with a fixed number of bits one or more digital words corresponding to at least the lowest frequency spectral component of said analog audio signals, and quantizing one or more digital words with a fixed number of bits and an adaptive number of bits.<br>18. A decoding method for the recovery of digital information from a coded signal, said digital information representing analog audio signals, comprising reconstructing with a fixed number of bits one or more digital words corresponding to at least the lowest frequency spectral component of said analog audio signals, but not reconstructing all digital words with a fixed number of bits, and generating signal sample blocks in response to said digital words by applying an inverse discrete transform function to the reconstructed digital words.<br>19. A decoding method for the recovery of digital information from a coded signal, said digital information representing analog audio signals, comprising reconstructing with a fixed number of bits one or more digital words corresponding to at least the lowest frequency spectral component of said analog audio signals, and reconstructing one or more digital words with a fixed number of bits and an adaptive number of bits, and generating signal sample blocks in response to said digital words.</p></layer>
<layer id = "layer335"><p><b>US5077798A:Method and system for voice coding based on vector quantization</b><br>A germicide sleeve for dental and medical instruments comprising a flexible non-permeable outer sleeve wall of plastic or the like, the sleeve being closed at one end, the inner wall lined with a compressible absorbent material such as foam rubber surrounding an elongated central cavity or bore which extends the length of the sleeve and opens at an open end thereof to receive the working portion of a dental or medical instrument therein, the absorbent material being impregnated with a germicide solution to disinfect the instrument while stored therein, the compressible absorbent material which completely surrounds the central bore or cavity also serving as a protective cushion for the instrument stored therein while awaiting use. The germicide sleeve is disposable after its first use, and the instrument may be placed in a new germicide sleeve after each use of the instrument. The open end of the germicide sleeve is covered by a breakable seal prior to use. The germicide solution may be injected into the sleeve to impregnate the absorbent material after the seal has been broken and just prior to placing a dental or medical instrument therein. In this way, the full active life of the germicide is available for disinfection of the instrument while stored therein, and a germicide injector having an elongated nozzle with spaced apart openings along its side wall for insertion into the central bore of the sleeve to impregnate the absorbent material is part of this invention.<br><b>Independant Claims</b><br>1. A system for voice coding based on vector quantization comprising: (a) means in which a distribution area of parameters representative of a voice is divided into a plurality of domains so that one vector (code vector) having elements represented by values of said parameters may correspond to one domain; (b) means for representing individual code vectors by codes specific thereto; (c) means for registering as neighboring vectors code vectors in a plurality of domains which are close, in terms of vector space distance, to each code vector; (d) means for storing said code vectors, codes and said codes of said neighboring vectors; (e) means for converting an input voice into a vector having elements represented by values of said parameters; (f) means for determining the distance between the converted input voice vector and each of said code vectors in said domains by reading out said neighboring vectors from said means for storing and calculating distances between each of said neighboring vectors and said converted input voice vector; (g) means for determining a code vector having a minimum value of distance to be a nearest vector and selecting a code representing said nearest vector from said stored codes for transmitting; (h) means for determining membership functions by numerically expressing the distance between said input voice vector and each of neighboring vectors registered in association with said selected code; and (i) means for transmitting, as vector quantization information, said numerically expressed membership functions and selected code.<br>10. A system for voice coding based on vector quantization comprising: (a) means in which a distribution area of first parameters representative of a voice is divided into a plurality of domains so that one vector (first code vector) having elements represented by values of said first parameters may correspond to one domain: (b) means for representing individual first code vectors by first codes specific thereto; (c) means for registering as neighboring vectors code vectors in a plurality of domains which are close, in terms of vector space distance, to each code vector; (d) first storage means for storing said first code vectors, said first codes and codes of said neighboring vectors; (e) means for converting an input voice into a vector having elements represented by values of said first parameters; (f) means for determining the distance between the converted input voice vector and each of said first code vectors in said domains by reading out said neighboring vectors from said first storage means and calculating distances between each of said neighboring vectors and said converted input voice vector; (g) means for determining a first code vector having a minimum value of distance to be a nearest vector and selecting a first code representing said nearest vector from said stored codes; (h) vector inverse quantization means for determining, from said selected first code, a reconstructed vector which approximates said input voice vector; (i) means for determining a quantization distortion representing a difference between said input voice vector and said reconstructed vector; (j) means in which a distribution area of second parameters representative of said quantization distortion is divided into a plurality of domains so that one vector having elements represented by values of said second parameters may correspond to one domain; (k) means for representing individual second code vectors by second codes specific thereto; (l) means for registering as second neighboring vectors second code vectors in a plurality of domains which are close, in terms of vector space distance, to each second code vector; (m) second storage means for storing said second code vectors, second codes and said codes for said second neighboring vectors; (n) means for converting said quantization distortion into a second vector having elements represented by values of said second parameters; (o) means for determining the distance between the quantization distortion vector and each of said second code vectors in said domains by reading out said second neighboring vectors from said second storage means and calculating distances between each of said second neighboring vectors and said quantization distortion vector; (p) means for determining a second code vector having a minimum value of distance to be a nearest vector and selecting a second code representing said nearest vector from said stored second codes; (q) means for determining membership functions by numerically expressing the distance between said quantization distortion vector and each of second neighboring vectors registered in association with said selected second code vector; and (r) means for delivering, as vector quantization information for said input voice, said numerically expressed membership functions and selected second and first codes.<br>11. A system for voice coding based on vector quantization comprising: (a) means in which a distribution area of parameters representative of a voice is divided into a plurality of domains so that one vector (code vector) having elements represented by values of said parameters may correspond to one domain; (b) means for representing individual code vectors by codes specific thereto; (c) means for storing said code vectors and said codes; (d) means for converting an input voice into a vector having elements represented by values of said parameters; (e) means for retrieving said storage means to select code vectors as candidate vectors for vector quantization on the basis of distances between a plurality of said code vectors and said converted input voice vector; (f) means for effecting fuzzy vector quantization of said input voice vector after each time when the candidate vectors are sequentially added one by one to a candidate vector having a minimum distance; (g) means for comparing a quantization distortion occurring before sequential addition of candidate vectors with that occurring after said sequential addition; (h) means responsive to a result of a comparison to decide in accordance with an increase or decrease in said quantization distortion whether the added candidate vectors would be used for the fuzzy vector quantization; (i) means for selecting a code of said candidate vector having information of highest similarity; (j) means for determining membership functions by numerically expressing the distance between said input voice vector and each of candidate vectors used for said fuzzy vector quantization; and (k) means for transmitting, as vector quantization information, said numerically expressed membership functions and selected code.<br>19. A system for voice coding based on vector quantization comprising: (a) means in which a distribution area of parameters representative of a voice is divided into a plurality of domains so that one vector (code vector) having elements represented by values of said parameters may correspond to one domain; (b) means for representing individual code vectors by code as specific thereto; (c) means for registering as neighboring vector code vectors in a plurality of domains which are close, in terms of vector space distance, to each code vector; (d) means for storing said code vectors, codes and said codes of said neighboring vectors; (e) means for converting an input voice into a vector having elements represented by values of said parameters; (f) means for determining the distance between the converted input voice vector and each of said code vectors in said domains by reading out said neighboring vectors from said means for storing and calculating distances between each of said neighboring vectors and said converted input voice vector; (g) means for determining a nearest vector having a minimum value of distance; (h) means for selecting, from said neighboring vector registered in association with said nearest vector, candidate vectors which are combined with said nearest vector to approximate said input voice vector; (i) means for determining a synthesis vector which approximates said input voice vector and which takes the form of a linear combination of said nearest vector and candidate vectors; (j) means for determining a coefficient of the linear combination through weighing by which the quantization distortion is minimized; and (k) means for transmitting, as vector quantization information, said coefficient of linear combination, said candidate vectors, said codes and said code of said nearest vector.<br>22. A system for voice decoding based on vector quantization comprising: (a) means for storing a table having code vectors, codes of said code vectors and codes of neighboring vectors registered in association with said code vectors, the contents of said table corresponding to the contents of a second table in a transmitting station; and (b) fuzzy vector inverse quantization means for determining a reconstructed vector representing an input voice through interpolation on the basis of codes of one or a plurality of received code vectors which are used for vector quantization, said determining operation being performed by use of received membership functions and said stored table, said received code vectors and said received membership functions being received by a receiver from said transmitting station.<br>23. A system for voice decoding based on vector quantization comprising: (a) first storage means for storing a table having code vectors, codes of said code vector and codes of neighboring vectors registered in association with said code vectors, the contents of said table corresponding to the contents of a second table in a transmitting station; (b) second storage means for storing a reconstructed vector representing an input voice produced through interpolation on the basis of codes of one or a plurality of received code vectors used for vector quantization, received membership functions and said stored table, said received code vectors and said received membership functions being received by a receiver from said transmitting station; (c) means for reading a reconstructed vector resulting from reconstruction of a preceding input voice vector form said second storage means when a signal is received; and (d) fuzzy vector inverse quantization means for determining a reconstructed vector of a currently received input voice vector through interpolation on the basis of a code of received code vectors, received membership functions, said stored table and said read-out reconstructed vector, said received code vectors and said received membership functions being received by said receiver from said transmitting station.<br>24. A system for voice decoding based on vector quantization comprising: (a) means for storing a table in which code vectors, codes of said code vector and said codes of neighboring vectors registered in association with said code vectors are contained which are the same as those used for vector quantization in the transmitting station; and (b) fuzzy vector inverse quantization means for determining a reconstructed vector representing an input voice pursuant to i=wu+(1-w)v where w: coefficient y: reconstructed vector input vector x.sub.i ={x.sub.1, x.sub.2, . . . , x.sub.l } nearest vector u.sub.i ={u.sub.1, u.sub.2, . . . , u.sub.l } candidate vectors used for approximation v.sub.i ={v.sub.1, v.sub.2, . . . , v.sub.l } said nearest vector .mu..sub.i has the minimum distance to said input vector X.sub.i, said candidate vectors V.sub.i correspond to some of said neighboring vectors On the basis of codes of a plurality of received code vectors used for the vector quantization, a received coefficient value used for vector approximation in the form of a linear combination, said received coefficient value being received by a receiver from a transmitting station, and said stored table, said received code vectors being received by said receiver from said transmitting station.<br>25. A voice communication system based on vector quantization comprising: a voice encoding system including (a) means in which a distribution area of parameters representative of a voice is divided into a plurality of domains so that one vector (code vector) having elements represented by values of said parameters may correspond to one domain, (b) means for representing individual code vectors by codes specific thereto, (c) means for registering as neighboring vectors code vectors in a plurality of domains which are close, in terms of vector space distance, to each code vector, (d) means for storing said code vectors, codes and said codes of said neighboring vectors, (e) means for converting an input voice into a vector having elements represented by values of said parameters, (f) means for determining the distance between the converted input voice vector and each of said code vectors in said domains by reading out said neighboring vectors from said means for storing and calculating distances between each of said neighboring vectors and said converted input voice vector, (g) means for determining a code vector having a minimum value of distance to be a nearest vector and selecting a code representing said nearest vector from said stored codes for transmitting, (h) means for determining membership functions by numerically expressing the distance between said input voice vector and each of neighboring vectors registered in association with said selected code, and (i) means for transmitting, as vector quantization information, said numerically expressed membership functions and selected code; and a voice decoding system including (j) means for storing a table in which code vectors, codes of said code vectors and said codes of neighboring vectors registered in association with said code vectors, the contents of said table corresponding to the contents of a second table in a transmitting station, and (k) fuzzy vector inverse quantization means for determining a reconstructed vector representing an input voice through interpolation on the basis of codes of one or a plurality of received code vectors which are used for vector quantization, said determining operation being performed by use of received membership functions and said stored table, said received code vectors and said received membership functions being received by a receiver from said transmitting station.<br>26. A voice communication system based on vector quantization comprising: a voice encoding system including (a) means in which a distribution area of first parameters representative of a voice is divided into a plurality of domains so that one vector (first code vector) having elements represented by values of said first parameters may correspond to one domain, (b) means for representing individual first code vectors by first codes specific thereto, (c) means for registering as neighboring vectors code vectors in a plurality of domains which are close, in terms of vector space distance, to each other, (d) first storage means for storing said first code vectors, said first codes and code of said neighboring vectors, (e) means for converting an input voice into a vector having elements represented by values of said first parameters, (f) means for determining the distance between the converted input voice vector and each of said first code vectors in said domains by reading out said neighboring vectors from said first storage means and calculating distances between each of said neighboring vectors and said converted input voice vector; (g) means for determining a first code vector having a minimum value of distance to be a nearest vector and selecting a first code representing said nearest vector from said stored codes; (h) vector inverse quantization means for determining, from said selected first code, a reconstructed vector which approximates said input voice vector, (i) means for determining a quantization distortion representing a difference between said input voice vector and said reconstructed vector, (j) means in which a distribution area of second parameters representative of said quantization distortion is divided into a plurality of domains so that one vector (second code vector) having elements represented by values of said second parameters may correspond to one domain, (k) means for representing individual second code vectors by second codes specific thereto, (l) means for registering as second neighboring vectors second code vectors in a plurality of domains which are close, in terms of vector space distance, to each second code vector, (m) second storage means for storing said second code vectors, second codes and said codes of said second neighboring vectors, (n) means for converting said quantization distortion into a second vector having elements represented by values of said second parameters, (o) means for determining the distance between the quantization distortion vector and each of said second code vectors in said domains by reading out said second neighboring vectors from said second storage means and calculating distances between each of said second neighboring vectors and said quantization distortion vector, (p) means for determining a second code vector having a minimum value of distance to be a nearest vector and selecting a second code representing said nearest vector from said stored second codes, (q) means for determining membership functions by numerically expressing the distance between said quantization distortion vector and each of second neighboring vectors registered in association with said selected second code vector, and (r) means for delivering, as vector quantization information for said input voice, said numerically expressed membership functions and selected second and first codes; and a voice decoding system including (s) means for storing a table in which code vectors, codes of said code vectors and said codes of neighboring vectors registered in association with said code vectors, the contents of said table corresponding to the contents of a second table in a transmitting station; and (t) fuzzy vector inverse quantization means for determining a reconstructed vector representing an input voice through interpolation on the basis of codes of one or a plurality of received code vectors which are used for vector quantization, said determining operation being performed by use of received membership functions and said stored table, said received code vectors and said received membership functions being received by a receiver from said transmitting station.<br>27. A voice communication system based on vector quantization comprising: a voice encoding system including a voice encoding system including (a) means in which a distribution area of parameters representative of a voice is divided into a plurality of domains so that one vector (code vector) having elements represented by values of said parameters may correspond to one domain, (b) means for representing individual code vectors by codes specific thereto, (c) means for storing said code vectors and said codes, (d) means for converting an input voice into a vector having elements represented by values of said parameters, (e) means for retrieving said storage means to select code vectors as candidate vectors for vector quantization on the basis of distances between a plurality of said code vectors and said converted input voice vector, (f) means for effecting fuzzy vector quantization of said input voice vector after each time when other candidate vectors are sequentially added one by one to a candidate vector having a minimum distance, (g) means for comparing a quantization distortion occurring before sequential addition of candidate vectors with that occurring after said sequential addition, (h) means responsive to a result of a comparison to decide in accordance with an increase or decrease in said quantization distortion whether the added candidate vectors would be used for the fuzzy vector quantization, (i) means for selecting a code of said candidate vector having information of highest, similarity, (j) means for determining membership functions by numerically expressing the distance between said input voice vector and each of candidate vectors used for said fuzzy vector quantization, and (k) means for transmitting, as vector quantization information, said numerically expressed membership functions and selected code; and a voice decoding system including (l) means for storing a table in which code vectors, codes of said code vectors and said codes of neighboring vectors registered in association with said code vectors, the contents of said table corresponding to the contents of a second table in a transmitting station; and (m) fuzzy vector inverse quantization means for determining a reconstructed vector representing an input voice through interpolation on the basis of codes of one or a plurality of received code vectors which are used for vector quantization, said determining operation being performed by use of received membership functions and said stored table, said received code vectors and said received membership functions being received by a receiver from said transmitting station.<br>28. A voice communication system based on vector quantization comprising: a voice encoding system including (a) means in which a distribution area of parameters representative of a voice is divided into a plurality of domains so that one vector (code vector) having elements represented by values of said parameters may correspond to one domain, (b) means for representing individual code vectors by codes specific thereto, (c) means for storing said code vectors and said codes, (d) means for converting an input voice into a vector having elements represented by values of said parameters, (e) means for retrieving said storage means to select code vectors as candidate vectors for vector quantization on the basis of distances between a plurality of said code vectors and said converted input voice vector, (f) means for effecting fuzzy vector quantization of said input voice vector after each time when other candidate vectors are sequentially added one by one to a candidate vector having a minimum distance, (g) means for comparing a quantization distortion occurring before sequential addition of candidate vectors with that occurring after said sequential addition, (h) means responsive to a result of a comparison to decide in accordance with an increase or decrease in said quantization distortion whether the added candidate vectors would be used for the fuzzy vector quantization, (i) means for selecting a code of said candidate vector having information of highest, similarity, (j) means for determining membership functions by numerically expressing the distance between said input voice vector and each of candidate vectors used for said fuzzy vector quantization, and (k) means for transmitting, as vector quantization information, said numerically expressed membership functions and selected code; and wherein said transmitting means includes (l) inverse quantization means for determining a reconstructed vector from said vector quantization information through interpolation, (m) means for determining the difference between said reconstructed vector and said input vector, and (n) means for fetching the stored reconstructed vector as one of said code vectors; and a voice decoding system including (o) first storage means for storing a table having code vectors, codes of said code vector and codes of neighboring vectors registered in association with said code vectors, the contents of said table corresponding to the contents of a second table in a transmitting station, (p) second storage means for storing a reconstructed vector representing an input voice produced through interpolation on the basis of codes of one or a plurality of received code vectors used for vector quantization, received membership functions and said stored table, said received code vectors and said received membership functions being received by a receiver from said transmitting station, (q) means for reading a reconstructed vector resulting from reconstruction of a preceding input voice vector from said second storage means when a signal is received, and (r) fuzzy vector inverse quantization means for determining a reconstructed vector of a currently received input voice vector through interpolation on the basis of a code of received code vectors, received membership functions, said stored table and said read-out reconstructed vector, said received code vector and said received membership functions being received by said receiver from said transmitting station.<br>29. A voice communication system based on vector quantization comprising: a voice encoding system including (a) means in which a distribution area of parameters representative of a voice is divided in to a plurality o domains so that one vector (code vector) having elements represented by values of said parameters may correspond to one domain, (b) means for representing individual code vectors by code as specific thereto, (c) means for registering as neighboring vector code vector in a plurality of domains which are close, in terms of vector space distance, to each code vector, (d) means for storing said code vectors, codes and said codes of said neighboring vectors, (e) means for converting an input voice into a vector having elements represented by values of said parameters, (f) means for determining the distance between the converted input voice vector and each of said code vectors in said domains by retrieving and storage means, (g) means for determining a nearest vector having a minimum value of distance, (h) means for selecting, from said neighboring vector registered in association with said nearest vector, candidate vectors which are combined with said nearest vector to approximate said input voice vector, (i) means for determining a synthesis vector which approximates said input voice vector and which takes the form of a linear combination of said nearest vector and candidate vectors, (j) means for determining a coefficient of the linear combination through weighing by which the quantization distortion is minimized, and (k) means for transmitting, as vector quantization information, said coefficient of linear combination, said candidate vectors, said codes and said code of said nearest vector; wherein said means for determining a synthesis vector includes means for determining the synthesis vector which is positioned on a straight line connecting said nearest vector and one of said candidate vectors, and said coefficient determining means determines the coefficient pursuant to ##EQU8## where l=0, 1, . . . , N N+1: the number of code vectors .parallel.lk: membership function d[i].sub.j.kappa. : the distance between input vector and code vector .alpha.: weighting coefficient; and voice decoding system including (l) means for storing a table in which code vectors, codes of said code vector and said codes of neighboring vectors registered in association with said code vectors are contained which are the same as those used for vector quantization in the transmitting station, and (m) fuzzy vector inverse quantization means for determining a reconstructed vector representing an input voice ##EQU9## where w: coefficient input vector X.sub.i -{x.sub.1, x.sub.2, . . . , x.sub.l } nearest vector u.sub.i ={u.sub.1, u.sub.2, . . . , u.sub.l } candidate vector used for approximation v.sub.1 ={v.sub.1, v.sub.2, . . . , v.sub.l }; said nearest vector u.sub.i has the minimum distance to said input vector X.sub.i, said candidate vectors V.sub.i correspond to some of said neighboring vectors on the basis of codes of a plurality of received code vectors used for the vector quantization, a received coefficient value used for vector approximation in the form of a linear combination, said received coefficient value being received by a receiver from a transmitting station, and said stored table, said received code vectors being received by said receiver from said transmitting station.<br>30. A method for voice coding based on vector quantization comprising the steps of: (a) dividing a distributed area of parameters representative of a voice into a plurality of domains making one vector (code vector) having elements represented by values of said parameters correspond to one domain, and storing code vectors; (b) storing codes assigned to said code vectors; (c) converting an input voice into a vector having elements represented by values of said parameters; (d) determining a code vector having a minimum value of distance from said input voice vector to be a nearest vector and selecting a code representing said nearest vector from said store codes for transmitting; (e) selecting a predetermined number of code vectors neighboring said nearest vector as candidate vectors for approximation of said input voice vector; (f) determining membership functions by numerically expressing the distance between said input voice vector and each of said selected code vectors and the distance between said input voice vector and said nearest vector, in accordance with ##EQU10## where l=0, 1 . . . , N .mu.l k: membership function d[i].sub.l.kappa. : the distance between input vector and code vector .alpha.: weighting coefficient; and (g) transmitting and numerically expressed membership functions and said selected code as vector quantization information.<br>33. A method for voice coding based on vector quantization comprising the steps of: (a) devising a distribution area of parameters representative of a voice into a plurality of domains, making one vector (code vector) having elements represented by values of said parameters correspond to one domain, and storing code vectors; (b) storing codes assigned to said code vectors; (c) converting an input voice into a vector having elements represented by values of said parameters; (d) determining a code vector having a minimum value of distance from said input voice vector to be a nearest vector and selecting a code representing said nearest vector from said stored codes for transmitting; (e) selecting a predetermined number of code vector neighboring said nearest at vector as candidate vectors for approximation of said input voice vector; (f) determining a synthesis vector which approximates said input voice vector and which takes the form of a linear combination of said nearest vector and candidate vectors; (g) determining a coefficient of the linear combination through weighing by which the quantization distortion is minimized; and (h) transmitting, as vector quantization information, said coefficient of linear combination, said codes of said candidate vectors and said selected code of said nearest vector.</p></layer>
<layer id = "layer336"><p><b>US6167375A:Method for encoding and decoding a speech signal including background noise</b><br>A container made from a synthetic resin, in particular, polyethylene terephthlate. The resin, after having been dried, is first injection molded into a preform like a test tube, and then softened by heating, and finally the required container is made by using the blow drawing technique in combination with a mold designed according the present invention for integrally blow molding containers having a radial base reinforcement structure. Said base reinforcement structure of the container comprises radially arranged enlarged feet, webs, and ribs, and a hub. In such a design, the hub extends outwardly into a radial configuration, with the enlarged feet supporting the weight of the bottle body, the portions between the feet serving as the webs, the feet and the webs being arranged alternately-relative to each other in the shape of a ring; the ribs engaging the front edges of the webs and recessed relative to the enlarged feet and extending smoothly to become the wall of the bottle, and arranged alternately relative to the enlarged feet also in the shape of a ring. In addition to providing good stability for the container to stand upright, the radial base reinforcement structure enhances the capability of withstanding the internal pressure and the impacts of external forces, thus preventing deformation and breakage of the bottle. Therefore, the container of the present invention is particularly suitable for use as bottles for carbonated beverages or as containers where reinforcement of the base structure is required.<br><b>Independant Claims</b><br>1. A method for encoding speech comprising the steps of: separating an input speech signal into a first component and a second component at each unit of time, the first component being mainly constituted by a speech signal and the second component being mainly constituted by a background noise signal which varies in spectrum more slowly than that of the speech signal; selecting a number of bits to be allocated for each of said first and second components from among a plurality of bit allocation candidates in accordance with feature parameters of the speech signal and the background noise signal; encoding said first and second components in accordance with the selected bit allocation using different encoding methods suitable for the first and second components, respectively; and outputting encoded data of said first and second components and information on said bit allocation as transmitted encoded data.<br>11. A method of decoding speech comprising the steps of: separating from transmitted input data information on bit allocation regarding each of first and second encoded data of first and second components, the first encoded data of the first component, and the second encoded data of the second component, wherein the first component is mainly constituted by a speech signal and the second component is mainly constituted by a background noise signal which varies in spectrum more slowly than that of the speech signal; decoding said information on bit allocation to obtain bit allocation regarding the first and second encoded data of said first and second components; decoding the first and second encoded data of said first and second components in accordance with the bit allocation to reproduce said first and second components and to obtain reproduced first and second components; and adding the reproduced first and second components to generate a final output speech signal.<br>12. A speech encoding apparatus comprising: means for separating an input speech signal into a first component and a second component at each unit of time, the first component being mainly constituted by a speech signal and the second component being mainly constituted by a background noise signal which varies in spectrum more slowly than that of the speech signal; means for selecting a number of bits to be allocated for each of said first and second components from among a plurality of bit allocation candidates in accordance with feature parameters of the speech signal and the background noise signal; means for encoding said first and second components in accordance with the bit allocation, using different encoding methods for the first and second components, respectively; and means for outputting encoded data of said first and second components and information on said bit allocation as transmitted encoded data.<br>22. A speech decoding apparatus comprising: means for separating from transmitted input data information on bit allocation regarding each of first and second encoded data of first and second components, the first encoded data of the first component, and the second encoded data of the second component, wherein the first component is mainly constituted by a speech signal and the second component is mainly constituted by a background noise signal which varies in spectrum more slowly than that of the speech signal; means for decoding said information on bit allocation to obtain bit allocation regarding the first and second encoded data of said first and second components; means for decoding the first and second encoded data of said first and second components in accordance with the bit allocation to reproduce said first and second components and to obtain reproduced first and second components; and means for adding the reproduced first and second components to generate a final output speech signal.<br>23. A speech encoding apparatus comprising: a component separator configured to separate an input speech signal into a first component and a second component at each unit of time, the first component being mainly constituted by a speech signal and the second component being mainly constituted by a background noise signal which varies in spectrum more slowly than that of the speech signal; a bit allocation selector configured to select a number of bits to be allocated for each of said first and second components from among a plurality of bit allocation candidates in accordance with feature parameters of the speech signal and the background noise signal; an encoder configured to encode said first and second components in accordance with the bit allocation, using different encoding methods for the first and second components, respectively; and a multiplexer configured to output encoded data of said first and second components and information on said bit allocation as transmitted encoded data.<br>24. A speech decoding apparatus comprising: a component separator configured to separate from transmitted input data information on bit allocation regarding each of first and second encoded data of first and second components, the first encoded data of the first component, and the second encoded data of the second component, wherein the first component is mainly constituted by a speech signal and the second component is mainly constituted by a background noise signal which varies in spectrum more slowly than that of the speech signal; a first decoder configured to decode said information on bit allocation to obtain bit allocation regarding the first and second encoded data of said first and second components; a second decoder configured to decode the first and second encoded data of said first and second components in accordance with the bit allocation to reproduce said first and second components and to obtain reproduced first and second components; and a mixer configured to add the reproduced first and second components to generate a final output speech signal.</p></layer>
<layer id = "layer337"><p><b>US5774846A:Speech coding apparatus, linear prediction coefficient analyzing apparatus and noise reducing apparatus</b><br>Graft copolymers and processes for the preparation thereof are provided. The copolymers comprise a base polymer having grafted thereto a monomeric 2-alkenyl azlactone. The surface properties of the graft copolymers can be modified by binding thereto nucleophilic reagents comprising further functional groups with desired properties. Further, the amount of azlactone available at the surface of a graft copolymer for binding to such nucleophilic reagents can be controlled by selecting a surface against which the graft copolymer is formed. The graft copolymers exhibit desirable thermoplastic, melt flow, and adhesion properties and are particularly useful for immobilizing proteins. Methods of immunoassay based on the immobilization of proteins are also disclosed. Another utility of the graft copolymers involves the compatibilizing of immiscible polymer blends.<br><b>Independant Claims</b><br>1. A speech coding apparatus, comprising: coding module storing means for storing a plurality of coding modules; speech analyzing means for analyzing a sample speech signal to obtain a plurality of sample characteristic parameters indicating sample speech characteristics of the sample speech signal, calculating a coding distortion from the sample characteristic parameters in each of the coding modules stored in the coding module storing means and analyzing a speech signal to obtain a plurality of characteristic parameters indicating speech characteristics of the speech signal; statistic processing means for statistically processing the sample characteristic parameters and the coding distortions obtained by the speech analyzing means to obtain a coding module selecting rule; coding module selecting means for selecting one of the coding modules stored in the coding module storing means as an appropriate coding module, in which a coding distortion for the characteristic parameters obtained by the speech analyzing means is minimized, according to the coding module selecting rule obtained by the statistic processing means; and coding means for coding the speech signal obtained by the speech analyzing means in the appropriate coding module selected by the coding module selecting means.</p></layer>
<layer id = "layer338"><p><b>US20020052738A1:Wideband speech coding system and method</b><br>The invention relates to a prosthesis comprising first and second prosthesis parts connected for mutual movement which are characterized by a locking element for locking respectively releasing the prosthesis parts relative to each other. The parts are preferably connected for mutual movement by an artificial joint comprising a first and a second joint part. The locking element is spring biased and co-acts in a locked position with a recess in one of the joint parts, whereby tilting of the locking element is bounded, and which in the released position is substantially freely tiltable. The prosthesis can be further provided with a pin for actively placing the locking element out of the active reach of the recess. One of the two prosthesis parts connected for mutual movement is formed with a cup so that the prosthesis can be fixed to the remaining part of an amputated extremity. Opposite the cup are a brace, a perforated band, a tape and an eye which are utilized for fixing the prosthesis part to a higher located part of the remaining part of the amputated extremity. The other of the two prosthesis parts is formed by a device for replacing at least a part of the amputated extremity and is preferably provided with damping material.<br><b>Independant Claims</b><br>1. A method of wideband speech decoding, comprising: (a) decoding a first portion of an input signal as a lowband speech signal; (b) decoding a second portion of an input signal as a noise-modulated excitation of a linear prediction encoding wherein said noise modulated excitation is noise modulated by a portion of the results of said decoding as a lowband speech signal of preceding step (a) and adaptively smoothed; and (c) combining the results of foregoing steps (a) and (b) to form a decoded wideband speech signal.<br>2. A wideband speech decoder, comprising: (a) a first speech decoder with an input for encoded narrowband speech; (b) a second speech decoder with an input for encoded highband speech and an input for the output of said first speech decoder, said second speech decoder using excitation of noise modulated by a portion of the output of said first speech decoder and adaptively smoothed; and (c) a combiner for the outputs of said first and second speech decoders to output decoded wideband speech.</p></layer>
<layer id = "layer339"><p><b>US5359696A:Digital speech coder having improved sub-sample resolution long-term predictor</b><br>A welding device comprising a body having a cylindrical portion and an integral gripping portion extending away from the cylindrical portion. A welding head is provided at one end of the cylindrical portion. The welding head is angularly displaceable relative to the cylindrical portion about the longitudinal axis of the cylindrical portion and supports an ultrasonic transducer and an anvil co-operable with the transducer. The transducer and anvil are relatively movable towards one another to pinch an object to be welded therebetween. A pulling device operable by a trigger is provided for pulling the transducer and the anvil towards one another and a battery pack is releasably attached to the gripping portion.<br><b>Independant Claims</b><br>1. A method of reconstructing speech comprising the steps of: receiving from a communication channel a set of speech parameters including codeword I and a delay parameter L, where L may have a value in a predetermined range including integer and non-integer values related to a speech pitch period; generating an excitation vector having a plurality of samples in response to the codeword I; filtering the excitation vector based on at least the delay parameter L and stored filter state samples, the step of filtering comprising the steps of: computing interpolated filter state samples from the stored filtered state samples using a non-integer L to determine the appropriate interpolation parameters, and combining the excitation vector with the interpolated filter state samples, thereby forming a filter output vector having a plurality of filter output samples; and processing the filter output vector to produce reconstructed speech.<br>5. Apparatus for reconstructing speech comprising: receiving circuitry for receiving from a communication channel a set of speech parameters including codeword I and a delay parameter L, where L may have a value in a predetermined range including integer and non-integer values related to a speech pitch period; generating circuitry for generating an excitation vector having a plurality of samples in response to the codeword I; filtering circuitry for filtering the excitation vector based on at least the delay parameter L and stored filter state samples, the filtering circuitry comprising: computing circuitry for computing interpolated filter state samples from the stored filtered state samples using a non-integer L to determine the appropriate interpolation parameters, and combining circuitry for combining the excitation vector with the interpolated filter state samples, thereby forming a filter output vector having a plurality of filter output samples; and processing circuitry for processing the filter output vector to produce reconstructed speech.<br>9. A method of reconstructing speech comprising the steps of: receiving from a communication channel a set of speech parameters including codeword I and a delay parameter L, where L may have a value in a predetermined range including integer and non-integer value related to a speech pitch period; generating an excitation vector having a plurality of samples in response to the codeword I; filtering the excitation vector based on at least the delay parameter L, a set of stored filter state samples and at least one set of stored interpolated filter state samples, the step of filtering comprises the steps of: choosing a chosen set of filter state samples from the group consisting of the set of stored filter state samples and the at least one set of stored interpolated filter state samples, the step of choosing using at least the delay parameter L, and combining the excitation vector with the chosen filter state samples, thereby forming a filter output vector having a plurality of filter output samples; and processing the filter output vector to produce reconstructed speech.<br>11. Apparatus for reconstructing speech comprising: receiving circuitry for receiving from a communication channel a set of speech parameters including codeword I and a delay parameter L, where L may have a value in a predetermined range including integer and non-integer values related to a speech pitch period; generating circuitry for generating an excitation vector having a plurality of samples in response to the codeword I; filtering circuitry for filtering the excitation vector based on at least the delay parameter L, a set of stored filter state samples and at least one set of stored interpolated filter state samples, the filtering circuitry comprising: choosing circuitry for choosing a chosen set of filter state samples from the group consisting of the set of stored filter state samples and the at least one set of stored interpolated filter state samples, the step of choosing using at least the delay parameter L, and combining circuitry for combining the excitation vector with the chosen filter state samples, thereby forming a filter output vector having a plurality of filter output samples; and processing circuitry for processing the filter output vector to produce reconstructed speech.<br>13. A method of encoding speech into sets of speech parameters for transmission on a communication channel, each set of speech parameters, the method comprising the steps of: sampling a voice signal plurality of times to provide a plurality of samples forming a present speech vector; generating a delay parameter L having a value in a predetermine range including integer and non-integer values related to a speech pitch period of the present speech vector; searching excitation vectors to determine a codeword I that best matches the present speech vector, the step of searching comprising the steps of: generating excitation vectors in response to corresponding codewords; filtering each excitation vector comprising the steps of; computing interpolated filter state samples from the stored filtered state samples using a non-integer L to determine the appropriate interpolation parameters, and combining the excitation vector with the interpolated filter state samples, thereby forming a filter output vector having a plurality of filter output samples; processing the filter output vector to produce a reconstructed speech vector; comparing the reconstructed speech vector to the present speech vector to determine the difference therebetween; and selecting the codeword I of the excitation vector for which the reconstructed speech vector differs the least from the present speech vector; and transmitting the selected codeword I and delay parameter L together with preselected speech parameters for the present speech vector on the communications channel, such that the speech pitch periods are more accurately predicted.<br>14. Apparatus for encoding speech into sets of speech parameters for transmission on a communication channel, each set of speech parameters, the apparatus comprising: sampling circuitry for sampling a voice signal a plurality of times to provide a plurality of samples forming a present speech vector; generating circuitry for generating a delay parameter L having a value in a predetermine range including integer and non-integer values related to a speech pitch period of the present speech vector; searching circuitry for searching excitation vectors to determine a codeword I that best matches the present speech vector, the searching circuitry comprising: generating circuitry for generating excitation vectors in response to corresponding codewords; filtering circuitry for filtering each excitation vector, the filtering circuitry comprising: computing circuitry for computing interpolated filter state samples from the stored filtered state samples using a non-integer L to determine the appropriate interpolation parameters, and combining circuitry for combining the excitation vector with the interpolated filter state samples, thereby forming a filter output vector having a plurality of filter output samples; processing circuitry for processing the filter output vector to produces a reconstructed speech vector; comparing circuitry for comparing the reconstructed speech vector to the present speech vector to determine the difference therebetween; and selecting circuitry for selecting the codeword I of the excitation vector for which the reconstructed speech vector differs the least from the present speech vector; and transmitting circuitry for transmitting the selected codeword I and delay parameter L together with pre-selected speech parameters for the present speech vector on the communications channel, such that the speech pitch periods are more accurately predicted.<br>15. A method of encoding speech into sets of speech parameters for transmission on a communication channel, each set of speech parameters, the method comprising the steps of: sampling a voice signal a plurality of times to provide a plurality of samples forming a present speech vector; generating a delay parameter L having a value in a predetermine range including integer and non-integer values relates to a speech pitch period of the present speech vector; searching excitation vectors to determine a codeword I that best matches the present speech vector, the step of searching comprising the steps of: generating excitation vectors in response to corresponding codewords; filtering each excitation vector based on at least the delay parameter L, a set of stored filter state samples and at least one set of stored interpolated filter state samples, the step of filtering comprising: choosing a chosen set of filter state samples from the group consisting of the set of stored filter state samples and the at least one set of stored interpolated filter state samples, the step of choosing using at least the delay parameter L, and combining the excitation vector with the chosen filter state samples, thereby forming a filter output vector having a plurality of filter output samples; processing the filter output vector to produce a reconstructed speech vector; comparing the reconstructed speech vector to the present speech vector to determine the difference therebetween; and selecting the codeword I of the excitation vector for which the reconstructed speech vector differs the least from the present speech vector; and transmitting the selected codeword I and delay parameter L together with preselected speech parameters for the present speech vector on the communications channel, such that the speech pitch periods are more accurately predicted.<br>16. Apparatus for encoding speech into sets of speech parameter for transmission on a communication channel, each set of speech parameters, the apparatus comprising: sampling circuitry for sampling a voice signal a plurality of times to provide a plurality of samples forming a present speech vector; generating circuitry for generating a delay parameter L having a value in a predetermine range including integer and non-integer values related to a speech pitch period of the present speech vector; searching circuitry for searching excitation vectors to determine a codeword I that best matches the present speech vector, the searching circuitry comprising: generating circuitry for generating excitation vectors in response to corresponding codewords; filtering circuitry for filtering each excitation vector based on at least the delay parameter L, a set of stored filter state samples and at least one set of stored interpolated filter state samples, the filtering circuitry comprising: choosing circuitry for choosing a chosen set of filter state samples from the group consisting of the set of stored filter state samples and the at least one set of stored interpolated filter state samples, the choosing circuitry using at least the delay parameter L, and combining circuitry for combining the excitation vector with the chosen filter state samples, thereby forming a filter output vector having a plurality of filter output samples; processing circuitry for processing the filter output vector to produce a reconstructed speech vector; comparing circuitry for comparing the reconstructed speech vector to the present speech vector to determine the difference therebetween; and selecting circuitry for selecting the codeword I of the excitation vector for which the reconstructed speech vector differs the least from the present speech vector; and transmitting circuitry for transmitting the selected codeword I and delay parameter L together with pre-selected speech parameters for the present speech vector on the communications channel, such that the speech pitch periods are more accurately predicted.</p></layer>
<layer id = "layer340"><p><b>US5261027A:Code excited linear prediction speech coding system</b><br>Formcoke is produced by introducing feedstocks of calcined coal particles, bituminous binder, an aqueous carbohydrate and phosphoric acid into a mixing zone. The resulting mixture is compacted into shapes, such as briquettes, which are then cured in an oxygen-containing atmosphere and optionally heated to coking temperatures.<br><b>Independant Claims</b><br>1. A method of encoding and transmitting an input speech signal by code excited linear prediction type encoding to provide a decodable signal, said method comprising the steps of: (a) providing a residual signal vector from a white noise code book, based on an error signal so as to reduce the error signal, (b) applying linear prediction to the white noise residual signal vector to obtain a code vector and a first coefficient, (c) applying linear prediction to a residual signal of a previous speech signal delayed by a pitch frequency to obtain a pitch prediction vector and a second coefficient, (d) providing an impulse residual signal vector having a predetermined relationship with the residual signal vector from the white noise code book, (e) applying linear prediction to the impulse residual signal vector provided in step (d) to obtain an impulse vector and a third coefficient, (f) applying variable gains to at least the code vector obtained by said step (b) and the impulse vector obtained by said step (e), (g) adding the code, pitch prediction and impulse vectors after applying the variable gains in step (f) to form a reproduced signal, (h) evaluating a difference between the reproduced signal formed by said step (g) and the input speech signal to provide the error signal for said step (a), and (i) transmitting a decodable signal based on at least the first, second and third coefficients.<br>13. An apparatus for encoding and transmitting an input speech signal, comprising: a pitch frequency delay circuit to delay a residual signal of a previous speech signal by a pitch frequency, a code book to store a plurality of white noise residual signal vectors, an impulse generating circuit to generate an impulse having a predetermined relationship with the white noise residual signal vectors stored in said code book, a linear prediction circuit operatively connected to said pitch frequency delay circuit, said code book, and said impulse generating circuit to output vectors and a coefficient, a variable gain circuit operatively connected to said linear prediction circuit to apply a variable gain to at least one of the output vectors of said linear prediction circuit, a first addition circuit operatively connected to said variable gain circuit to produce a reproduced composite vector, a second addition circuit operatively connected to said first addition circuit to add the reproduced composite vector and a vector of the input speech signal to output an error signal, an evaluating circuit operatively connected to said second addition circuit and said code book to identify a white noise residual signal vector stored in said code book in response to the error signal, and an output transmitter operatively connected to at least said linear prediction circuit to transmit a decodable signal based on at least the coefficient.<br>21. An apparatus for encoding and transmitting an input speech signal to provide a decodable signal, comprising: first code book means for storing first data and generating a white noise signal based on the stored first data and an index; second code book means for storing second data and generating an impulse signal based on the stored second data and the index; linear prediction means for applying linear prediction to the white noise and impulse signals and generating a coefficient; processing means for comparing the white noise and impulse signals with the input speech signal to provide an error signal; evaluating means for generating the index based on the error signal; and transmitting means for transmitting a decodable signal based on at least the coefficient.<br>29. An apparatus for encoding an input speech signal, comprising: code book means for storing white noise data and generating a white noise signal based on the stored white noise data and an index; impulse means for generating an impulse signal having a predetermined relationship with the white noise data stored in said code book means based on the index; linear prediction means for applying linear prediction to the white noise and impulse signals and generating a coefficient; processing means for comparing the white noise and impulse signals with the input speech signal to provide an error signal; evaluating means for generating the index based on the error signal; and transmitting means for transmitting a decodable signal based on at least the coefficient.<br>32. A method of encoding and transmitting an input speech signal to provide a decodable signal, comprising the steps of: (a) generating a first signal based on stored first data and an index; (b) generating a second signal based on stored second data and the index; (c) applying linear prediction to the first and second signals and generating third and fourth signals and a coefficient; (d) adding the third and fourth signals to generate a fifth signal; (e) comparing the fifth signal with the input speech signal to generate an error signal; (f) generating the index based on the error signal; and (g) transmitting a decodable signal based on at least the coefficient.<br>35. An apparatus for receiving and decoding a decodable signal to reproduce a speech signal, comprising: receiving means for receiving and demultiplexing the decodable signal to generate at least an index signal and a coefficient; first code book means for storing first data and generating a white noise signal based on the stored first data and the index signal from the receiving means; second code book means for storing second data and generating an impulse signal based on the stored second data and the index signal from the receiving means; linear prediction means for applying linear prediction to the white noise and impulse signals based on the coefficient from said receiving means to reproduce the speech signal.<br>36. An apparatus for receiving and decoding a decodable signal to reproduce a speech signal, comprising: receiving means for receiving and demultiplexing the decodable signal to generate at least an index signal, a coefficient and a phase signal; code book means for storing a plurality of white noise residual signal vectors and outputting a white noise residual signal vector based on the index signal from said receiving means; impulse generating means for generating an impulse signal having a predetermined relationship with the white noise residual signal vectors stored in said code book based on the phase signal from said receiving means; and linear prediction means for applying linear prediction to the white noise residual signal vectors and the impulse signal based on the coefficient from the receiving means to reproduce the speech signal.</p></layer>
<layer id = "layer341"><p><b>US6240386B1:Speech codec employing noise classification for noise compensation</b><br><b>Independant Claims</b><br>1. A speech codec using an analysis by synthesis approach on a speech signal having varying characteristics, the speech codec comprising: an encoder that generates speech parameters from the speech signal; a decoder, communicatively coupled to the encoder, that reproduces the speech signal from the speech parameters; at least one of the encoder and the decoder performs noise classification; and at least one of the encoder and the decoder utilizing the noise classification in performing noise compensation.<br>10. A speech codec using an analysis by synthesis approach on a speech signal having varying characteristics, the speech codec comprising: a processing circuit that selectively applies noise compensation upon identification of at least one of the varying characteristics of the speech signal to improve reproduction quality of the speech signal, the varying characteristics comprise characteristics indicative of at least one of noise, pulse-like speech, and noise-like speech; and a speech reproduction circuit, communicatively coupled to the processing circuit, that reproduces the speech signal.<br>18. A method used by a speech codec that applies an analysis by synthesis coding approach to a speech signal having varying characteristics, the method comprising: applying noise classification upon identification of at least one of the varying characteristics of the speech signal; applying noise compensation in response to the noise classification; and reproducing the speech signal after the compensation has been applied.</p></layer>
<layer id = "layer342"><p><b>US20030182104A1:Audio decoder with dynamic adjustment</b><br>A recording head is so designed that a plurality of nozzle openings for each of the nozzle opening arrays are arranged at intervals of at least four or more print-pitches in the sub-scanning direction, that the nozzle opening arrays are divided into at least two groups, that the nozzle opening arrays belonging to each of the groups are positioned along the same line in the main scanning direction, and that the groups are shifted away from each other at least two print-pitches in the sub-scanning direction. Dots of different groups do not contact each other during printing, and when printing for one scan line is completed, a recording medium is fed a number of print-pitches that corresponds to the nozzle opening count, so that a paper feeding distance error can be constant.<br><b>Independant Claims</b><br>1. A method of dynamically modifying a signal-modification profile at decoding to account for encoding noise, including: providing an auditory perception model; providing a multi-band audio signal-modification profile; receiving a stream of data representing an encoded audio signal, including encoding parameter data; estimating a signal spectrum of the stream of data; estimating encoding noise based on the encoding parameter data; and adjusting the audio signal-modification profile in one or more frequency bands based on the estimated signal spectrum, the estimated encoding noise and the auditory perception model.<br>17. A component device that dynamically modifies a signal-modification profile responsive to an auditory perception model, including: a processor having an input, the input receiving a stream of data representing an encoded audio signal, including encoding parameter data; logic operable on the processor to estimate a signal spectrum from the stream of data; estimate encoding noise based on the encoding parameter data; and adjust the audio signal-modification profile in one or more frequency bands based on the estimated signal spectrum, the estimated encoding noise and the auditory perception model.</p></layer>
<layer id = "layer343"><p><b>US20030187635A1:Method for modeling speech harmonic magnitudes</b><br>A process is disclosed for manufacturing thin-walled moldings with a ground layer (4) made of thermoplastic materials and a covering layer (5) made of prefabricated flat covering materials pressed together with the ground layer by a back pressing technique in a form tool (8) having a top die (6) and a bottom die (7). The object of the process is to produce thin-walled moldings having laminated and non-laminated areas in a simple manner, with no danger of damaging sensitive covering layer materials and with non-laminated areas having a high quality surface. For that purpose, during or after back pressure lamination, while or after the two dies are closed, besides at least one molding area (2) laminated with a covering layer by a back pressing technique, at least another area (3) of the molding is produced by injection molding thermoplastic material in the part of the molding cavity (17) in which the area of the molding which is not laminated with a covering layer (5) is produced.<br><b>Independant Claims</b><br>1. A method of modeling a signal comprising: a) identifying a plurality of harmonic frequencies; b) identifying a plurality of harmonic magnitudes corresponding to spectral magnitudes of the signal at the plurality of harmonic frequencies; c) interpolating the plurality of harmonic magnitudes to obtain a plurality of spectral magnitudes at a set of fixed frequencies; d) inverse transforming the plurality of spectral magnitudes to obtain a pseudo auto-correlation sequence; e) calculating linear prediction coefficients from the pseudo auto-correlation sequence; f) calculating model harmonic magnitudes by sampling a spectral envelope defined by the linear prediction coefficients; g) calculating a first set of scale factors as the ratio of the harmonic magnitudes to the model harmonic magnitudes; h) interpolating the first set of scale factors to obtain a second set of scale factors at the set of fixed frequencies; i) calculating model spectral magnitudes at the set of fixed frequencies by sampling the spectral envelope defined by the linear prediction coefficients at the set of fixed frequencies; j) multiplying the model spectral magnitudes at the set of fixed frequencies by the second set of scale factors to obtain a new plurality of spectral magnitudes; k) inverse transforming the new plurality of spectral magnitudes to obtain a new pseudo auto-correlation sequence; and l) calculating new linear prediction coefficients from the new pseudo auto-correlation sequence, wherein the signal is modeled by the new linear prediction coefficients.<br>19. A method of modeling a signal comprising: a) identifying a plurality of harmonic frequencies; b) identifying a plurality of harmonic magnitudes corresponding to spectral magnitudes of the signal at the plurality of harmonic frequencies; c) interpolating the plurality of harmonic magnitudes to obtain a plurality of spectral magnitudes at a set of fixed frequencies; d) calculating a modified plurality of spectral magnitudes at a set of fixed frequencies by applying a modifying function to the plurality of spectral magnitudes at a set of fixed frequencies; e) inverse transforming the modified plurality of spectral magnitudes to obtain a pseudo auto-correlation sequence; f) calculating linear prediction coefficients from the pseudo auto-correlation sequence; g) calculating model harmonic magnitudes by sampling a spectral envelope defined by the linear prediction coefficients and applying an inverse of the modifying function; h) calculating a first set of scale factors as the ratio of the harmonic magnitudes to the model harmonic magnitudes; i) interpolating the first set of scale factors to obtain a second set of scale factors at the set of fixed frequencies; j) calculating model spectral magnitudes at the set of fixed frequencies by sampling the spectral envelope defined by the linear prediction coefficients at the set of fixed frequencies; k) multiplying the model spectral magnitudes at the set of fixed frequencies by the second set of scale factors to obtain a new plurality of spectral magnitudes; l) inverse transforming the new plurality of spectral magnitudes to obtain a new pseudo auto-correlation sequence; and m) calculating new linear prediction coefficients from the new pseudo auto-correlation sequence, wherein the signal is modeled by the new linear prediction coefficients.<br>23. A system of modeling a signal, comprising: a) an input for receiving the signal; b) a harmonic analyzer operable to identify a plurality of harmonic magnitudes and a plurality of harmonic frequencies of the signal; c) a first interpolator, responsive to the plurality of harmonic magnitudes and operable to produce a first plurality of spectral magnitudes at a set of fixed frequencies; d) an inverse transformer, responsive to the first plurality of spectral magnitudes or to a next plurality of spectral magnitudes and operable to produce a pseudo auto-correlation sequence therefrom; e) a linear prediction analyzer, operable to calculate a set of linear prediction coefficients from the pseudo auto-correlation sequence; f) a first spectrum calculator, responsive to the set of linear prediction coefficients and operable to produce a plurality of model harmonic magnitudes therefrom; g) a scale calculator operable to calculate a first set of scale factors as the ratio of the harmonic magnitudes to the model harmonic magnitudes; h) a second interpolator, operable to interpolate the first set of scale factors to obtain a second set of scale factors at the set of fixed frequencies; i) a second spectrum calculator, operable to calculate model spectral magnitudes at the set of fixed frequencies by sampling the spectral envelope defined by the linear prediction coefficients at the set of fixed frequencies; j) a multiplier, operable to multiply the model spectral magnitudes at the set of fixed frequencies by the second set of scale factors to obtain the next plurality of spectral magnitudes; and k) an output for outputting the linear prediction coefficients.<br>26. A device for modeling a signal, wherein the device is directed by a computer program stored in at least one of a memory, an application specific integrated circuit, a digital signal processor and a field programmable gate array, wherein the computer program is operable to: a) identify a plurality of harmonic frequencies; b) identify a plurality of harmonic magnitudes corresponding to spectral magnitudes of the signal at the plurality of harmonic frequencies; c) interpolate the plurality of harmonic magnitudes to obtain a plurality of spectral magnitudes at a set of fixed frequencies; d) inverse transform the plurality of spectral magnitudes to obtain a pseudo autocorrelation sequence; e) calculate linear prediction coefficients from the pseudo auto-correlation sequence; f) calculate model harmonic magnitudes by sampling a spectral envelope defined by the linear prediction coefficients; g) calculate a first set of scale factors as the ratio of the harmonic magnitudes to the model harmonic magnitudes; h) interpolate the first set of scale factors to obtain a second set of scale factors at the set of fixed frequencies; i) calculate model spectral magnitudes at the set of fixed frequencies by sampling the spectral envelope defined by the linear prediction coefficients at the set of fixed frequencies; j) multiply the model spectral magnitudes at the set of fixed frequencies by the second set of scale factors to obtain a new plurality of spectral magnitudes; k) inverse transform the new plurality of spectral magnitudes to obtain a new pseudo auto-correlation sequence; and l) calculate new linear prediction coefficients from the new pseudo auto-correlation sequence, and wherein the signal is modeled by the new linear prediction coefficients.<br>35. A computer readable medium containing instructions which, when operated on a computer, carry out a process of modeling a plurality of harmonic magnitudes at a plurality of harmonic frequencies, the process comprising: a) interpolating the plurality of harmonic magnitudes to obtain a plurality of spectral magnitudes at a set of fixed frequencies; b) inverse transforming the plurality of spectral magnitudes to obtain a pseudo auto-correlation sequence; c) calculating linear prediction coefficients from the pseudo auto-correlation sequence; d) calculating model harmonic magnitudes by sampling a spectral envelope defined by the linear prediction coefficients; e) calculating a first set of scale factors as the ratio of the harmonic magnitudes to the model harmonic magnitudes; f) interpolating the first set of scale factors to obtain a second set of scale factors at the set of fixed frequencies; g) calculating model spectral magnitudes at the set of fixed frequencies by sampling the spectral envelope defined by the linear prediction coefficients at the set of fixed frequencies; h) multiplying the model spectral magnitudes at the set of fixed frequencies by the second set of scale factors to obtain a new plurality of spectral magnitudes; i) inverse transforming the new plurality of spectral magnitudes to obtain a new pseudo auto-correlation sequence; and j) calculating new linear prediction coefficients from the new pseudo auto-correlation sequence, wherein the signal is modeled by the new linear prediction coefficients.<br>41. A device for modeling a signal, wherein the device is directed by a computer program stored in at least one of a memory, an application specific integrated circuit, a digital signal processor and a field programmable gate array, wherein the computer program is operable to: a) identify a plurality of harmonic frequencies; b) identify a plurality of harmonic magnitudes corresponding to spectral magnitudes of the signal at the plurality of harmonic frequencies; c) assign the plurality of harmonic magnitudes to a subset of a set of fixed frequencies and assign dummy harmonic magnitudes to the remainder of the set of fixed frequencies to obtain a plurality of spectral magnitudes at the set of fixed frequencies; d) inverse transform the plurality of spectral magnitudes to obtain a pseudo auto-correlation sequence; and e) calculate linear prediction coefficients from the pseudo auto-correlation sequence, and wherein the harmonic magnitudes are modeled by the linear prediction coefficients.</p></layer>
<layer id = "layer344"><p><b>US20030206624A1:Full duplex echo cancelling circuit</b><br>An apparatus is automatically conveying cartridges reliably and correctly without causing errors, making it possible to enhance the operation efficiency and performance of the apparatus. The apparatus is automatically conveying cartridges disposed adjacent to a recording/reproducing apparatus, and is comprised of a cell mechanism having racks, an accessor mechanism having an accessor, and a conveyance control unit for controlling the conveyance of the cartridges by controlling the accessor mechanism, wherein the accessor is provided with catcher hands, a catcher hand drive mechanism, an open detector mechanism for detecting the open state of said catcher hands, and a closed detector mechanism for detecting the closed state of said catcher hand. The conveyance control unit is equipped with a catcher hand controller which controls the catcher hands to assume an open state, a closed state or a middle state which is an intermediate state relying upon the data detected by the open detector mechanism and the closure detector mechanism.<br><b>Independant Claims</b><br>1. In a telephone having a first channel including a microphone input and a line output and a second channel including a line input and a speaker output, the improvement comprising: a sub-band filter bank and a non-linear processor coupled in series in each channel; at least one adaptive echo canceller coupled between said first channel and said second channel in parallel with a first echo path; a control circuit for controlling said adaptive echo canceller, said sub-band filter bank, and said non-linear processor to provide at least 15 dB more echo suppression than in systems without a sub-band filter bank and a non-linear processor coupled in series in each channel.<br>11. A method for echo suppression in a telephone having a receive channel and a transmit channel, said method comprising the steps of: defining a plurality of call states irrespective of noise; defining at least two noise levels; defining a matrix of operating conditions according to call state and noise level; providing a sub-band filter bank and a non-linear processor coupled in series in at least one channel; providing at least one adaptive echo canceller coupled between said receive channel and said transmit channel in parallel with a first echo path; operating the sub-band filter bank, the non-linear processor, and the adaptive echo canceller according to the matrix.<br>15. In a telephone having a first channel including a microphone input and a line output and a second channel including a line input and a speaker output, the improvement comprising: a sub-band filter bank and a non-linear processor coupled in series in each channel; a first adaptive echo canceller coupled between said first channel and said second channel in parallel with a first echo path; a second adaptive echo canceller coupled between said second channel and first second channel in parallel with a second echo path; a control circuit for controlling the adaptive echo cancellers, said sub-band filter bank, and said non-linear processor to provide at least 15 dB more echo suppression than in systems without a sub-band filter bank and a non-linear processor coupled in series in each channel.<br>18. In a telephone having a first channel including a microphone input and a line output and a second channel including a line input and a speaker output, the improvement comprising: a sub-band filter bank and a non-linear processor coupled in series in each channel; a first adaptive echo canceller coupled between said first channel and said second channel in parallel with a first echo path; a second adaptive echo canceller coupled between said second channel and first second channel in parallel with a second echo path; a control circuit for controlling the adaptive echo cancellers, said sub-band filter bank, and said non-linear processor to provide at least 15 dB more echo suppression than in systems without a sub-band filter bank and a non-linear processor coupled in series in each channel; wherein said control circuit monitors the outputs from said voice activity detectors to define at least three operating states, including a receive state and a transmit state, and to further define at least two noise levels; wherein said control circuit causes said first adaptive echo canceller to adapt during the receive state regardless of noise level, causes the second adaptive echo canceller to adapt during the transmit state in the lower noise level, and causes the second adaptive echo canceller to reset during the transmit state in the higher noise level.<br>20. In a telephone having a first channel including a microphone input and a line output and a second channel including a line input and a speaker output, the improvement comprising: a sub-band filter bank and a non-linear processor coupled in series in each channel; at least one adaptive echo canceller coupled between said first channel and said second channel in parallel with a first echo path; a control circuit for controlling said adaptive echo canceller, said sub-band filter bank, and said non-linear processor to provide at least 15 dB more echo suppression than in systems without a sub-band filter bank and a non-linear processor coupled in series in each channel; wherein said control circuit monitors the outputs from said voice activity detectors to define at least three operating states, including a receive state and a transmit state, and to further define at least two noise levels; wherein said control circuit causes the sub-band filter bank in said first channel to be by-passed during the transmit state in the lower noise level.<br>22. In a telephone having a first channel including a microphone input and a line output and a second channel including a line input and a speaker output, the improvement comprising: a sub-band filter bank and a non-linear processor coupled in series in each channel; at least one adaptive echo canceller coupled between said first channel and said second channel in parallel with a first echo path; a control circuit for controlling said adaptive echo canceller, said sub-band filter bank, and said non-linear processor to provide at least 15 dB more echo suppression than in systems without a sub-band filter bank and a non-linear processor coupled in series in each channel; wherein said control circuit monitors the outputs from said voice activity detectors to define at least three operating states, including a quiet state characterized by a voice signal not being detected in either channel; wherein said control circuit causes the output signals from the sub-band filters in each bank to be partially attenuated during said quiet state.<br>23. The telephone as set forth in claim 23 wherein the output signals from the sub-band filters in each bank are each attenuated the same amount during said quiet state.<br>25. A method for echo suppression in a telephone having a receive channel and a transmit channel, said method comprising the steps of: defining a plurality of call states irrespective of noise; defining at least two noise levels; defining a matrix of operating conditions according to call state and noise level; providing a sub-band filter bank and a non-linear processor coupled in series in at least one channel; providing at least one adaptive echo canceller coupled between said receive channel and said transmit channel in parallel with a first echo path; operating the sub-band filter bank, the non-linear processor, and the adaptive echo canceller according to the matrix and in a hierarchical order.</p></layer>
<layer id = "layer345"><p><b>US8239208B2:Spectral enhancing method and device</b><br>A heart rate alarm system includes an article of clothing, at least two conductive units, at least one alarm device, a heart rate measurement unit, a first transmission unit, a second transmission unit, and an operation unit. The at least two conductive units are coupled to each other through at least one conductive fibric. The heart rate measurement unit measures a heart rate through the at least two conductive units, and generates a control signal and a heart rate value according to the heart rate. The first transmission unit transmits the control signal to the at least one alarm device and transmits the heart rate value. The at least one alarm device generates at least one alarm signal according to the control signal. The operation unit calculates a heart beat period, a heart physiological age, indicators of autonomic nervous system, and/or a calorie consumption indicator.<br><b>Independant Claims</b><br>1) A method of enhancing spectral content of a decoded signal, the signal having an incomplete spectrum including a first spectral frequency band, said method comprising the following steps: performing at least one translation of the spectral content of said first frequency band into a second frequency band excluded from said spectrum to generate a translated-spectrum signal, filtering the incomplete spectrum signal through a bank of analysis filters and applying output signals from said bank of analysis filters to inputs of translated ranks of inputs of a bank of synthesis filters to generate a translated-spectrum signal having a spectrum restricted to said second spectral frequency band; shaping the spectrum of the translated-spectrum signal to produce an enhancement signal; and adding the enhancement signal to the incomplete spectrum signal to produce an enhanced-spectrum signal, the generation of the translated-spectrum signal including whitening said spectral content by applying a whitening filter to said first spectral frequency band so that the spectrum of the translated-spectrum signal is a whitened version of said spectral content.<br>17) A method of improving decoding of an incomplete spectrum signal, said incomplete spectrum signal having been produced by encoding in a spectrum limiting manner a wide frequency band source signal, comprising enhancing the decoded signal having an incomplete spectrum which include a first spectral frequency band having an envelope by: performing at least one translation of the spectral content of said first frequency band into a second frequency band excluded from said spectrum to generate a translated-spectrum signal, filtering the incomplete spectrum signal through a bank of analysis filters and applying output signals from said bank of analysis filters to inputs of translated ranks of inputs of a bank of synthesis filters to generate a translated-spectrum signal having a spectrum restricted to said second spectral frequency band; shaping the spectrum of the translated-spectrum signal to produce an enhancement signal; and adding the enhancement signal to the incomplete spectrum signal to produce an enhanced-spectrum signal, the generation of the translated-spectrum signal including whitening said spectral content by applying a whitening filter to said first spectral frequency band so that the spectrum of the translated-spectrum signal is a whitened version of said spectral content.<br>20) A device for enhancing spectral content of a decoded signal, the signal having an incomplete spectrum including a first spectral frequency band having an envelope, said device comprising: a generator adapted to apply at least one translation of the spectral content of said first frequency band into a second frequency band excluded from said spectrum, by filtering the incomplete spectrum signal through a bank of analysis filters and applying output signals from said bank of analysis filters to inputs of translated ranks of inputs of a bank of synthesis filters to generate a translated-spectrum signal having a spectrum restricted to said second spectral frequency band, said generator being adapted to whiten said spectral content to generate a translated-spectrum signal; shaping means for shaping the spectrum of the translated-spectrum signal to produce an enhancement signal; and an adder adapted to add the enhancement signal to the incomplete spectrum signal to produce an enhanced-spectrum signal, wherein the generator is configured to apply a whitening filter to said first spectral frequency band so that the spectrum of the translated-spectrum signal is a whitened version of said spectral content.<br>21) A method of enhancing spectral content of a decoded signal, the signal having an incomplete spectrum including a first spectral frequency band, said method comprising the following steps: performing at least one translation of the spectral content of said first frequency band into a second frequency band excluded from said spectrum to generate a translated-spectrum signal, filtering the incomplete spectrum signal through a bank of analysis filters and applying output signals from said bank of analysis filters to inputs of translated ranks of inputs of a bank of synthesis filters to generate a translated-spectrum signal having a spectrum restricted to said second spectral frequency band; shaping the spectrum of the translated-spectrum signal to produce an enhancement signal; and adding the enhancement signal to the incomplete spectrum signal to produce an enhanced-spectrum signal, the generation of the translated-spectrum signal including whitening said spectral content by filtering said spectral content through a whitening filter having a transfer function which is approximately inverse of an envelope function of the first spectral frequency band of the incomplete spectrum signal so that the spectrum of the translated-spectrum signal is a whitened version of said spectral content.</p></layer>
<layer id = "layer346"><p><b>US20030216907A1:Enhancing the aural perception of speech</b><br>In a method and apparatus for ultrasound imaging of biological tissue using higher-order nonlinear signal components an ultrasound line is acquired at different excitation levels. The acquisition is repeated I times with identical beamforming parameters, but varying excitation level. All of the transmitted waveforms are nonlinearly distorted, but the degree of distortion depends on the excitation level, making it possible to extract individual nonlinear signal components by properly combining the received echo signals. A pre-computed estimation matrix, dependent on the order of an estimation model and the excitation levels, is stored in computer memory and used to compute the nonlinear components of interest. The real-time calculations reduce to a linear combination of the received echo signals. A further reduction in computational load can be achieved if one is interested in only the n-th-order nonlinear component.<br><b>Independant Claims</b><br>1. An apparatus for processing an electrical signal representing speech for enhancing the perception of speech, said apparatus comprising: a harmonics generator having an input for receiving said electrical signal and an output, said generator increasing the harmonic content of the electrical signal; a first filter coupled to said output and producing a filtered output signal; a multiplier coupled to said first filter for adjusting the amplitude of the filtered output signal; a first amplitude detector coupled to said first filter for producing a first control signal representative of said filtered output signal; a second amplitude detector coupled to said harmonics generator for producing a second control signal; and a divider for producing a third control signal representative of the ratio of the second control signal to the first control signal; wherein said third control signal is coupled to said multiplier for adjusting the amplitude of the filtered output signal.<br>10. An apparatus for increasing the harmonic content of an electrical signal, said apparatus comprising: a first amplifier having a first transfer function, sgn(x)·[abs(x)]c; a first filter coupled to said first amplifier; and a second amplifier having a second transfer function, sgn(x)·[abs(x)]1/c; wherein 1<c<2.<br>13. A method for processing an electrical signal representing speech for enhancing the perception of speech, said method comprising the steps of: increasing the harmonic content of the electrical signal to produce an enhanced signal; attenuating low frequency components of the enhanced signal to produce a filtered, enhanced signal; and adjusting the amplitude of the filtered, enhanced signal in accordance with the ratio of the amplitudes of the unfiltered signal to the filtered signal.<br>17. A method for processing an electrical signal representing speech for enhancing the perception of speech, said method comprising the steps of: attenuating low frequency components of the electrical signal to produce an enhanced signal; and adjusting the amplitude of the enhanced signal in accordance with the ratio of the amplitudes of the electrical signal to the enhanced signal.</p></layer>
<layer id = "layer347"><p><b>US20030216908A1:Automatic gain control</b><br>A process of forming a self aligned contact on a surface of a wafer having one or more gate structures and a contact region adjacent the gate structures. The gate structures are isolated from the contact region by one or more spacers having predetermined thicknesses. The process comprises the steps of depositing a conformal etch stop layer over the gate structures and contact region, depositing a sacrificial layer over the etch stop layer, selectively removing a portion of the sacrificial layer to expose a portion of the etch stop layer adjacent the contact region and removing the etch stop layer to expose contact region. The etch stop layer protects spacers from damage resulting from selective etch of the sacrificial layer. In one preferred embodiment, the etch stop layer has a substantially uniform thickness and may be removed by a timed etch.<br><b>Independant Claims</b><br>1. A method comprising estimating power of a speech portion of a speech signal that includes speech portions separated by non-speech portions, the power for the speech portion being estimated based on a power envelope that spans the speech portion, and refraining from adjusting the gain of an automatic gain control during the speech portions.<br>10. A method comprising detecting voice activity as an indication of the start of each portion of a speech signal, the speech signal including word portions separated by pause portions, estimating power for the word portions, and controlling the gain of an automatic gain control to be constant for the duration of the word portions and to be adjusted, based on the estimated power, during the pauses between the words.<br>11. A method comprising estimating power of a speech portion of a speech signal that includes speech portions separated by non-speech portions, the power for the speech portion being estimated based on a power envelope that spans the speech portion, and controlling an automatic gain control based on the power estimate.<br>16. Apparatus comprising a port to receive a speech signal, and an automatic gain control configured to apply a constant gain to a speech portion of the signal and to adjust the gain during non-speech portions of the signal based on power estimates done during previous speech portions.<br>19. A medium carrying instructions capable of causing a machine to estimate power of a speech portion of a speech signal that includes speech portions separated by non-speech portions, the power for the speech portion being estimated based on a power envelope that spans the speech portion, and refrain from adjusting the gain of an automatic gain control during the speech portions.<br>21. A system comprising a port to receive speech signals, an automatic gain control configured to estimate power of a speech portion of a speech signal that includes speech portions separated by non-speech portions, the power for the speech portion being estimated based on a power envelope that spans the speech portion, and refrain from adjusting the gain of an automatic gain control during the speech portions, and elements configured to perform speech functions based on an output of the automatic gain control.<br>23. Apparatus comprising means for estimating power of a speech portion of a speech signal that includes speech portions separated by non-speech portions, the power for the speech portion being estimated based on a power envelope that spans the speech portion, and means for refraining from adjusting the gain of an automatic gain control during the speech portions.</p></layer>
<layer id = "layer348"><p><b>US20050165603A1:Method and device for frequency-selective pitch enhancement of synthesized speech</b><br>A wireless mobile station comprising: 1) an RF transceiver that up-converts a baseband signal to produce an output RF signal; 2) an antenna coupled to the RF transceiver for transmitting the output RF signal; 3) a power supply that supplies power to the RF transceiver; and 4) switching circuitry associated with the antenna that provides a first conduction path between the power supply and the RF transceiver, such that when the antenna is in a first position, the first conduction path is closed and power is supplied to the RF transceiver from the power supply and when the antenna is translated to a second position, the first conduction path is opened and the power is not supplied to the RF transceiver from the power supply.<br><b>Independant Claims</b><br>1. A method for, post-processing a decoded sound signal in view of enhancing a perceived quality of said decoded sound signal, comprising: dividing the decoded sound signal into a plurality of frequency sub-band signals; and applying post-processing to at least one of the frequency sub-band signals, but not all the frequency sub-band signals.<br>32. A device for post-processing a decoded sound signal in view of enhancing a perceived quality of said decoded sound signal, comprising: means for dividing the decoded sound signal into a plurality of frequency sub-band signals; and means for post-processing at least one of the frequency sub-band signals, but not all the frequency sub-band signals.</p></layer>
<layer id = "layer349"><p><b>US20050154584A1:Method and device for efficient frame erasure concealment in linear predictive based speech codecs</b><br>The present invention is concerned with mixed anhydrides. The mixed anhydrides are prepared by adding an adjuvant base to a mixture of acid and reactive acid derivative. The mixed anhydrides play an role primarily in activating and coupling reactions.<br><b>Independant Claims</b><br>1. A method of concealing frame erasure caused by frames of an encoded sound signal erased during transmission from an encoder to a decoder, comprising: determining, in the encoder, concealment/recovery parameters; transmitting to the decoder concealment/recovery parameters determined in the encoder; and in the decoder, conducting frame erasure concealment and decoder recovery in response to the received concealment/recovery parameters.<br>46. A method of concealing frame erasure caused by frames of an encoded sound signal erased during transmission from an encoder to a decoder, comprising: determining, in the encoder, concealment/recovery parameters; and transmitting to the decoder concealment/recovery parameters determined in the encoder.<br>71. A method for the concealment of frame erasure caused by frames erased during transmission of a sound signal encoded under the form of signal-encoding parameters from an encoder to a decoder, comprising: determining, in the decoder, concealment/recovery parameters from the signal-encoding parameters; in the decoder, conducting erased frame concealment and decoder recovery in response to concealment/recovery parameters determined in the decoder.<br>88. A device for conducting concealment of frame erasure caused by frames of an encoded sound signal erased during transmission from an encoder to a decoder, comprising: means for determining, in the encoder, concealment/recovery parameters; means for transmitting to the decoder concealment/recovery parameters determined in the encoder; and in the decoder, means for conducting frame erasure concealment and decoder recovery in response to received concealment/recovery parameters determined by the determining means.<br>133. A device for conducting concealment of frame erasure caused by frames of an encoded sound signal erased during transmission from an encoder to a decoder, comprising: means for determining, in the encoder, concealment/recovery parameters; and means for transmitting to the decoder concealment/recovery parameters determined in the encoder.<br>158. A device for the concealment of frame erasure caused by frames erased during transmission of a sound signal encoded under the form of signal-encoding parameters from an encoder to a decoder, comprising: means for determining, in the decoder, concealment/recovery parameters from the signal-encoding parameters; in the decoder, means for conducting erased frame concealment and decoder recovery in response to concealment/recovery parameters determined by the determining means.</p></layer>
<layer id = "layer350"><p><b>US20040002856A1:Multi-rate frequency domain interpolative speech CODEC system</b><br>Disclosed is a decorative tire sidewall shield cover that provides the tire sidewall (<b>16</b>) with added beauty and protection. The device is a substantially planar ring-like member having a central aperture (<b>42</b>) substantially of the same diameter as the wheel or hub (<b>20</b>) opening of the tire (<b>18</b>). The decorative sidewall shield can also have a centrally disposed flange or lip (<b>30</b>) that will be positioned between the tire rim (<b>18</b>) and wheel rim (<b>20</b>) being held in place by tire air pressure. In addition to an exterior shield for tires such as motor vehicles, the tire shield covers both sides of a tire, such as for a motorcycle. The material used would have abrasion resistance properties.<br><b>Independant Claims</b><br>1. A coding system for a coder/decoder (codec) for providing adaptive bandwidth broadening to an encoder, comprising: a linear prediction (LP) front end, adapted to process an input signal which provides LP parameters that are computed during a predetermined interval; an open loop pitch estimator, adapted to perform pitch frequency estimation on said input signal for substantially all of said predetermined intervals; an adaptive bandwidth broadening module, adapted to perform the following operations: derive a spectrum sampling frequency for said predetermined interval as the pitch frequency or its integer submultiple depending on the pitch frequency; determine a LP power spectrum at the harmonics of said spectrum sampling frequency for said input signal for said frame; compute a peak to average ratio of said LP spectrum based on said spectrum sampling frequency of said frame; and adaptively bandwidth broaden said LP filter coefficients based on said peak to average ratio of said LP spectrum for all harmonic multiples of said spectral sampling frequency.<br>5. A coding system for a codec, comprising: A linear prediction front end adapted to process an input signal to provide LP parameters which are quantized and encoded over predetermined intervals and are used to compute a LP residual signal; an open loop pitch estimator adapted to process the LP residual signal, pitch information, pitch interpolation information and provide a pitch contour within the predetermined intervals; a prototype waveform extraction module, which is adapted in response to the LP residual signal and the pitch contour to extract a prototype waveform (PW) for a number of equal subintervals within the predetermined intervals and to extract an additional approximate PW in the subinterval immediately after the ending of a previous subinterval; a PW gain computation module, adapted to compute a PW gain for substantially all the subintervals; and a gain vector predictive vector quantization (VQ) module, adapted to quantize and encode the PW gains for substantially all the subintervals after they are filtered by a weighted window, decimated, and after subtracting from them a predicted average PW gain value for a current predetermined interval computed from the quantized PW gain values of a preceding predetermined interval.<br>11. A frequency domain interpolative (FDI) coder/decoder (codec), comprising: a PW normalization and alignment module, adapted to compute a sequence of aligned prototype waveform (PW) vectors for a frame via a low complexity alignment process; and a PW subband correlation computation module, adapted to compute a PW correlation vector for all harmonics for the frame and average the PW correlation vector across the harmonics in five subbands in order to derive a PW subband correlation vector.<br>21. A frequency domain interpolative (FDI) coder/decoder (codec), comprising: a PW magnitude quantizer, adapted to perform the following: directly quantize a prototype waveform (PW) in a magnitude domain for substantially every frame without said PW being decomposed into complex components; hierarchically quantize a PW magnitude vector based on a voicing classification using a mean-deviations representation; adaptively vector quantize the mean component of the representation in multiple subbands; derive a variable dimension deviations vector as the difference of the input PW magnitude vector and the full band representation of the quantized PW subband mean vector for all harmonics; select a fixed dimensional deviations subvector from the said variable dimensional deviations vector based on location of speech formant frequencies for a subframe; and provide the said fixed dimensional deviations subvector for adaptive vector quantization.<br>22. A coding system for a coder/decoder (codec), comprising: a linear prediction (LP) front end, adapted to process an input signal which provides LP parameters that are computed during a predetermined interval; an open loop pitch estimator, adapted to perform pitch estimation on said input signal for substantially all of said predetermined intervals; a voice activity detection module, that uses the LP parameters and pitch information; a voicing measure computation module, adapted to provide a voicing measure that characterizes a degree of voicing and is derived from a plurality of input parameters that are correlated to the degree of periodicity of the input signal for substantially all predetermined intervals; a prototype waveform (PW) subband correlation computation module, adapted to provide a PW subband correlation vector, said PW subband correlation vector characterizing a degree of correlation between successive PW vectors as a function of frequency and computed for substantially all predetermined intervals; an adaptive bandwidth broadening module, adapted to reduce annoying artifacts due to spurious spectral peaks by performing the following: compute a measure of VAD likelihood based on voice activity detection (VAD) flags for a preceding, a current and a next predetermined interval; and compute average PW gain values for inactive predetermined intervals and active unvoiced predetermined intervals.<br>27. A low bit rate coding system for a coder/decoder (codec), comprising: a linear prediction (LP) front end, adapted to process an input signal which provides LP parameters that are computed during a predetermined interval; an open loop pitch estimator, adapted to perform pitch estimation on said input signal for substantially all of said predetermined intervals; a voice activity detection module, adapted to process and provide the LP parameters and pitch information to the decoder; a prototype waveform (PW) encoder, adapted to provide a look ahead based on said predetermined interval in order to smooth PW parameters; and a voicing measure computation module, adapted to provide a voicing measure, said voicing measure characterizing a degree of voicing derived from a plurality of input parameters that are correlated to the degree of periodicity of the input signal for substantially all predetermined intervals.<br>36. A low bit rate coding system for a coder/decoder (codec), comprising: a linear prediction (LP) front end, adapted to process an input signal which provides LP parameters that are estimated, quantized and transmitted for substantially all frames of a first duration; an open loop pitch estimator, adapted to perform pitch estimation on said input signal for substantially all of said frames of a first duration and quantize and transmit pitch information for substantially all frames of a second duration; a voice activity detection module, adapted to combine voice activity detection (VAD) flags associated with two successive frames of a first duration based on processing the LP parameters and the pitch information every frame of a first duration and transmitting the VAD flags to the decoder substantially every frame of a second duration; and a prototype waveform (PW) encoder, adapted to provide a look ahead frame based on said frame of a first duration in order to smooth PW parameters including at least one of PW gain, a voicing measure, subband correlations and spectral magnitude.<br>44. A method for providing adaptive bandwidth broadening to an encoder of a coder/decoder (codec), comprising: processing an input signal which provides LP parameters that are computed during a predetermined interval; performing pitch frequency estimation on said input signal for substantially all of said predetermined intervals; deriving a spectrum sampling frequency for said predetermined interval as the pitch frequency or its integer submultiple depending on the pitch frequency; determining a LP power spectrum at the harmonics of said spectrum sampling frequency for said input signal for said frame; computing a peak to average ratio of said LP spectrum based on said spectrum sampling frequency of said frame; and adaptively bandwidth broadening said LP filter coefficients based on said peak to average ratio of said LP spectrum for all harmonic multiples of said spectral sampling frequency.<br>45. A method of providing a coding system for a codec, comprising: processing an input signal to provide LP parameters which are quantized and encoded over predetermined intervals and are used to compute a LP residual signal; processing the LP residual signal, pitch information, pitch interpolation information and providing a pitch contour within the predetermined intervals; extracting a prototype waveform (PW) for a number of equal subintervals within the predetermined intervals and extracting an additional approximate PW in the subinterval immediately after the ending of a previous subinterval in response to the LP residual signal and the pitch contour; computing a PW gain for substantially all the subintervals; and quantizing and encoding the PW gains for substantially all the subintervals after the subintervals are filtered by a weighted window, decimated, and subtracted from a predicted average PW gain value for a current predetermined interval which is computed from the quantized PW gain values of a preceding predetermined interval.<br>46. A method of providing a coding system for a coder/decoder (codec), comprising: computing a sequence of aligned prototype waveform (PW) vectors for a frame via a low complexity alignment process; and computing a PW correlation vector for all harmonics for the frame and averaging the PW correlation vector across the harmonics in five subbands in order to derive a PW subband correlation vector.<br>47. A method of providing a coding system for a frequency domain interpolative (FDI) coder/decoder (codec), comprising: directly quantizing a prototype waveform (PW) in a magnitude domain for substantially every frame without said PW being decomposed into complex components; hierarchically quantizing a PW magnitude vector based on a voicing classification using a mean-deviations representation; adaptively vector quantizing the mean component of the representation in multiple subbands; deriving a variable dimension deviations vector as the difference of the input PW magnitude vector and the full band representation of the quantized PW subband mean vector for all harmonics; selecting a fixed dimensional deviations subvector from the said variable dimensional deviations vector based on a location of speech formant frequencies for a subframe; and providing the said fixed dimensional deviations subvector for adaptive vector quantization.<br>48. A method of providing a coding system for a coder/decoder (codec), comprising: processing an input signal which provides LP parameters that are computed during a predetermined interval; performing a pitch estimation on said input signal for substantially all of said predetermined intervals; processing the LP parameters and pitch information; providing a voicing measure that characterizes a degree of voicing and is derived from a plurality of input parameters that are correlated to the degree of periodicity of the input signal for substantially all predetermined intervals; providing a PW subband correlation vector, said PW subband correlation vector characterizing a degree of correlation between successive PW vectors as a function of frequency and computed for substantially all predetermined intervals; reducing annoying artifacts due to spurious spectral peaks by performing the following: computing a measure of VAD likelihood based on voice activity detection (VAD) flags for a preceding, a current and a next predetermined interval; and computing average PW gain values for inactive predetermined intervals and active unvoiced predetermined intervals.<br>49. A method of providing a low bit rate coding system for a coder/decoder (codec), comprising: processing an input signal which provides LP parameters that are computed during a predetermined interval; performing pitch estimation on said input signal for substantially all of said predetermined intervals; processing the LP parameters and pitch information to the decoder; providing a look ahead based on said predetermined interval in order to smooth PW parameters; and providing a voicing measure, said voicing measure characterizing a degree of voicing derived from a plurality of input parameters that are correlated to the degree of periodicity of the input signal for substantially all predetermined intervals.<br>50. A method of providing a low bit rate coding system for a coder/decoder (codec), comprising: processing an input signal which provides LP parameters that are estimated, quantized and transmitted for substantially all frames of a first duration; performing a pitch estimation on said input signal for substantially all of said frames of a first duration and quantizing and transmiting pitch information for substantially all frames of a second duration; combining voice activity detection (VAD) flags associated with two successive frames of a first duration; processing the LP parameters and the pitch information every frame of a first duration and transmitting the VAD flags to the decoder substantially every frame of a second duration; and providing a look ahead frame based on said frame of a first duration in order to smooth PW parameters including at least one of PW gain, a voicing measure, subband correlations and a spectral magnitude.</p></layer>
<layer id = "layer351"><p><b>US20050171785A1:Audio decoding device, decoding method, and program</b><br>In a semiconductor device of the present invention, a first semiconductor region is formed so that a peripheral edge thereof is located between a first field plate ring that corresponds to one of field plate rings located at the innermost side thereof and a second field plate ring that corresponds to one of the field plate rings adjacent the first plate ring. Accordingly, when a surge voltage is applied to the semiconductor device of the present invention, an electric field concentration at a part of the isolation film located under the first one of the field plate rings is relaxed and an electric field intensity decreases. Therefore, the reliability of the isolation film for withstanding the surge voltage increases.<br><b>Independant Claims</b><br>1. An audio decoding apparatus comprising: a bit stream separator for separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; a low-frequency decoder for decoding said low-frequency bit stream to generate a low-frequency audio signal; a subband divider for dividing said low-frequency audio signal into a plurality of complex-valued signals in respective frequency bands to generate low-frequency subband signals; a corrective coefficient extractor for calculating an energy corrective coefficient based on said low-frequency subband signals; an energy corrector for correcting a target energy described by said high-frequency bit stream with said energy corrective coefficient to calculate a corrected target energy; a band expander for generating a high-frequency subband signal by correcting, in amplitude, the signal energy of a signal which is generated by copying and processing said low-frequency subband signals as instructed by said high-frequency bit stream, at said corrected target energy; and a subband combiner for combining real parts of said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>6. An audio decoding apparatus comprising: a bit stream separator for separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; a low-frequency decoder for decoding said low-frequency bit stream to generate a low-frequency audio signal; a subband divider for dividing said low-frequency audio signal into a plurality of real-valued signals in respective frequency bands to generate low-frequency subband signals; a corrective coefficient generator for generating a predetermined energy corrective coefficient; an energy corrector for correcting a target energy described by said high-frequency bit stream with said energy corrective coefficient to calculate a corrected target energy; a band expander for generating a high-frequency subband signal by correcting, in amplitude, the signal energy of a signal which is generated by copying and processing said low-frequency subband signals as instructed by said high-frequency bit stream, at said corrected target energy; and a subband combiner for combining said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>9. An audio decoding method comprising the steps of: separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; decoding said low-frequency bit stream to generate a low-frequency audio signal; dividing said low-frequency audio signal into a plurality of complex-valued signals in respective frequency bands to generate low-frequency subband signals; calculating an energy corrective coefficient based on said low-frequency subband signals; correcting a target energy described by said high-frequency bit stream with said energy corrective coefficient to calculate a corrected target energy; generating a high-frequency subband signal by correcting, in amplitude, the signal energy of a signal which is generated by copying and processing said low-frequency subband signals as instructed by said high-frequency bit stream, at said corrected target energy; and combining real parts of said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>14. An audio decoding method comprising the steps of: separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; decoding said low-frequency bit stream to generate a low-frequency audio signal; dividing said low-frequency audio signal into a plurality of real-valued signals in respective frequency bands to generate low-frequency subband signals; generating a predetermined energy corrective coefficient; correcting a target energy described by said high-frequency bit stream with said energy corrective coefficient to calculate a corrected target energy; generating a high-frequency subband signal by correcting, in amplitude, the signal energy of a signal which is generated by copying and processing said low-frequency subband signals as instructed by said high-frequency bit stream, at said corrected target energy; and combining said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>17. A program for enabling a computer to perform: a bit stream separating process for separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; a low-frequency decoding process for decoding said low-frequency bit stream to generate a low-frequency audio signal; a complex subband dividing process for dividing said low-frequency audio signal into a plurality of complex-valued signals in respective frequency bands to generate low-frequency subband signals; a corrective coefficient extracting process for calculating an energy corrective coefficient based on said low-frequency subband signals; an energy correcting process for correcting a target energy described by said high-frequency bit stream with said energy corrective coefficient to calculate a corrected target energy; a band expanding process for generating a high-frequency subband signal by correcting, in amplitude, the signal energy of a signal which is generated by copying and processing said low-frequency subband signals as instructed by said high-frequency bit stream, at said corrected target energy; and a subband combining process for combining real parts of said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>22. A program for enabling a computer to perform: a bit stream separating process for separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; a low-frequency decoding process for decoding said low-frequency bit stream to generate a low-frequency audio signal; a complex subband dividing process for dividing said low-frequency audio signal into a plurality of real-valued signals in respective frequency bands to generate low-frequency subband signals; a corrective coefficient generating process for generating a predetermined energy corrective coefficient; an energy correcting process for correcting a target energy described by said high-frequency bit stream with said energy corrective coefficient to calculate a corrected target energy; a band expanding process for generating a high-frequency subband signal by correcting, in amplitude, the signal energy of a signal which is generated by copying and processing said low-frequency subband signals as instructed by said high-frequency bit stream, at said corrected target energy; and a subband combining process for combining said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>25. An audio decoding apparatus comprising: a bit stream separator for separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; a low-frequency decoder for decoding said low-frequency bit stream to generate a low-frequency audio signal; a subband divider for dividing said low-frequency audio signal into a plurality of real-valued signals in respective frequency bands to generate low-frequency subband signals; an energy corrector for correcting a target energy described by said high-frequency bit stream with a predetermined energy corrective coefficient to calculate a corrected target energy; a band expander for generating a high-frequency subband signal by correcting, in amplitude, the signal energy of a signal which is generated by copying and processing said low-frequency subband signals as instructed by said high-frequency bit stream, at said corrected target energy; and a subband combiner for combining said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>26. An audio decoding apparatus comprising: a bit stream separator for separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; a low-frequency decoder for decoding said low-frequency bit stream to generate a low-frequency audio signal; a subband divider for dividing said low-frequency audio signal into a plurality of real-valued signals in respective frequency bands to generate low-frequency subband signals; an energy corrector for outputting an energy corrective coefficient for a signal which is generated by copying and processing said low-frequency subband signals; a band expander for generating a high-frequency subband signal by correcting, in amplitude, the signal energy of the signal which is generated by copying and processing said low-frequency subband signals as instructed by said high-frequency bit stream, using said energy corrective coefficient; and a subband combiner for combining said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>27. An audio decoding apparatus comprising: a bit stream separator for separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; a low-frequency decoder for decoding said low-frequency bit stream to generate a low-frequency audio signal; a subband divider for dividing said low-frequency audio signal into a plurality of real-valued signals in respective frequency bands to generate low-frequency subband signals; an energy corrector for calculating a corrected target energy using an instruction of said high-frequency bit stream and a predetermined energy corrective coefficient; a band expander for generating a high-frequency subband signal by correcting, in amplitude, the signal energy of a signal which is generated by copying and processing said low-frequency subband signals as instructed by said high-frequency bit stream; and a subband combiner for combining said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>28. An audio decoding apparatus comprising: a bit stream separator for separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; a low-frequency decoder for decoding said low-frequency bit stream to generate a low-frequency audio signal; a subband divider for dividing said low-frequency audio signal into a plurality of real-valued signals in respective frequency bands to generate low-frequency subband signals; a band expander for generating a high-frequency subband signal by correcting, in amplitude, the signal energy of a signal which is generated by copying and processing said low-frequency subband signals using an instruction included in said high-frequency bit stream and a predetermined energy corrective coefficient; and a subband combiner for combining said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>29. An audio decoding apparatus comprising: a bit stream separator for separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; a low-frequency decoder for decoding said low-frequency bit stream to generate a low-frequency audio signal; a subband divider for dividing said low-frequency audio signal into a plurality of real-valued signals in respective frequency bands to generate low-frequency subband signals; a band expander for generating a high-frequency subband signal by correcting the signal energy (Er) of a signal which is generated by copying and processing said low-frequency subband signals, rather than a target energy (R) described by said high-frequency bit stream, with the reciprocal (1/a) of a predetermined energy corrective coefficient (a) when a corrected target energy (aR) which is produced by correcting said target energy (R) with said predetermined energy corrective coefficient (a) and the signal energy (Er) are corrected in amplitude such that the corrected target energy (aR) and the signal energy (Er) are equal to each other; and a subband combiner for combining said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>30. An audio decoding method comprising the steps of: separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; decoding said low-frequency bit stream to generate a low-frequency audio signal; dividing said low-frequency audio signal into a plurality of real-valued signals in respective frequency bands to generate low-frequency subband signals; correcting a target energy described by said high-frequency bit stream with a predetermined energy corrective coefficient to calculate a corrected target energy; generating a high-frequency subband signal by correcting, in amplitude, the signal energy of a signal which is generated by copying and processing said low-frequency subband signals as instructed by said high-frequency bit stream, at said corrected target energy; and combining said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>31. An audio decoding method comprising the steps of: separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; decoding said low-frequency bit stream to generate a low-frequency audio signal; dividing said low-frequency audio signal into a plurality of real-valued signals in respective frequency bands to generate low-frequency subband signals; outputting an energy corrective coefficient for a signal which is generated by copying and processing said low-frequency subband signals; generating a high-frequency subband signal by correcting, in amplitude, the signal energy of the signal which is generated by copying and processing said low-frequency subband signals as instructed by said high-frequency bit stream, using said energy corrective coefficient; and combiner for combining said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>32. An audio decoding method comprising the steps of: separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; decoding said low-frequency bit stream to generate a low-frequency audio signal; dividing said low-frequency audio signal into a plurality of real-valued signals in respective frequency bands to generate low-frequency subband signals; calculating a corrected target energy using an instruction of said high-frequency bit stream and a predetermined energy corrective coefficient; generating a high-frequency subband signal by correcting, in amplitude, the signal energy of a signal which is generated by copying and processing said low-frequency subband signals as instructed by said high-frequency bit stream; and combining said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>33. An audio decoding method comprising the steps of: separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; decoding said low-frequency bit stream to generate a low-frequency audio signal; dividing said low-frequency audio signal into a plurality of real-valued signals in respective frequency bands to generate low-frequency subband signals; generating a high-frequency subband signal by correcting, in amplitude, the signal energy of a signal which is generated by copying and processing said low-frequency subband signals using an instruction included in said high-frequency bit stream and a predetermined energy corrective coefficient; and combining said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>34. An audio decoding method comprising the steps of: separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; decoding said low-frequency bit stream to generate a low-frequency audio signal; dividing said low-frequency audio signal into a plurality of real-valued signals in respective frequency bands to generate low-frequency subband signals; generating a high-frequency subband signal by correcting the signal energy (Er) of a signal which is generated by copying and processing said low-frequency subband signals, rather than a target energy (R) described by said high-frequency bit stream, with the reciprocal (1/a) of a predetermined energy corrective coefficient (a) when a corrected target energy (aR) which is produced by correcting said target energy (R) with said predetermined energy corrective coefficient (a) and the signal energy (Er) are corrected in amplitude such that the corrected target energy (aR) and the signal energy (Er) are equal to each other; and combining said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>35. A program for enabling a computer to perform: a bit stream separating process for separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; a low-frequency decoding process for decoding said low-frequency bit stream to generate a low-frequency audio signal; a subband dividing process for dividing said low-frequency audio signal into a plurality of real-valued signals in respective frequency bands to generate low-frequency subband signals; an energy correcting process for correcting a target energy described by said high-frequency bit stream with a predetermined energy corrective coefficient to calculate a corrected target energy; a band expanding process for generating a high-frequency subband signal by correcting, in amplitude, the signal energy of a signal which is generated by copying and processing said low-frequency subband signals as instructed by said high-frequency bit stream, at said corrected target energy; and a subband combining process for combining said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>36. A program for enabling a computer to perform: a bit stream separating process for separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; a low-frequency decoding process for decoding said low-frequency bit stream to generate a low-frequency audio signal; a subband dividing process for dividing said low-frequency audio signal into a plurality of real-valued signals in respective frequency bands to generate low-frequency subband signals; an energy correcting process for outputting an energy corrective coefficient for a signal which is generated by copying and processing said low-frequency subband signals; a band expanding process for generating a high-frequency subband signal by correcting, in amplitude, the signal energy of the signal which is generated by copying and processing said low-frequency subband signals as instructed by said high-frequency bit stream, using said energy corrective coefficient; and a subband combining process for combining said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>37. A program for enabling a computer to perform: a bit stream separating process for separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; a low-frequency decoding process for decoding said low-frequency bit stream to generate a low-frequency audio signal; a subband dividing process for dividing said low-frequency audio signal into a plurality of real-valued signals in respective frequency bands to generate low-frequency subband signals; an energy correcting process for calculating a corrected target energy using an instruction of said high-frequency bit stream and a predetermined energy corrective coefficient; a band expanding process for generating a high-frequency subband signal by correcting, in amplitude, the signal energy of a signal which is generated by copying and processing said low-frequency subband signals as instructed by said high-frequency bit stream; and a subband combining process for combining said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>38. A program for enabling a computer to perform: a bit stream separating process for separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; a low-frequency decoding process for decoding said low-frequency bit stream to generate a low-frequency audio signal; a subband dividing process for dividing said low-frequency audio signal into a plurality of real-valued signals in respective frequency bands to generate low-frequency subband signals; a band expanding process for generating a high-frequency subband signal by correcting, in amplitude, the signal energy of a signal which is generated by copying and processing said low-frequency subband signals using an instruction included in said high-frequency bit stream and a predetermined energy corrective coefficient; and a subband combining process for combining said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.<br>39. A program for enabling a computer to perform: a bit stream separating process for separating a bit stream into a low-frequency bit stream and a high-frequency bit stream; a low-frequency decoding process for decoding said low-frequency bit stream to generate a low-frequency audio signal; a subband dividing process for dividing said low-frequency audio signal into a plurality of real-valued signals in respective frequency bands to generate low-frequency subband signals; a band expanding process for generating a high-frequency subband signal by correcting the signal energy (Er) of a signal which is generated by copying and processing said low-frequency subband signals, rather than a target energy (R) described by said high-frequency bit stream, with the reciprocal (1/a) of a predetermined energy corrective coefficient (a) when a corrected target energy (aR) which is produced by correcting said target energy (R) with said predetermined energy corrective coefficient (a) and the signal energy (Er) are corrected in amplitude such that the corrected target energy (aR) and the signal energy (Er) are equal to each other; and a subband combining process for combining said low-frequency subband signals and said high-frequency subband signals to produce a decoded audio signal.</p></layer>
<layer id = "layer352"><p><b>US6691092B1:Voicing measure as an estimate of signal periodicity for a frequency domain interpolative speech codec system</b><br>The conductive rivet designed to connect the first and second conducting surfaces of circuit board through an aperture in the board. The rivet includes a conical member with an associated insulating washer associated on one side of circuit board. A T-shaped rivet and cooperating insulating sleeve are designed to contact the opposite side of the circuit board and provide a thermal conduction path via tail on the T-shaped rivet to the conical member on the opposing side.<br><b>Independant Claims</b><br>1) A frequency domain interpolative coding system for low bit-rate coding of speech signals, comprising: a linear prediction (LP) front end, responsive to an input signal, providing LP parameters which are quantized and encoded over predetermined intervals and used to compute a LP residual; an open loop pitch estimator, responsive to said LP residual signal, a pitch quantizer, and a pitch interpolator yielding a pitch contour within the predetermined interval; a voice activity detector (VAD) mechanism responsive to said LP parameters and open loop pitch, generating a VAD flag for every predetermined interval; a signal processor responsive to said LP residual signal and the pitch contour for extracting a prototype waveform (PW) for a number of equal sub-intervals within the predetermined interval; and said signal processor computing a PW gain for generating a normalized PW for each sub-interval and a PW gain vector for the predetermined interval; a separation of the normalized PW into a slowly evolving waveform (SEW) component and a rapidly evolving waveform (REW) component using a low-pass filter along every pitch harmonic track; a representation of one or more of the components of the normalized PW in spectral magnitude-phase form; and a characterization of the degree of periodicity of the input signal by a voicing measure, derived from certain parameters that are correlated to signal periodicity and computed from the input signal, PW, SEW and REW over the predetermined interval.<br>8) A frequency domain interpolative coding system for low bit-rate coding of speech signals, comprising: a linear prediction (LP) front end responsive to an input signal, providing LP parameters which are quantized and encoded over predetermined intervals and used to compute a LP residual signal; an open loop pitch estimator responsive to said LP residual signal, a pitch quantizer, and a pitch interpolator yielding a pitch contour within the predetermined interval; a signal processor responsive to said LP residual signal and the pitch contour for extracting a prototype waveform (PW) for a number of equal sub-intervals within the predetermined interval; and said signal processor computing a PW gain for generating a normalized PW for each sub-interval and a PW gain vector for the predetermined interval; a separation of the normalized PW into a slowly evolving waveform (SEW) component and a rapidly evolving waveform (REW) component using a low pass filter along every pitch harmonic track; a characterization of the degree of periodicity of the input signal by a voicing measure, derived from certain parameters that are correlated to signal periodicity and computed from the input signal, PW, SEW and REW over the predetermined interval; a representation of the SEW component in spectral magnitude-phase form and transmission of only the spectral magnitude information of the SEW component; and a reconstruction of the SEW and REW phase components at the decoder using the received SEW and REW magnitude components, the voicing measure, and pitch frequency contour information.</p></layer>
<layer id = "layer353"><p><b>US8145491B2:Techniques for enhancing the performance of concatenative speech synthesis</b><br>The present disclosure relates to a method for improving the perception of an image. The method may include subjecting an original image to a series of independent processes, each producing a pixel calculated using a respective reference kernel. The reference kernels each may comprise pixels from the original image.<br><b>Independant Claims</b><br>1) A method for use with speech synthesis, comprising the steps of: determining a value indicating how much pitch is to be modified for a current speech segment; and selecting one of a plurality of speech segment modification techniques based on the value; wherein the step of determining a value further comprises the steps of: determining an original pitch value; and determining a requested pitch value; wherein the step of determining an original pitch value comprises the step of subtracting a next pitch mark from a current pitch mark to determine the original pitch value.</p></layer>
<layer id = "layer354"><p><b>US20020055836A1:Speech coder/decoder</b><br>In an apparatus for feeding an original document, the time which is needed until the first original document is transported onto a transportation path after storing original documents is shortened. The original documents stacked on an original document supporting plate are successively supplied one by one in order from an uppermost original document. A discharged original document is steadily and easily inserted between the original document supporting plate and the original documents stacked on the original document supporting plate. When a hopper sensor detects that the original documents are stacked on the original document supporting plate, the original document supporting plate is moved upward until the upper surface of the uppermost one of the original documents contact a level sensor. At this stage, the original documents are supplied successively one by one from the uppermost original document by a paper feeding mechanism. An image from an original document which has traveled along a transportation path is read by a reading part of the copying machine on which the apparatus is mounted. When a document discharge sensor is turned on, the original document supporting plate is moved downward to a home position at a high speed, and the discharged original document is inserted into a space which is created at this stage between the original document supporting plate and the original documents stacked on the original document supporting plate.<br><b>Independant Claims</b><br>1. A speech coder comprising a speech coding means for determining an input speech signal excitation signal expressed in the form of a plurality of pulses such as to minimize the distortion, with respect to the input speech signal, of a reproduced speech signal obtained by exciting a linear prediction synthesis filter, which is prescribed by linear prediction coefficients of the input speech signal, on the basis of the excitation signal, and a control circuit for generating control parameters on the basis of designated control data, the speech coding means serving to code the input speech signal on the basis of the control parameters.<br>2. A speech coder comprising a speech coding means for determining an input speech signal excitation signal expressed in the form of a plurality of pulses such as to minimize the distortion, with respect to the input speech signal, of a reproduced speech signal obtained by exciting a linear prediction synthesis filter, which is prescribed by linear prediction coefficients of the input speech signal, on the basis of the excitation signal, and a control circuit for receiving a designated bit rate and a coding delay as control data and generating control parameters on the basis of the control data, the speech coding means serving to code the input speech signal on the basis of the control parameters.<br>3. A speech coder comprising a speech coding means for determining an input speech signal excitation signal expressed in the form of a multi-pulse signal constituted by a plurality of pulses such as to minimize the distortion, with respect to the input speech signal, of a reproduced speech signal obtained by exciting a linear prediction synthesis filter, which is prescribed by linear prediction coefficients of such input speech signal, on the basis of the excitation signal, a control circuit, supplied with the designated bit rate and coding delay as control data, for generating control parameters on the basis of the control data, the speech coding means serving to code the input speech signal on the basis of the control parameters, a control circuit for receiving a designated bit rate and a coding delay as control data and generating control parameters on the basis of the control data, the speech coding means serving to code the input speech signal on the basis of the control parameters, and a parameter setting circuit for setting parameters necessary from coding the multi-pulse signal as setting parameters on the basis of predetermined ones of the control parameters, the predetermined control parameters being supplied to the parameter setting circuits, the speech coding means serving to code the input speech signal on the basis of the control parameters and the setting parameters.<br>4. A speech coder comprising a speech coding means for determining an input speech signal excitation signal expressed in the form of a plurality of pulses such as to minimize the distortion, with respect to the input speech signal, of a reproduced speech signal obtained by exciting a linear prediction synthesis filter, which is prescribed by linear prediction coefficients of the input speech signal, on the basis of the excitation signal, and a control circuit for receiving a designated bit rate, a coding delay and a computational effort extent as control data and generating control parameters on the basis of the control data, the speech coding means serving to code the input speech signal on the basis of the control parameters.<br>5. A speech coder comprising a speech coding means for determining an input speech signal excitation signal expressed in the form of a multi-pulse signal constituted by a plurality of pulses such as to minimize the distortion, with respect to the input speech signal, of a reproduced speech signal obtained by exciting a linear prediction synthesis filter, which is prescribed by linear prediction coefficients of such input speech signal, on the basis of the excitation signal, a control circuit, supplied with the designated bit rate, coding delay and computation amounts as control data, for generating control parameters on the basis of the control data, the speech coding means serving to code the input speech signal on the basis of the control parameters, a control circuit for receiving a designated bit rate and a coding delay as control data and generating control parameters on the basis of the control data, the speech coding means serving to code the input speech signal on the basis of the control parameters, and a parameter setting circuit for setting parameters necessary from coding the multi-pulse signal as setting parameters on the basis of predetermined ones of the control parameters, the predetermined control parameters being supplied to the parameter setting circuits, the speech coding means serving to code the input speech signal on the basis of the control parameters and the setting parameters.<br>6. A speech decoder for restoring a reproduced speech signal from received coded speech data, the coded speech data including a speech signal excitation signal, linear prediction synthesis filter coefficients and control data, comprising a control circuit for generating control parameters on the basis of the control data, and speech decoding means for restoring a reproduced speech signal by restoring the excitation signal and the linear prediction synthesis filter coefficient by decoding from the coded speech data on the basis of the control parameters and exciting a linear prediction synthesis filter, which is prescribed by the linear prediction synthesis filter coefficient, on the basis of the excitation signal.<br>8. A speech decoder for restoring a reproduced speech signal from received coded speech data, the coded speech data including a speech signal excitation signal, linear prediction synthesis filter coefficients, bit rate and coding delay, comprising a control circuit for generating control parameters on the basis of the bit rate and coding delay, and speech decoding means for restoring a reproduced speech signal by restoring the excitation signal and the linear prediction synthesis filter coefficient by decoding from the coded speech data on the basis of the control parameters and exciting a linear prediction synthesis filter, which is prescribed by the linear prediction synthesis filter coefficient, on the basis of the excitation signal.<br>10. A speech decoder for restoring a reproduced speech signal from received coded speech data, the coded speech data including a speech signal excitation signal, linear prediction synthesis filter coefficients, a bit rate and a coding delay, the excitation signal being expressed in the form of a multi-pulse constituted by a plurality of pulses, the speech decoder comprising a control circuit for generating control parameters on the basis of the bit rate and the coding delay, a parameter setting circuit for setting parameters necessary for coding the multi-pulse as setting parameters on the basis of predetermine ones of the control parameters, and speech decoding means for restoring a reproduced speech signal by restoring the excitation signal and the linear prediction synthesis filter coefficient by decoding from the coded speech data on the basis of the control parameters and the setting parameters and exciting a linear prediction synthesis filter, which is prescribed by the linear prediction synthesis filter coefficient, on the basis of the excitation signal.<br>12. A speech coding method comprising of computing frame length from bit rate and coding delay, selecting control parameters from a table in which a plurality of control parameters for controlling an operation of CELP coding on the basis of the bit rate, computing pulse number of multi-pulse excitation signal, pulse position candidates of each pulse and candidate positions thereof from the sub-frame length and bit number of multi-pulse signal.<br>13. A speech coding method comprising dividing an input speech signal into frames on the basis of a given frame length, generating control parameters of frame length, sub-frame length and bit distribution that are necessary for coding, from given bit rate and coding delay data, and setting parameters necessary for generating a multi-pulse signal from the given bit rate and coding delay.</p></layer>
<layer id = "layer355"><p><b>US8090577B2:Bandwidth-adaptive quantization</b><br>A method in one embodiment includes applying an organic coating to a magnetic head for reducing exposure of the head to oxidation promoting materials; and storing the magnetic head. A method in another embodiment includes applying an organic coating to a magnetic head for reducing exposure of the head to oxidation promoting materials, the organic coating being applied to the magnetic head after the head is installed in the magnetic storage system. Another method includes fabricating a tape having an applicator portion for applying an organic coating to a magnetic head for reducing exposure of the head to oxidation promoting materials; applying the organic coating to the applicator portion of the tape; and applying a lubricant to a data portion of the tape. A method in another embodiment includes fabricating a tape having a data portion, and a cleaning portion for removing an organic coating from a magnetic head.<br><b>Independant Claims</b><br>1) A method for processing an acoustic signal, said method comprising performing each of the following acts within a device that is configured to process acoustic signals: calculating an energy of a first frame of the acoustic signal in each of a first frequency band and a second frequency band that is higher than the first frequency band; calculating an energy of a second frame of the acoustic signal in each of the first and second frequency bands; based on the calculated energies of said first frame in said first and second frequency bands, classifying the first frame as speech, including selecting a first coding rate for said first frame as an initial rate decision for said first frame; based on the calculated energies of said second frame in said first and second frequency bands, classifying the second frame as speech, including selecting a second coding rate for said second frame as an initial rate decision for said second frame; calculating an energy of said first frame in a third frequency band that is higher than said second frequency band; calculating an energy of said second frame in a fourth frequency band that includes at least the first frequency band; based on the calculated energy of said first frame in said third frequency band, deciding to alter the initial rate decision for said first frame; based on the calculated energy of said second frame in said fourth frequency band, deciding to alter the initial rate decision for said second frame; in response to said deciding to alter the initial rate decision for said first frame, selecting a third coding rate for said first frame that is different than said first coding rate; and in response to said deciding to alter the initial rate decision for said second frame, selecting a fourth coding rate for said second frame that is different than said second coding rate, wherein said deciding to alter the initial rate decision for said second frame is not based on a calculated energy of said second frame in said third frequency band.<br>16) An apparatus for processing an acoustic signal, said apparatus comprising: a frame classifier configured to calculate an energy of a first frame of the acoustic signal in each of a first frequency band and a second frequency band that is higher than the first frequency band and to calculate an energy of a second frame of the acoustic signal in each of the first and second frequency bands; a voice activity detector configured to determine a presence of speech in a first frame of the acoustic signal and to determine a presence of speech in a second frame of the acoustic signal that is separate from said first frame; a rate selector configured to produce an initial rate decision for said first frame, based on the determined presence of speech in said first frame, and to produce an initial rate decision for said second frame, based on the determined presence of speech in said second frame; and a spectral analyzer configured to calculate an energy of said first frame in a third frequency band that is higher than said second frequency band and to calculate an energy of said second frame in a fourth frequency band that includes at least the first frequency band, wherein said rate selector is configured to decide to alter the initial rate decision for said first frame, based on the calculated energy of said first frame in said third frequency band, and to decide to alter the initial rate decision for said second frame, based on the calculated energy of said second frame in said fourth frequency band, and wherein said rate selector is configured to produce the initial rate decision for said first frame by selecting a first coding rate for said first frame and to produce the initial rate decision for said second frame by selecting a second coding rate for said first frame, and wherein said rate selector is configured to alter the initial rate decision for said first frame by selecting, in response to said deciding to alter the initial rate decision for said first frame, a third coding rate for said first frame that is different than said first coding rate and to alter the initial rate decision for said second frame by selecting, in response to said deciding to alter the initial rate decision for said second frame, a fourth coding rate for said second frame that is different than said second coding rate, wherein said deciding to alter the initial rate decision for said second frame is not based on a calculated energy of said second frame in said third frequency band.<br>25) An apparatus for processing an acoustic signal, said apparatus comprising: means for calculating an energy of a first frame of the acoustic signal in each of a first frequency band and a second frequency band that is higher than the first frequency band; means for calculating an energy of a second frame of the acoustic signal in each of the first and second frequency bands; means for classifying the first frame as speech, based on the calculated energies of said first frame in said first and second frequency bands, said means including means for selecting a first coding rate for said first frame as an initial rate decision for said first frame; means for classifying the second frame as speech, based on the calculated energies of said second frame in said first and second frequency bands, said means including means for selecting a second coding rate for said second frame as an initial rate decision for said second frame; means for calculating an energy of said first frame in a third frequency band that is higher than said second frequency band; means for calculating an energy of said second frame in a fourth frequency band that includes at least the first frequency band; means for deciding to alter the initial rate decision for said first frame, based on the calculated energy of said first frame in said third frequency band; means for deciding to alter the initial rate decision for said second frame, based on the calculated energy of said second frame in said fourth frequency band; means for selecting, in response to said deciding to alter the initial rate decision for said first frame, a third coding rate for said first frame that is different than said first coding rate; and means for selecting, in response to said deciding to alter the initial rate decision for said second frame, a fourth coding rate for said second frame that is different than said second coding rate, wherein said deciding to alter the initial rate decision for said second frame is not based on a calculated energy of said second frame in said third frequency band.<br>27) A computer-readable non-transitory storage medium comprising instructions which when executed by a processor cause the processor to: calculate an energy of a first frame of the acoustic signal in each of a first frequency band and a second frequency band that is higher than the first frequency band; calculate an energy of a second frame of the acoustic signal in each of the first and second frequency bands; classify the first frame as speech, based on the calculated energies of said first frame in said first and second frequency bands, including selecting a first coding rate for said first frame as an initial rate decision for said first frame; classify the second frame as speech, based on the calculated energies of said second frame in said first and second frequency bands, including selecting a second coding rate for said second frame as an initial rate decision for said second frame; calculate an energy of said first frame in a third frequency band that is higher than said second frequency band; calculate an energy of said second frame in a fourth frequency band that includes at least the first frequency band; decide to alter the initial rate decision for said first frame, based on the calculated energy of said first frame in said third frequency band; decide to alter the initial rate decision for said second frame, based on the calculated energy of said second frame in said fourth frequency band; in response to said deciding to alter the initial rate decision for said first frame, select a third coding rate for said first frame that is different than said first coding rate; and in response to said deciding to alter the initial rate decision for said second frame, select a fourth coding rate for said second frame that is different than said second coding rate, wherein said deciding to alter the initial rate decision for said second frame is not based on a calculated energy of said second frame in said third frequency band.</p></layer>
<layer id = "layer356"><p><b>US20020133335A1:Methods and systems for celp-based speech coding with fine grain scalability</b><br>A smoke detector is provided with testing apparatus for determining if its sensitivity is within a predetermined acceptable range. The testing apparatus stores in the detector a range representing acceptable sensitivities. When a test is initiated the resulting test output is compared to the sensitivity range, or its representation, and a warning signal is provided when the output is not acceptable. According to one feature, the stored representations of the acceptable range include a maximum acceptable value and a minimum acceptable value, and the warning signal indicates when the output is above the maximum or below the minimum. According to other features, the output signal is periodic at one frequency when above the maximum and at another frequency when below the minimum. The test is initiated by a magnetic reed switch and the results are immediately apparent. Each smoke detector is calibrated on an individual basis that accounts for its particular electrical response, and the calibration information is retained in the detector wherever it goes after installation.<br><b>Independant Claims</b><br>1. A method of encoding a speech signal in a code excited linear prediction (CELP)-based speech processing system that includes an adaptive codebook and a fixed codebook, wherein the speech signal is divided into frames and each frame is further divided into sequential sub-frames, the method comprising: generating linear prediction coding (LPC) coefficients for a frame; generating pitch-related information by using the adaptive codebook, for each sub-frame of the frame; generating pulse-related information by using the fixed codebook, for a first sub-frame of the frame and for a second sub-frame of the frame; generating a basic bit-stream from the LPC coefficients, the pitch-related information, and the pulse-related information for the first sub-frame; and generating enhancement bits from the pulse-related information for the second sub-frame.<br>9. A method of synthesizing speech in a code excited linear prediction (CELP)-based speech processing system that includes an adaptive codebook and a fixed codebook, wherein a speech signal is divided into frames and each frame is further divided into sub-frames, the method comprising: receiving a basic bit-stream which includes linear prediction coding (LPC) coefficients for a frame, pitch-related information for all sub-frames of the frame, and first pulse-related information for a part of the sub-frames; receiving enhancement bits which include a part or a whole of second pulse-related information for a remainder of the sub-frames; generating an excitation by referring to the adaptive codebook and the fixed codebook based on the pitch-related information included in the basic bit-stream and the first pulse-related information included in the basic bit-stream, respectively; generating an excitation by referring to the adaptive codebook and the fixed codebook based on the pitch-related information included in the basic bit-stream and the part or the whole of the second pulse-related information included in the enhancement bits, respectively; and outputting synthesized speech according to the excitations and the LPC coefficients.<br>13. A speech processing system based on code excited linear prediction (CELP) for encoding a speech signal, wherein the speech signal is divided into frames and each frame is further divided into sub-frames, the system comprising: a generator of linear prediction coding (LPC) coefficients for a frame; a first portion including an adaptive codebook for generating pitch-related information for each sub-frame of the frame; a second portion including a fixed codebook for generating pulse-related information for each sub-frame of the frame, the pulse-related information including first information for a first kind of sub-frame and second information for a second kind of sub-frame; and a parameter encoder for generating a basic bit-stream from the LPC coefficients, the pitch-related information, and the first pulse-related information, and for generating enhancement bits from the second pulse-related information.<br>17. A speech processing system based on code excited linear prediction (CELP) for synthesizing speech, wherein a speech signal is divided into frames and each frame is further divided into sub-frames, the system comprising: a parameter decoder for extracting linear prediction coding (LPC) coefficients for a frame, pitch-related information for all the sub-frames of the frame, and first pulse-related information for a part of the sub-frames, from a basic bit-stream received, and for extracting a part or a whole of second pulse-related information for a remainder of the sub-frames from enhancement bits received; a first portion including an adaptive codebook for generating an excitation based on the pitch-related information; a second portion including a fixed codebook for generating an excitation based on the first pulse-related information or based on the part or the whole of the second pulse-related information; and a synthesizer for outputting synthesized speech according to the excitations and the LPC coefficients.</p></layer>
<layer id = "layer357"><p><b>US8438019B2:Classification of audio signals</b><br>An intelligent care provider medical practice system which learns the care provider's preferences and historical diagnosis for predicting and treating patients based on provided information. The system makes use of one or more medical knowledge bases and utilizes artificial intelligence and reasoning to learn the provider's preferences and tendencies. The system also automatically generates the provider's notes, treatment plans, and other medical practice actions for treating, billing, and processing the patient after an exam or visit.<br><b>Independant Claims</b><br>16) A mobile communication device comprising an encoder comprising an input configured to input frames of an audio signal in a frequency band, a first excitation block configured to perform a first excitation for a speech like audio signal which is mostly speech signal, and a second excitation block configured to perform a second excitation for a music like audio signal, wherein said encoder further comprises a filter configured to divide the frequency band into at least a first and a second group of sub band audio signals, wherein each sub band audio signal has a narrower bandwidth than said frequency band and said second group containing sub bands of higher frequencies than said first group wherein said filter further comprises a filter block configured to produce information indicative of normalised signal energies of a current frame of the audio signal at least at one sub band; and the device also comprising an excitation selection block configured to select one excitation block among said at least first excitation block and a second excitation block, the selection based on a defined relation between normalised signal energy of said first group of sub bands and normalised signal energy of said second group of sub bands for the frames of the audio signal and to use said relation in the selection of the excitation block so that the selected excitation block performs the excitation for a frame of the audio signal.<br>26) A method comprising: receiving input frames of an audio signal in a frequency band at a device; using a first excitation for a speech like audio signal which is mostly speech signal; using a second excitation for a music like audio signal; dividing the frequency band into at least a first and a second group of sub band audio signals, wherein each sub band audio signal has a narrower bandwidth than said frequency band and said second group containing sub bands of higher frequencies than said first group; producing information indicative of normalised signal energies of a current frame of the audio signal at least at one sub band by using a filter block; selecting one excitation among said at least first excitation and said second excitation by defining a relation between normalised signal energy of said first group of sub bands and normalised signal energy of said second group of sub bands for the frames of the audio signal and using said relation in the selection of the excitation; and using the selected excitation to perform the excitation for a frame of the audio signal.<br>17) A system comprising an encoder comprising: a processor; a memory including machine executable instructions, the memory and the machine executable instructions being configured to, in association with the processor, cause the encoder to: receive frames of an audio signal in a frequency band; perform a first excitation for a speech like audio signal which is mostly speech signal; and perform a second excitation for a music like audio signal; wherein said encoder is further caused to: divide the frequency band into at least a first and a second group of sub band audio signals, wherein each sub band audio signal has a narrower bandwidth than said frequency band and said second group containing sub bands of higher frequencies than said first group; produce information indicative of normalised signal energies of a current frame of the audio signal at least at one sub band; select one excitation among said at least first excitation and said second excitation, the selection based on a defined relation between normalised signal energy of said first group of sub bands and normalised signal energy of said second group of sub bands for the frames of the audio signal and to use said relation in the selection of the excitation; and perform the selected excitation for a frame of the audio signal.<br>8) A device comprising an encoder comprising an input configured to input frames of an audio signal in a frequency band, a first excitation block configured to perform a first excitation for a speech like audio signal which is mostly speech signal, and a second excitation block configured to perform a second excitation for a music like audio signal, wherein said encoder further comprises a filter configured to divide the frequency band into at least a first and a second group of sub band audio signals, wherein each sub band audio signal has a narrower bandwidth than said frequency band and said second group containing sub bands of higher frequencies than said first group wherein said filter further comprises a filter block configured to produce information indicative of normalised signal energies of a current frame of the audio signal at least at one sub band; and the device also comprising an excitation selection block configured to select one excitation block among said at least first excitation block and said second excitation block, the selection based on a defined relation between normalised signal energy of said first group of sub bands and normalised signal energy of said second group of sub bands for the frames of the audio signal and to use said relation in the selection of the excitation block so that the selected excitation block performs the excitation for a frame of the audio signal.<br>1) An apparatus comprising: a processor; a memory including machine executable instructions, the memory and the machine executable instructions being configured to, in association with the processor, cause the apparatus to: receive frames of an audio signal in a frequency band; perform a first excitation for a speech like audio signal which is mostly speech signal; and perform a second excitation for a music like audio signal; wherein the apparatus is further caused to: divide the frequency band into at least a first and a second group of sub band audio signals, wherein each sub band audio signal has a narrower bandwidth than said frequency band, and said second group containing sub bands of higher frequencies than said first group; produce information indicative of normalised signal energies of a current frame of the audio signal at least at one sub band; select one excitation among said at least first excitation and said second excitation, the selection based on a defined relation between normalised signal energy of said first group of sub bands and normalised signal energy of said second group of sub bands for the frames of the audio signal and to use said relation in the selection of the excitation; and perform the selected excitation for a frame of the audio signal.<br>31) A non-transitory computer readable medium stored with instructions, which when executed by a processor, perform: compressing audio signals in a frequency band, in which a first excitation is used for a speech like audio signal which is mostly speech signal, and a second excitation is used for a music like audio signal; dividing the frequency band into at least a first and a second group of sub band audio signals, wherein each sub band audio signal has a narrower bandwidth than said frequency band and said second group containing sub bands of higher frequencies than said first group; producing information indicative of normalised signal energies of a current frame of the audio signal at least at one sub band by using a filter block; selecting one excitation among said at least first excitation and said second excitation by defining a relation between normalised signal energy of said first group of sub bands and normalised signal energy of said second group of sub bands for the frames of the audio signal and using said relation in the selection of the excitation; and using the selected excitation to perform the excitation for a frame of the audio signal.</p></layer>
<layer id = "layer358"><p><b>USRE43985E1:Controlling loudness of speech in signals that contain speech and other types of audio material</b><br>A portable electronic device includes a main body, and an antenna module. The main body includes an upper surface and a lower surface. A recessed portion is formed in the upper surface and a receiving portion is formed in the lower surface. The antenna module includes an antenna and a holder. The antenna is attached to the holder. The holder includes a first end portion and a second end portion. The first end portion and the second end portion are respectively engaged in the recessed portion and the receiving portion. A connector electronically connects the antenna.<br><b>Independant Claims</b><br>36) 36. A method for signal processing that comprises: receiving an input audio signal; extracting features for a first segment, second segment, and third segment of the input audio signal; analyzing the extracted features to classify the first and third segments as speech segments; analyzing the extracted features to classify the second segment as a non-speech segment, the second segment being louder than at least one of the first and third segments; analyzing the first segment to determine a first estimated loudness; analyzing the third segment to determine a second estimated loudness; and adjusting, a loudness control parameter, based at least upon the first estimated loudness and the third estimated loudness, for the third segment to a reduce variation of speech loudness between the first and third segments despite the presence of the second segment.<br>49) 49. A method for signal processing, the method comprising: receiving an input audio signal; extracting features of an interval of the input audio signal for a first segment and a second segment of the input audio signal; analyzing the extracted features to classify the first and second segments as speech segments; analyzing the first segment to determine a first estimated loudness; analyzing the second segment to determine a second estimated loudness; and adjusting a loudness of the first segment to reduce variation of speech loudness between the first and second segments based at least upon the first estimated loudness and the second estimated loudness.<br>1) A method for signal processing that comprises: receiving an audio signal; extracting features of the audio signal; analyzing one or more of the extracted features to perform a speech determination; classifying segments within an interval of the audio signal as speech segments or non-speech segments based upon the speech determination, wherein each segment has a respective loudness, and the loudness or the speech segments is less than the loudness of one or more loud non-speech segments; analyzing one or more of the extracted features of the audio signal to obtain an estimated loudness of the speech segments; and providing an indication of the loudness of the interval of the audio signal by calculating control information from a weighted combination of the estimated loudness of the speech segments and the loudness of the non-speech segments in which the estimated loudness of the speech segments is weighted more heavily.<br>33) A method for signal processing that comprises: receiving an input audio signal; extracting features of the input audio signal, the extracted features representing an interval of the input of audio signal; analyzing the extracted features to perform a speech determination; classifying the interval of the audio signal as speech or non-speech based upon the speech determination, wherein each interval has a respective loudness and the a loudness of the interval classified as speech is less than the a loudness of one or more other segments classified as non-speech; analyzing the extracted features of the interval classified as speech to obtain an estimated loudness of the interval classified as speech; calculating a loudness control parameter, the loudness control parameter being proportional to the difference between the estimated loudness of intervals classified as speech adjusting a loudness of the interval classified as speech, the adjustment being determined by a loudness control parameter and the estimated loudness; and adjusting an estimated a loudness of the one or more other intervals classified as non-speech, the adjustment being proportional to the calculated loudness control parameter.<br>45) 45. A method for signal processing, the method comprising: receiving an input audio signal; extracting features of an interval of the input audio signal for a first segment and a second segment of the input audio signal; analyzing the extracted features to classify the first and second segments as speech segments; analyzing the first segment to determine a first estimated loudness; analyzing the second segment to determine a second estimated loudness; and adjusting a loudness of the second segment to reduce variation of speech loudness between the first and second segments using a loudness control parameter that is based, at least in part, on the first estimated loudness and the second estimated loudness.</p></layer>
<layer id = "layer359"><p><b>US20040052384A1:Noise suppression</b><br><b>Independant Claims</b><br>1. An apparatus comprising: a noise variability estimator determining an amount of variability of background noise in a speech-plus-noise signal; and a channel gain generator adjusting a gain applied to the speech-plus-noise signal based on the amount of variability in the background noise.<br>8. An apparatus for noise suppression, the apparatus comprising: a channel signal energy estimator for estimating a total energy of a speech-plus-noise signal; a noise energy estimator for estimating a noise energy of the speech-plus-noise signal; a channel signal-to-noise (SNR) estimator having the noise energy estimate and the total energy estimate as an input and outputting an SNR estimate of the speech-plus-noise signal; a SNR variability estimator for estimating the SNR variability of the speech-plus-noise signal; and a channel gain generator for attenuating the speech-plus-noise signal based on the SNR variability of the speech-plus-noise signal.<br>12. A method for noise suppression, the method comprising the steps of: estimating an amount of variability in background noise in a speech-plus-noise signal; and adjusting a gain applied to the speech-plus noise signal based on the amount of variability in the background noise.</p></layer>
<layer id = "layer360"><p><b>US20050149339A1:Audio decoding apparatus and method</b><br>In a mobile communications system, a mobile station communicates with a first base station operating at a first antenna specific weight factor. While the mobile station is both in a coverage area of the first base station and a coverage area of a second base station, the mobile station transmits a control signal to the second base station which causes the second base station to operate at a second antenna specific weight factor which is the same as the first antenna specific weight factor. The mobile station then communicates with the second base station, operating at the second antenna specific weight factor, to complete a handoff operation.<br><b>Independant Claims</b><br>1. An audio decoding apparatus for decoding a wideband audio signal from a bitstream containing encoded information for a narrowband audio signal, comprising: a bitstream demultiplexer that demultiplexes encoded information from the bitstream; a decoder that decodes a narrowband audio signal from the demultiplexed encoded information; an analysis filter bank that divides the decoded narrowband audio signal into multiple first subband signals; a band expander that generates multiple second subband signals from at least one first subband signal, each second subband signal having a higher frequency band than the frequency band of the first subband signals; an aliasing remover that adjusts a gain of the second subband signal in order to suppress the aliasing components occurring in the second subband signals; and a real-valued calculation synthesis filter bank that synthesizes the first subband signal and second subband signal to obtain a wideband audio signal.<br>2. An audio decoding apparatus for decoding a wideband audio signal from a bitstream containing encoded information for a narrowband audio signal, comprising: a bitstream demultiplexer that demultiplexes encoded information from the bitstream; a decoder that decodes a narrowband audio signal from the demultiplexed encoded information; an analysis filter bank that divides the decoded narrowband audio signal into multiple first subband signals; a band expander that generates multiple second subband signals from at least one first subband signal, each second subband signal having a higher frequency band than the frequency band of the first subband signals; an aliasing detector that detects a degree of occurrence of aliasing components in the multiple second subband signals generated by the band expander; an aliasing remover that adjusts a gain of the second subband signal based on the detected degree of occurrence of aliasing components to suppress the aliasing components; and a real-valued calculation synthesis filter bank that synthesizes the first subband signal and second subband signal to obtain a wideband audio signal.<br>15. An audio decoding method for decoding a wideband audio signal from a bitstream containing encoded information for a narrowband audio signal, comprising: demultiplexing encoded information from the bitstream; decoding a narrowband audio signal from the demultiplexed encoded information; dividing the decoded narrowband audio signal into multiple first subband signals; generating multiple second subband signals from at least one first subband signal, each second subband signal having a higher frequency band than the frequency band of the first subband signals; adjusting a gain of the second subband signal in order to suppress the aliasing components occurring in the second subband signals; and synthesizing the first subband signal and the second subband signal with a real-valued filtering calculation to obtain the wideband audio signal.<br>16. An audio decoding method for decoding a wideband audio signal from a bitstream containing encoded information for a narrowband audio signal, comprising: demultiplexing encoded information from the bitstream; decoding a narrowband audio signal from the demultiplexed encoded information; dividing the decoded narrowband audio signal into multiple first subband signals; generating multiple second subband signals from at least one first subband signal, each second subband signal having a higher frequency band than the frequency band of the first subband signals; detecting a degree of occurrence of aliasing components in each of the generated multiple second subband signals before the second subband signals are generated; adjusting a gain of the second subband signal based on the detected degree of occurrence of aliasing components in order to suppress the aliasing components; and synthesizing the first subband signal and the second subband signal with a real-valued filtering calculation to obtain the wideband audio signal.</p></layer>
<layer id = "layer361"><p><b>US20040078200A1:Noise reduction in subbanded speech signals</b><br>A plurality of electrode bars are arranged in parallel with each other, and side electrode bars are connected to the corresponding opposite ends of the electrode bars, thereby forming a ladder-like RF discharge electrode. Power supply points are arranged axisymmetrically with respect to a reference line, which is a bisector which bisects one side of the RF discharge electrode, while being spaced a predetermined distance from the reference line, thereby suppressing voltage distribution on the ladder electrode, which has an effect on uniformity of discharge distribution, to a sufficiently low level of nonuniformity. Thus, uniform distribution of film deposition rate can be obtained, thereby enabling uniform deposition even in large-area applications.<br><b>Independant Claims</b><br>1. A method for reducing noise in a speech signal, the speech signal including intermittent speech in the presence of noise, the method comprising: receiving the speech signal; estimating a noise floor in the received speech signal; splitting the received speech signal into a plurality of subband signals; determining a subband variable gain for each subband based on the estimated noise floor in the received speech signal and on the subband signals; multiplying each subband signal by the subband variable gain for that subband to produce a scaled subband signal; combining the scaled subband signals to produce an output speech signal; determining the presence of speech in a filtered speech signal; and suspending noise floor estimation during periods when speech is determined to be present in the filtered speech signal.<br>10. A system for reducing noise in an input speech signal, the input speech signal including intermittent speech in the presence of noise, the system comprising: an analysis filter bank accepting the input speech signal, the analysis filter bank comprising a plurality of filters, each filter in the analysis filter bank extracting a subband signal from the speech signal; a plurality of variable gain multipliers, each variable gain multiplier multiplying one subband signal by a subband variable gain to produce a subband product signal; a synthesizer accepting the plurality of subband product signals and generating a reduced noise speech signal; a voice activity detector detecting the presence of speech in the reduced noise speech signal; and gain calculation logic for calculating the subband variable gains, the gain calculation logic operative to: (a) determine a noise floor level based on the input speech signal if the presence of speech is not detected, (b) hold the noise floor level constant if the presence of speech is detected, and (c) determine the subband variable gains based on the noise floor level.<br>13. A system for reducing noise in an input speech signal, the input speech signal including intermittent speech in the presence of noise, the system comprising: an analysis filter bank accepting the input speech signal, the analysis filter bank comprising a plurality of filters, each filter in the analysis filter bank extracting a subband signal from the input speech signal; a plurality of variable gain multipliers, each variable gain multiplier multiplying one subband signal by a subband variable gain to produce a subband product signal; a speech signal synthesizer accepting the plurality of subband product signals and generating a reduced noise speech signal; a plurality of speech detection multipliers, each speech detection multiplier multiplying one subband signal by a speech detection subband gain to produce a detection subband signal; a speech detection synthesizer accepting the plurality of detection subband signals and generating a speech detection signal; a voice activity detector detecting the presence of speech in the speech detection signal; and gain calculation logic generating the subband variable gains based on the detected presence of speech.<br>18. A method of processing a speech signal, the speech signal including intermittent speech in the presence of noise, the method comprising: dividing the speech signal into subbands; multiplying each subband of the speech signal by a subband variable gain; and determining each subband variable gain based on the speech signal and on the presence of speech detected after noise is removed from the speech signal.<br>19. A system for processing a speech signal comprising: means for dividing the speech signal into at least one set of subbands; means for amplifying each subband from a first set of subbands; means for combining the plurality of filtered first set subbands to produce a first filtered speech signal; means for determining the presence of speech based in the first filtered speech signal; means for amplify each subband from a second set of subbands; means for combining the plurality of filtered second set subbands to produce a second filtered speech signal; and means for determining the variable gains based on the detected presence of speech and on the speech signal.</p></layer>
<layer id = "layer362"><p><b>US20050267746A1:Method for interoperation between adaptive multi-rate wideband (AMR-WB) and multi-mode variable bit-rate wideband (VMR-WB) codecs</b><br>Disclosed is a diffusion film comprising a transparent polymeric film base bearing a plurality of integral contiguous layers, each layer having a pattern of complex lenses on a surface thereof, at least two such contiguous layers comprising material having an index of refraction differing by at least 0.1.<br><b>Independant Claims</b><br>1. An interworking function, comprising a unit operable with a source-controlled Variable bit-rate Multi-mode WideBand (VMR-WB) codec providing a mode of operation that is interoperable with an Adaptive Multi-Rate wideband (AMR-WB) codec, where in a VMR-WB encoding/AMR-WB decoding case, speech frames are encoded in an AMR-WB interoperable mode of a VMR-WB encoder using one of bit rates corresponding to Interoperable-Full Rate (I-FR) for active speech frames, Interoperable-Half Rate (I-HR) at least for dim-and-burst signaling, Quarter Rate-Comfort Noise Generator (CNG-QR) to encode at least relevant background noise frames and Eighth Rate-Comfort Noise Generator (CNG-ER) frames for background noise frames not encoded as CNG-QR frames, said interworking function operable such that, invalid frames are transmitted to an AMR-WB decoder as erased frames; I-FR frames are transmitted to the AMR-WB decoder as 12.65, 8.85 or 6.60 kbps AMR-WB frames depending on the I-FR type; CNG-QR frames are transmitted to the AMR-WB decoder as Silence Descriptor Update (SID_UPDATE) frames; CNG-ER frames are transmitted to the AMR-WB decoder as NO_DATA frames; and I-HR frames are translated to 12.65, 8.85, or 6.60 kbps frames, depending on the frame type, by generating missing algebraic codebook indices, where bits indicating the I-HR type are discarded.</p></layer>
<layer id = "layer363"><p><b>US20040083095A1:Method and apparatus for coding a noise-suppressed audio signal</b><br>In a headlight optical axis adjusting apparatus and method for a vehicle, the shape of a road in front of the vehicle is detected by a CCD camera based on a change in lane marking line which indicates the lane width on the road, before the steering angle of a vehicle steering wheel is detected by a steering angle sensor. Left and right swivel lights of the vehicle are swiveled and adjusted based on the change in the lane marking line or the steering angle. The optical axis of the left or right swivel light is first swiveled and adjusted based on the change in the lane marking line. The driver's forward visibility can thus be improved before the driver turns the steering wheel.<br><b>Independant Claims</b><br>1. A method comprising the steps of: filtering a first frame of data to produce a filtered first frame; combining a portion of the filtered first frame with an unfiltered portion of a second frame to produce a combined portion; and substituting the combined portion for the portion of the filtered first frame.<br>5. A method for coding a noise-suppressed signal, the method comprising the steps of: performing noise suppression on a first frame of data to produce a noise-suppressed first frame; overlapping and adding a portion of the noise-suppressed first frame with a non-noise suppressed portion of a second frame to produce a combined portion; substituting the combined portion for the portion of the noise-suppressed first frame; and performing linear predictive coding (LPC) on the noise-suppressed first frame containing the combined portion.<br>6. An apparatus comprising: a filter having a first frame of data as an input and outputting a filtered first frame; a signal combiner having a portion of the filtered first frame as an input and a portion of an unfiltered second frame as an input and outputting a combined portion, wherein the combined portion comprises an addition of the portion of the filtered first frame with the portion of the unfiltered second frame; and a buffer storing the filtered first frame having the combined portion substituted for the portion of the filtered first frame.</p></layer>
<layer id = "layer364"><p><b>US8121847B2:Communication terminal with a parameterised bandwidth expansion, and method for the bandwidth expansion thereof</b><br>A method and apparatus for processing enhanced uplink data is disclosed. A request for uplink resources is transmitted, wherein the request for uplink resources is a request to transmit data over an enhanced dedicated channel (E-DCH). An uplink scheduling grant is received in response to the request for uplink resources. Data from medium access control for dedicated channel (MAC-d) flows is multiplexed into a medium access control for enhanced uplink (MAC-e) protocol data unit (PDU). A transport format combination (TFC) is selected for transmission of the MAC-e PDU. The MAC-e PDU is transmitted over the E-DCH using an identified hybrid automatic repeat request (H-ARQ) process. Feedback information is received in response to the transmitted MAC-e PDU. The MAC-e PDU is retransmitted using the identified H-ARQ process on a condition that the feedback information indicates a negative acknowledgment (NACK) of the MAC-e PDU transmission.<br><b>Independant Claims</b><br>1) A communication device, comprising: a bandwidth expansion device for expanding a bandwidth of a narrowband speech signal at its low-frequency and/or high-frequency end by synthesis of at least one frequency band contained within said narrowband speech signal, the narrowband speech signal having at least two net bit rates; and a memory unit, communicatively coupled to said bandwidth expansion device, wherein said memory unit stores a reference table that includes at least one parameter value used for the bandwidth expansion for the at least two net bit rates of the narrowband speech signal, wherein the reference table takes account, as parameters, of an amount of energy in a synthesized frequency band and of a spectral structure of the synthesized frequency band, and wherein the spectral structure of the synthesized frequency band takes account of a probability of occurrences of artifacts at specific frequencies in the narrowband speech signal.<br>2) A method for expanding a bandwidth of a narrowband speech signal for a communication terminal, the method comprising: a) detecting a net bit rate of the narrowband speech signal for the communication terminal; accessing a memory that includes a reference table, the reference table including associations between at least two net bit rates and parameter values used for bandwidth expansion, in order to determine the at least one parameter value which is suitable for the detected net bit rate, wherein the reference table takes account, as parameters, of an amount of energy of a synthesized frequency band, and a spectral structure of the synthesized frequency band, and wherein the spectral structure of the synthesized frequency band takes account of a probability of occurrences of artifacts at specific frequencies in the narrowband speech signal; and c) expanding the bandwidth by means of a bandwidth expansion device on the basis of the parameters determined for the detected net bit rate in step b).</p></layer>
<layer id = "layer365"><p><b>US8315860B2:Interoperable vocoder</b><br>A radio-frequency (RF) apparatus, which may reside in a receiver or transceiver, includes receive-path circuitry. The receive-path circuitry includes a poly-phase filter and a harmonic filter. The poly-phase filter accepts an input signal and generates two output signals. One output signal of the poly-phase filter constitutes an in-phase (I) signal. The other output signal of the poly-phase filter constitutes a quadrature (Q) signal. The a harmonic filter couples to the poly-phase filter. The harmonic filter accepts as input signals the in-phase and quadrature output signals of the poly-phase filter.<br><b>Independant Claims</b><br>1) A speech coder configured to encode a sequence of digital speech samples into a bit stream, the speech coder being operable to: divide the digital speech samples into one or more frames; compute model parameters for multiple frames, the model parameters including at least a first parameter conveying pitch information; determine the voicing state of a frame; modify the first parameter conveying pitch information to designate the determined voicing state of the frame if the determined voicing state of the frame is equal to one of a set of multiple reserved voicing states; and quantize the model parameters to generate quantizer bits which are used to produce the bit stream.<br>31) A speech decoder configured to decode digital speech samples from a sequence of bits, the speech decoder being operable to: divide the sequence of bits into individual frames that each contain multiple bits; reconstruct speech model parameters from a frame of bits, the reconstructed speech model parameters for a frame including one or more spectral parameters representing the spectral magnitude information for the frame; determine from the reconstructed speech model parameters whether the frame represents a tone signal; modify the spectral parameters if the frame represents a tone signal, such that the modified spectral parameters better represent the spectral magnitude information of the determined tone signal; and generate digital speech samples from the reconstructed speech model parameters and the modified spectral parameters.<br>24) A speech decoder configured to decode digital speech samples from a sequence of bits, the speech decoder being operable to: divide the sequence of bits into individual frames, each frame containing multiple bits; form quantizer values from a frame of bits, the formed quantizer values including at least a first quantizer value representing the pitch and a second quantizer value representing the voicing state; determine if the first and second quantizer values belong to a set of multiple reserved quantizer values; reconstruct speech model parameters for a frame from the quantizer values, the speech model parameters representing the voicing state of the frame being reconstructed from the first quantizer value representing the pitch if the first and second quantizer values are determined to belong to the set of reserved quantizer values; and compute a set of digital speech samples from the reconstructed speech model parameters.<br>17) A speech coder configured to encode a sequence of digital speech samples into a bit stream, the speech coder being operable to: divide the digital speech samples into one or more frames; determine whether the digital speech samples for a frame correspond to a tone signal; and compute model parameters for multiple frames, the model parameters including at least a first parameter representing the pitch and spectral parameters representing the spectral magnitude at harmonic multiples of the pitch; if the digital speech samples for a frame are determined to correspond to a tone signal, assign values to the pitch parameter and the spectral parameters to approximate the detected tone signal; and quantize the model parameters, including the pitch parameter and the spectral parameters to which values are assigned to approximate the detected tone signal if the digital speech samples for the frame are determined to correspond to the tone signal, to generate quantizer bits which are used to produce the bit stream.</p></layer>
<layer id = "layer366"><p><b>US20050256709A1:Band extending apparatus and method</b><br>Methods and apparatuses to provide advertising based on pre-computed sub-playlists are described. The sub-playlists are generated based on one or more demographic characteristics. One or more sub-playlists are used to generate a playlist for a particular user or group of users. In one embodiment, the sub-playlists are generated at a network operations center or other location remote from the device on which the ultimate playlist is displayed; however, the sub-playlists can be generated locally or on a local network device. One or more sub-playlists corresponding to the demographic characteristics of a device user or group of users are combined to provide a playlist for the user or group of users. The playlist is displayed to the user or group of users.<br><b>Independant Claims</b><br>1. A band extending apparatus receiving at least an input signal of a preset frequency band to output a band extended signal corresponding to said input signal extended in a frequency band thereof, said apparatus comprising: a spectral parameter calculating unit for calculating spectral parameters representing spectrum characteristics of said input signal of said preset frequency band; a noise generating circuit for generating a noise signal; and a coefficient calculating unit for shifting the frequency of said spectral parameters to then find filter coefficients; said band extended signal being generated based on said noise signal, filer coefficients and said input signal.<br>2. A band extending apparatus comprising: a spectral parameter calculating unit, receiving at least an input signal of a preset frequency band to calculate spectral parameters representing spectral characteristics; a noise generating unit for generating a noise signal; a coefficient calculating unit for shifting the frequency of said spectral parameters to then find filter coefficients; a gain unit for supplying a gain to an output of said noise generating unit; a synthesis filter unit for passing an output signal of said gain unit through a synthesis filter, formed using said filter coefficients, to reproduce a signal for band extension; and means for adding a signal corresponding to said input signal converted in a sampling frequency thereof to an output signal of said synthesis filter unit to generate a band extended signal.<br>4. A band extending apparatus comprising: a spectral parameter calculating unit, receiving at least an input signal of a preset frequency band to calculate spectral parameters representing spectral characteristics; an adaptive codebook unit, calculating a pitch period at least from said input signal to generate an adaptive codebook component based on said pitch period and a past sound source signal; a noise generating unit for generating a noise signal; a coefficient calculating unit for shifting the frequency of said spectral parameters to find filter coefficients; a gain unit for supplying a gain to at least one of an output signal of said noise generating unit and an output signal of said adaptive codebook unit, and for summing the output signals to output a sound source signal; a synthesis filter unit, receiving said sound source signal from said gain unit to a synthesis filter formed using said filter coefficients to reproduce a signal for band extension; and means for summing a signal corresponding to said input signal converted in a sampling frequency thereof to an output signal of said synthesis filter unit to produce a band extended signal.<br>6. A band extending apparatus comprising: a spectral parameter calculating unit, receiving at least with an input signal of a preset frequency band to calculate spectral parameters representing spectral characteristics; an adaptive codebook unit for calculating a pitch period at least from said input signal to generate an adaptive codebook component based on said pitch period and past sound source signal; a noise generating unit for generating a noise signal; a coefficient calculating unit for shifting the frequency of said spectral parameters to then find filter coefficients; a gain unit for supplying a gain to at least one of an output of said noise generating unit and an output signal of said adaptive codebook unit and for summing the resulting signals to output a sound source signal; a pitch pre-filter for filtering said sound source signal from said gain unit, using said pitch period; a synthesis filter unit for supplying an output signal of said pitch pre-filter to a synthesis filter formed using said filter coefficients to generate band-expanding signal; and means for summing a signal corresponding to said input signal converted in a sampling frequency thereof to an output signal of said synthesis filter unit to generate a band extended signal.<br>8. A band extending apparatus comprising: a spectral parameter calculating unit, receiving at least with an input signal of a preset frequency band to calculate spectral parameters representing spectral characteristics; a pitch generating unit, calculating a pitch period at least from said input signal to generate a period signal using said pitch period; a noise generating unit for generating a noise signal; a coefficient calculating unit for shifting the frequency of said spectral parameters to find filter coefficients; a gain unit for supplying a proper gain to at least one of an output signal of said noise generating unit and an output signal of said pitch generating unit, and for summing the resulting output signals to output a sound source signal; a synthesis filter unit, receiving said sound source signal from said gain unit to a synthesis filter, formed using said filter coefficients, to reproduce a signal for band extension; and means for summing a signal corresponding to said input signal converted in a sampling frequency thereof to an output signal of said synthesis filter unit, to produce a band extended signal.<br>10. A band extending apparatus comprising: a spectral parameter calculating unit, receiving at least an input signal of a preset frequency band to calculate spectral parameters representing spectral characteristics; a pitch generating unit for calculating a pitch period at least from said input signal to generate a period signal using said pitch signal; a noise generating unit for generating a noise signal; a coefficient calculating unit for shifting the frequency of said spectral parameters to then find filter coefficients; a gain unit for supplying a gain to at least one of an output signal of said noise generating unit and an output signal of said pitch generating unit and for summing the resulting output signals to output a sound source signal; a pitch pre-filter for filtering said sound source signal from said gain unit, using said pitch period; a synthesis filter unit, receiving an output signal of said pitch pre-filter to reproduce a signal for band extension; and means for summing a signal corresponding to said input signal converted in a sampling frequency thereof to an output signal of said synthesis filter unit to obtain a band extended signal.<br>20. A band extending method in which at least an input signal of a preset band is input and the frequency range of said input signal is extended, said method comprising: calculating spectral parameters representing spectral characteristics of the input signal of said preset band entered; shifting the frequency of said spectral parameters and then finding filter coefficients; generating a noise signal; and generating a band extended signal, using said noise signal and said filter coefficients, generated in said steps, and the input signal.<br>21. A band extending method comprising: receiving at least an input signal of a preset frequency band to calculate spectral parameters representing spectral characteristics; shifting the frequency of said spectral parameters to then find filter coefficients; supplying a gain to a noise signal generated by a noise generating unit; passing a signal, added by said gain, through a synthesis filter, formed using said filter coefficients, to reproduce a signal for band extension; and summing a signal corresponding to said input signal converted in a sampling frequency thereof to an output signal of said synthesis filter unit to generate a band extended signal.<br>23. A band extending method comprising: receiving at least an input signal of a preset frequency band to calculate spectral parameters representing spectral characteristics; calculating a pitch period at least from said input signal to generate an adaptive codebook component based on said pitch period and a past sound source signal; shifting the frequency of said spectral parameters to find filter coefficients; supplying a gain to at least one of a noise signal from a noise generating unit and to said adaptive codebook component and for summing the resulting output signals to output a sound source signal; receiving said sound source signal from said gain unit to a synthesis filter formed using said filter coefficients to reproduce a signal for band extension; and summing a signal corresponding to said input signal converted in a sampling frequency thereof to an output signal of said synthesis filter unit to obtain a band extended signal.<br>25. A band extending method comprising: receiving at least an input signal of a preset frequency band to calculate spectral parameters representing spectral characteristics; calculating a pitch period at least from said input signal to generate an adaptive codebook component based on said pitch period and the past sound source signal; shifting the frequency of said spectral parameters to then find filter coefficients; supplying a gain to at least one of a noise signal from a noise generating unit and said adaptive codebook component and for summing the resulting signals to output a sound source signal; pre-filtering said sound source signal, using said pitch period; supplying the results of processing of said pitch pre-filter to a synthesis filter formed using said filter coefficients to generate a signal for band extension; and summing a signal corresponding to said input signal converted in a sampling frequency thereof to an output signal of said synthesis filter unit to generate a band extended signal.<br>27. A band extending method comprising: receiving at least an input signal of a preset frequency band to calculate spectral parameters representing spectral characteristics; calculating a pitch period at least from said input signal to generate a period signal using said pitch period; shifting the frequency of said spectral parameters to find filter coefficients; supplying a gain to at least one of a noise signal of said noise generating unit and said period signal and for summing the resulting output signals to output a sound source signal; receiving said sound source signal to a synthesis filter formed using said filter coefficients to reproduce a signal for band extension; and summing a signal, corresponding to said input signal converted in a sampling frequency thereof to an output signal of said synthesis filter unit to obtain a band extended signal.<br>29. A band extending method comprising: receiving at least an input signal of a preset frequency band and calculating spectral parameters representing spectral characteristics; calculating a pitch period at least from said input signal to generate a period signal using said pitch signal; shifting the frequency of said spectral parameters to then find filter coefficients; supplying a gain to at least one of an output signal of said noise generating unit and said pitch signal and for summing the resulting output signals to output a sound source signal; pre-filtering said sound source signal using said pitch period; receiving a signal representing the result of processing by said pitch pre-filter to a synthesis filter formed using said pitch period to reproduce a signal for band extension; and summing a signal corresponding to said input signal converted in a sampling frequency thereof to an output signal of said synthesis filter unit to produce a band extended signal.</p></layer>
<layer id = "layer367"><p><b>US20040101038A1:Systems and methods for far-end noise reduction and near-end noise compensation in a mixed time-frequency domain compander to improve signal quality in communications systems</b><br><b>Independant Claims</b><br>1. A noise-adaptive compander adapted to amplify a far-end signal, which comprises a plurality of subbands, based on a near-end noise estimate of a near-end signal, comprising: a master gain unit operable for generating a master gain value for each subband; a scaling unit operable for creating a scaled master gain value by applying a scaling factor to the master gain value for each subband; a combiner operable for combining the scaled master gain for each subband of the far-end signal with the far-end signal; a synthesis filter bank operable for receiving the output of the combiner unit and generating a full-band signal; a limiter unit operable for reducing peaks in the full-band signal; and a reverse scaling unit operable for creating a modified far-end signal by multiplying the full-band signal with the scaling factor.<br>22. A method of amplifying a far-end signal, which comprises a plurality of subbands, based on a near-end noise level estimate, comprising: selecting a master gain value for each subband; applying a scaling factor to the master gain value for each frequency component in the far-end signal to create a scaled master gain value; combining the selected minimum gains for each subband of the far-end signal with the far-end signal; receiving the output of the combiner unit and generating a single far-end signal; reducing peaks in the modified far-end signal; and amplifying the modified far-end signal by multiplying the modified far-end signal with the scaling factor.<br>29. A method of coupling a noise reduction gain to a noise compensation gain to avoid cross modulation, comprising: calculating a total gain value from a near-end signal; setting a linear range of the noise compensation gain using the total gain value; and setting a maximum noise reduction gain value such that the sum of the maximum noise reduction gain value and the total gain value equals a predefined value.</p></layer>
<layer id = "layer368"><p><b>US6745162B1:System and method for bit allocation in an audio encoder</b><br>An insect trap using attractant light, comprising a source of insect attractant light and a housing that can be mounted on a generally planar or flat mounting surface. The housing and the source of light cooperate to form a bidirectional or a multidirectional (overlapping or non-overlapping) pattern of insect attractant light. The housing comprises one, two or more openings for the insect attractant light that is reflected and radiated onto the flat mounting surface. The housing and the source of insect attractant light can cooperate to form a light pattern directed in a continuous display pattern that can surround the housing. The housing openings further facilitate the entry of flying insect pests into the trap. As the insects enter the trap, they are immobilized on an insect immobilization surface mounted within the trap. Cooperation between direct radiant light, reflected light and the position of the housing and insect immobilization surface forms at least two (preferably non-overlapping) light displays that can substantially increase capture rates when compared to prior traps. The trap can also display a light pattern substantially surrounding the trap housing.<br><b>Independant Claims</b><br>1) A method for allocating bits in an audio encoder system for encoding frames of input audio data, the method comprising: filtering the input audio data into sub-bands in a first frame; generating a masking threshold for each of the sub-bands in the first frame; and determining if a pre-bit allocation process will be implemented by cumulatively comparing corresponding sub-band signal to masking ratios in successive frames, wherein the determining comprises obtaining the difference of signal to masking ratios in corresponding sub-bands in a plurality of frames and determining whether the difference of signal to masking ratios exceeds a predetermined threshold.<br>10) A method for allocating bits in an audio encoder system for encoding frames of input audio data, the method comprising: filtering the input audio data into sub-bands in a first frame; generating a masking threshold for each of the sub-bands in the first frame; and determining if a pre-bit allocation process will be implemented by cumulatively comparing corresponding sub-band signal to masking ratios in successive frames, wherein the determining includes computing the difference between successive sub-band signal to masking ratios, and filtering said difference using a low-pass filter.<br>13) A method allocating bits in an audio compression system, the method comprising: filtering input audio data frames into sub-bands; passing the input filtered audio data through a modeler; generating a masking threshold for each sub-band as the filtered audio data is passed through the modeler; calculating the signal to masking ratios of successive sub-bands; and determining if a pre-bit allocation process will be implemented by cumulatively comparing corresponding sub-band signal to masking ratios in successive frames, wherein the determining includes computing the difference between successive sub-band signal to masking ratios, and filtering said difference using a low-pass filter.<br>20) A method for allocating bits in an audio encoder system for encoding frames of input audio data, the method comprising: filtering the input audio data into sub-bands; generating a masking threshold for each of the sub-bands; calculating a signal to masking ratio using the masking threshold generated for each sub-band; computing a difference between successive sub-band signal to masking ratios; determining if a pre-bit allocation process will be implemented by cumulatively comparing corresponding sub-band signal to masking ratios in successive frames; computing a bit release time based on the difference between the signal to masking ratios of successive sub-bands, wherein the bit release time computing includes computing a bit release time proportional to the absolute value of the difference between the signal to masking ratios of successive sub-bands.<br>22) An audio encoder system for input audio data frames comprising: a filter which filters the input audio data frames into sub-bands; a psycho-acoustic modeler which generates a masking threshold for each sub-band and calculates the signal to masking ratio for the sub-bands; a comparator for determining if a pre-bit allocation process will be implemented by cumulatively comparing corresponding sub-band signal to masking ratios in successive frames; and a bit allocator which assigns or not assigns pre-bit allocation to each sub-band based on a comparison of signal to masking ratios of successive sub-bands, wherein the bit allocator calculates the difference between the signal to masking ratios of successive sub-bands, and includes a low-pass filter for filtering said difference.<br>23) An audio encoder system for input audio data frames comprising: a filter which filters the input audio data frames into sub-bands; a psycho-acoustic modeler which generates a masking threshold for each sub-band and calculates the signal to masking ratio for the sub-bands; a comparator for determining if a pre-bit allocation process will be implemented by cumulatively comparing corresponding sub-band signal to masking ratios in successive frames; and a bit allocator which assigns or not assigns pre-bit allocation to each sub-band based on a comparison of signal to masking ratios of successive sub-bands, wherein the bit allocator computes a bit release time based on the difference between the signal to masking ratios of successive sub-bands.</p></layer>
<layer id = "layer369"><p><b>US8244525B2:Signal encoding a frame in a communication system</b><br>Alpha-helix mimetic structures and compounds represented by the formula (I) wherein the general formula and the definition of each symbol are as defined in the specification, a compound relating thereto, and methods relating thereto, are disclosed. Applications of these compounds in the treatment of medical conditions, e.g., cancer diseases, fibrotic diseases, and pharmaceutical compositions comprising the mimetics are further disclosed.<br><b>Independant Claims</b><br>1) A method comprising: calculating, in an encoder, a first set of parameters associated with at least one frame of a received signal, wherein said first set of parameters comprises parameters based on energy levels of a plurality of frequency bands associated with the at least one frame; selecting, in a first stage, one of algebraic code excited linear prediction excitation, transform coding excitation or an uncertain mode based at least in part on predetermined conditions associated with the first set of parameters; calculating a second set of parameters associated with the at least one frame; selecting, in a second stage, one of algebraic code excited linear prediction excitation and transform coding excitation based at least in part on the second set of parameters and whether in the first stage the uncertain mode is selected; and encoding the frame using the selected one of algebraic code excited linear prediction excitation and the transform coding excitation from the second stage.<br>19) An apparatus comprising: at least one processor; and at least one memory including computer program code, the at least one memory and the computer program code configured to, with the at least one processor, cause the apparatus at least to calculate a first set of parameters associated with at least one frame of a received signal, wherein said first set of parameters comprises parameters based on energy levels of a plurality of frequency bands associated with the at least one frame; select, in a first stage, one of algebraic code excited linear prediction excitation, transform coding excitation or an uncertain mode based at least in part on predetermined conditions associated with the first set of parameters; calculate a second set of parameters associated with the at least one frame; select, in a second stage, one of algebraic code excited linear prediction excitation and transform coding excitation based at least in part on the second set of parameters and whether in the first stage the uncertain mode is selected; and encode the frame using the selected one of algebraic code excited linear prediction excitation and the transform coding excitation from the second stage.<br>36) A terminal comprising: at least one processor; and at least one memory including computer program code, the at least one memory and the computer program code configured to, with the at least one processor, cause the apparatus at least to calculate a first set of parameters associated with at least one frame of a received signal, wherein said first set of parameters comprises parameters based on energy levels of a plurality of frequency bands associated with the at least one frame; select, in a first stage, one of algebraic code excited linear prediction excitation, transform coding excitation or an uncertain mode based at least in part on predetermined conditions associated with the first set of parameters; calculate a second set of parameters associated with the at least one frame; select, in a second stage, one of algebraic code excited linear prediction excitation and transform coding excitation based at least in part on the second set of parameters and whether in the first stage the uncertain mode is selected; and encode the frame using the selected one of algebraic code excited linear prediction excitation and the transform coding excitation from the second stage.<br>40) A computer program, embodied on a non-transitory computer readable medium, said computer program being configured to control a processor to perform a method comprising: calculating a first set of parameters associated with at least one frame of a received signal, wherein said first set of parameters comprises parameters based on energy levels of a plurality of frequency bands associated with the at least one frame; selecting, in a first stage, one of algebraic code excited linear prediction excitation, transform coding excitation or an uncertain mode based at least in part on predetermined conditions associated with the first set of parameters; calculating a second set of parameters associated with the at least one frame; selecting, in a second stage, one of algebraic code excited linear prediction excitation and transform coding excitation based at least in part on the second set of parameters and whether in the first stage the uncertain mode is selected; and encoding the frame using the selected one of algebraic code excited linear prediction excitation and the transform coding excitation from the second stage.<br>42) An apparatus comprising: first calculating means for calculating a first set of parameters associated with at least one frame of the received signal, wherein said first set of parameters comprises parameters based on energy levels of a plurality of frequency bands associated with the at least one frame; first selecting means for selecting one of algebraic code excited linear prediction excitation, transform coding excitation or an uncertain mode based at least in part on predetermined conditions associated with the first set of parameters; second calculating means for calculating a second set of parameters associated with the at least one frame; second selecting means for selecting one of algebraic code excited linear prediction excitation and transform coding excitation based at least in part on the second set of parameters and whether in the first stage the uncertain mode is selected; and encoding means for encoding the frame using the selected one of algebraic code excited linear prediction excitation and the transform coding excitation from the second selecting means.</p></layer>
<layer id = "layer370"><p><b>US8150685B2:Method for high quality audio transcoding</b><br>After a vitreous gel of an eyeball is liquefied, a choroid is exposed; a vitreous humor is sucked to decrease a pressure in a vitreous body; a pocket is formed in the choroid; and then an implant is inserted into the pocket.<br><b>Independant Claims</b><br>1) A method for producing a destination codec bitstream in a destination codec from a source codec bitstream in a source codec, by a transcoder comprising a processor, the method comprising: determining if a pass through is to be performed; if the pass through is to be performed, outputting the source codec bitstream as the destination codec bitstream; if the pass through is not to be performed, outputting the destination codec bitstream in the destination codec, wherein outputting the destination codec bitstream comprises: determining if a linear prediction analysis is to be performed; and determining if an analysis-by-synthesis search for one or more excitation parameters is to be performed.</p></layer>
<layer id = "layer371"><p><b>US20040153316A1:Voice transcoder</b><br>An operator for controlling the movement of a window sash relative to a frame with a raised surface along a frame sill thereof, wherein the operator includes a base having a first support surface, an aperture and a bottom exterior surface with a slot therein, the base attached to the frame with the raised surface fitting substantially within the slot. The operator also includes a cover secured to the base and having a second support surface with a hole therethrough defining an internal shoulder, the second support surface mating with the first support surface. A post extends from the cover and through the aperture in the base when the operator is assembled. An arm is pivotally secured to the post and attachable to the sash to control the movement of the sash between open and closed positions. A worm drivably engages the arm and has a worm shaft and a worm shoulder disposed on the worm shaft. The worm is directly supported by the first and second surfaces at one end and the worm shoulder engages the internal shoulder as the worm shaft protruding from the hole. Also a method for manufacturing the operator includes the steps of passing the worm shaft through the hole with the worm shoulder engaging the internal shoulder and the worm disposed against the first support surface, fitting the arm to central post, the arm in drivable engagement with the worm, placing the base and the cover together with the worm disposed between the first and second support surfaces and the central post and the plurality of fastener posts protruding through the plurality of apertures, forming the central post, controlling the time and force applied in the central post forming step to eliminate the axial play along the central post, and securing the plurality of fastener posts.<br><b>Independant Claims</b><br>1. A method of transcoding first encoded voice bits into second encoded voice bits, the method comprising: dividing the first encoded voice bits into one or more received frames, with each received frame containing multiple ones of the first encoded voice bits; computing first parameter bits for at least one of the received frames by applying error control decoding to one or more of the encoded voice bits contained in the received frame; computing speech parameters from the first parameter bits; quantizing the speech parameters to produce second parameter bits; forming a transmission frame by applying error control encoding to one or more of the second parameter bits; and including the transmission frame in the second encoded voice bits.<br>28. A method for converting a sequence of first encoded voice bits into a sequence of second encoded voice bits, the method comprising: dividing the sequence of first voice bits into one or more input frames, with each of the input frames containing multiple ones of the first voice bits; reconstructing speech parameters for one or more of the input frames, wherein the speech parameters reconstructed for a previous frame are stored and used during reconstruction of the speech parameters for a later frame; processing the speech parameters to produce an output frame of bits; and combining one or more of the output frames to form a sequence of second encoded voice bits.</p></layer>
<layer id = "layer372"><p><b>US20040158461A1:Class quantization for distributed speech recognition</b><br>An adjustment mechanism for a clutch. The adjustment mechanism includes an annular adjustment structure having an adjustment profile with a ramp section, a first adjustment segment, a last adjustment segment and a plurality of intermediate adjustment segments. The first adjustment segment is configured to correspond to a first clutch setting and the last adjustment segment is configured to correspond to a last clutch setting. The ramp section is positioned between the first and last adjustment segments such that the adjustment structure is rotatable between the first and last adjustment segments and between the last and first adjustment segments without engaging any of the intermediate adjustment segments.<br><b>Independant Claims</b><br>1. A method on an information processing system for quantizing class information and pitch information of audio, comprising: receiving audio; capturing a frame of the audio; determining a pitch of the frame; calculating a codeword representing the pitch of the frame, wherein a first codeword value indicates an indefinite pitch; determining a class of the frame, wherein the class is any one of at least two classes indicating an indefinite pitch and at least one class indicating a definite pitch; and calculating a codeword representing the class of the frame, wherein the codeword length is the maximum of the minimum number of bits required to represent the at least two classes indicating an indefinite pitch and the minimum number of bits required to represent the at least one class indicating a definite pitch, wherein the pitch and the class of the frame are represented by the two codewords.<br>9. An information processing system for quantizing class information and pitch information of audio, comprising: a microphone for receiving audio; and a digital signal processor for capturing a frame of the audio, determining a pitch of the frame, calculating a codeword representing the pitch of the frame, wherein a first codeword value indicates an indefinite pitch, determining a class of the frame, wherein the class is any one of at least two classes indicating an indefinite pitch and at least one class indicating a definite pitch and calculating a codeword representing the class of the frame, wherein the codeword length is the maximum of the minimum number of bits required to represent the at least two classes indicating an indefinite pitch and the minimum number of bits required to represent the at least one class indicating a definite pitch, wherein the pitch and the class of the frame are represented by the two codewords.<br>17. A method in a distributed speech recognition system, the method comprising: receiving audio; organizing the received audio into frames; quantizing audio pitch information for each frame, wherein the quantized audio pitch information for each frame being represented by one of a plurality of quantized pitch values; and quantizing class information for each frame, wherein the quantized class information for each frame being represented by one of a plurality of quantized class values, and wherein one of the plurality of quantized pitch values being reserved to indicate whether the quantized class information for each frame is one of a not voiced class category and a voiced class category, the quantized class value for each frame being selected from one of the not voiced class category and the voiced class category.</p></layer>
<layer id = "layer373"><p><b>US20060198542A1:Method for the treatment of compressed sound data for spatialization</b><br>A method of synchronizing a watermark decoder with a watermark encoder uses a spatio-temporal (3D) synchronization pattern added to a data pattern to produce a watermark pattern for embedment into a signal. The spatio-temporal synchronization pattern is formed by multiplying a spatial (2D) synchronization pattern with a pseudo-noise sequence for a block of signal frames having a duration of N frames. Quadrature carrier modulation may be used to increase detectability of the watermark pattern at the watermark decoder. The watermarked signal is correlated with the spatial synchronization pattern to recover a temporal synchronization signal that is used to determine a temporal offset between the watermark encoder and watermark decoder. The temporal offset is then used to synchronize the watermark decoder with the watermark encoder. Once synchronized various applications may be implemented using the spatial synchronization pattern, and error correction may be applied to the data pattern as well as the addition of a low data rate channel using Walsh codes.<br><b>Independant Claims</b><br>1. A method of processing sound data, for spatialized restitution of acoustic signals, in which: a) at least one first set and one second set of weighting terms, representative of a direction of perception of said acoustic signal by a listener, are obtained for each acoustic signal; and b) said acoustic signals are applied to at least two sets of filtering units, disposed in parallel, so as to deliver at least a first output signal and a second output signal each corresponding to a linear combination of the acoustic signals weighted by the collection of weighting terms respectively of the first set and of the second set and filtered by said filtering units, wherein: each acoustic signal in step a) is at least partially compression-coded and is expressed in the form of a vector of subsignals associated with respective frequency subbands, and each filtering unit is devised so as to perform a matrix filtering applied to each vector, in the frequency subband space.<br>2. (canceled)<br>3. (canceled)<br>4. (canceled)<br>5. (canceled)<br>6. (canceled)<br>7. (canceled)<br>8. (canceled)<br>9. (canceled)<br>10. (canceled)<br>11. (canceled)<br>12. (canceled)<br>13. (canceled)<br>14. (canceled)<br>15. (canceled)<br>16. (canceled)<br>17. (canceled)<br>18. (canceled)<br>26. A processing sound data system, for spatialized restitution of acoustic signals, comprising: means for obtaining, for each acoustic signal, at least one first set and one second set of weighting terms, representative of a direction of perception of said acoustic signal by a listener; and at least two sets of filtering units, which said acoustic signals are applied to, said sets of filtering units being disposed in parallel, so as to deliver at least a first output signal and a second output signal each corresponding to a linear combination of the acoustic signals weighted by the collection of weighting terms respectively of the first set Cni and of the second set Dni and filtered by said filtering units, wherein: said each acoustic signal is at least partially compression-coded and is expressed in the form of a vector of subsignals associated with respective frequency subbands, and each filtering unit is devised so as to perform a matrix filtering applied to each vector, in the frequency subband space.</p></layer>
<layer id = "layer374"><p><b>US8595002B2:Half-rate vocoder</b><br>A verification device transmits challenge information to a first entity device, and for each authentication context received in return, verifies that challenge information identical to the challenge information transmitted in advance is described, to thereby confirm that the authentication context is the current one. As a result, a repetitive attack in which the past authentication context is repeatedly used is prevented and the security against repetitive attacks is improved.<br><b>Independant Claims</b><br>53) A speech decoder configured to decode digital speech samples from a bit stream, the speech decoder being operable to: divide the bit stream into one or more frames of bits; extract a first FEC (“forward error control”) codeword from a frame of bits; error control decode the first FEC codeword to produce a first parameter codeword; use the first parameter codeword to determine whether the frame of bits corresponds to a tone signal; extract tone amplitude bits from the first parameter codeword if the frame of bits is determined to correspond to a tone signal, otherwise extract pitch bits, voicing bits, and gain bits from the first codeword if the frame of bits is determined to not correspond to a tone signal, the extracted pitch bits, voicing bits and gain bits including less than all of a set of quantizer bits for the frame; and use either the tone amplitude bits or the pitch bits, voicing bits and gain bits to compute digital signal samples.<br>65) A speech decoder configured to decode a frame of bits into speech samples, the speech decoder being operable to: determine the number of bits in the frame of bits; extract spectral bits from the frame of bits; use one or more of the spectral bits to form a spectral codebook index, wherein the index is determined at least in part by the number of bits in the frame of bits; reconstruct spectral information using the spectral codebook index; and compute speech samples using the reconstructed spectral information.<br>1) A speech coder configured to encode a sequence of digital speech samples into a bit stream, the speech coder being operable to: divide the digital speech samples into one or more frames; compute model parameters for a frame; quantize the model parameters to produce pitch bits conveying pitch information, voicing bits conveying voicing information, and gain bits conveying signal level information, wherein the pitch bits, the voicing bits and the gain bits are included in quantizer bits for the frame; combine one or more of the pitch bits with one or more of the voicing bits and one or more of the gain bits to create a first parameter codeword that includes less than all of the quantizer bits for the frame; encode the first parameter codeword with an error control code to produce a first FEC (“forward error control”) codeword; and include the first FEC codeword in a bit stream for the frame.<br>42) A speech decoder configured to decode digital speech samples from a bit stream, the speech decoder being operable to: divide the bit stream into one or more frames of bits; extract a first FEC (“forward error control”) codeword from a frame of bits; error control decode the first FEC codeword to produce a first parameter codeword; extract pitch bits, voicing bits and gain bits from the first parameter codeword, the extracted pitch bits, voicing bits and gain bits including less than all of a set of quantizer bits for the frame; use the extracted pitch bits to at least in part reconstruct pitch information for the frame; use the extracted voicing bits to at least in part reconstruct voicing information for the frame; use the extracted gain bits to at least in part reconstruct signal level information for the frame; and use the reconstructed pitch information, voicing information and signal level information for one or more frames to compute digital speech samples.</p></layer>
<layer id = "layer375"><p><b>US6782365B1:Graphic interface system and product for editing encoded audio data</b><br>An improved vibrating actuator for notifying the user of a call upon signal arrival by any of a buzzer, a speech and a vibration, and a power supply mechanism thereof. The device has high impact resistance by a magnetic yoke having a flange, a damper material is provided between an oscillation plate and a cover to prevent generation of noise, and a hole is provided in the cover to change acoustic characteristics as required within the same frequency band. As a power supply mechanism for ensuring electrical connection, a projecting electrical connection terminal is provided on the actuator side, and a conductive material touching with the electrical connection terminal is provided as a power supply terminal electrically connected to a power supply section of a circuit board.<br><b>Independant Claims</b><br>1) A graphic interface system for direct editing of a subband encoded audio signal having a plurality of frequency subbands, the system comprising: receiver for receiving the subband encoded audio signal; control logic operative to generate a spectral graph of the subband encoded audio signal, the spectral graph including an amplitude of each of the plurality of frequency subbands of the subband encoded audio signal as a function of time, and to mark at least one selectable edit point of the subband encoded audio signal, wherein the at least one selectable edit point includes an amplitude of any one of the plurality of frequency subbands of the subband encoded audio signal at a selected time; a display unit for displaying the spectral graph and the at least one selectable edit point; and an input device for selecting the at least one selectable edit point.<br>14) A graphic interface product for direct editing of a subband encoded audio signal having a plurality of frequency subbands, the product for use with a receiver for receiving the subband encoded audio signal, a display unit and an input device, the product comprising: a storage medium; computor readable instructions recorded on the storage medium, the instructions operative to generate a spectral graph of the subband encoded audio signal received by the receiver, the spectral graph including an amplitude of each one of the plurality of frequency subbands of the subband encoded audio signal as a function of time, and to mark at least one selectable edit point of the subband encoded audio signal, wherein the at least one selectable edit point includes an amplitude of any one of the frequency subbands of the subband encoded audio signal at a selected time, the display unit is provided for displaying the spectral graph and the at least one selectable edit point, and the input device is provided for selecting the at least one selectable edit point.</p></layer>
<layer id = "layer376"><p><b>US10134409B2:Segmenting audio signals into auditory events</b><br><b>Independant Claims</b><br>6) A method for processing an audio signal, the system comprising: examining time concurrent segments of the audio signal across at least two channels of audio content to determine a respective spectral content of successive time segments in each of the at least two channels; calculating a difference in spectral content between the respective spectral content of the successive time segments, wherein the spectral content comprises a frequency-dependent amplitude value in each segment; locating, in a detector, auditory event boundaries based on one or more spectral characteristics of the audio signal over time in the at least two channels to define auditory events in the audio signal when the difference in spectral content is above a defined threshold value, wherein an auditory event is between adjacent auditory event boundaries and each auditory event boundary represents an end of a preceding auditory event and a beginning of a next auditory event; identifying a dominant subband of a plurality of subbands within each segment by summing a square of a magnitude spectrum for each subband of the plurality of subbands; and adjusting the audio signal comprising the auditory events, based on the located auditory event boundaries, to produce a processed signal.<br>11) A non-transitory computer readable medium that contains instructions that when executed by a processor cause the processor to perform a method comprising: examining time concurrent segments of the audio signal across at least two channels of audio content to determine a respective spectral content of successive time segments in each of the at least two channels; calculating a difference in spectral content between the respective spectral content of the successive time segments, wherein the spectral content comprises a frequency-dependent amplitude value in each segment; locating, in a detector, auditory event boundaries based on one or more spectral characteristics of the audio signal over time in the at least two channels to define auditory events in the audio signal when the difference in spectral content is above a defined threshold value, wherein an auditory event is between adjacent auditory event boundaries and each auditory event boundary represents an end of a preceding auditory event and a beginning of a next auditory event; identifying a dominant subband of a plurality of subbands within each segment by summing a square of a magnitude spectrum for each subband of the plurality of subbands; and adjusting the audio signal comprising the auditory events, based on the located auditory event boundaries, to produce a processed signal.<br>1) A system for processing an audio signal, the system comprising: an analyzer determining a respective spectral content of successive time segments of the audio signal across at least two channels of audio content; a calculator calculating a difference in spectral content between the respective spectral content of the successive time segments, wherein the spectral content comprises a frequency-dependent amplitude value in each segment; a detector locating auditory event boundaries based on one or more spectral characteristics of the audio signal over time in the at least two channels to define auditory events in the audio signal when the difference in spectral content is above a defined threshold value, wherein an auditory event is between adjacent auditory event boundaries and each auditory event boundary represents an end of a preceding auditory event and a beginning of a next auditory event, the detector further identifying a dominant subband of a plurality of subbands within each segment by summing a square of a magnitude spectrum for each subband of the plurality of subbands; and a processor for adjusting the audio signal comprising the auditory events, based on the located auditory event boundaries, to produce a processed audio signal.</p></layer>
<layer id = "layer377"><p><b>US20040172240A1:Comparing audio using characterizations based on auditory events</b><br>A method and article are disclosed wherein a substrate is provided with a photocatalytically-activated self-cleaning surface by forming a photocatalytically-activated self-cleaning coating on the substrate by spray pyrolysis chemical vapor deposition or magnetron sputter vacuum deposition. The coating has a thickness of at least about 500 Angstroms to limit sodium-ion poisoning to a portion of the coating facing the substrate. Alternatively, a sodium ion diffusion barrier layer is deposited over the substrate prior to the deposition of the photocatalytically-activated self-cleaning coating to prevent sodium ion poisoning of the photocatalytically-activated self-cleaning coating. The substrate includes glass substrates, including glass sheet and continuous float glass ribbon.<br><b>Independant Claims</b><br>1. A method for determining if one audio signal is derived from another audio signal or if two audio signals are derived from the same audio signal, comprising comparing reduced-information characterizations of said audio signals, wherein said reduced-information characterizations are based on auditory scene analysis.</p></layer>
<layer id = "layer378"><p><b>US20040181397A1:Adaptive correlation window for open-loop pitch</b><br>A library for cartridges of a data storage tape comprises a drive with a cartridge pocket and a magazine revolving about the drive with a plurality of receivers for the cartridges. The receivers are positionable in front of a cartridge pocket in order to change a cartridge between the receiver and the cartridge pocket. Cartridges can be inserted or removed through a port of the housing of the library into the receiver of the magazine. The cartridge pocket, a receiver positioned in front of the cartridge pocket, and the port of the housing may be linearly aligned such that cartridges can also be inserted through the port directly into the cartridge pocket or can be removed directly from the cartridge pocket through the port.<br><b>Independant Claims</b><br>1. A method for improving pitch determination comprising: obtaining an input voiced speech signal; allocating said input voiced speech signal into a plurality of windows of a fixed sample size for pitch lag determination; selecting a target window of said plurality of windows by sliding the window until a predefined condition is satisfied; and computing optimum pitch correlation between said the target window and the window at a distant pitch lag.<br>7. A computer program product comprising: a computer usable medium having computer readable program code embodied therein for improving pitch determination, said computer readable program code configured to cause a computer to: obtain an input voiced speech signal; allocate said input voiced speech signal into a plurality of windows of a fixed sample size for pitch lag determination; select a target window of said plurality of windows by sliding the window until a predefined condition is satisfied; and compute an optimum pitch correlation between said the target window and the window at a distant pitch lag.</p></layer>
<layer id = "layer379"><p><b>US20040196989A1:Method and apparatus for expanding audio data</b><br>A functional mammalian growth factor receptor/yeast histidine kinase chimera in <i>Saccharomyces cerevisiae</i>. In a preferred embodiment, the extracellular domain of the human epidermal growth factor receptor has been fused to the intracellular kinase domain of the SLN1 gene. The SLN1 gene encodes the plasma membrane sensor kinase of the yeast high osmolarity/glycerol response MAP kinase pathway. The chimeric protein is almost completely nonfunctional because the EGFR ECD is not capable of dimerization in the absence of ligand. In the presence of ligand, however, the chimeric kinase is activated and phosphorylation through the pathway is quantitatively repressed. This measure of pathway activity can be utilized to identify agonists and antagonists of the EGFR and other tyrosine kinase growth factor receptors in yeast cells.<br><b>Independant Claims</b><br>1. A method for time stretching audio data without changing the pitch comprising: obtaining at least one audio data stream; obtaining at least one energy property representation of said at least one audio data stream; obtaining at least one optimal input segment for time stretching using said at least one energy property representation; defining a first segment and a second segment that at least overlap said optimal input segment; and generating an output segment by sequentially crossfading said first segment and said second segment while alternately reversing the sense of at least one of said first segment and said second segment.</p></layer>
<layer id = "layer380"><p><b>US8315861B2:Wideband speech decoding apparatus for producing excitation signal, synthesis filter, lower-band speech signal, and higher-band speech signal, and for decoding coded narrowband speech</b><br>To improve throughput by reducing the resource used for transmitting a parameter relating to retransmission control and decreasing the overhead of retransmission control signaling. In a case where a retransmission control method is employed in consideration of adaptive MCS control in which the encoding rate can be changed, the scheduling section sets the MCS in accordance with CQI notified from the communication counterpart apparatus. When transmission data is encoded, the RV parameter bit-number setting section sets the number of bits used for signaling the RV parameter to decrease as the encoding rate of the first transmission is decreased and sets the RV parameter based on the number of bits. For example, in a case where the encoding rate R is R>2/3, two bits are set. In a case where the encoding rate 1/3<R≦2/3, one bit is set. On the other hand, in a case where R≦1/3, zero bits is set.<br><b>Independant Claims</b><br>3) A wideband speech decoding apparatus having: means for producing an excitation signal from coded data; means for producing a synthesis filter; and means for decoding a speech signal from the excitation signal and the synthesis filter, comprising: acquisition means for acquiring identification information which identifies that the speech signal to be decoded is narrowband; and modification means for modifying the decoded speech signal or the excitation signal based on the acquired identification information.<br>4) A wideband speech decoding apparatus having: lower-band production means for producing a speech signal on a lower-band side; and higher-band production means for producing a higher-band signal, comprising: acquisition means for acquiring identification information which identifies that a speech signal to be decoded is narrowband; and modification means for modifying the speech signal or an excitation signal decoded in the lower-band production means based on the identification information.<br>5) A wideband speech decoding apparatus having: means for producing an excitation signal from coded data; means for producing a synthesis filter; and means for decoding a speech signal from the excitation signal and the synthesis filter, comprising: acquisition means for acquiring identification information which identifies that the speech signal to be decoded is narrowband; and means for thinning out and accordingly sampling down the decoded speech signal or a signal resulting from the speech signal without using any band limiting filter in a case where narrowband is identified from the acquired identification information.<br>6) A wideband speech decoding apparatus having: lower-band production means for producing a speech signal on a lower-band side; and higher-band production means for producing a higher-band signal, comprising: acquisition means for acquiring identification information which identifies that the speech signal to be decoded is narrowband; and means for sampling down the decoded speech signal or a signal resulting from the speech signal by means of thinning-out without using any band limiting filter in a case where narrowband is identified from the acquired identification information.<br>7) A wideband speech decoding apparatus having: lower-band production means for producing a speech signal on a lower-band side; and higher-band production means for producing a higher-band signal, comprising: means for acquiring identification information which identifies that the speech signal to be decoded is narrowband; and means for controlling the higher-band production means based on the acquired identification information.<br>8) A wideband speech decoding apparatus having: lower-band production means for producing a speech signal on a lower-band side; and higher-band production means for producing a higher-band signal, comprising: means for acquiring identification information which identifies that a speech signal to be decoded is narrowband; and means for modifying the signal from the higher-band production means based on the acquired identification information.<br>1) A wideband speech decoding apparatus having: means for producing an excitation signal from coded data; means for producing a synthesis filter; and means for decoding a speech signal from the excitation signal and the synthesis filter, comprising: acquisition means for acquiring identification information which identifies the speech signal to be decoded is narrowband; and control means for controlling decoding means based on the identification information.<br>2) A wideband speech decoding apparatus having: lower-band production means for producing a speech signal on a lower-band side; and higher-band production means for producing a higher-band signal, comprising: acquisition means for acquiring identification information which identifies that the speech signal to be decoded is narrowband; and control means for controlling the lower-band production means based on the identification information.</p></layer>
<layer id = "layer381"><p><b>US8571878B2:Speech compression and decompression apparatuses and methods providing scalable bandwidth structure</b><br>The invention relates to a device for measuring a quantity of a reducing agent, preferably NH<sub>3</sub>, contained in a vessel (<b>10; 110; 210</b>) containing a storage material (<b>11; 111; 211</b>) in which the reducing agent is stored, the volume of the storage material (<b>11; 111; 211</b>) varying depending on the quantity of reducing agent which it contains. The measuring device comprises means (<b>13, 14, 14′; 113, 114; 213, 214</b>) associated with the vessel (<b>10; 110; 210</b>), said means being suitable for measuring the quantity of reducing agent stored in the storage material (<b>11; 111; 211</b>) depending on the volume of the latter.<br><b>Independant Claims</b><br>1) A speech compression apparatus including one or more processing devices, the apparatus comprising: a first band-transform unit, including the at least one of the one or more processing devices to transform a wideband speech signal into a narrowband low-band speech signal such that the narrowband low-band speech signal has a narrower bandwidth and lower maximum frequency than the wideband speech signal; a narrowband speech compressor compressing the narrowband low-band speech signal and outputting a result of the compressing as a low-band speech packet; a decompression unit decompressing the low-band speech packet and obtaining a decompressed wideband low-band speech signal; a difference detection unit generating a difference signal, having plural defined frequency bands, representing differences between the wideband speech signal and the decompressed wideband low-band speech signal through respective analyses of plural defined frequency bands of the wideband speech signal and respective analyses of plural defined frequency bands of the decompressed wideband low-band speech signal; and a high-band speech compression unit respectively compressing each of plural defined frequency bands of a high-band speech signal, derived from plural respective defined frequency band analyses of the wideband speech signal and the difference signal, and outputting a result of the compressing by the high-band speech compression unit as a high-band speech packet.<br>31) A method of improving quantization efficiency during compression of a high-band speech signal sampled from audible sound, the method, comprising: obtaining, based on determined acoustic characteristics of a wideband speech signal, a weight function for plural defined frequency bands of the high-band speech signal from a masked signal of defined frequency bands of the high-band speech signal and defined frequency bands of a generated difference signal, the generated difference signal representing differences between a decompressed wideband low-band speech signal and a wideband speech signal through respective analyses of plural defined frequency bands of the wideband speech signal and respective analyses of plural defined frequency bands of the decompressed wideband low-band speech signal; compressing each of the frequency bands of the high-band speech signal in accordance with correlations between frequency bands and between a frequency band and time according to the obtained weight function; and respectively compressing each of the plural defined frequency bands of the difference signal detected according to the obtained weight function, wherein the decompressed wideband low-band signal represents a transformation of the wideband speech signal into a narrowband low-band speech signal.<br>22) A speech compression apparatus, including one or more processing devices, the apparatus comprising: a first band-transform unit, including the at least one of the one or more processing devices to transform a wideband speech signal into a narrowband low-band speech signal such that the narrowband low-band speech signal has a narrower bandwidth and lower maximum frequency than the wideband speech signal; a narrowband speech compressor compressing the narrowband low-band speech signal and outputting a result of the compressing as a low-band speech packet; a decompression unit decompressing the low-band speech packet and obtaining a decompressed wideband low-band speech signal; a difference detection unit generating a difference signal, having plural defined frequency bands, representing differences between the wideband speech signal and the decompressed wideband low-band speech signal through respective analyses of plural defined frequency bands of the wideband speech signal and respective analyses of plural defined frequency bands of the decompressed wideband low-band speech signal; and a high-band speech compression unit compressing each of plural defined frequency bands of a high-band speech signal, derived from plural respective defined frequency band analyses of the wideband speech signal and the difference signal, and outputting the result of the compressing by the high-band speech compression unit as a high-band speech packet, wherein the high-band speech compression unit comprises: a filter bank dividing the wideband speech signal into the plural defined frequency bands and outputting a plurality of divided wideband speech signals; a masking unit generating masked signals for each of the plurality of divided wideband speech signals; a weight function calculator calculating a frequency domain weight function using the masked signals and the difference signal; a discrete Fourier transformer (DFT) obtaining DFT coefficients for each of the plurality of divided wideband speech signals using the difference signal output from the difference detection unit; an RMS quantizer obtaining an RMS value for each of the plural frequency bands of the high-band speech signal using the DFT coefficient, and quantizing the RMS value; a normalizer normalizing the DFT coefficient using the quantized RMS value; a DFT coefficient quantizer quantizing the normalized DFT coefficient using the frequency domain weight function; and a packeting unit packeting the quantized RMS value and the quantized DFT coefficient and outputting a result of the packeting as the high-band speech packet.<br>32) A speech compression apparatus, including one or more processing devices, the apparatus comprising: a first band-transform unit including the at least one of the one or more processing devices to transform a wideband speech signal to a narrowband low-band speech signal such that the narrowband low-band speech signal has a narrower bandwidth and lower maximum frequency than the wideband speech signal; a narrowband speech compressor compressing the narrowband low-band speech signal and outputting a result of the compressing as a low-band speech packet; a decompression unit decompressing the low-band speech packet and obtaining a decompressed wideband low-band speech signal; a difference detection unit generating a difference signal a representing differences between the wideband speech signal and the decompressed wideband low-band speech signal through respective analyses of plural defined frequency bands of the wideband speech signal and analyses of plural defined frequency bands of the decompressed wideband low-band speech signal; and a high-band speech compression unit compressing a high-band speech signal, derived from plural respective defined frequency band analyses of the wideband speech signal and the difference signal, and outputting the result of the compressing of the high-band speech signal as a high-band speech packet, wherein the difference detection unit detects the difference signal by a masking between the wideband speech signal and the decompressed wideband low-band speech signal, and wherein the masking is performed such that a masked signal for the wideband speech signal is masked by a masked signal for the decompressed wideband low-band speech signal.<br>23) A speech decompression apparatus, including one or more processing devices, for decompressing a speech signal that is compressed into a scalable bandwidth structure, the apparatus comprising: a narrowband speech decompressor receiving a low-band speech packet, representing a transformation of a wideband speech signal into a narrowband low-band speech signal, decompressing the low-band speech packet, and outputting a decompressed narrow low-band speech signal; a high-band speech decompression unit receiving a high-band speech packet, respectively decompressing each of plural defined frequency bands of the high-band speech packet, and outputting a decompressed high-band speech signal by respectively adding each of the plural defined decompressed frequency bands of the high-band speech packet together; and an adder, including the at least one of the one or more processing devices to add the decompressed narrow low-band speech signal and the decompressed high-band speech signal and output a result of the adding as the wideband speech signal, with the high-band speech signal having been derived by an encoder from plural respective defined frequency band analyses of the wideband speech signal and a difference signal, the difference signal having represented differences between the wideband speech signal and a decompressed wideband low-band speech signal, from the low-band speech packet, through respective analyses of plural defined frequency bands of the wideband speech signal and respective analyses of the plural defined frequency bands of the decompressed wideband low-band speech signal.<br>26) A speech decompression apparatus, including at one or more processing devices, for decompressing a speech signal that is compressed into a scalable bandwidth structure, the apparatus comprising: a narrowband speech decompressor receiving a low-band speech packet, representing a transformation of a wideband speech signal into a narrowband low-band speech signal, decompressing the low-band speech packet, and outputting a decompressed narrow low-band speech signal; a high-band speech decompression unit, including the at least one of the one or more processing devices to receive a high-band speech packet, decompress the high-band speech packet, and output a decompressed high-band speech signal; and an adder adding the decompressed narrow low-band speech signal and the decompressed high-band speech signal and outputting a result of the adding as the wideband speech signal, with the high-band speech signal having been derived by an encoder from defined frequency band analyses of the wideband speech signal and a difference signal having represented differences between defined frequency bands of the wideband speech signal and defined frequency bands of a wideband low-band speech signal derived from the low-band speech packet, wherein, based upon the encoder plural respective defined frequency band analyses of the wideband speech signal and the difference signal for derivation of the high-band speech packet, the high-band speech packet includes a quantized RMS value, a predictor type index used when the speech signal is compressed, and a quantized DFT coefficient, and wherein the high-band speech decompression unit self-calculates respective DFT coefficient phases for each of plural frequency band information within a corresponding high-band portion of the speech signal and respectively uses each of the self-calculated DFT coefficient phases when the quantized DFT coefficient is an inverse DFT.<br>27) A speech compression method for a wideband speech signal sampled from audible sound, the method comprising: transforming the wideband speech signal into a narrowband low-band speech signal such that the narrowband low-band speech signal has a narrower bandwidth and lower maximum frequency than the wideband speech signal; compressing the narrowband low-band speech signal and transmitting the compressed narrowband low-band speech signal as a low-band speech packet; decompressing the low-band speech packet and obtaining a decompressed wideband low-band signal; generating a difference signal, having plural defined frequency bands, representing differences between the decompressed wideband low-band signal and the wideband speech signal through respective analyses of plural defined frequency bands of the wideband speech signal and analyses of plural defined frequency bands of the decompressed wideband low-band speech signal; and compressing each of plural defined frequency bands of a high-band speech signal, derived from plural respective defined frequency band analyses of the wideband speech signal and the difference signal, and transmitting the compressed high-band speech signal as a high-band speech packet.<br>28) A speech decompression method for decompressing a compressed wideband speech signal of sampled audible sound, the method comprising: decompressing a low-band speech packet of a speech signal, representing a transformation of a wideband speech signal into a narrowband low-band speech signal, into a narrowband low-band speech signal; respectively decompressing each of plural defined frequency bands of a high-band speech packet of the speech signal and obtaining a high-band speech signal by respectively adding each of the plural defined decompressed frequency bands of the high-band speck pack together; transforming the narrowband low-band speech signal into a decompressed wideband low-band speech signal; and adding the decompressed wideband low-band speech signal and the high-band speech signal and outputting a result of the adding as the wideband speech signal, with the high-band speech signal having been derived by an encoder from plural respective defined frequency band analyses of the wideband speech signal and the a difference signal, the difference signal having represented differences between the wideband speech signal and a decompressed wideband low-band speech signal, from the low-band speech packet, through respective analyses of plural defined frequency bands of the wideband speech signal and respective analyses of the plural defined frequency bands of the decompressed wideband low-band speech signal.<br>9) A speech compression apparatus, including one or more processing devices, the apparatus comprising: a first band-transform unit, including the at least one of the one or more processing devices to transform a wideband speech signal into a narrowband low-band speech signal such that the narrowband low-band speech signal has a narrower bandwidth and lower maximum frequency than the wideband speech signal; a narrowband speech compressor compressing the narrowband low-band speech signal and outputting a result of the compressing as a low-band speech packet; a decompression unit decompressing the low-band speech packet and obtaining a decompressed wideband low-band speech signal; a difference detection unit generating a difference signal, having plural defined frequency bands, representing differences between the wideband speech signal and the decompressed wideband low-band speech signal through respective analyses of plural defined frequency bands of the wideband speech signal and respective analyses of plural defined frequency bands of the decompressed wideband low-band speech signal; and a high-band speech compression unit compressing each of plural defined frequency bands of a high-band speech signal, derived from plural respective defined frequency band analyses of the wideband speech signal and the difference signal, and outputting a result of the compressing by the high-band speech compression unit as a high-band speech packet.<br>30) A method of compensating for distortion occurring in a narrowband speech compressor compressing a speech signal sampled from audible sound, the method comprising: generating a difference signal, having plural defined frequency bands, representing respective differences between a decompressed wideband low-band signal and a corresponding wideband speech signal through respective analyses of plural defined frequency bands of the decompressed wideband low-band speech signal and respective analyses of plural defined frequency bands of the corresponding wideband speech signal; and compressing each of plural defined frequency bands of a high-band speech signal, derived from plural respective defined frequency band analyses of the wideband speech signal and the difference signal, and transmitting the compressed high-band speech signal as a high-band speech packet, wherein the decompressed wideband low-band signal represents a transformation of the corresponding wideband speech signal into a narrowband low-band speech signal.</p></layer>
<layer id = "layer382"><p><b>US20040252849A1:Microphone array for preserving soundfield perceptual cues</b><br>A lock device for bicycle, which comprises an outer cylinder of a frame, an inner cylinder of front fork, and a transmission assembly mounted between the aforesaid parts; the transmission assembly includes a fixed member, which has a transverse cylindrical hole for receiving a lock device; the outer surface of the lock cylinder of the lock device is furnished with a gear portion; a key is plugged into the keyhole of the lock device to push a plurality of tumbler disks to move; the engage surface of the key can drive the outer casing to turn, and then the gear portion of the outer casing will actuate the transmission assembly to move so as to have the frame and the front fork locked up at an angle of 45 degrees.<br><b>Independant Claims</b><br>1. A sound recording arrangement comprising: a plurality of at least three microphones situated nominally on a common plane, at points nominally on a circle having a diameter that corresponds to a sound time-of-arrival difference of approximately 0.9 msec between a pair of microphones that is diametrically situated from each other; and means for communicating signals of said microphones to other equipment where no microphones connected to said means that are nominally on said common plane are on other than said circle.<br>11. A sound recording arrangement comprising: an N plurality of directional microphones, when N is equal to or greater than 3, situated nominally on a common plane, at points nominally on a circle having a diameter that corresponds to a sound time-of-arrival difference of approximately 0.9 msec between a pair of said directional microphones that is diametrically situated from each other, where said plurality of directional microphones, as a group, are more sensitive to sound arriving from a front direction of said arrangement than from any other direction.; and means for communicating signals of said microphones to other equipment.</p></layer>
<layer id = "layer383"><p><b>US8437482B2:Method, apparatus and computer program for calculating and adjusting the perceived loudness of an audio signal</b><br>A system and a method for determining one or more wave characteristics from a moving platform are disclosed. A sonar system, such as an Acoustic Doppler Current Profiler, can profile the water motion relative to the platform, and an earth reference can determine a measure of the platform motion relative to a fixed earth reference. Both water profile and earth reference measurements can be synergistically employed to compensate for motion of the platform. Directional wave spectra and non-directional wave spectrum can be computed and translated via linear wave theory to surface height spectra and used to calculate characteristics, such as significant wave height, peak period, and peak direction.<br><b>Independant Claims</b><br>1) A method for processing an audio signal, comprising calculating, in response to the audio signal, a gain value, which when multiplied with the audio signal makes the error between the perceived loudness of the audio signal and a reference loudness level within a threshold, wherein a portion of calculating said gain value is a non-linear process for which no closed form solution for said gain value exists, and wherein the calculating includes deriving from said audio signal an excitation signal divided into a plurality of frequency bands that simulate the excitation pattern along the basilar membrane of the inner ear, deriving from the excitation signal in each frequency band of the excitation signal, in said non-linear process, a specific loudness, and combining the specific loudnesses to obtain the perceived loudness, iteratively adjusting the magnitude of the excitation signal until the error between the perceived loudness and the reference loudness is below said threshold, the iterative adjusting being performed in an iterative loop that includes deriving the specific loudness in each frequency band of the excitation signal and excludes deriving said excitation signal, and adjusting the perceived loudness of the audio signal using the calculated gain value.<br>2) A method for processing a plurality of audio signals, comprising calculating, in response to each of the audio signals, a respective gain value, which when multiplied with the audio signal makes the error between the perceived loudness of the audio signal and a reference loudness level within a threshold, the same reference loudness being applied with respect to all of the audio signals, wherein a portion of calculating said gain value is a non-linear process for which no closed form solution for said gain value exists, and wherein the calculating includes deriving from said audio signal an excitation signal divided into a plurality of frequency bands that simulate the excitation pattern along the basilar membrane of the inner ear, deriving from the excitation signal in each frequency band of the excitation signal, in said non-linear process, a specific loudness, and combining the specific loudnesses to obtain the perceived loudness, iteratively adjusting the magnitude of the excitation signal until the error between the perceived loudness and the reference loudness is below said threshold, the iterative adjusting being performed in an iterative loop that includes deriving the specific loudness in each frequency band of the excitation signal and excludes deriving said excitation signal, and adjusting the perceived loudness of each audio signal using the respective calculated gain value.</p></layer>
<layer id = "layer384"><p><b>US20050004793A1:Signal adaptation for higher band coding in a codec utilizing band split coding</b><br>A variable rate transmission system transmits a variable rate data packet including an accompanying rate indication signal indicative of the transmission rate of the variable data packet. The data packet can be spread using a long pseudonoise (PN) code, the mask of which can be selected in accordance with the transmission rate of the variable rate data packet. A preamble, providing the transmission rate, can be punctured into an outgoing pilot signal. The rate indication signal can be encoded in accordance with a set of orthogonal functions that are part of the indication of the transmission rate of the data packet.<br><b>Independant Claims</b><br>1. A method of adjusting a bandwidth extension algorithm for band-split encoding and decoding using analysis and synthesis filterbanks and separate encoders and decoders for each band, comprising the steps of: receiving by a high-band encoder an indication signal generated by a low-band encoder in response to a low-band signal from said analysis filterbank; and adjusting by the high-band encoder an enhancing perception parameter of a high-band encoded signal generated by the high-band encoder in response to a high-band signal from said analysis filterbank and based on said indication signal thus adjusting said bandwidth extension algorithm, wherein the high-band signal and the low-band signal represent two signals out of M frequency-band signals generated by the analysis filterbank by splitting an input signal into M frequency bands, M is an integer of at least a value of two and a band frequency range of said high-band signal is higher than the band frequency range of said low-band signal, and wherein the high-band and low-band encoders with the analysis filterbank form a transmitter of the input signal and the high-band and low-band decoders with the synthesis filterbank form a receiver of a re-transmitted input signal which is spectrally encoded in said M bands with said adjustment applied to the high-band encoded signal.<br>15. A system for adjusting a bandwidth extension algorithm for band-split encoding and decoding, comprising: an analysis filterbank, responsive to an input signal, for providing M frequency-band signals generated by splitting the input signal into M frequency bands, wherein M is an integer of at least a value of two; a high-band encoder, responsive to a high-band signal and to an indication signal, for providing a high-band encoded signal and for adjusting an enhancing perception parameter of the high-band encoded signal thus adjusting said bandwidth extension algorithm; and a low-band encoder, responsive to a low-band signal, for providing said indication signal, wherein the high-band signal and the low-band signal represent two signals out of said M frequency-band signals generated by the analysis filterbank and a band frequency range of said high-band signal is higher than the band frequency range of said low-band signal.<br>29. An electronic device, capable of adjusting a bandwidth extension algorithm for band-split encoding, comprising: an analysis filterbank, responsive to an input signal, for providing M frequency-band signals generated by splitting the input signal into M frequency bands, wherein M is an integer of at least a value of two; a high-band encoder, responsive to a high-band signal and to an indication signal, for providing a high-band encoded signal and for adjusting an enhancing perception parameter of the high-band encoded signal thus adjusting said bandwidth extension algorithm; and a low-band encoder, responsive to a low-band signal, for providing said indication signal and for providing a low-band encoded signal, wherein the high-band signal and the low-band signal represent two signals out of said M frequency-band signals generated by the analysis filterbank and a band frequency range of said high-band signal is higher than the band frequency range of said low-band signal.</p></layer>
<layer id = "layer385"><p><b>US20050049864A1:Intelligent acoustic microphone fronted with speech recognizing feedback</b><br>A closing unit for an injection molding machine for processing plastic material includes a fixed mold mounting plate connected to a moveable mold mounting plate by means of a crank or toggle lever mechanism, which is operated by at least two motor-driven spindles arranged in series and having thread pitches in an opposite manner. One spindle is operatively connected to the fixed mounting plate, whereas the other spindle is connected to the crank or toggle lever mechanism. A sleeve-like force transmission element is arranged concentrically in relation to the spindles. Spindle nuts are respectively provided on opposite end faces of the force transmission element and interact with the power transmission element and the spindles.<br><b>Independant Claims</b><br>1. A process for regulating a speech recognition system, in which the reception characteristic of a microphone system is controlled by an optimization unit (10), wherein speech signals are received and processed via the microphone system, and in which in the course of the processing of the speech signals the reception characteristics of the microphone system (12) are so controlled by the optimization unit (10), that the recognition power of the speech recognizer (11) downstream of the optimization unit (10) is optimized, wherein the speech signals received by the speech recognizer (11) are supplied by multiple parallel or quasi-parallel speech channels (15), wherein the speech recognizer (11) processes these speech channels parallel, at least in time, and compares the quality of the recognition results with each other, and wherein on the basis of this comparison: on the one hand, the speech signals from that speech channel (14) which have the potential for a best possible recognition are selected and further processed, and on the other hand, the optimization unit (10) obtains from the speech recognizer the necessary regulating signals (18), in order to optimize the reception characteristic of the microphone array (12) in regard to the respective speech channel (14) via which the respective speech signal is received which has the potential for the best possible recognition.<br>6. A device for regulating a speech recognition system, comprised of a microphone system with an optimization unit (10) for modification of the received characteristic of the microphone system (12), which has at least one speech recognizer (11), to which the speech signals are supplied and which processes these, wherein the speech recognizer (11) is in communication with the optimization device (10) for modification of the reception characteristics of the microphone system (12), so that via this communication the received characteristic can be regulated in the manner that the recognition performance of the speech recognizer (11) downstream of the optimization unit (10) is optimized, wherein the speech recognizer (11) is supplied with speech signals via multiple parallel signal lines (14), wherein the speech recognizer (11) is in communication with the optimization device (10) in such a manner that the speech signals are supplied to it via parallel or quasi-parallel speech channels (14), and wherein the speech recognizer (11) is so designed, that it process these different speech signals parallel or quasi-parallel and can compare the recognition results with each other with regard to their quality, and that on the basis of this comparison: on the one hand the speech signals of the respective speech channel are selected and further processed, which have the potential for the best possible recognition, and on the other hand the optimization unit (10) obtains from the speech recognizer the necessary regulating signals (18), in order to optimize the reception characteristic of the microphone array in regard to the respective speech channel (14), which relay the speech signals which have the potential for the best possible recognition.</p></layer>
<layer id = "layer386"><p><b>US20050049857A1:Method and apparatus using harmonic-model-based front end for robust speech recognition</b><br>A high-efficiency electronic circuit generates and regulates a supply voltage and includes a charge-pump voltage multiplier which is associated with an oscillator and has an output connected to a voltage regulator in order to ultimately output said supply voltage. Advantageously, the circuit comprises a first hysteresis comparator having as inputs the regulator output and the multiplier output, and comprises a second hysteresis comparator having as inputs a reference potential and a partition of the voltage presented on the regulator output. The comparators are structurally and functionally independent of each other, and their outputs are coupled to the oscillator through a logic circuit to modulate the oscillator operation.<br><b>Independant Claims</b><br>1. A method of identifying an estimate for a noise-reduced value representing a portion of a noise-reduced speech signal, the method comprising: decomposing a portion of a noisy speech signal into a harmonic component and a random component; determining a scaling parameter for at least the harmonic component; multiplying the harmonic component by the scaling parameter for the harmonic component to form a scaled harmonic component; multiplying the random component by a scaling parameter for the random component to form a scaled random component; and summing the scaled harmonic component and the scaled random component to form the noise-reduced value.<br>13. A computer-readable medium having computer-executable instructions for performing steps comprising: identifying a harmonic component and a random component in a noisy speech signal; combining the harmonic component and the random component to produce a noise-reduced value; and using the noise-reduced value to perform speech recognition.</p></layer>
<layer id = "layer387"><p><b>US20060165202A1:Signal processor for robust pattern recognition</b><br>A system and method includes an interoperability engine dynamically generating and updating an application database, a web-based portal in a computer communications network, and a baseline data schema from at least one of a data source and a supplemental data source comprising self-describing documents, and enabling interoperability among application systems. The application database dynamically generates a reporting database. The web-based portal provides access to the application systems via the application database and the reporting database. The self-describing documents may be hosted. An integration unit maps the application systems to the baseline data schema and facilitates transmission and messaging between the baseline data schema and the application systems.<br><b>Independant Claims</b><br>1. A signal processing method for use with a pattern recogniser, comprising the steps of:— receiving an input signal to be recognised; for successive respective portions of the input signal, generating a feature vector having a plurality of characteristic coefficients representative of the signal portion; for any particular ith signal portion, calculating k sets (k>0) of dynamic coefficients in dependence on the characteristic coefficients for the ith portion and the characteristic coefficients of signal portions temporally adjacent to the ith portion, said dynamic coefficients being representative of the temporal variation of the characteristic coefficients; and outputting at least part of the k sets of dynamic coefficients to the pattern recogniser.<br>6. A signal processing method for use with a pattern recogniser, comprising the steps of:— receiving an input signal to be recognised; for successive respective portions of the input signal, generating a feature vector having a plurality of characteristic coefficients representative of the signal portion; for any particular ith signal portion: calculating the mean of each characteristic coefficient in dependence on corresponding coefficients from temporally adjacent signal portions; and normalising the values of the characteristic coefficients in dependence on the calculated mean values; the method further comprising outputting the normalised characteristic coefficients to the pattern recogniser.<br>11. A noise cancellation method for removing noise from a signal, comprising the steps of:— receiving a signal to be processed; estimating a noise spectrum from the signal, said estimating including deriving a plurality of noise parameter values; and cancelling the estimated noise spectrum from a spectrum of the signal in dependence on the values of the plurality of noise parameters.<br>16. A signal processing system for use with a pattern recogniser, comprising:— a signal input at which an input signal to be recognised is received; and a signal processor arranged in use to:— i) for successive respective portions of the input signal, generate a feature vector having a plurality of characteristic coefficients representative of the signal portion; and ii) for any particular ith signal portion, calculate k sets (k>0) of dynamic coefficients in dependence on the characteristic coefficients for the ith portion and the characteristic coefficients of signal portions temporally adjacent to the ith portion, said dynamic coefficients being representative of the temporal variation of the characteristic coefficients; and iii) output at least part of the k sets of dynamic coefficients to the pattern recogniser.<br>21. A signal processing system for use with a pattern recogniser, comprising:— a signal input at which an input signal to be recognised is received; and a signal processor arranged in use to:— i) for successive respective portions of the input signal, generate a feature vector having a plurality of characteristic coefficients representative of the signal portion; ii) for any particular ith signal portion: a) calculate the mean of each characteristic coefficient in dependence on corresponding coefficients from temporally adjacent signal portions; and b) normalise the values of the characteristic coefficients in dependence on the calculated mean values; the signal processor being further arranged in use to:— iii) output the normalised characteristic coefficients to the pattern recogniser.<br>26. A noise cancellation system for removing noise from a signal, comprising:— a signal input for receiving a signal to be processed; a noise estimator for estimating a noise spectrum from the signal, said noise estimator being further arranged to derive a plurality of noise parameter values; and a noise cancellor for cancelling the estimated noise spectrum from a spectrum of the signal in dependence on the values of the plurality of noise parameters.</p></layer>
<layer id = "layer388"><p><b>US6859420B1:Systems and methods for adaptive wind noise rejection</b><br>A page width printhead assembly (<highlight><bold>1</bold></highlight>) for a digital inkjet printer has a support member that can be secured in the printer, and a printhead (<highlight><bold>2</bold></highlight>) that can be mounted to the support member. The support member has a core with at least one ink reservoir (<highlight><bold>6, 7, 8 </bold></highlight>and <highlight><bold>9</bold></highlight>) enclosed within a laminated shell (<highlight><bold>4</bold></highlight>). The materials and structure of the shell (<highlight><bold>4</bold></highlight>) and the core (<highlight><bold>5</bold></highlight>) are selected and configured so that the co-efficient of thermal expansion of the support member as a whole is substantially equal to that of the printhead (<highlight><bold>2</bold></highlight>).<br><b>Independant Claims</b><br>1) A method of rejecting wind noise, comprising: distributing a plurality of acoustic sensors over a surface of a body; identifying at least one sensor of the plurality of acoustic sensors that is subject to low wind noise to obtain at least one identified sensor; passing signals from the at least one identified sensor as low wind noise signals; and rejecting signals from non-identified sensors of the plurality of acoustic sensors as high wind noise signals.<br>16) A system for rejecting wind noise incident on a surface of a body, a plurality of acoustic sensors being distributed over the surface of the body, the system comprising: means for identifying at least one sensor of the plurality of sensors that is subject to a low wind noise; means for passing signals from the at least one identified sensor as low wind noise signals; and means for rejecting signals from non-identified sensors of the plurality of sensors as high wind noise signals.<br>17) A system for rejecting wind noise at a plurality of sensors, comprising: input logic configured to receive a signal from each of the plurality of sensors; a processor configured to assign a weight value to each of the received signals; and output logic configured to derive a wind noise rejected output signal based on a function of the assigned weight values and the received signals.<br>32) A method of rejecting signal noise, comprising: receiving signals from a plurality of sensors to obtain received signals; assigning a weight value to each of the received signals; and deriving a noise rejected output signal based on a function of the assigned weight values and the received signals.</p></layer>
<layer id = "layer389"><p><b>US6862567B1:Noise suppression in the frequency domain by adjusting gain according to voicing parameters</b><br>Chemically and physically stable pharmaceutical formulations, of the potent antidepressant, fluoxetine, its enantiomers and salts.<br><b>Independant Claims</b><br>1) A method of suppressing noise in a signal, said method comprising the steps of: estimating a signal to noise ratio for said signal; classifying said signal to a classification; calculating a gain for said signal using said signal to noise ratio and said classification; and modifying said signal using said gain; wherein said calculating step calculates said gain based on γdh=μg(σ″q−σth)−γn, wherein μg is adjusted according to said classification, and wherein γdh is a gain in a db domain, μg is a gain slope, σ″q is a modified signal-to-noise ratio, σth is a threshold level, and γn is an overall gain factor.<br>7) A method of suppressing noise in a signal having a first signal portion and a second signal portion, wherein said first signal portion is a look-ahead signal of said second signal portion, said method comprising the steps of: computing a voicing parameter using said first signal portion; estimating a signal to noise ratio for said second signal portion; calculating a gain for said second signal portion using said signal to noise ratio and said voicing parameter; and modifying said signal using said gain; wherein said calculating step calculates said gain based on γdb=μg(σ″q−σth)+γn, wherein μg is adjusted according to said voicing parameter, and wherein γdh is a gain in a db domain, μg is a gain slope, σ″q is a modified signal-to-noise ratio, σth is a threshold level, and γn is an overall gain factor.<br>13) A noise suppression system comprising: a signal to noise ratio estimator; a signal classifier; a signal gain calculator; and a signal modifier; wherein said estimator estimates a signal to noise ratio of said signal, said signal is given a classification using said signal classifier, said signal gain is calculated based on said signal to noise ratio and said classification using said calculator, and wherein said signal modifier modifies said signal by applying said gain; and wherein said calculator calculates said gain based on γdb=μg(σ″q−σth)+γn, wherein μg is adjusted according to said classification, and wherein γdb is a gain in a db domain, μg is a gain slope, σ″q is a modified signal-to-noise ratio, σth is a threshold level, and γn is an overall gain factor.<br>16) A system capable of suppressing noise in a signal having a first signal portion and a second signal portion, wherein said first signal portion is a look-ahead signal of said second signal portion, said system comprising: a signal processing module for computing a voicing parameter of said first signal portion; a signal to noise ratio estimator; a signal gain calculator; and a signal modifier; wherein said estimator estimates a signal to noise ratio of said second signal portion, said second signal portion gain is calculated based on said signal to noise ratio and said voicing parameter using said calculator, and wherein said signal modifier modifies said second signal portion by applying said gain; and wherein said signal gain calculator determines said gain based on γdb=μg(σ″q−σth)+γn, wherein μg is adjusted according to said voicing parameter, and wherein μdb is a gain in a db domain, μg is a gain slope, σ″q is a modified signal-to-noise ratio, σth is a threshold level, and γn is an overall gain factor.</p></layer>
<layer id = "layer390"><p><b>US20070067166A1:Method and device of multi-resolution vector quantilization for audio encoding and decoding</b><br>Drilling, completing or workover of a well, particularly an oil and/or gas well, is carried out using a fluid which includes a continuous phase including an ester of the formula (I): (R<sup>2</sup>)<sub>p</sub>-Ph-(CH<sub>2</sub>)<sub>m</sub>—COO-(AO)<sub>n</sub>-R<sup>1 </sup>where R<sup>1</sup>, AO, n, m, Ph, R<sup>2 </sup>and p have defined meanings and particularly where the esters are alkyl or alkenyl benzoate esters. These esters are beneficial by having a range of viscosities, especially extending to low viscosities, and attractive toxicological and environmental profiles for use in drilling, completion and/or workover of wells.<br><b>Independant Claims</b><br>1. A method of multi-resolution vector quantization for audio encoding, characterized in that it comprises the steps of: adaptively filtering an input audio signal so as to gain a time-frequency filter coefficient and outputting a filtered signal; dividing vectors of the filtered signal in a time-frequency plane so as to gain a vector combination; selecting vectors to be quantized; quantizing the selected vectors and calculating a residual error of quantization; and transmitting a quantized codebook information as a side-information of an encoder to an audio decoder to quantize and encode the residual error of quantization.<br>15. A method of multi-resolution vector quantization for audio decoding, characterized in that it comprises the following steps of: demultiplexing a code stream to gain a side information of the multi-resolution vector quantization, an energy of a selected point and location information of vector quantization; inverse quantizing vectors to obtain a normalized vector according to the above information and calculating a normalization factor to rebuild a quantized vector in an original time-frequency plane; adding the rebuilt vector to a residual error of a corresponding time-frequency coefficient according to the location information; obtaining a rebuilt audio signal by inverse filtering in multi-resolution and mapping from frequency to time.<br>19. A device of multi-resolution vector quantization for audio encoding, characterized in that it comprises: a time-frequency mapper, a multi-resolution filter, a multi-resolution vector quantizer, a psychological acoustic calculation module and a quantization encoder; the time-frequency mapper for receiving an input audio signal to process mapping from time to frequency domain and output to the multi-resolution filter; the multi-resolution filter foradaptively filtering the signal, and outputting a filtered signal to the psychological acoustic calculation module and the multi-resolution vector quantizer; the multi-resolution vector quantizer for vector quantizing the filtered signal and calculating a residual error of quantization, transmitting a quantized signal as a side information to an audio decoder and outputting the residual error of quantization to the quantization encoder; the psychological acoustic calculation module for calculating a masking threshold of a psychological acoustic model according to the input audio signal, and outputting the masking threshold to the quantization encoder so as to control noise allowed in quantization; the quantization encoder for quantizing and entropy coding the residual error output by the multi-resolution vector quantizer to gain an encoded code stream information under restriction of the allowed noise output by the psychological acoustic calculation module.<br>22. A device of multi-resolution vector quantization for audio decoding, characterized in that it comprises: a decoding and inverse-quantizing device, a multi-resolution inverse-vector quantizer, a multi-resolution inverse filter and a frequency-time mapper; the decoding and inverse -quantizing device for demultiplexing, entropy decoding and inverse-quantizing a code stream to obtain a side information and encoding data and outputting to the multi-resolution inverse-vector quantizer; the multi-resolution inverse-vector quantizer for quantizing a inverse-vector to rebuild a quantized vector, adding a rebuilt vector to a residual coefficient of a time-frequency plane and outputting to the multi-resolution inverse filter; the multi-resolution inverse filter for inverse filtering the vector rebuilt by the multi-resolution vector quantizer and outputting to the frequency-time mapper; the frequency-time mapper for mapping a signal from frequency to time to obtain a final rebuilt audio signal.</p></layer>
<layer id = "layer391"><p><b>US6889185B1:Quantization of linear prediction coefficients using perceptual weighting</b><br>Embodiments of the present invention provide for ringing and inter-symbol interference reduction in optical communications. In one embodiment of the present invention, the rise time of the signal is longer than the fall time of the signal. The resulting asymmetrical driver pulse is sent to the laser. The resulting overshoot, ringing, undershoot and chirp of the output from the laser are greatly reduced. As a result, the eye is approximately symmetrical and is less closed.<br><b>Independant Claims</b><br>1) In a coder including an LPC filter and a translator for translating LPC coefficients to LSF coefficients, an LSF quantizer comprising: a codebook responsive to an LSF target vector for quantizing said LSF target vector; means for searching within said codebook for determining codebook entry that results in quantized output that best matches LSF target vector using LSF weights computed from perceptual-weighting input response to the LPC filter; means for applying said LSF target vector to said codebook to provide a quantized output; said searching means including means for applying an impulse to said LPC filter; means for running samples of said LPC response; a perceptual filter for filtering said samples; and means for calculating autocorrelation function by weighted response, Jacobian matrix for said LSF vectors, correlation of rows of Jacobian matrix, and LSF weights by multiplying correlation matrices.<br>6) In a coder including an LPC filter and a translator for translating LPC coefficients to LSF coefficients, an LSF quantizer comprising: a codebook responsive to an LSF target vector for quantizing said LSF target vector; means for searching within said codebook for determining codebook entry that results in quantized output that best matches LSF target vector using LSF weights computed from perceptual-weighting input response to the LPC filter; means for applying said LSF target vector to said codebook to provide a quantized output; said searching means including means for applying an impulse to said LPC filter; means for running samples of said LPC response; a perceptual filter for filtering said samples; and means for calculating autocorrelation function by weighted response to thereby provide LSF weights computed from perceptual-weighting input response to the LPC filter.</p></layer>
<layer id = "layer392"><p><b>US6898566B1:Using signal to noise ratio of a speech signal to adjust thresholds for extracting speech parameters for coding the speech signal</b><br>A new and distinct variety of Peach tree characterized by its low chilling requirement, early to mid-season ripening, having attractive clingstone fruit having yellow fleshed, medium-high firm, good quality fruit.<br><b>Independant Claims</b><br>1) A method of estimating a plurality of speech parameters of a speech signal for coding said speech signal using one of a plurality of speech coding algorithms, said plurality of speech parameters including pitch information, said plurality of speech parameters being calculated using a plurality of thresholds, said method comprising: estimating a background noise level in said speech signal to determine a signal to noise ratio (SNR) for said speech signal; adjusting one or more of said plurality of thresholds based on said SNR to generate one or more SNR adjusted thresholds; analyzing said speech signal to extract said pitch information using said one or more SNR adjusted thresholds; and repeating said estimating, said adjusting and said analyzing to code said speech signal using one of said plurality of speech coding algorithms.<br>7) A speech coding system capable of estimating a plurality of speech parameters of a speech signal for coding said speech signal using one of a plurality of speech coding algorithms, said plurality of speech parameters including pitch information, said plurality of speech parameters being calculated using a plurality of thresholds, said speech coding system comprising: a background noise level estimation module configured to estimate background noise level in said speech signal to determine a signal to noise ratio (SNR) for said speech signal; a threshold adjustment module configured to adjust one or more of said plurality of thresholds based on said SNR to generate one or more SNR adjusted thresholds; a speech signal analyzer module configured to analyze said speech signal to extract said pitch information using said one or more SNR adjusted thresholds; and wherein said background noise level estimation module, said threshold adjustment module and said speech signal analyzer module repeat estimating background noise level, adjusting one or more of said plurality of thresholds and analyzing said speech signal to code said speech signal using one of said plurality of speech coding algorithms.</p></layer>
<layer id = "layer393"><p><b>US20050132870A1:Time-scale modification of music signals based on polyphase filterbanks and constrained time-domain processing</b><br>The present invention is directed to methods to rapidly assess the overall coagulant properties of a patient's blood sample by inhibiting the activation of the intrinsic contact activation pathway of coagulation and activating the extrinsic pathway of coagulation. When the sample is whole blood, the resulting clotting time represents the overall coagulant activity of the plasma and cellular components of the blood, which is indicative of existing or impending pathology arising from abnormal coagulability. The invention also provides a method for measuring the risk of a patient for a thrombotic event and for monitoring the effectiveness of procoagulant/anticoagulant therapy. A blood collection apparatus suitable for use in for performing the methods of the invention is also provided.<br><b>Independant Claims</b><br>1. A method of time-scale modification of a digital audio signal comprising the steps of: separating the digital audio signal into a plurality of frequency bands; detecting the energy in each frequency band; determining the frequency band having the highest energy; separately time-scale modifying each of the plurality of frequency bands producing corresponding time-scale modified frequency band signals by analyzing each frequency band in a set of first equally spaced, overlapping time windows having a first overlap amount Sa, selecting a base overlap Ss for output synthesis corresponding to a desired time scale modification, calculating a measure of similarity between overlapping frames of the frequency band having the highest energy for a range of overlaps between Ss+kmin to Ss+kmax of the single audio signal, where kmin is a minimum overlap deviation and kmax is a maximum overlap deviation, determining an overlap deviation km yielding the largest measure of similarity for the frequency band having the highest energy, calculating a measure of similarity between overlapping frames of frequency bands other than the highest energy frequency band for a range of overlaps around km smaller than the range between Ss+kmin to Ss+kmax, determining an overlap deviation ki yielding the largest measure of similarity for each frequency band other than having the highest energy frequency band, synthesizing an output signal for each frequency band in a set of second equally spaced, overlapping time windows having the corresponding determined overlap amount; and combining the separate time-scale modified frequency band signals.<br>7. A digital audio apparatus comprising: a source of a digital audio signal; a digital signal processor connected to said source of a digital audio signal programmed to perform time scale modification on the digital audio signal by separating the digital audio signal into a plurality of frequency bands, detecting the energy in each frequency band; determining the frequency band having the highest energy; separately time-scale modifying each of the plurality of frequency bands producing corresponding time-scale modified frequency band signals by analyzing each frequency band in a set of first equally spaced, overlapping time windows having a first overlap amount Sa, selecting a base overlap Ss for output synthesis corresponding to a desired time scale modification, calculating a measure of similarity between overlapping frames of the frequency band having the highest energy for a range of overlaps between Ss+kmin to Ss+kmax of the single audio signal, where kmin is a minimum overlap deviation and kmax is a maximum overlap deviation, determining an overlap deviation km yielding the largest measure of similarity for the frequency band having the highest energy, calculating a measure of similarity between overlapping frames of frequency bands other than the highest energy frequency band for a range of overlaps around km smaller than the range between Ss+kmin to Ss+kmax, determining an overlap deviation ki yielding the largest measure of similarity for each frequency band other than having the highest energy frequency band, synthesizing an output signal for each frequency band in a set of second equally spaced, overlapping time windows having the corresponding determined overlap amount, combining the separate time-scale modified frequency band signals; and an output device connected to the digital signal processor for outputting the time scale modified digital audio signal.</p></layer>
<layer id = "layer394"><p><b>US20050137858A1:Speech coding</b><br>A high pressure discharge lamp includes a quartz glass bulb having a sealing portion; and a pair of electrodes. Each electrode of the pair of electrodes is disposed so as to be opposite the other in the quartz glass bulb. The quartz glass bulb of the high pressure discharge lamp contains at least mercury and a halogen gas. The partial pressure of oxygen (O) in the quartz glass bulb is about 2.5×10<HIL><SP>−3 </SP></HIL>Pa or less and the partial pressure of the halogen gas in the quartz glass bulb is in the range between about 1×10<HIL><SP>−8 </SP></HIL>μmol/mm<HIL><SP>3 </SP></HIL>and 1×10<HIL><SP>−7 </SP></HIL>μmol/mm<HIL><SP>3</SP></HIL>.<br><b>Independant Claims</b><br>1. A method for use in speech coding, said method comprising: pre-processing a to be encoded speech based signal such that a phase structure of said to be encoded speech based signal is approached to a phase structure which would be obtained if said to be encoded speech based signal was encoded and decoded; and applying an encoding to said pre-processed to be encoded speech based signal.<br>11. A device for performing a speech coding, said device comprising: a pre-processing portion adapted to pre-process a to be encoded speech based signal such that a phase structure of said to be encoded speech based signal is approached to a phase structure which would be obtained if said to be encoded speech based signal was encoded and decoded; and a coding portion which is adapted to apply an encoding to a to be encoded speech based signal.<br>17. A coding module for performing a speech coding, said coding module comprising: a pre-processing portion adapted to pre-process a to be encoded speech based signal such that a phase structure of said to be encoded speech based signal is approached to a phase structure which would be obtained if said to be encoded speech based signal was encoded and decoded; and a coding portion which is adapted to apply an encoding to a to be encoded speech based signal.<br>22. A system comprising at least one device for performing a speech coding, said at least one device comprising: a pre-processing portion adapted to pre-process a to be encoded speech based signal such that a phase structure of said to be encoded speech based signal is approached to a phase structure which would be obtained if said to be encoded speech based signal was encoded and decoded; and a coding portion which is adapted to apply an encoding to a to be encoded speech based signal.<br>28. A software program product in which a software code for use in speech coding is stored, said software code realizing the following steps when running in a processing unit: pre-processing a to be encoded speech based signal such that a phase structure of said to be encoded speech based signal is approached to a phase structure which would be obtained if said to be encoded speech based signal was encoded and decoded; and applying an encoding to said pre-processed to be encoded speech based signal.</p></layer>
<layer id = "layer395"><p><b>US8577675B2:Method and device for speech enhancement in the presence of background noise</b><br>A micromechanical component includes: an adjustable element connected to a holder at least via a spring; a first sensor device with at least one first piezo-resistive sensor element, which first sensor device provides a first sensor signal relating to a first mechanical stress, the first piezo-resistive sensor element being situated on or in an anchoring region of the spring; and a second sensor device with at least one second piezo-resistive sensor element, which second sensor device provides a second sensor signal relating to a second mechanical stress, the second piezo-resistive sensor element being situated on or in an anchoring region of the spring.<br><b>Independant Claims</b><br>73) A speech encoder comprising a processor; and a computer readable memory including computer program code, the computer readable memory and the computer program code configured to, with the processor, cause the speech encoder to perform at least the following: perform frequency analysis to produce a spectral domain representation of the speech signal comprising a number of frequency bins corresponding to an analysis window; group the frequency bins into a number of frequency bands, where a frequency band comprises at least two frequency bins; determine whether speech activity in a speech frame of the speech signal is voiced speech activity; and in response to determining that the speech activity is voiced speech activity, perform noise suppression by determining a scaling factor specific for each frequency bin on a per-frequency-bin basis on bins in a first number of frequency bands of the speech frame, wherein the scaling factor specific for each frequency bin is based at least in part on a signal-to-noise ratio determined for the specific frequency bin, and perform noise suppression by determining a scaling factor specific for each frequency band on a per-frequency-band basis on bands in a second number of frequency bands of the speech frame, wherein the scaling factor specific for each frequency band is based at least in part on a signal-to-noise ratio determined for the specific frequency band where determining the scaling factor specific for each frequency bin on a per-frequency-bin basis on the bins in the first number of frequency bands of the speech frame comprises separately calculating the scaling factor specific for each frequency bin on a per-frequency-bin basis on the bins in the first number of frequency bands of the speech frame and where determining the scaling factor specific for each frequency band on a per-frequency-band basis on the bands in the second number of frequency bands of the speech frame comprises separately calculating the scaling factor specific for each frequency band on a per-frequency-band basis on the bands in the second number of frequency bands of the speech frame.<br>74) An automatic speech recognition system comprising apparatus comprising a processor; and a computer readable memory including computer program code, the computer readable memory and the computer program code configured to, with the processor, cause the apparatus to perform in the automatic speech recognition system at least the following: perform frequency analysis to produce a spectral domain representation of the speech signal comprising a number of frequency bins corresponding to an analysis window; group the frequency bins into a number of frequency bands, where a frequency band comprises at least two frequency bins; determine whether speech activity in a speech frame of the speech signal is voiced speech activity; and in response to determining that the speech activity is voiced speech activity, perform noise suppression by determining a scaling factor specific for each frequency bin on a per-frequency-bin basis on bins in a first number of frequency bands of the speech frame, wherein the scaling factor specific for each frequency bin is based at least in part on a signal-to-noise ratio determined for the specific frequency bin, and perform noise suppression by determining a scaling factor specific for each frequency band on a per-frequency-band basis on bands in a second number of frequency bands of the speech frame, wherein the scaling factor specific for each frequency band is based at least in part on a signal-to-noise ratio determined for the specific frequency band where determining the scaling factor specific for each frequency bin on a per-frequency-bin basis on the bins in the first number of frequency bands of the speech frame comprises separately calculating the scaling factor specific for each frequency bin on a per-frequency-bin basis on the bins in the first number of frequency bands of the speech frame and where determining the scaling factor specific for each frequency band on a per-frequency-band basis on the bands in the second number of frequency bands of the speech frame comprises separately calculating the scaling factor specific for each frequency band on a per-frequency-band basis on the bands in the second number of frequency bands of the speech frame.<br>75) A mobile phone comprising a processor; and a computer readable memory including computer program code, the computer readable memory and the computer program code configured to, with the processor, cause the mobile phone to perform at least the following: perform frequency analysis to produce a spectral domain representation of the speech signal comprising a number of frequency bins corresponding to an analysis window; group the frequency bins into a number of frequency bands, where a frequency band comprises at least two frequency bins; determine whether speech activity in a speech frame of the speech signal is voiced speech activity; and in response to determining that the speech activity is voiced speech activity, perform noise suppression by determining a scaling factor specific for each frequency bin on a per-frequency-bin basis on bins in a first number of frequency bands of the speech frame, wherein the scaling factor specific for each frequency bin is based at least in part on a signal-to-noise ratio determined for the specific frequency bin, and perform noise suppression by determining a scaling factor specific for each frequency band on a per-frequency-band basis on bands in a second number of frequency bands of the speech frame, wherein the scaling factor specific for each frequency band is based at least in part on a signal-to-noise ratio determined for the specific frequency band where determining the scaling factor specific for each frequency bin on a per-frequency-bin basis on the bins in the first number of frequency bands of the speech frame comprises separately calculating the scaling factor specific for each frequency bin on a per-frequency-bin basis on the bins in the first number of frequency bands of the speech frame and where determining the scaling factor specific for each frequency band on a per-frequency-band basis on the bands in the second number of frequency bands of the speech frame comprises separately calculating the scaling factor specific for each frequency band on a per-frequency-band basis on the bands in the second number of frequency bands of the speech frame.<br>37) An apparatus comprising a processor; and a computer readable memory including computer program code, the computer readable memory and the computer program code configured to, with the processor, cause the apparatus to perform at least the following: perform frequency analysis to produce a spectral domain representation of a speech signal comprising a number of frequency bins corresponding to an analysis window; group the frequency bins into a number of frequency bands, where a frequency band comprises at least two frequency bins; determine whether speech activity in a speech frame of the speech signal is voiced speech activity; and in response to determining that the speech activity is voiced speech activity, perform noise suppression by determining a scaling factor specific for each frequency bin on a per-frequency-bin basis on bins in a first number of frequency bands of the speech frame, wherein the scaling factor specific for each frequency bin is based at least in part on a signal-to-noise ratio determined for the specific frequency bin, and perform noise suppression by determining a scaling factor specific for each frequency band on a per-frequency-band basis on bands in a second number of frequency bands of the speech frame, wherein the scaling factor specific for each frequency band is based at least in part on a signal-to-noise ratio determined for the specific frequency band where determining the scaling factor specific for each frequency bin on a per-frequency-bin basis on the bins in the first number of frequency bands of the speech frame comprises separately calculating the scaling factor specific for each frequency bin on a per-frequency-bin basis on the bins in the first number of frequency bands of the speech frame and where determining the scaling factor specific for each frequency band on a per-frequency-band basis on the bands in the second number of frequency bands of the speech frame comprises separately calculating the scaling factor specific for each frequency band on a per-frequency-band basis on the bands in the second number of frequency bands of the speech frame.<br>1) A method comprising: performing frequency analysis to produce a spectral domain representation of a speech signal comprising a number of frequency bins corresponding to an analysis window; grouping the frequency bins into a number of frequency bands, where a frequency band comprises at least two frequency bins; determining whether speech activity in a speech frame of the speech signal is voiced speech activity; and in response to determining that the speech activity is voiced speech activity, performing noise suppression, by a processor, by determining a scaling factor specific for each frequency bin on a per-frequency-bin basis on bins in a first number of frequency bands of the speech frame, wherein the scaling factor specific for each frequency bin is based at least in part on a signal-to-noise ratio determined for the specific frequency bin, and performing noise suppression by determining a scaling factor specific for each frequency band on a per-frequency-band basis on bands in a second number of frequency bands of the speech frame, wherein the scaling factor specific for each frequency band is based at least in part on a signal-to-noise ratio determined for the specific frequency band where determining the scaling factor specific for each frequency bin on a per-frequency-bin basis on the bins in the first number of frequency bands of the speech frame comprises separately calculating the scaling factor specific for each frequency bin on a per-frequency-bin basis on the bins in the first number of frequency bands of the speech frame and where determining the scaling factor specific for each frequency band on a per-frequency-band basis on the bands in the second number of frequency bands of the speech frame comprises separately calculating the scaling factor specific for each frequency band on a per-frequency-band basis on the bands in the second number of frequency bands of the speech frame.</p></layer>
<layer id = "layer396"><p><b>US20050149321A1:Pitch detection of speech signals</b><br>Within a frame period there are defined a managing data transmission area and a data transfer area. Within the managing data transmission area there is made a transmission of data for determining a state of polling control and within the data transfer area there is performed the communication among a plurality of the communicating stations through the polling control based on the data transmitted within the managing data transmission area. As a result of this, in a case where access management of the communication is performed by polling, the transmission efficiency within the network is enhanced.<br><b>Independant Claims</b><br>1. A system for determining a pitch of speech from a speech signal, the system including: (1) an input device to receive the speech and generate the speech signal; and (2) a processor structured to: (a) distinguish the speech signal into voiced, unvoiced or silenced sections using speech signal energy levels; (b) apply a Fourier Transform to the voiced speech signal section and obtain speech signal parameters; (c) determine peaks of the Fourier transformed voiced speech signal section; (d) track the speech signal parameters of the determined peaks to select partials; and (e) determine the pitch from the selected partials using a two-way mismatch error calculation.<br>7. A method of determining a pitch of speech from a speech signal, the method including the steps of: producing or obtaining the speech signal; distinguishing the speech signal into voiced, unvoiced or silenced sections using speech signal energy levels; applying a Fourier Transform to the voiced speech signal section and obtaining speech signal parameters; determining peaks of the Fourier transformed voiced speech signal section; tracking the speech signal parameters of the determined peaks to select partials; and determining the pitch from the selected partials using a two-way mismatch error calculation.<br>28. A system for determining a pitch of speech from a speech signal, the system comprising: (1) an input device to receive the speech and generate the speech signal; and (2) a processor structured to: (a) distinguish the speech signal into voiced, unvoiced or silenced speech signal sections using speech signal energy levels; (b) apply a windowing procedure to the voiced speech signal section to generate a frame; (c) apply a Fourier Transform to the frame and obtain speech signal parameters; (d) determine peaks of the Fourier transformed frame; (e) track the speech signal parameters of the determined peaks to select partials; and (f) determine the pitch from the selected partials using a two-way mismatch error calculation.<br>39. A system for estimating a pitch of speech from a speech signal, the system including: (1) an input device to receive the speech and produce the speech signal; (2) a memory unit or storage unit adapted to communicate required data to a processing unit; and (3) the processing unit operating on the speech signal and structured to: (a) section the speech signal into voiced, unvoiced or silenced sections using speech signal energy levels; (b) apply a Fast Fourier Transform to the voiced speech signal section and generate speech signal parameters; (c) determine peaks of the Fourier transformed voiced speech signal section; (d) track the speech signal parameters of the determined peaks to select partials; and (e) calculate the pitch from the selected partials using a two-way mismatch error calculation.<br>41. A system for determining a pitch of speech from a speech signal, comprising: means for producing or obtaining the speech signal; means for distinguishing the speech signal into voiced, unvoiced or silenced speech signal sections using speech signal energy levels; means for applying a Fourier Transform to the voiced speech signal section and obtaining speech signal parameters; means for determining peaks of the Fourier transformed voiced speech signal section; means for tracking the speech signal parameters of the determined peaks to select partials; and means for determining the pitch from the selected partials using a two-way mismatch error calculation.</p></layer>
<layer id = "layer397"><p><b>US20050192795A1:Identification of the presence of speech in digital audio data</b><br>In a welding system for performing butt welding which comprises butting the end surfaces of steel plates, materials to be welded, placed on the upper surface of a table of a welding stage and welding the end surfaces together, a welding head is a laser/arc combined welding head for simultaneously performing laser light irradiation and arc discharge of the materials <b>38 </b>to be welded, thereby welding the materials to be welded, and the position of an arc electrode <b>40 </b>in an up-and-down direction relative to the materials <b>38 </b>to be welded, the position of the arc electrode in a direction perpendicular to the direction of the optical axis of laser light <b>32 </b>applied to the materials <b>38 </b>to be welded, and the inclination angle of the arc electrode relative to the optical axis of the laser light <b>32 </b>can be adjusted.<br><b>Independant Claims</b><br>1. Method for determining speech related audio data within a record of digital audio data, the method comprising steps for extracting audio features from the record of digital audio data, classifying the record of digital audio data based on the extracted audio features and with respect to one or more predetermined audio classes, and marking at least a part of the record of digital audio data classified as speech, characterised in that the extraction of at least one audio feature comprises the following steps: partitioning the record of digital audio data into adjoining frames, for each frame defining a window being formed by a sequence of adjoining frames containing the frame under consideration, determining for the frame under consideration and at least one further frame of the window a spectral-emphasis-value which is related to the frequency distribution contained in the digital audio data of the respective frame, and assigning a presence-of-speech indicator value to the frame under consideration based on an evaluation of the differences between the spectral-emphasis-values determined for the frame under consideration and the at least one further frame of the window.</p></layer>
<layer id = "layer398"><p><b>US20050192796A1:Audio codec system and audio signal encoding method using the same</b><br>A method for intelligent image recording includes receiving a first image (<b>44</b>) and a second image (<b>46</b>) from an image source (<b>18</b>). The method also includes automatically determining variations between the first image (<b>44</b>) and the second image (<b>46</b>). The method further includes recording the second image (<b>46</b>) if the variations exceed a predetermined value. Determining variations between the first and second images (<b>44,46</b>) may include determining and comparing pixel color values for pixels of the first image (<b>44</b>) with corresponding pixels of the second image (<b>46</b>).<br><b>Independant Claims</b><br>1. An audio codec system comprising: an encoder for encoding analog audio signals being inputted using predetermined coding parameters; a decoder for decoding the audio signals encoded by the encoder using the same coding parameters as the parameters of the encoder and outputting the decoded signals to the encoder; a differential computation block for computing a differential that corresponds to a difference between an actually inputted signal and an estimated signal through the encoding and the decoding; and a coding parameter computation block for computing new coding parameters using the differential computed by the differential computation block and a quantization critical value.<br>5. A method for encoding audio signals comprising the steps of: encoding analog audio signals being inputted using initial coding parameters; decoding the encoded audio signals using the initial coding parameters and re-encoding the decoded signals; computing a differential through the encoding and the decoding steps and computing new coding parameters using the computed differential; repeatedly performing the encoding and the decoding steps using the newly computed coding parameters; and if optimized coding parameters are computed through the repeated encoding and decoding steps, encoding the signals using the computed optimized coding parameters.<br>11. A method for encoding audio signals being inputted, the method comprising the step of: repeatedly performing an encoding and a decoding so as to determine optimized coding parameters.</p></layer>
<layer id = "layer399"><p><b>US20050177364A1:Methods and devices for source controlled variable bit-rate wideband speech coding</b><br>The present invention is embodied in an apparatus, and related method, for sensing a person's facial movements, features and characteristics and the like to generate and animate an avatar image based on facial sensing. The avatar apparatus uses an image processing technique based on model graphs and bunch graphs that efficiently represent image features as jets. The jets are composed of wavelet transforms processed at node or landmark locations on an image corresponding to readily identifiable features. The nodes are acquired and tracked to animate an avatar image in accordance with the person's facial movements. Also, the facial sensing may use jet similarity to determine the person's facial features and characteristic thus allows tracking of a person's natural characteristics without any unnatural elements that may interfere or inhibit the person's natural characteristics.<br><b>Independant Claims</b><br>1. A source-controlled Variable bit-rate Multi-mode WideBand (VMR-WB) codec comprising a unit operable with an Adaptive Multi-Rate wideband (AMR-WB) codec, where in a VMR-WB encoding/AMR-WB decoding case, speech frames are encoded in an AMR-WB interoperable mode of a VMR-WB encoder using one of bit rates corresponding to Interoperable-Full Rate (I-FR) for active speech frames, Interoperable-Half Rate (I-HR) at least for dim-and-burst signaling, Quarter Rate-Comfort Noise Generator (CNG-QR) to encode at least relevant background noise frames and Eighth Rate-Comfort Noise Generator (CNG-ER) frames for background noise frames not encoded as CNG-QR frames, said unit responsive to a case that voice activity is not detected for using CNG-ER encoding, further responsive to a case that voice activity is detected, and responsive to a voiced versus unvoiced classification such that if a frame is classified as unvoiced, the frame is encoded with one of Unvoiced HR or Unvoiced QR encoding, further responsive to a frame not being classified as unvoiced for using a stable voiced classification, and if the frame is classified as stable voiced, encoded the frame using Voiced HR encoding, else assuming the frame to likely contain a non-stationary speech segment for using an appropriate FR encoding, whereas a frame with low energy, and not detected as at least a background or an unvoiced frame, is encoded using generic HR coding to reduce the average data rate; an unvoiced classification decision being based on at least some of a voicing measure r̅x, a spectral tilt et, an energy variation within a frame dE, and a relative frame energy Erel, where decision thresholds are set based at least in part on an operating mode comprising a required average data rate.<br>2. A method for encoding a sampled speech signal comprising speech frames, the method comprising: determining whether a current frame of the sampled speech signal is an active speech frame or an inactive speech frame, if said current frame is an active speech frame, performing a classification procedure to determine whether the current frame is an unvoiced frame, said classification procedure comprising examining at least three of the following parameters in order to determine whether the current frame is an unvoiced frame: a) a voicing measure (rx,r̅x); b) a spectral tilt measure (etilt , et); c) an energy variation within the current frame (dE); d) a relative energy of the current frame (Erel); and when the current frame is classified as an unvoiced frame by said classification procedure, encoding the current frame using an unvoiced signal coding algorithm.<br>34. A device for encoding a sampled speech signal comprising speech frames, the device comprising: a voice activity detector for determining whether frames of the sampled speech signal are active speech frames or inactive speech frames; a classification unit arranged to perform a classification procedure on active speech frames to determine whether said active speech frames are unvoiced frames, said classification procedure comprising examining at least three of the following parameters in order to determine whether a current frame is an unvoiced frame: a) a voicing measure (rx,r̅x); b) a spectral tilt measure (etilt,et); c) an energy variation within the current frame (dE); d) a relative energy of the current frame (Erel); said device being arranged to encode the current frame using an unvoiced signal coding algorithm when the classification unit classifies the current frame as an unvoiced frame.<br>66. A device for encoding a sampled speech signal comprising speech frames, the device comprising: means for determining whether a current frame of the sampled speech signal is an active speech frame or an inactive speech frame, means, responsive to said current frame being an active speech frame, for performing a classification procedure to determine whether the current frame is an unvoiced frame, said classification procedure comprising examining at least three of the following parameters in order to determine whether the current frame is an unvoiced frame: a) a voicing measure (rx,r̅x); b) a spectral tilt measure (etilt, et); c) an energy variation within the current frame (dE); d) a relative energy of the current frame (Erel); and means for encoding the current frame using an unvoiced signal coding algorithm when the current frame is classified as an unvoiced frame by said classification procedure.<br>67. A speech encoder, responsive to a current frame being classified as an active speech frame, for encoding said current frame using an unvoiced signal coding algorithm, wherein an active speech frame is further classified as an active unvoiced speech frame by examining at least three parameters selected from the set: a voicing measure (rx,r̅x), a spectral tilt measure (etilt,et), an energy variation within the current frame (dE), and a relative energy of the current frame (Erel).<br>68. A program of machine-readable instructions, tangibly embodied on an information bearing medium and executable by a digital data processor, to perform actions directed toward encoding a sampled speech signal comprising speech frames, the actions comprising: determining whether a current frame of the sampled speech signal is an active speech frame or an inactive speech frame, performing a classification procedure on an active speech frame to determine whether the current frame is an unvoiced frame, said classification procedure comprising examining at least three of the following parameters in order to determine whether the current frame is an unvoiced frame: a) a voicing measure (rx,r̅x); b) a spectral tilt measure (etilt,et); c) an energy variation within the current frame (dE); d) a relative energy of the current frame (Erel); and encoding the current frame using an unvoiced signal coding algorithm when the current frame is classified as an unvoiced frame by said classification procedure.</p></layer>
<layer id = "layer400"><p><b>US6931373B1:Prototype waveform phase modeling for a frequency domain interpolative speech codec system</b><br>Various systems and methods are disclosed for carrying out combustion in a fuel-cut operation in some or all of the engine cylinders of a vehicle. Further, various subsystems are considered, such as fuel vapor purging, air-fuel ratio control, engine torque control, catalyst design, and exhaust system design.<br><b>Independant Claims</b><br>1) A frequency domain interpolative CODEC system for low bit rate coding of speech, comprising: a linear prediction (LP) front end adapted to process an input signal providing LP parameters which are quantized and encoded over predetermined intervals and used to compute a LP residual signal; an open loop pitch estimator adapted to process said LP residual signal, a pitch quantizer, and a pitch interpolator and provide a pitch contour within the predetermined intervals; and a signal processor responsive to said LP residual signal and the pitch contour and adapted to perform the following: provide a voicing measure, said voicing measure characterizing a degree of voicing of said input speech signal and is derived from several input parameters that are correlated to degrees of periodicity of the signal over the predetermined intervals; extract a prototype waveform (PW) from the LP residual and the open loop pitch contour for a number of equal sub-intervals within the predetermined intervals; normalize the PW by a gain value of said PW; encode a magnitude of said PW; and reconstruct a nonstationarity component of a PW phase at a decoder every subinterval using only a received PW magnitude, a stationary component of said PW, said voicing measure, a PW subband nonstationarity measure and a pitch frequency contour information; wherein a ratio is computed comparing the ratio of the energy of the nonstationarity component of the PW to that of the stationary component of the PW which is averaged over five PW subbands.<br>13) A frequency domain interpolative CODEC system for low bit rate coding of speech, comprising: a linear prediction (LP) front end adapted to process an input signal providing LP parameters which are quantized and encoded over predetermined intervals and used to compute a LP residual signal; an open loop pitch estimator adapted to process said LP residual signal, a pitch quantizer, and a pitch interpolator and provide a pitch contour within the predetermined intervals; a signal processor responsive to said LP residual signal and the pitch contour and adapted to perform the following: provide a voicing measure, said voicing measure characterizing a degree of voicing of said input speech signal and is derived from several input parameters that are correlated to degrees of periodicity of the signal over the predetermined intervals; extract a prototype waveform (PW) from the LP residual and the open loop pitch contour for a number of equal sub-intervals within the predetermined intervals; normalize the PW by a gain value of said PW; encode a magnitude of said PW; and reconstruct a nonstationarity component of a PW phase at a decoder every subinterval using only a received PW magnitude, a stationary component of said PW, said voicing measure, a PW subband nonstationarity measure and a pitch frequency contour information; wherein a ratio is computed comparing the ratio of the energy of the nonstationarity component of the PW to that of the stationary component of the PW which is averaged over five PW subbands.</p></layer>
<layer id = "layer401"><p><b>US20050182624A1:Method and apparatus for constructing a speech filter using estimates of clean speech and noise</b><br>Techniques are provided for the implementation of dynamically biased circuits. In these circuits, bias currents are varied according to signal amplitude. Benefits include reduced power dissipation, reduced noise, and increased dynamic range. The techniques can be employed in various types of circuits such as, for example, amplifiers, log-domain circuits, and filters.<br><b>Independant Claims</b><br>1. A method of identifying a clean speech signal from a noisy speech signal, the method comprising: receiving an observation vector representing a segment of a noisy speech signal; estimating a clean speech value and a noise value based on the observation vector; using the clean speech value and the noise value to set a gain for a filter; and applying the observation vector to the filter to produce a filtered clean speech vector representing a segment of a clean speech signal.<br>13. A computer-readable medium having computer-executable instructions for performing steps comprising: obtaining an estimate of a clean speech value and an estimate of a noise value derived from a noisy speech signal; setting a numerator of a filter gain ratio as a function of the clean speech value and the noise value; setting a denominator of the filter gain ratio as a function of the clean speech value and the noise value; using the filter gain ratio in a filter that is applied to the noisy speech signal.</p></layer>
<layer id = "layer402"><p><b>US8438026B2:Method and system for generating training data for an automatic speech recognizer</b><br>A method of operating an electric machine includes flowing a coolant into an interior portion of a housing of the electric machine, and sensing a level of coolant in a coolant collection area within the interior portion with a coolant level sensor arranged at the housing.<br><b>Independant Claims</b><br>9) A method for generating training data for an automatic speech recognizer operating at a first sampling frequency, comprising: deriving spectral characteristics from audio data sampled at a second frequency lower than the first sampling frequency; extending a bandwidth of the spectral characteristics by retrieving bandwidth extending information from a codebook so that the audio data sampled at the second frequency is compatible with the automatic speech recognizer operating at the first sampling frequency; and processing the bandwidth extended spectral characteristics to give the required training data, wherein extending the bandwidth includes augmenting the spectral characteristics of the audio data sampled at the second frequency with a set of spectral characteristics of audio data sampled at the first sampling frequency obtained from the codebook, wherein each entry in the codebook is generated by: deriving a first set of spectral characteristics from audio data sampled at the first sampling frequency; performing a sampling rate transformation on the audio data to the second frequency and deriving a corresponding second set of spectral characteristics; and generating a codebook entry comprising information from the first and second sets of spectral characteristics, stored such that the first and second sets of spectral characteristics are associated with each other and yet remain separate.<br>1) A method for generating training data for an automatic speech recognizer operating at a first sampling frequency, comprising: deriving spectral characteristics from audio data sampled at a second frequency lower than the first sampling frequency; extending a bandwidth of the spectral characteristics by retrieving bandwidth extending information from a codebook so that the audio data sampled at the second frequency is compatible with the automatic speech recognizer operating at the first sampling frequency; and processing the bandwidth extended spectral characteristics to give the required training data, wherein extending the bandwidth includes augmenting the spectral characteristics of the audio data sampled at the second frequency with a set of spectral characteristics of audio data sampled at the first sampling frequency obtained from the codebook, wherein each entry in the codebook is generated by: deriving a first set of spectral characteristics from audio data sampled at the first sampling frequency; performing a sampling rate transformation on the audio data to the second frequency and deriving a corresponding second set of spectral characteristics; and generating a codebook entry comprising information from the second set of spectral characteristics, together with additional bandwidth extending information extracted from the first set of spectral characteristics.<br>8) A system for generating training data for an automatic speech processor operating at a first sampling frequency, comprising: a hardware converter for deriving spectral characteristics from audio data sampled at a second frequency lower than the first sampling frequency; a hardware retrieval unit for retrieving bandwidth extending information for the spectral characteristics from a codebook so that the audio data sampled at the second frequency is compatible with the automatic speech processor operating at the first sampling frequency; and a hardware processing module for processing the bandwidth-extended spectral characteristics to give the required training data, wherein the hardware retrieval unit augments the spectral characteristics of the audio data sampled at the second frequency with the set of spectral characteristics of audio data sampled at the first sampling frequency obtained from the codebook, wherein each entry in the codebook is generated by: deriving a first set of spectral characteristics from audio data sampled at the first sampling frequency; performing a sampling rate transformation on the audio data to the second frequency and deriving a corresponding second set of spectral characteristics; and generating a codebook entry comprising information from the second set of spectral characteristics, together with additional bandwidth extending information extracted from the first set of spectral characteristics.</p></layer>
<layer id = "layer403"><p><b>US20050207502A1:Transcoder and code conversion method</b><br>An edge-deployed database proxy. A database access system which has been configured with the database proxy can include a universal database connectivity driver having a first exposed interface through which access to a database server can be provided; a database proxy driver registered with the universal database connectivity driver; and, a database driven application programmatically linked to the database proxy driver. Significantly, the database proxy driver can have a second exposed interface which conforms with the first exposed interface of the universal database connectivity driver. The database proxy driver further can have a configuration for invoking at least one auxiliary task in addition to providing access to the database server through the first exposed interface of the universal database connectivity driver.<br><b>Independant Claims</b><br>1. A transcoder that performs inter-conversion between a code encoded in accordance with a first encoding method and a code encoded in accordance with a second encoding method, comprising: a first decoding unit, receiving a code encoded by the first encoding method, for decoding the received code in accordance with a first decoding method to output a decoded signal; a spectrum parameter calculating unit, receiving the decoded signal, for calculating a spectrum parameter representing spectrum characteristics to output the resultant spectrum parameter; a noise generating unit for generating a noise signal; a coefficient calculating unit for shifting a frequency of the spectrum parameter, and calculating filter coefficients to output the filter coefficients; a gain unit for applying a gain to the output signal from said noise generating unit to output the resulting signal; a synthesis filter unit including a synthesis filter configured by the filter coefficients from said coefficient calculating unit, said synthesis filter, receiving the output signal from said gain unit, for passing the output signal through the synthesis filter to output a signal of a band required for band conversion; a sampling frequency conversion circuit for converting the decoded signal using a predetermined sampling frequency to output the resulting signal; an adder for summing the output signal of said sampling frequency conversion circuit and the output signal of said synthesis filter unit to output the resulting signal; and a second encoding unit, receiving the output signal of said adder for encoding the output signal in accordance with the second encoding method to produce and output a second code.<br>2. A transcoder that performs inter-conversion between a code encoded in accordance with a first encoding method and a code encoded in accordance with a second encoding method, comprising: a first decoding unit, receiving a code encoded in accordance with the first encoding method, for decoding the received code in accordance with a first decoding method to output a decoded signal; a spectrum parameter calculating unit, receiving the decoded signal, for calculating a spectrum parameter representing spectrum characteristics; an adaptive codebook unit for calculating a pitch period from the decoded signal and generating an adaptive codebook component based on the pitch period and a past sound source signal; a noise generating unit for generating a noise signal; a coefficient calculating unit for shifting a frequency of the spectrum parameter and calculating filter coefficients; a gain unit for applying a gain to at least one of the output signal of said noise generating unit and the output signal of said adaptive codebook unit and adding up the signals to output a sound source signal; a synthesis filter unit including a synthesis filter configured by the filter coefficients from said coefficient calculating unit, synthesis filter unit receiving the sound source signal from said gain unit, and passing the sound source signal through the synthesis filter to output a signal of a band required for band conversion; a sampling frequency conversion circuit for converting the decoded signal using a predetermined sampling frequency to output the resulting signal; an adder for summing the output signal of said sampling frequency conversion circuit and the output signal of said synthesis filter unit to output the resulting signal; and a second encoding unit, receiving the output signal of said adder and encodes the output signal in accordance with the second encoding method to produce and output a second code.<br>3. A transcoder that performs inter-conversion between a code encoded in accordance with a first encoding method and a code encoded in accordance with a second encoding method, comprising: a first decoding unit, receiving a code encoded in accordance with the first encoding method, for decoding the received code in accordance with a first decoding method to output a decoded signal; a spectrum parameter calculating unit, receiving the decoded signal for calculating a spectrum parameter representing spectrum characteristics; an adaptive codebook unit for calculating a pitch period from the decoded signal and generating an adaptive codebook component based on the pitch period and a past sound source signal; a noise generating unit for generating a noise signal; a coefficient calculating unit for shifting a frequency of the spectrum parameter and calculating filter coefficients; a gain unit for applying a gain to at least one of the output signal of said noise generating unit and the output signal of said adaptive codebook unit to add up the signals to output a sound source signal; a pitch pre-filter for performing pre-filtering processing for the sound source signal from said gain unit using the pitch period; a synthesis filter unit including a synthesis filter configured by the filter coefficients from said coefficient calculating unit, said synthesis filter unit passing the output signal of said pitch pre-filter through the synthesis filter to output a signal of a band required for band conversion; a sampling frequency conversion circuit for converting the decoded signal using a predetermined sampling frequency to output the resulting signal; an adder for summing the output signal of said sampling frequency conversion circuit and the output signal of said synthesis filter unit to output the resulting signal; and a second encoding unit, receiving the output signal of said adder, for encoding the output signal in accordance with the second encoding method to produce and output a second code.<br>4. A transcoder that performs inter-conversion between a code encoded in accordance with a first encoding method and a code encoded in accordance with a second encoding method, comprising: a first decoding unit, receiving a code encoded in accordance with the first encoding method, for decoding the received code in accordance with a first decoding method, to output a decoded signal; a spectrum parameter calculating unit, receiving the decoded signal, for calculating a spectrum parameter representing spectrum characteristics; a periodic signal generation unit for calculating a pitch period from the decoded signal and generating a periodic signal using the pitch period; a noise generating unit for generating a noise signal; a coefficient calculating unit for shifting a frequency of the spectrum parameter and calculating filter coefficients; a gain unit for applying a gain to at least one of the output signal of said noise generating unit and the output signal of said periodic signal generation unit and adding up the signals to output a sound source signal; a synthesis filter unit including a synthesis filter configured by the filter coefficients from said coefficient calculating unit, said synthesis filter unit receiving the sound source signal from said gain unit, and passing the sound source signal through the synthesis filter to output a signal of a band required for band conversion; a sampling frequency conversion circuit for converting the decoded signal using a predetermined sampling frequency to output the resulting signal; an adder for summing the output signal of said sampling frequency conversion circuit and the output signal of said synthesis filter unit and outputs the resulting signal; and a second encoding unit, receiving the output signal of said adder and encodes the output signal in accordance with the second encoding method to produce and output a second code.<br>5. A transcoder that performs inter-conversion between a code encoded in accordance with a first encoding method and a code encoded in accordance with a second encoding method, comprising: a first decoding unit, receiving a code encoded in accordance with the first encoding method, for decoding the received code in accordance with a first decoding method, to output a decoded signal; a spectrum parameter calculating unit, receiving the decoded signal, for calculating a spectrum parameter representing spectrum characteristics; a periodic signal generation unit for calculating a pitch period from the decoded signal and generating a periodic signal using the pitch period; a noise generating unit for generating a noise signal; a coefficient calculating unit for shifting a frequency of the spectrum parameter and calculating filter coefficients; a gain unit for applying a gain to at least one of the output signal of said noise generating unit and the output signal of said periodic signal generation unit and adding up the signals to output a sound source signal; a pitch pre-filter for performing pre-filtering processing for the sound source signal from said gain unit using the pitch period; a synthesis filter unit including a synthesis filter configured by the filter coefficients from said coefficient calculating unit, said synthesis filter unit passing the output signal of said pitch pre-filter through the synthesis filter to output a signal of a band required for band conversion; a sampling frequency conversion circuit for converting the decoded signal using a predetermined sampling frequency to output the resulting signal; an adder for summing the output signal of said sampling frequency conversion circuit and the output signal of said synthesis filter unit and outputs the resulting signal; and a second encoding unit, receiving the output signal of said adder and encodes the output signal in accordance with the second encoding method to produce and output a second code.<br>19. A code conversion method for use by a transcoder that performs inter-conversion between a code encoded in accordance with a first encoding method and a code encoded in accordance with a second encoding method, comprising: a step of decoding a code in accordance with a first decoding method and outputting a decoded signal, said code encoded in accordance with the first encoding method; a step of calculating a spectrum parameter from the decoded signal and outputting the spectrum parameter, said spectrum parameter representing spectrum characteristics; a step of shifting a frequency of the spectrum parameter, calculating filter coefficients, and outputting the calculated filter coefficients; a step of applying a gain to an output signal from a noise generating unit; a step of passing the output signal having the gain applied thereto, through a synthesis filter to output a signal of a band required for band conversion, said synthesis filter configured by the filter coefficients; a step of adding up a signal, which is generated by converting the decoded signal using a predetermined sampling frequency, and the output signal of said synthesis filter; and a step of encoding the addition result in accordance with the second encoding method to produce and output a second code.<br>20. A code conversion method for use by a transcoder that performs inter-conversion between a code encoded in accordance with a first encoding method and a code encoded in accordance with a second encoding method, comprising: a step of decoding a code in accordance with a first decoding method and outputting a decoded signal, said code encoded in accordance with the first encoding method; a step of calculating a spectrum parameter from the decoded signal and outputting the spectrum parameter, said spectrum parameter representing spectrum characteristics; a step of calculating a pitch period from the decoded signal and, based on the pitch period and a past sound source signal, generating an adaptive codebook component; a step of shifting a frequency of the spectrum parameter, calculating filter coefficients, and outputting the calculated filter coefficients; a step of applying a gain to at least one of a noise output from a noise generating unit and the adaptive codebook component and adding up the signals to output a sound source signal; a step of passing the sound source signal through a synthesis filter to output a signal of a band required for band conversion, said synthesis filter configured by the filter coefficients; a step of adding up a signal, which is generated by converting the decoded signal using a predetermined sampling frequency, and the output signal of said synthesis filter; and a step of encoding the addition result in accordance with the second encoding method to produce and output a second code.<br>21. A code conversion method for use by a transcoder that performs inter-conversion between a code encoded in accordance with a first encoding method and a code encoded in accordance with a second encoding method, comprising: a step of decoding a code in accordance with a first decoding method and outputting a decoded signal, said code encoded in accordance with the first encoding method; a step of calculating a spectrum parameter from the decoded signal and outputting the spectrum parameter, said spectrum parameter representing spectrum characteristics; a step of calculating a pitch period from the decoded signal and, based on the pitch period and a past sound source signal, generating an adaptive codebook component; a step of shifting a frequency of the spectrum parameter, calculating filter coefficients, and outputting the calculated filter coefficients; a step of applying a gain to at least one of a noise output from a noise generating unit and the adaptive codebook component and adding up the signals to output a sound source signal; a step of performing pitch pre-filtering processing for the sound source signal using the pitch period; a step of passing the pitch pre-filtered signal through a synthesis filter to output a signal of a band required for band conversion, said synthesis filter configured by the filter coefficients; a step of adding up a signal, which is generated by converting the decoded signal using a predetermined sampling frequency, and the output signal of said synthesis filter; and a step of encoding the addition result in accordance with the second encoding method to produce and output a second code.<br>22. A code conversion method for use by a transcoder that performs inter-conversion between a code encoded in accordance with a first encoding method and a code encoded in accordance with a second encoding method, comprising: a step of decoding a code in accordance with a first decoding method and outputting a decoded signal, said code encoded in accordance with the first encoding method; a step of calculating a spectrum parameter from the decoded signal and outputting the spectrum parameter, said spectrum parameter representing spectrum characteristics; a step of calculating a pitch period from the decoded signal and generating a periodic signal using the pitch period; a step of shifting a frequency of the spectrum parameter, calculating filter coefficients, and outputting the calculated filter coefficients; a step of applying a gain to at least one of a noise output from a noise generating unit and the periodic signal and adding up the signals to output a sound source signal; a step of passing the sound source signal through a synthesis filter to output a signal of a band required for band conversion, said synthesis filter configured by the filter coefficients; a step of adding up a signal, which is generated by converting the decoded signal using a predetermined sampling frequency, and the output signal of said synthesis filter; and a step of encoding the addition result in accordance with the second encoding method to produce and output a second code.<br>23. A code conversion method for use by a transcoder that performs inter-conversion between a code encoded in accordance with a first encoding method and a code encoded in accordance with a second encoding method, comprising: a step of decoding a code in accordance with a first decoding method and outputting a decoded signal, said code encoded in accordance with the first encoding method; a step of calculating a spectrum parameter from the decoded signal and outputting the spectrum parameter, said spectrum parameter representing spectrum characteristics; a step of calculating a pitch period from the decoded signal and generating a periodic signal using the pitch period; a step of shifting a frequency of the spectrum parameter, calculating filter coefficients, and outputting the calculated filter coefficients; a step of applying a gain to at least one of a noise output from a noise generating unit and the periodic signal and adding up the signals to output a sound source signal; a step of performing pitch pre-filtering processing for the sound source signal using the pitch period; a step of passing the pitch pre-filtered signal through a synthesis filter to output a signal of a band required for band conversion, said synthesis filter configured by the filter coefficients; a step of adding up a signal, which is generated by converting the decoded signal using a predetermined sampling frequency, and the output signal of said synthesis filter; and a step of encoding the addition result in accordance with the second encoding method to produce and output a second code.</p></layer>
<layer id = "layer404"><p><b>US20050228651A1:Robust real-time speech codec</b><br>A speech recognition method is disclosed for activating a hyperlink of an Internet page. In particular the method comprises determining hypertexts of the hyperlinks in text information, determining corresponding first phoneme sequences of hypertexts, receiving a spoken command from a user, determining a second phoneme sequence corresponding to the spoken command, determining the hyperlink selected by the user using the first and second phoneme sequences, activating the selected hyperlink, where one quality value is determined for each hypertext when first phoneme sequences are determined and where an extra hypertext is determined when the quality value of a hypertext is below a threshold and is assigned to the hypertext of the Internet page or in lieu of the hypertext, and where a first phoneme sequence determined for the extra hypertext has a quality value that exceeds the threshold.<br><b>Independant Claims</b><br>1. In an audio processing tool, a method comprising: processing plural frames for an audio signal, wherein the plural frames include a mix of one or more intra frames and one or more predicted frames, wherein at least one of the one or more predicted frames uses long-term prediction from outside of the predicted frame, and wherein each of the one or more intra frames uses no long-term prediction from outside of the intra frame; and outputting a result.<br>17. In an audio encoder, a method of encoding plural frames for an audio signal, the method comprising: encoding plural predicted frames of the plural frames; and encoding plural intra frames of the plural frames, wherein the encoder sets intra frame usage and inserts the plural intra frames among the plural predicted frames according to the intra frame usage.<br>23. In an audio decoder, a method comprising: decoding plural frames for an audio signal, wherein the plural frames include one or more intra frames and one or more predicted frames, and wherein frame-level type signaling information differentiates the one or more intra frames from the one or more predicted frames in a bitstream; and outputting decoded information.<br>28. In a speech processing tool, a method comprising: processing a frame for a speech signal, including processing primary encoded information for the frame and one or more versions of forward error correction information for the frame, wherein the primary encoded information comprises plural parameter values, and wherein each of the one or more versions of forward error correction information comprises a subset of the plural parameter values selected based at least in part on an estimate of extra available bits; and outputting a result.<br>35. In a speech processing tool, a method comprising: processing a frame for a speech signal, including processing primary encoded information for the frame and plural versions of forward error correction information for the frame, wherein the primary encoded information comprises plural parameter values, and wherein each of the plural versions of forward error correction information comprises a different subset of the plural parameter values for the frame; and outputting a result.<br>40. In an audio processing tool, a method comprising: processing encoded information for an audio signal, wherein the encoded information includes forward error correction information for a first frame and primary encoded information for a second frame, and wherein at least some of the forward error correction information for the first frame is predictively encoded relative to the primary encoded information for the second frame; and outputting a result.<br>49. In a real-time speech encoder that uses linear prediction, a method comprising: encoding a speech signal as plural linear prediction parameters, including adjusting bitrate and quality for a current frame of the speech signal based at least in part on (a) complexity of the current frame, (b) complexity and/or rate of at least some surrounding segments of the speech signal, (c) desired operating rate, (d) currently available network bandwidth, and (e) current network congestion or noise conditions or decoder feedback; and outputting encoded speech.<br>52. In an encoder-side audio processing tool, a method of encoding one or more frames of an audio signal, the method comprising: estimating a number of extra available bits for a segment of the audio signal after basic encoding; and using at least some of the extra available bits for adaptive forward error correction.<br>60. In a real-time speech encoder that uses linear prediction, a method comprising: encoding a speech signal as plural linear prediction parameters, including adjusting bitrate and quality for a current segment of the speech signal based at least in part on a quality smoothness criteria for a transition between a previous segment and the current segment; and outputting encoded speech.<br>64. In an audio processing tool, a method comprising: processing a frame for an audio signal, including processing first information that represents the frame as a predicted frame or intra frame, and further including processing second information that represents the frame as an intra frame; and outputting a result.</p></layer>
<layer id = "layer405"><p><b>US6963833B1:Modifications in the multi-band excitation (MBE) model for generating high quality speech at low bit rates</b><br>A measuring system that includes a scale and a transparent substrate located opposite the scale. The transparent includes a graduation structure and a semiconductor layer arranged on a first side of the transparent substrate facing away from the scale, wherein a photodetector, a light source and an electronic circuit are integrated into the semiconductor layer.<br><b>Independant Claims</b><br>1) A method for processing a signal, the method comprising the steps of: dividing the signal into frames, each frame having a corresponding spectrum; selecting a plurality of pitch candidates from a first frame; selecting a plurality of pitch candidates from a second frame; selecting a plurality of pitch candidates from a third frame: calculating a cumulative error function for a plurality of paths, each path including a pitch candidate from the first frame, a pitch candidate from the second frame, and a pitch candidate from the third frame; selecting a path corresponding to a low cumulative error function; basing a pitch estimate for a current frame on the selected path; using the pitch estimate for the current frame to process the signal.<br>26) A method for processing a signal comprising the steps of: dividing the signal into frames; obtaining a pitch estimate for a current frame; refining the obtained pitch estimate comprising the sub-step of: computing backward and forward sub-multiples of the obtained pitch estimate for the current frame; determining whether the backward sub-multiples satisfy at least one backward constraint equation; determining whether the forward sub-multiples satisfy at least one forward constraint equation; selecting a low backward sub-multiple that satisfies the at least one backward constraint equation as the backward pitch estimate, wherein the obtained pitch estimate of the current frame is selected as the backward pitch estimate if a backward sub-multiple does not satisfy the at least one backward constraint equation; selecting a low forward sub-multiple that satisfies the at least one forward constraint equation as the forward pitch estimate, wherein the obtained pitch estimate of the current frame is selected as the forward pitch estimate if a forward sub-multiple does not satisfy the at least one forward constraint equation; using the backward pitch estimate to compute a backward cumulative error; using the forward pitch estimate to compute a forward cumulative error; comparing the forward cumulative error to the backward cumulative error; refining the chosen pitch estimate for the current frame based on the comparison; and using the refined pitch estimate for the current frame to process the signal.</p></layer>
<layer id = "layer406"><p><b>US8688440B2:Coding apparatus, decoding apparatus, coding method and decoding method</b><br>The invention provides methods for reprogramming somatic cells to generate multipotent or pluripotent cells. Such methods are useful for a variety of purposes, including treating or preventing a medical condition in an individual. The invention further provides methods for identifying an agent that reprograms somatic cells to a less differentiated state.<br><b>Independant Claims</b><br>1) A coding apparatus comprising: an acquisition section that acquires a spectrum of a voice signal including a low frequency band spectrum and a high frequency band spectrum; a first coding section that codes the low frequency band spectrum, to generate first coded information; a first decoding section that decodes the first coded information, to generate decoded low frequency band spectrum; a generation section that generates a shape of an estimated high frequency band spectrum by duplicating the decoded low frequency band spectrum; a first subband amplitude calculation section that divides the estimated high frequency band spectrum into a plurality of subbands and calculates a first average amplitude value of the estimated high frequency band spectrum in each of the plurality of subbands; a second subband amplitude calculation section that divides the high frequency band spectrum into a plurality of subbands and calculates a second average amplitude value of the high frequency band spectrum in each of the plurality of subbands; a gain codebook that outputs only a gain of specific subbands, the specific subbands including a subband of the estimated high frequency band spectrum adjacent to the low frequency band spectrum among the plurality of subbands of the estimated high frequency band spectrum; an interpolation section that finds a gain of a subband of the estimated high frequency band spectrum other than the specific subbands by interpolating the gain of the specific subbands; a multiplication section that multiplies the first average amplitude value by the gain output from the gain codebook or the interpolation section in each of the subbands; a second coding section that calculates a distortion between a multiplied result of the multiplication section and the second average amplitude value and codes only the gain of the specific subbands when the distortion is smallest; and an output terminal that outputs coded information obtained by the first and second coding sections.<br>10) A coding method comprising: an acquisition step of acquiring a spectrum of a voice signal including a low frequency band spectrum and a high frequency band spectrum; a first coding step of coding the low frequency band spectrum, to generate first coded information; a first decoding step of decoding the first coded information, to generate decoded low frequency hand spectrum; a generation step of generating a shape of an estimated high frequency band spectrum by duplicating the decoded low frequency band spectrum; a first subband amplitude calculation step of dividing the estimated high frequency band spectrum into a plurality of subbands and calculating a first average amplitude value of the estimated high frequency band spectrum in each of the plurality of subbands; a second subband amplitude calculation step of dividing the high frequency band spectrum into a plurality of subbands and calculating a second average amplitude value of the high frequency band spectrum in each of the plurality of subbands; a gain output step of outputting only a gain of specific subbands, the specific subbands including a subband of the estimated high frequency band spectrum adjacent to the low frequency band spectrum among the plurality of subbands of the estimated high frequency hand spectrum; an interpolation step of finding a gain of a subband of the estimated high frequency band spectrum other than the specific subbands by interpolating the gain of the specific subbands; a multiplication step of multiplying the first average amplitude value by the gain output from the gain output step or the interpolation step in each of the subbands; a second coding step of calculating a distortion between a multiplied result of the multiplication step and the second average amplitude value and coding only the gain of the specific subbands when the distortion is smallest; and an output step of outputting coded information obtained by the first and second coding steps.<br>11) A decoding method that decodes coded information relating to a spectrum of a voice signal including a low frequency band spectrum and a high frequency band spectrum, comprising: a first decoding step of decoding coded information relating to the low frequency band spectrum, to generate a decoded low frequency band spectrum; a second decoding step of decoding coded information relating to the high frequency band spectrum, to generate only a gain of specific subbands, the specific subbands including a subband of the high frequency band spectrum adjacent to the low frequency band spectrum among the plurality of subbands into which the high frequency band spectrum is divided; an interpolation step of finding a gain of a subband other than the specific subbands by interpolating the gain of the specific subbands; and a high frequency band spectrum generation step of generating the high frequency band spectrum using the decoded low frequency band spectrum obtained by the first decoding step and the gains obtained by the second decoding step and the interpolation step.<br>5) A decoding apparatus that decodes coded information relating to a spectrum of a voice signal including a low frequency band spectrum and a high frequency band spectrum, comprising: a first decoding section that decodes coded information relating to the low frequency band spectrum, to generate a decoded low frequency band spectrum; a second decoding section that decodes coded information relating to the high frequency band spectrum, to generate only a gain of specific subbands, the specific subbands including a subband of the high frequency band spectrum adjacent to the low frequency band spectrum among the plurality of subbands into which the high frequency band spectrum is divided; an output terminal that outputs the decoded low frequency band spectrum obtained by the first decoding section and the gains obtained by the second decoding section; an interpolation section that finds a gain of a subband other than the specific subbands by interpolating the gain of the specific subbands; and a high frequency band spectrum generation section that generates the high frequency band spectrum using the decoded low frequency band spectrum obtained by the first decoding section and the gains obtained by the second decoding section and the interpolation section.</p></layer>
<layer id = "layer407"><p><b>US8712768B2:System and method for enhanced artificial bandwidth expansion</b><br>An electrical connector assembly comprises a primary connector housing, a mating connector housing, a primary lock, and a secondary lock. The primary lock is defined by both the primary connector housing and the mating connector housing. The secondary lock is supported by the mating connector housing and is arranged and configured for interacting with the primary lock so as to prevent the primary lock, when positioned in a locked position, from disengaging. The primary lock comprises a lock arm extending from the primary connector housing and a lock lever extending from the mating connector housing.<br><b>Independant Claims</b><br>1) A method for expanding narrowband speech signals to wideband speech signals, the method comprising: determining signal type information from a signal; obtaining characteristics for forming an upper band signal using the determined signal type information; detecting babble noise in the signal based on a gradient index, enemy information, and a noise level estimate; determining signal noise information, wherein the signal noise information is determined based on a far-end signal-to-noise ratio and a near-end signal-to-noise ratio; using the determined signal noise information to modify the obtained characteristics for forming the upper band signal; and forming the upper band signal using the modified characteristics.<br>5) A communication device configured to receive wideband signals, the device comprising: an interface that communicates with a wireless network; and programmed instructions stored in a memory and configured to expand received narrowband signals to wideband signals by adjusting an artificial bandwidth expansion algorithm based on noise conditions, wherein the noise conditions comprise a far-end signal-to-noise ratio and a near-end signal-to-noise ratio; and detect babble noise based on a gradient index, energy information, and a noise level estimate.<br>7) A device in a communication network that expands narrowband speech signals into wideband speech signals, the device comprising: a narrowband codec that receives narrowband speech signals in a network; a wideband codec that communicates wideband speech signals to wideband terminals in communication with the network; and programmed instructions that expand the narrowband speech signals to wideband speech signals by adjusting an artificial bandwidth expansion algorithm based on noise conditions, wherein the noise conditions comprise a far-end signal-to-noise ratio and a near-end signal-to-noise ratio and detect babble noise based on a gradient index, energy information, and a noise level estimate.<br>8) A system for expanding narrowband speech signals to wideband speech signals, the system comprising: means for determining signal type information from a signal; means for obtaining characteristics for forming an upper band signal using the determined signal type information; means for detecting babble noise based on a gradient index, energy information, and a noise level estimate means for determining signal noise information, wherein the signal noise information is determined based on a far-end signal-to-noise ratio and a near-end signal-to-noise ratio; means for using the determined signal noise information to modify the obtained characteristics for forming the upper band signal; and means for forming the upper band signal using the modified characteristics.<br>9) A computer program product, embodied in a computer-readable medium, that expands narrowband speech signals to wideband speech signals, the computer program product comprising: computer code to: determine signal type information from a signal; obtain characteristics for forming an upper band signal using the determined signal type information; detect babble noise based on a gradient index, energy information, and a noise level estimate determine signal noise information, wherein the signal noise information is determined based on a far-end signal-to-noise ratio and a near-end signal-to-noise ratio; use the determined signal noise information to modify the obtained characteristics for forming the upper band signal; and form the upper band signal using the modified characteristics.</p></layer>
<layer id = "layer408"><p><b>US20050288923A1:Speech enhancement by noise masking</b><br>A system and method is directed to scheduling user preference satellite radio station selections in a mobile vehicle. The method provides creating at least one vehicle preference selection schedule utilizing a user interface, transferring the vehicle preference selection schedule into a mobile communication unit, monitoring a satellite radio system broadcast, requesting the vehicle preference selection schedule from the mobile communication unit, and extracting a radio station selection from the broadcast based on the vehicle preference selection schedule. The system further provides a means for creating a vehicle preference selection schedule utilizing a user interface, a means for transferring the vehicle preference selection schedule into a mobile communication unit, a means for monitoring a satellite radio system broadcast, a means for requesting the vehicle preference selection list from the mobile communication unit, and a means for extracting a selection from the broadcast based on the vehicle preference selection schedule.<br><b>Independant Claims</b><br>1. A method of noise reduction of an input signal comprising performing a preprocessing first spectral subtraction to remove tonal noise and generate a tonal noise removed signal, and performing a second spectral subtraction to remove noise from the said tonal noise removed signal.<br>18. Apparatus for noise reduction of an input signal comprising, means for performing a preprocessing first spectral subtraction to remove tonal noise and for generating a tonal noise removed signal, and means for performing a second spectral subtraction to remove noise from the said tonal noise removed signal.</p></layer>
<layer id = "layer409"><p><b>US6993480B1:Voice intelligibility enhancement system</b><br>A component box has a shape of a substantially flat plate, and is stacked along a direction UPR toward the ceiling of a vehicle with its center placed at a central portion of a casing for a battery pack. Cooling wind which has been used for air-conditioning inside the vehicle and supplied from a cooling fan to the battery pack is supplied to a coolant introducing space located on an upper side of a module, passes through a gap between adjacent battery groups to flow down to a lower side of the battery groups, and then is emitted from a coolant lead-out space located at a lower side of the module out of the battery pack. Since the component box is in contact with a cooling wind passage with the casing therebetween, the component box in contact with the cooling wind via the casing is cooled down simultaneously with the cooling of the module. Since the component box is placed with its center positioned at the central portion of the battery pack, variations in temperature among batteries can be suppressed.<br><b>Independant Claims</b><br>1) A system for enhancing intelligibility of a voice signal that is degraded by factors that reduce intelligibility of the voice signal, said system comprising: an input configured to receive a voice signal that includes human spoken words; an aural filter operatively coupled to said input, said aural filter configured to filter said voice signal to produce a filter output signal wherein low frequencies below speech frequencies and high frequencies above speech frequencies are attenuated with respect to speech frequencies; a speech expander operatively coupled to said aural filter to produce an expanded signal, said speech expander configured to amplify said filter output signal according to an amplifier gain, wherein said amplifier gain is a function of an envelope amplitude of said filter output signal; and a combiner configured to combine at least a portion of said expanded signal and at least a portion of said voice signal to produce an enhanced signal representing said spoken words; wherein, when the voice signal is operating a high volume levels, the system emphasizes middle speech frequencies over low and high frequencies; and wherein, when the voice signal is operating at low volume levels, the system provides more low and high frequency components of the voice signal than when the voice signal is operating a high volume levels; such that the system provides a transfer function which approximates an inverse of the transfer function of human hearing.<br>4) A communication device for sending voice information to a communication receiver, where the voice information may become contaminated by noise that reduces the intelligibility of the voice information, said communication device comprising: a sender configured to send a voice signal comprising words spoken by a person over a communication channel; and a voice enhancer operably connected to said sender, said voice enhancer comprising: an aural filter operatively coupled to a voice signal in said sender, said aural filter configured to filter said voice signal to produce a filter output signal wherein low frequencies below speech frequencies and high frequencies above speech frequencies are attenuated with respect to speech frequencies; a speech expander operatively coupled to said aural filter to produce an expanded voice signal, said speech expander configured to amplify said filter output signal according to an amplifier gain, wherein said amplifier gain is a function of an envelope amplitude of said filter output signal; and a combiner configured to combine at least a portion of said expanded voice signal and at least a portion of said voice signal to produce an enhanced voice signal; wherein said voice enhancer is configured to provide a transfer function that approximates an inverse of loudness contours for human hearing; wherein said speech expander comprises a gain controlled amplifier; and wherein the amplifier gain increases according to an attack time constant when said envelope amplitude has a positive slope and said amplifier gain decreases according to a decay time constant when said envelope amplitude has a negative slope.<br>5) A communication device configured to receive voice information from a communication sender, comprising: a communication receiver configured to receive voice information comprising words spoken by a person from a communication channel; and a voice enhancer operably connected to said communication receiver, said voice enhancer comprising: an aural filter configured to filter an input signal to produce a filtered signal; an expander comprising an amplifier configured to amplify said filtered signal to produce an amplified signal, wherein a gain of said amplifier is a function of an amplitude envelope of said filtered signal; and a combiner configured to combine at least a portion of said amplified signal and at least a portion of said input signal to produce an output signal; wherein said voice enhancer enhances formants of the voice information to increase intelligibility of the voice information; and wherein said voice enhancer provides a transfer function that approximates a complement of Fletcher-Munson curves for tones in a frontal sound field for humans.<br>13) An apparatus, comprising: an aural filter configured to filter an input signal comprising words spoken by a person to produce a filtered signal; an expander comprising an amplifier configured to amplify said filtered signal to produce an amplified signal, wherein a gain of said amplifier depends in part on an envelope of said filtered signal; and a combiner configured to combine at least a portion of said amplified signal and at least a portion of said input signal to produce an output signal; wherein said apparatus is configured to provide a transfer function that emphasizes middle speech frequencies over low and high frequencies at high volume levels and is flatter at low volume levels.<br>28) A method for enhancing intelligibility of voice information, comprising the steps of: filtering at least a portion of a first signal that includes human voice sounds to produce a filtered signal having an amplitude envelope; expanding at least a portion of said filtered signal using an amplifier having a variable gain to produce an enhanced signal; detecting the amplitude envelope to produce a gain control signal to control the gain of the amplifier; and combining at least a portion of said first signal with said enhanced signal to produce an improved signal; wherein the method emphasizes middle speech frequencies over low and high frequencies at high volume levels and is flatter at low volume levels, such that the method provides a transfer function which approximates an inverse of loudness contours for human hearing.<br>45) An apparatus for enhancing intelligibility of voice information, said apparatus comprising: aural filter means for filtering an input signal to produce a filtered signal, said input signal containing human voice information; gain controlled amplifier means for amplifying the filtered signal to produce an expanded signal; gain control means for controlling a gain of the gain controlled amplifier as a function of an envelope amplitude of the filtered signal; attack time means for increasing the gain for an attack time when a slope of the envelope amplitude is positive; decay time means for decreasing the gain for a decay time when the slope of the envelope amplitude is negative; and combiner means for combining at least a portion of said expanded signal with at least a portion of said input signal; wherein said apparatus is configured to provide a transfer function that emphasizes middle speech frequencies over low and high frequencies at high volume levels and is flatter at low volume levels, such that said transfer function approximates an inverse of loudness contours for human hearing of tones in a sound field.<br>46) An apparatus, comprising: an input configured to receive an input signal comprising words spoken by a person; and a dynamic filter configured to filter said input signal to produce an enhanced signal with modified voice components, said dynamic filter configured to provide a transfer function that depends at least in part on an envelope of the input signal, wherein said transfer function emphasizes middle speech frequencies over low and high frequencies at high volume levels and is flatter at low volume levels.<br>53) A method of improving the intelligibility of voice sounds contained within a signal source when the signal source is reproduced through a loudspeaker, said method comprising the following steps: detecting an envelope of a signal source comprising words spoken by a person to produce a control signal; filtering the signal source according to a frequency response related to human hearing characteristics to produce a filtered signal; modifying the frequency response used to filter said signal source wherein the amount of modification is a function of the control signal; and combining the signal source with the filtered signal to produce an output signal having enhanced voice sounds; wherein, when the first signal is operating a high volume levels, the method emphasizes middle speech frequencies over low and high frequencies; and wherein, when the first signal is operating at low volume levels, the method provides more low and high frequency components of the first signal than when the first signal is operating a high volume levels; such that the method provides a transfer function which approximates an inverse of loudness contours for human hearing.<br>56) A method of emphasizing human speech sounds contained within a signal source to produce an output signal comprises the following steps: bandpass filtering said signal source to produce a filtered signal wherein said filtered signal includes speech frequencies and attenuates frequencies below and above speech frequencies; analyzing at least a portion of said filtered signal to produce a control signal wherein said control signal represents a slope of an amplitude envelope of said filtered signal; amplifying said filtered signal during a first amplification period to provide an enhancement signal wherein the level of amplification of said filtered signal is increased when the slope is positive; amplifying said filtered signal during a second amplification period to provide an enhancement signal wherein the level of amplification of said filtered signal is decreased when the slope is negative; and combining said enhancement signal with said signal source to produce an output signal; wherein said method provides a transfer function that emphasizes middle speech frequencies over low and high frequencies at high volume levels and is flatter at low volume levels, such that said transfer function approximates an inverse of loudness contours for human hearing of tones in a sound field.<br>59) A voice enhancement device for enhancing intelligibility of a voice signal comprising: a filter configured to receive a voice input signal, the filter configured to attenuate low frequencies below speech frequencies and high frequencies above speech frequencies with respect to speech frequencies to produce a filtered signal; an envelope detector configured to receive at least a portion of the filtered signal, the envelope detector configured to detect an envelope amplitude of the filtered signal to produce an envelope signal, wherein the envelope signal approximates the envelope amplitude of the filtered signal; an amplifier configured to receive the filtered signal, the amplifier having a gain control input for controlling a gain of the amplifier, the amplifier configured to amplify the filtered signal according to the gain to produce an amplified signal; an attack/decay buffer comprising an attack time constant and a decay time constant configured to receive the envelope signal and to produce a gain control signal to control the gain of the amplifier, wherein the attack/decay buffer provides the gain control signal to the gain control input to increase the gain of the amplifier at a rate given by the attack time constant when the envelope signal has a positive slope and to decrease the gain of the amplifier at a rate given by the decay time constant when the envelope signal has a negative slope; and a combiner configured to add at least a portion of the voice input signal with the amplified signal to produce an enhanced voice signal; wherein said device is configured to provide a transfer function that approximates an inverse of loudness contours for human hearing of tones in a sound field.</p></layer>
<layer id = "layer410"><p><b>US8670988B2:Audio encoding/decoding apparatus and method providing multiple coding scheme interoperability</b><br>The invention relates to a check-tile for validating instrument scales of color measurement instruments, in particular goniospectrophotometers, said check-tile comprising a non-transparent (opaque) substrate coated with a multi-layer coating, said multi-layer coating comprising: A) a pigmented ground coat, wherein said pigmented ground coat is opaque and made of a base coat coating composition I comprising at least one achromatic solid pigment, B) a pigmented mid-coat, wherein said pigmented mid-coat is translucent and made of a base coat coating composition II comprising at least one transparent interference pigment and at least one transparent or semi-transparent solid pigment, and C) a clear top coat made of a transparent clear coat coating composition on top of the mid-coat.<br><b>Independant Claims</b><br>11) A speech decoding method for decoding encoded data of a speech signal which has an active speech component and an inactive speech component, the method comprising: decoding by a first decoding method first encoded data of the speech signal to generate first decoded data; decoding by a second decoding method that is different from the first decoding method second encoded data, which differs from the first encoded data, of the speech signal to generate second decoded data; and selecting, with an integrated circuit or computer processor, one of the first and second decoded data to represent the speech signal, wherein the second encoded data, with which the first encoded data has been overwritten by an encoder, and is extracted from the first encoded data, wherein a portion of the first encoded data being overwritten has less than a predetermined sensitivity.<br>10) A speech coding method for encoding a speech signal which has an active speech component and an inactive speech component, the method comprising: encoding by a first encoding method a segment of the speech signal to generate first coded data; encoding by a second coding method that is different from the first coding method the segment of the speech signal to generate second coded data, which differs from the first coded data, when the segment of the speech signal is inactive speech; determining whether the segment of the speech signal is active speech or inactive speech; determining whether to use the second coded data when the segment of the speech signal is inactive speech; and overwriting, with an integrated circuit or computer processor, a portion of the first coded data with the second coded data when the segment of the speech signal is determined to be inactive speech and the second coded data is determined to be used, wherein the portion of the first coded data being overwritten has less than a predetermined sensitivity.<br>1) A speech coding apparatus that encodes a speech signal which has an active speech component and an inactive speech component, the speech coding apparatus comprising: a first coder that encodes by a first coding method a segment of the speech signal to generate first coded data; a second coder that encodes by a second coding method that is different from the first coding method the segment of the speech signal to generate second coded data, which differs from the first coded data, when the segment of the speech signal is inactive speech; a first determination section that determines whether the segment of the speech signal is active speech or inactive speech; a second determination section that determines whether to use the second coded data when the segment of the speech signal is inactive speech; and an embedding section that overwrites a portion of the first coded data with the second coded data, wherein the portion of the first coded data being overwritten has less than a predetermined sensitivity, when the first determination section determines that the segment of the speech signal is inactive speech and the second determination section determines that the second coded data is to be used.<br>9) A speech decoding apparatus that decodes encoded data of a speech signal which has an active speech component and an inactive speech component, the speech decoding apparatus comprising: a first decoder that decodes by a first decoding method first encoded data of the speech signal to generate first decoded data; a second decoder that decodes by a second decoding method that is different from the first decoding method second encoded data, which differs from the first encoded data, of the speech signal to generate second decoded data; and a selection section that selects one of the first and second decoded data to represent the speech signal, wherein the second encoded data, with which the first encoded data has been overwritten by an encoder, is extracted from the first encoded data, wherein a portion of the first encoded data being overwritten has less than a predetermined sensitivity.</p></layer>
<layer id = "layer411"><p><b>US20060074646A1:Method of cascading noise reduction algorithms to avoid speech distortion</b><br>An intake air control valve of the invention has a valve body and a valve holder, and is attached to a communication hole on a partition wall separating a surge tank chamber within a surge tank of a multiple cylinder internal combustion engine by fitting and inserting a valve holder. A valve hole is formed within the valve holder, and a butterfly type valve body is attached via a valve shaft so as to freely open and close a valve hole. A seal member is fitted to a groove provided in a peripheral edge portion of the valve holder. The seal member is formed by a fitting and attaching portion fitted and attached to an inner side of the groove of the valve holder and a leading end seal portion brought into contact with an inner peripheral portion of the communication hole in the partition wall. Recess portions open to an inner side of the groove is provided in the fitting and attaching portion in parallel in a longitudinal direction so as to be sectioned by a plurality of ribs. Accordingly, it is possible to prevent the seal member fitted to a peripheral edge portion of the valve holder from falling away and it is possible to secure a good sealing property at a time of full closing.<br><b>Independant Claims</b><br>1. A method of reducing noise by cascading a plurality of noise reduction algorithms, the method comprising: receiving a noisy signal resulting from an unobservable signal corrupted by additive background noise; applying a sequence of noise reduction algorithms to the noisy signal, wherein a first noise reduction algorithm in the sequence receives the noisy signal as its input and provides an output, and wherein each successive noise reduction algorithm in the sequence receives the output of the previous noise reduction algorithm in the sequence as its input and provides an output, with the final noise reduction algorithm in the sequence providing a system output signal that resembles the unobservable signal; and wherein the sequence of noise reduction algorithms includes a plurality of noise reduction algorithms that are sufficiently different from each other such that resulting distortions and artifacts are sufficiently different to result in reduced human perception of the artifact and distortion levels in the system output signal.</p></layer>
<layer id = "layer412"><p><b>US10361671B2:Methods and apparatus for adjusting a level of an audio signal</b><br><b>Independant Claims</b><br>5) An audio processing apparatus for adjusting a level of an audio signal, the audio processing apparatus comprising:an analysis filterbank for dividing an audio signal into a plurality of frequency bands;a delay unit for delaying at least one of the plurality of the frequency bands;a parameter generator for obtaining modification parameters for at least one of the plurality of frequency bands, the modification parameters comprising filter coefficients and amplitude scale factors, each amplitude scale factor respectively operating in a frequency band of the plurality of frequency bands and each amplitude scale factor representing an average energy over the frequency band and a time segment;a first processor for deriving gain factors for at least one of the plurality of frequency bands, the gain factors determined based on the amplitude scale factors;a smoother for smoothing the gain factors;a second processor for determining a level of noise from noise compensation factors;a first adjuster for applying the gain factors to at least one of the frequency bands to generate gain adjusted frequency bands;a second adjuster for adjusting the level of noise based on the gain adjusted frequency bands;a filter for filtering at least one of the frequency bands, the filter generated with the filter coefficients; anda synthesis filterbank for synthesizing the plurality of frequency bands to generate an output audio signal;wherein the gain factors are both time and frequency varying.<br>1) A method for adjusting a level of an audio signal in an audio processing apparatus, the method comprising:dividing an audio signal into a plurality of frequency bands;delaying at least one of the plurality of the frequency bands;obtaining modification parameters for at least one of the plurality of frequency bands, the modification parameters comprising filter coefficients and amplitude scale factors, each of the amplitude scale factors respectively operating in a frequency band of the plurality of frequency bands and each amplitude scale factor representing an average energy over the frequency band and a time segment;deriving gain factors for at least one of the plurality of frequency bands, the gain factors determined based on the amplitude scale factors;smoothing the gain factors;determining a level of noise from noise compensation factors;applying the gain factors to at least one of the frequency bands to generate gain adjusted frequency bands;adjusting the level of noise based on the gain adjusted frequency bands;filtering at least one of the frequency bands with a filter generated with the filter coefficients; andsynthesizing the plurality of frequency bands to generate an output audio signal;wherein the gain factors are both time and frequency varying.</p></layer>
<layer id = "layer413"><p><b>US20070124140A1:Method for extending the spectral bandwidth of a speech signal</b><br>A contact terminal for measurement is provided, for transmitting a signal between a desired probe pin among a plurality of probe pins arranged in parallel at a predetermined distance in a predetermined direction on the surface of a probe substrate and an external measurement apparatus. The contact terminal for measurement includes: a signal terminal having an width smaller than the distance between the probe pins provided on both sides of one probe pin in the arrangement direction; two ground terminals to which a ground potential is applied, which are provided on both sides of the signal terminal in the arrangement direction and which have each width larger than that of the signal terminal in the arrangement direction; and a signal line electrically connecting the signal terminal to a signal input terminal of the external measurement apparatus.<br><b>Independant Claims</b><br>1. A method for extending the spectral bandwidth of an excitation signal of a speech signal, comprising: determining a bandwidth limited excitation signal of the speech signal; and generating a bandwidth extended excitation signal based on the bandwidth limited excitation signal.<br>12. A method for reconstructing noisy parts of a speech signal recorded in a noisy environment, comprising: determining the noisy parts of the speech signal in which the noise components of the recorded signal dominate the speech components of the speech signal; determining a bandwidth limited spectral envelope of the speech signal; determining a bandwidth limited excitation signal on the basis of the speech signal, the noisy parts of the speech signal being suppressed; generating a bandwidth extended excitation signal by applying a non-linear function to the excitation signal; and replacing the noisy parts of the speech signal on the basis of the extended parts of the bandwidth extended excitation signal for generating an enhanced speech signal.<br>24. A method for enhancing the quality of a speech signal, comprising: determining a spectral envelope of the speech signal based on the speech signal having a limited spectral bandwidth; generating a bandwidth limited excitation signal of the speech signal; extending the spectral bandwidth of the generated excitation signal; and applying the bandwidth extended excitation signal to the spectral envelope for generating the enhanced speech signal.<br>34. A system for extending the spectral bandwidth of the speech signal transmitted by a bandwidth limited transmission system and for signal reconstruction for noisy parts of the speech signal recorded in a noisy environment, the system comprising: a determination unit for determining a spectral envelope based upon a bandwidth limited part of the speech signal; a generating unit for generating an bandwidth limited excitation signal; a calculation unit for calculating an bandwidth extended excitation signal and for applying the spectral envelope to the bandwidth extended excitation signal for generating an enhanced speech signal.</p></layer>
<layer id = "layer414"><p><b>US8284947B2:Reverberation estimation and suppression system</b><br>Exemplary near field communication (“NFC”) transaction management and application systems and methods are disclosed herein. An exemplary method includes a computing system tracking NFC transactions associated with a profile and providing a service based on the tracked NFC transactions associated with the profile. In certain examples, the tracking includes aggregating the NFC transactions associated with the profile over time. In certain examples, the profile comprises a customer premises profile specifying one or more customer premises equipment (“CPE”) devices for which to track the NFC transactions. Corresponding methods and systems are also disclosed.<br><b>Independant Claims</b><br>42) A reverberation suppression system comprising: signal analysis hardware operative to identify a first reverberant characteristic in a first frequency band of a signal; signal-to-noise ratio estimation hardware operable to determine a signal-to-noise ratio of the signal in the first frequency band; and attenuation hardware responsive to the signal analysis hardware and the signal-to-noise ratio estimation hardware, where the attenuation hardware is operable to attenuate the signal in the first frequency band to generate a reverberation suppressed signal, where the attenuation hardware is operable to set an attenuation level for the signal in the first frequency band based on the signal-to-noise ratio of the signal in the first frequency band, and where the attenuation hardware is operable to attenuate the signal in the first frequency band to a greater extent when the signal-to-noise ratio is relatively high and the first reverberant characteristic is identified than when the signal-to-noise ratio is relatively low and the first reverberant characteristic is identified; where the signal analysis hardware is operative to identify the first reverberant characteristic in the first frequency band based on a comparison between a signal decay rate in the first frequency band and a reverberation decay rate threshold, and where the signal analysis hardware is operative to adapt the reverberation decay rate threshold over time based on an identification of a linear signal decay characteristic.<br>14) A reverberation analysis system comprising: a signal input; signal analysis logic coupled to the signal input and operable to estimate a first decay rate for signal content of a first frequency band, where the signal analysis logic is operable to adapt a first reverberation decay rate threshold over time based on an identification of a linear signal decay characteristic, and where the signal analysis logic comprises a processor that executes instructions stored in a memory; comparison logic coupled to the signal analysis logic and operable to perform a comparison between the first decay rate and the first reverberation decay rate threshold; characterization logic coupled to the comparison logic and operable to identify whether the first frequency band is a reverberant frequency band based on the comparison between the first decay rate and the first reverberation decay rate threshold; attenuation logic operable to attenuate the first frequency band to generate a reverberation suppressed signal in response to a characterization of the first frequency band as the reverberant frequency band; and a signal output coupled to the attenuation logic and operable to output the reverberation suppressed signal.<br>1) A reverberation suppression system comprising: signal analysis logic operative to analyze a signal decay rate in a first frequency band of a signal, where the signal analysis logic is operative to identify a first reverberant characteristic in the first frequency band of the signal based on a comparison between the signal decay rate in the first frequency band and a first reverberation decay rate threshold, where the signal analysis logic is operative to adapt the first reverberation decay rate threshold over time based on an identification of a linear signal decay characteristic, and where the signal analysis logic comprises a processor that executes instructions stored in a memory; and attenuation logic responsive to identification of the first reverberant characteristic to attenuate the signal in the first frequency band to generate a reverberation suppressed signal.<br>21) A method for suppressing reverberation, comprising: adapting a reverberation decay rate threshold over time based on an identification of a linear signal decay characteristic; determining a division of a signal into multiple frequency bands; determining a signal decay rate in at least one frequency band of the multiple frequency bands; identifying the at least one frequency band as being a reverberant frequency band based on a comparison between the signal decay rate in the at least one frequency band and the reverberation decay rate threshold; and attenuating the signal in the reverberant frequency band to generate a reverberation suppressed signal.<br>31) A product comprising: a non-transitory machine readable medium; and machine readable instructions embodied on the machine readable medium that: adapt a reverberation decay rate threshold over time based on an identification of a linear signal decay characteristic; determine a signal decay rate in a frequency band of an input signal; identify a reverberant frequency band based on a comparison between the signal decay rate and the reverberation decay rate threshold; and attenuate the signal in the reverberant frequency band to generate a reverberation suppressed signal.</p></layer>
<layer id = "layer415"><p><b>US7013269B1:Voicing measure for a speech CODEC system</b><br>Hydrogels having improved elasticity and mechanical strength properties are obtained by subjecting a hydrogel formulation containing a strengthening agent to chemical or physical crosslinking conditions subsequent to initial gel formation. Superporous hydrogels having improved elasticity and mechanical strength properties are similarly obtained whenever the hydrogel formulation is provided with a foaming agent. Interpenetrating networks of polymer chains comprised of primary polymer(s) and strengthening polymer(s) are thereby formed. The primary polymer affords capillary-based water sorption properties while the strengthening polymer imparts significantly enhanced mechanical strength and elasticity to the hydrogel or superporous hydrogel. Suitable strengthening agents can be natural or synthetic polymers, polyelectrolytes, or neutral, hydrophilic polymers.<br><b>Independant Claims</b><br>1) A frequency domain interpolative CODEC system for low bit rate coding of speech, comprising: a linear prediction (LP) front end adapted to process an input signal providing LP parameters which are quantized and encoded over predetermined intervals and used to compute a LP residual signal; an open loop pitch estimator adapted to process said LP residual signal, a pitch quantizer, and a pitch interpolator adapted to provide a pitch contour within the predetermined intervals; and a signal processor responsive to said LP residual signal and the pitch contour and adapted to perform the following: extract a prototype waveform (PW) from the LP residual and the open loop pitch contour for a number of equal sub-intervals within the predetermined intervals; normalize the PW by said PW's gain; extract measures of periodicity from the normalized PW that are correlated to degrees of periodicity over each predetermined interval; extract measures of periodicity from open loop parameters derived from the input signal that are correlated to degrees of periodicity over each predetermined interval; and provide an overall voicing measure for each predetermined interval, said voicing measure characterizing a degree of voicing of said input signal, by combining the measures of periodicity extracted from the open loop parameters and the measures of periodicity extracted from the normalized PW over the predetermined intervals.</p></layer>
<layer id = "layer416"><p><b>US20070271092A1:Scalable Encoding Device and Scalable Enconding Method</b><br>An ink-jet recording material comprising a substrate having thereon an ink absorbing layer containing a mordant which exhibits the following properties: when a thin layer chromatograph is prepared by immersion coating in 1 weight % aqueous solution of the mordant, the thin layer chromatography results in; a) an Rf flow rate value being equal at most 0.4, when a dye represented by following Formula (1) is developed using a developing solvent containing ethanol and water at a volume ratio of 1:1; b) the Rf value being at most 0.3, when C. I. Direct Blue 199 dye is developed using the same developing solvent; and c) the Rf value being at most 0.5, when C. I. Direct Yellow 86 dye is developed using the same developing solvent.<chemistry id="CHEM-US-00001" num="1"><img id="EMI-C00001" he="36.75mm" wi="73.91mm" file="US20050123695A1-20050609-C00001.TIF" alt="embedded image" img-content="chem" img-format="tif"/></chemistry><br><b>Independant Claims</b><br>1. A scalable encoding apparatus that obtains a wideband LSP parameter from a narrowband LSP parameter, the scalable encoding apparatus comprising: a first conversion section that converts the narrowband LSP parameter into a series of autocorrelation coefficients; an up-sampling section that up-samples the autocorrelation coefficients; a second conversion section that converts the up-sampled autocorrelation coefficients into an LSP parameter; and a third conversion section that converts frequency band of the LSP parameter into wideband to obtain the wideband LSP parameter.<br>8. A scalable encoding method that obtains a wideband LSP parameter from a narrowband LSP parameter, the scalable encoding method comprising: a first conversion step of converting a narrowband LSP parameter into a series of autocorrelation coefficients; an up-sampling step of up-sampling the autocorrelation coefficients; a second conversion step of converting the up-sampled autocorrelation coefficients into an LSP parameter; and a third conversion step of converting frequency band of the LSP parameter into wideband and obtaining a wideband LSP parameter.</p></layer>
<layer id = "layer417"><p><b>US20060265216A1:Packet loss concealment for block-independent speech codecs</b><br>A probe to measure particulates suspended in molten metal includes an inner tube forming a receiving chamber. The tube includes an orifice permitting molten metal to flow into the chamber. A gas passageway extends out of the tube for connection to a vacuum source. A first electrode including a first member extends into the chamber. A second electrode surrounds a portion of the tube. The first and second electrodes connect to a measurement device for measuring changes in the electrical potential produced by particulates passing through the orifice. A liquidus depressing material within the chamber lowers the liquidus temperature of the molten metal and permits a longer period for measuring particulates therein. A second member is connected to the gas passageway at a first end of the second member. A chill block spaced from the liquidus depressing material is attached to a second end of the second member.<br><b>Independant Claims</b><br>1. A method for decoding a speech signal comprising: decoding one or more non-erased frames of the speech signal; detecting a first erased frame of the speech signal; and responsive to detecting the first erased frame: deriving a filter based on previously-decoded portions of the speech signal; calculating a ringing signal segment using the filter, and generating a replacement frame for the first erased frame, wherein generating the replacement frame includes overlap adding the ringing signal segment to an extrapolated waveform.<br>12. A method for decoding a speech signal comprising: decoding one or more non-erased frames of the speech signal; detecting an erased frame of the speech signal; and responsive to detecting the erased frame: deriving a short-term filter based on previously-decoded portions of the speech signal, generating a sequence of pseudo-random white noise samples, filtering the sequence of pseudo-random white noise samples through the short term filter to generate an extrapolated waveform, and generating a replacement frame for the erased frame based on the extrapolated waveform.<br>19. A method for decoding a speech signal, comprising: decoding one or more non-erased frames of the speech signal; detecting an erased frame of the speech signal; and responsive to detecting the erased frame: deriving a short-term filter and a long-term filter based on previously-decoded portions of the speech signal, generating a periodic waveform component using the short-term filter and long-term filter; generating a random waveform component using the short-term filter; and generating a replacement frame for the erased frame, wherein generating a replacement frame comprises mixing the periodic waveform component and the random waveform component.</p></layer>
<layer id = "layer418"><p><b>US8374855B2:System for suppressing rain noise</b><br>A travel control device for a work vehicle includes: a hydraulic pump; a plurality of hydraulic motors connected to the hydraulic pump in parallel through a closed-circuit connection, that drive different wheels with pressure oil delivered from the hydraulic pump; a slip detection device that detects a slip occurring at each of the wheels; and a flow control device that reduces, upon detection of a slip occurring at any of the wheels by the slip detection device, a quantity of pressure oil supplied to a hydraulic motor for driving the wheel at which the slip has been detected, among the plurality of hydraulic motors.<br><b>Independant Claims</b><br>17) A non-transitory computer-readable storage medium with executable instructions stored thereon, where the instructions are configured to cause a processor to perform the steps of: fitting a model to a portion of an input signal; identifying that a noise of the input signal is associated with rain based on a correlation between the model and the portion of the input signal; and dampening at least a portion of the noise associated with rain from the input signal to obtain an output sound signal with reduced rain noise content.<br>10) A method of dampening rain noise, comprising: fitting a model to a portion of an input signal; identifying that a noise of the input signal is associated with rain based on a correlation between the model and the portion of the input signal; and dampening at least a portion of the noise associated with rain from the input signal to obtain an output sound signal with reduced rain noise content.<br>1) A system for attenuating rain noise, comprising: a rain noise detector configured to analyze a frequency spectrum of an input signal to identify whether the input signal contains a rain noise, where the rain noise detector is configured to fit a model to a portion of the input signal and identify that a noise of the input signal is associated with rain based on a correlation between the model and the portion of the input signal; and a rain noise attenuator configured to remove at least a portion of the rain noise identified by the noise detector from the input signal to obtain an output sound signal with reduced rain noise content.</p></layer>
<layer id = "layer419"><p><b>US8630864B2:Method for switching rate and bandwidth scalable audio decoding rate</b><br>A magnetic memory element includes a first stacked unit and a second stacked unit. The first stacked unit includes a first ferromagnetic layer, a second ferromagnetic layer, and a first nonmagnetic layer. The second ferromagnetic layer is stacked with the first ferromagnetic layer. The second ferromagnetic layer has a first and second portion. The first and second portion has a changeable direction of magnetization. The second portion is stacked with the first portion in a stacking direction of the first ferromagnetic layer and the second ferromagnetic layer. A magnetic resonance frequency of the second portion is lower than a magnetic resonance frequency of the first portion. The first nonmagnetic layer is provided between the first ferromagnetic layer and the second ferromagnetic layer. The second stacked unit is stacked with the first stacked unit in the stacking direction. The second stacked unit includes a third ferromagnetic layer.<br><b>Independant Claims</b><br>7) A non-transitory computer readable medium encoded with a computer program executed by a processor which causes bitrate switching when decoding an audio signal coded by a multirate audio coding system, the computer program comprising: program code instructions for supplying a first signal and a second signal from a decoded signal to an input of a cross-fading module, at least one of the first and second signals being post-processed in a post-processing step, the post-processing forming part of a set of post-processing operations suited to different sets of rates; program code instructions for, upon detection of a rate switch between a current frame at a rate lying within a first set of rates and a preceding frame at a rate lying within a second set of rates, performing crossfading by weighting to reduce a weight of the second signal, whether post-processed or unpost-processed, according to the post-processing suited to the second set of rates and to increase a weight of the first signal, whether post-processed or unpost-processed, according to the post-processing suited to the first set of rates to obtain an output signal; program code instructions for, upon detection of a rate switch between a current frame at a rate lying within a second set of rates and a preceding frame at a rate lying within a first set of rates, performing a cross-fading by weighting to reduce the weight of the first signal, whether post-processed or unpost-processed, according to the post-processing suited to the first set of rates and to increase the weight of the second signal, whether post-processed or unpost-processed, according to the post-processing suited to the second set of rates to obtain an output signal.<br>1) A method of bitrate switching when decoding an audio signal coded by a multirate audio coding system, said method comprising: supplying a first signal and a second signal from a decoded signal to an input of a cross-fading module, at least one of the first and second signals being post-processed in a post-processing step, the post-processing forming part of a set of post-processing operations suited to different sets of rates; upon detection of a rate switch between a current frame at a rate lying within a first set of rates and a preceding frame at a rate lying within a second set of rates, performing crossfading by weighting to reduce a weight of the second signal, whether post-processed or unpost-processed, according to the post-processing suited to the second set of rates and to increase a weight of the first signal, whether post-processed or unpost-processed, according to the post-processing suited to the first set of rates to obtain an output signal; and upon detection of a rate switch between a current frame at a rate lying within a second set of rates and a preceding frame at a rate lying within a first set of rates, performing a cross-fading by weighting to reduce the weight of the first signal, whether post-processed or unpost-processed, according to the post-processing suited to the first set of rates and to increase the weight of the second signal, whether post-processed or unpost-processed, according to the post-processing suited to the second set of rates to obtain an output signal.<br>10) A multirate audio decoder, comprising: a cross fade module receiving as input a first signal and a second signal obtained from a decoded signal, at least one of the first and second signals having undergone post-processing from a set of post-processing operations suited to different sets of rates, the crossfading module being configured to: upon detection of a rate switch between a current frame at a rate lying within a first set of rates and a preceding frame at a rate lying within a second set of rates, perform a cross-fading by weighting to reduce a weight of the second signal, whether post-processed or unpost-processed, according to a post-processing operation suited to the second set of rates and to increase the weight of the first signal, whether post-processed or unpost-processed, according to the post-processing operation suited to the first set of rates, to obtain an output signal from the cross-fading module; and upon detection of a rate switch between a current frame at a rate lying within a second set of rates and a preceding frame at a rate lying within a first set of rates, perform a cross-fading by weighting to reduce a weight of the first signal, whether post-processed or unpost-processed, according to a post-processing operation suited to the first set of rates and to increase the weight of the second signal, whether post-processed or unpost-processed, according to the post-processing operation suited to the second set of rates to obtain an output signal from the cross-fading module.</p></layer>
<layer id = "layer420"><p><b>US20060089958A1:Periodic signal enhancement system</b><br>A load push lift truck includes a push plate with sufficient clearance over its blades such that it can push a stack of cartons from a standard pallet when the blades of the lift truck are inserted in the four-way channels of the pallet. The clearance may be provided by a gate at the lower edge of the push plate that can be raised and lowered to increase or reduce the clearance of the push plate relative to the blades. A side shift mechanism may be provided to facilitate lateral positioning of cargo carried by the blades of the lift truck. A pallet retainer mounted on the lift truck to retain the pallet on the blades when the stacks of cartons are pushed from the pallet. A pallet stop mounted at the rear portions of the blades may be positioned to prevent a pallet from being pushed back on the blades beyond the face of the push plate.<br><b>Independant Claims</b><br>1. A signal enhancement system comprising: a signal input; delay logic coupled to the signal input; an adaptive filter coupled to the delay logic; and reinforcement logic coupled to the adaptive filter and the signal input.<br>17. A signal enhancement system comprising: a signal input; means for delaying an input signal received through the signal input; means for adaptively filtering the delayed signal; and means for reinforcing the input signal with the filtered output signal.<br>22. A signal enhancement system comprising: a signal input; frequency tracking logic coupled to the signal input and comprising an output, the frequency tracking logic operable to output a fundamental frequency of an input signal; an adder coupled to the signal input and the output that reinforces the input signal with the fundamental frequency.<br>31. A method for enhancing a signal, comprising: receiving an input signal; delaying the input signal; estimating periodicity in the input signal based on a delayed signal; and reinforcing the input signal with the delayed signal.<br>41. A product comprising: a machine readable medium; and machine readable instructions embodied on the machine readable medium that: delay an input signal; estimate periodicity in the input signal based on a delayed signal; and reinforce the input signal with the delayed signal.</p></layer>
<layer id = "layer421"><p><b>US20060089959A1:Periodic signal enhancement system</b><br>A strain of hepatitis E virus from Pakistan (SAR-55) implicated in an epidemic of enterically transmitted non-A, non-B hepatitis, now called hepatitis E, is disclosed. The invention relates to the expression of the whole structural region of SAR-55, designated open reading frame 2 (ORF-2), in a eukaryotic expression system. The expressed protein is capable of forming HEV virus-like particles which can serve as an antigen in diagnostic immunoassays and as an immunogen or vaccine to protect against infection by hepatitis E.<br><b>Independant Claims</b><br>1. A signal enhancement system comprising: a signal input; partitioned delay logic coupled to the signal input; a partitioned adaptive filter coupled to the partitioned delay logic and comprising multiple adaptive filter outputs; filter reinforcement logic coupled to the adaptive filter outputs; gain logic coupled to the filter reinforcement logic; and signal reinforcement logic coupled to the signal input and the gain logic and comprising an enhanced signal output.<br>16. A signal enhancement system comprising: means for receiving an input signal; means for delaying the input signal by multiple different delays; means for partitioned adaptive filtering the input signal based on the multiple different delays; and means for reinforcing the input signal with a partitioned adaptive filtering output.<br>20. A signal enhancement system comprising: a signal input; an M1 sample delay coupled to the signal input; an M2 sample delay coupled to the M1 sample delay; a first adaptive filter coupled to the M1 sample delay and comprising a first filter output; a second adaptive filter coupled to the M2 sample delay and comprising a second filter output; filter reinforcement logic connected to the first filter output and the second filter output; and signal reinforcement logic connected to the signal input and the filter reinforcement logic.<br>31. A method for enhancing a signal, comprising: receiving an input signal comprising a fundamental frequency; delaying the input signal by multiple different sample delays to obtain multiple differently delayed input signals; applying a partitioned adaptive filter comprising multiple individual adaptive filters to the multiple differently delayed input signals; generating a filtered output with the partitioned adaptive filter, the filtered output approximately delayed by an integer multiple of the fundamental frequency; generating an error signal for each of the multiple individual adaptive filters; adapting each of the individual adaptive filters based on the error signal for that individual adaptive filter; and reinforcing the input signal with the filtered output.<br>37. A product comprising: a machine readable medium; and machine readable instructions embodied on the machine readable medium that: delay an input signal comprising a fundamental frequency by multiple sample delays to obtain multiple differently delayed input signals; apply a partitioned adaptive filter comprising multiple individual adaptive filters to the multiple delayed input signals; generate a filtered output with the partitioned adaptive filter, the filtered output approximately delayed by an integer multiple of the fundamental frequency; and reinforce the input signal with the output estimate.</p></layer>
<layer id = "layer422"><p><b>US7039581B1:Hybrid speed coding and system</b><br>A multi-band antenna (<b>1</b>) used in an electronic device and formed of a metallic sheet by defining holes therein, including a first radiating portion (<b>30</b>), a second radiating portion (<b>31</b>), a third radiating portion (<b>32</b>), a ground portion (<b>2</b>), and a coaxial transmission line (<b>4</b>). The first radiating portion, the ground portion and the coaxial transmission line cooperatively form a loop antenna operated at a higher frequency band of about 5.15-5.875 GHz. The second radiating portion, the ground portion and the coaxial transmission line cooperatively form a first inverted-F antenna operated at another higher frequency band of about 5.725-5.875 GHz. The third radiating portion, the ground portion and the coaxial transmission line cooperatively form a second inverted-F antenna operated at a lower frequency band of about 2.4-2.5 GHz.<br><b>Independant Claims</b><br>1) A hybrid speech encoder, comprising: (a) a linear prediction, pitch and, voicing analyzer; (b) a parametric encoder coupled to said analyzer; and (c) a waveform encoder coupled to said analyzer; (d) wherein said parametric encoder encodes an alignment phase.<br>4) A speech decoder, comprising: (a) a linear prediction synthesizer; and (b) a parametric decoder coupled to said synthesizer; (c) wherein said parametric decoder decodes an alignment phase.<br>6) A speech encoder, comprising: (a) a linear prediction, pitch and, voicing analyzer; and (b) a parametric encoder coupled to said analyzer; (c) wherein said parametric encoder encodes an alignment phase.</p></layer>
<layer id = "layer423"><p><b>US8170879B2:Periodic signal enhancement system</b><br>Effective synthesis gas purification is achieved by applying copper adsorbents which are resistant to the reduction by the components of the synthesis gas H<sub>2 </sub>and CO at normal operation conditions. The novel adsorbents are produced by admixing small amounts of an inorganic halide, such as NaCl, to the basic copper carbonate precursor followed by calcination at a temperature sufficient to decompose the carbonate. The introduction of the halide can be also achieved during the forming stage of adsorbent preparation. These reduction resistant copper oxides can be in the form of composites with alumina and are especially useful for purification of synthesis gas or gas streams containing hydrogen carbon monoxide or other reducing agents.<br><b>Independant Claims</b><br>1) A signal enhancement system comprising: a processor; a signal input; partitioned delay logic coupled to the signal input; a partitioned adaptive filter coupled to the partitioned delay logic and comprising multiple adaptive filter outputs; gain logic coupled to the adaptive filter outputs, where the gain logic is configured to receive an adaptive filter output signal from at least one of the adaptive filter outputs and generate a gain-weighted adaptive filter output signal from the adaptive filter output signal; and signal reinforcement logic comprising an enhanced signal output, and where the processor is configured to execute the signal reinforcement logic to add the gain-weighted adaptive filter output signal to an input signal received on the signal input to increase a first periodic signal component in the input signal that is at least partially in-phase with a second periodic signal component in the gain-weighted adaptive filter output signal.<br>11) A method for signal enhancement comprising: receiving an input signal; delaying the input signal by multiple delays; processing the multiply delayed input signal in a partitioned adaptive filter comprising multiple adaptive filter outputs; biasing an adaptive filter output signal received from at least one of the adaptive filter outputs to generate a gain-weighted adaptive filter output signal from the adaptive filter output signal; generating a summed adaptive filter output signal after biasing, where the summed adaptive filter output signal comprises a sum of the gain-weighted adaptive filter output signal and at least one other adaptive filter output signal; and reinforcing periodic signal content in the input signal with the summed adaptive filter output signal by adding the summed adaptive filter output signal to the input signal to increase a first periodic signal component in the input signal that is at least partially in-phase with a second periodic signal component in the summed adaptive filter output signal, where the act of reinforcing is performed by a processor executing signal reinforcement logic.<br>20) A product comprising: a machine readable storage medium; and machine readable instructions encoded on the medium that: delay an input signal by multiple delays; process the multiply delayed input signal in a partitioned adaptive filter comprising multiple adaptive filter outputs; bias an adaptive filter output signal received from at least one of the adaptive filter outputs to generate a gain-weighted adaptive filter output signal from the adaptive filter output signal; generate a summed adaptive filter output signal after biasing, where the summed adaptive filter output signal comprises a sum of the gain-weighted adaptive filter output signal and at least one other adaptive filter output signal; and reinforce periodic signal content in the input signal with the summed adaptive filter output signal by adding the summed adaptive filter output signal to the input signal to increase a first periodic signal component in the input signal that is at least partially in-phase with a second periodic signal component in the summed adaptive filter output signal.<br>29) A pitch detector comprising: a processor; a signal input; an adaptive filter coupled to the signal input, the adaptive filter comprising filter coefficients and operable to adapt based on an error signal; pitch detection logic coupled to the adaptive filter, where the processor is configured to execute the pitch detection logic and find a peak in the filter coefficients and produce a pitch estimate based on the position of the peak; and a pitch estimate output coupled to the pitch detection logic.<br>35) A method for pitch detection comprising: receiving an input signal; filtering the input signal through an adaptive filter; updating filter coefficients in the adaptive filter based on an error signal; determining a peak in the filter coefficients by a pitch detector comprising a non-transitory computer-readable medium or circuit; producing a pitch estimate based on the position of the peak.<br>41) A voice detector comprising: a processor; a signal input; an adaptive filter coupled to the signal input, the adaptive filter comprising filter coefficients and operable to adapt based on an error signal; voice detection logic coupled to the adaptive filter, where the processor is configured to execute the voice detection logic to analyze the filter coefficients of the adaptive filter to determine a detection measure based on the filter coefficients of the adaptive filter, where the voice detection logic is operable to analyze the detection measure to detect whether voiced speech is present in a signal received on the signal input; a voice detection output coupled to the voice detection logic.<br>46) A method for voice detection comprising: receiving an input signal; filtering the input signal through an adaptive filter; updating filter coefficients in the adaptive filter based on an error signal; analyzing the filter coefficients of the adaptive filter to determine a detection measure based on the filter coefficients of the adaptive filter, where the act of analyzing the filter coefficients is performed by a voice detector comprising a non-transitory computer-readable medium or circuit; analyzing the detection measure to detect whether periodic components are present in the input signal; and asserting a voice detection output based on a determination that the detection measure is above a threshold.</p></layer>
<layer id = "layer424"><p><b>US20080126082A1:Scalable Decoding Apparatus and Scalable Encoding Apparatus</b><br>A load terminal for use in a remote controlled load management system includes a control unit for starting to count a delay time and sending to a central controller monitoring data indicating that an illumination load has been turned off while controlling a power supply ON/OFF unit to keep the power supply to the illumination load when a transmission signal including a control data instructing to turn off the illumination load is received by a transmission signal transceiver unit. The control unit restarts the count of the delay time when the transmission signal transceiver unit receives a transmission signal including a control data instructing to turn on the illumination load during the count of the delay time from the central controller.<br><b>Independant Claims</b><br>1. A scalable decoding apparatus comprising: a first decoding section that decodes low frequency band coded information and obtains a low frequency band decoded signal; and a second decoding section that obtains a high frequency band decoded signal from the low frequency band decoded signal and high frequency band coded information, wherein the second decoding section comprises: a transform section that transforms the low frequency band decoded signal and obtains a low frequency band spectrum; an adjusting section that carries out amplitude adjustment on the low frequency band spectrum; and a generating section that generates a high frequency band spectrum in a pseudo manner using the amplitude-adjusted low frequency band spectrum and the high frequency band coded information.</p></layer>
<layer id = "layer425"><p><b>US8326621B2:Repetitive transient noise removal</b><br>Glycol ethers are made by a process in which an alcohol, an alkylene oxide and a catalytic amount of an aromatic, heterocyclic amine catalyst are contacted under reactive conditions. Representative catalysts include substituted and unsubstituted pyridines and imidazoles. The process uses known oxides and alcohols, and produces more mono- and di-adduct products than does a corresponding process using a caustic catalyst. Moreover, the process can be conducted at a lower reaction temperature than a corresponding process using a caustic catalyst without sacrificing oxide conversion rates yet producing fewer carbonyl impurities.<br><b>Independant Claims</b><br>1) A system for attenuating repetitive transient noise, comprising: a repetitive transient noise detector configured to determine whether an aural signal includes a repetitive transient noise based on a comparison between the aural signal and a repetitive transient noise model, where the repetitive transient noise detector comprises a processor configured to perform the comparison by fitting the repetitive transient noise model to the aural signal in a time-frequency domain, and where the repetitive transient noise detector is configured to identify the repetitive transient noise as being repetitive based on a correlation between a temporal shape of the aural signal and a temporal shape of the repetitive transient noise model, and a correlation between a spectral shape of the aural signal and a spectral shape of the repetitive transient noise model; and a repetitive transient noise attenuator responsive to the repetitive transient noise detector and configured to attenuate the repetitive transient noise identified in the aural signal and generate a noise-reduced aural signal.<br>21) A system for attenuating repetitive transient noise, comprising: a repetitive transient noise detector comprising a processor configured to determine whether a transient noise of an aural signal is repetitive based on a comparison between the aural signal and a repetitive transient noise model; where the repetitive transient noise detector is configured to perform the comparison by fitting the repetitive transient noise model to the aural signal in a time-frequency domain, and where the repetitive transient noise detector is configured to identify the transient noise as being repetitive based on a correlation between a temporal shape of the aural signal and a temporal shape of the repetitive transient noise model, and a correlation between a spectral shape of the aural signal and a spectral shape of the repetitive transient noise model; where the repetitive transient noise detector is configured to update the repetitive transient noise model based on one or more characteristics of the transient noise in response to an identification that the transient noise is repetitive; and a repetitive transient noise attenuator responsive to the repetitive transient noise detector and configured to generate a noise-reduced aural signal by attenuation of the transient noise identified in the aural signal as being repetitive.<br>13) A method of attenuating repetitive transient noise, comprising: detecting whether a transient noise of an aural signal is repetitive based on a comparison between the aural signal and a repetitive transient noise model by fitting the repetitive transient noise model to the aural signal in a time-frequency domain; identifying the transient noise as being repetitive based on a correlation between a temporal shape of the aural signal and a temporal shape and spectral shapes of the repetitive transient noise model, and a correlation between a spectral shape of the aural signal and a spectral shape of the repetitive transient noise model; and attenuating the repetitive transient noise identified in the aural signal to generate a noise-reduced aural signal.</p></layer>
<layer id = "layer426"><p><b>US20060229869A1:Method of and apparatus for reducing acoustic noise in wireless and landline based telephony</b><br>An electrical wire has a central electrically conductive member such as copper, aluminum, gold or silver or admixtures or alloys thereof, coated by a photoresistive insulator, preferably of a negative photoresistive material such as polyimide. A non-mechanical method of stripping a desired portion of the length of the insulator from the electrical wire comprises exposing the desired length of the electrical wire to a source of UV light. The UV light then “softens” the insulator which either evaporates or can be dissolved by immersing it in a solvent.<br><b>Independant Claims</b><br>1-66. (canceled)<br>2) 1-66. (canceled)<br>3) 1-66. (canceled)<br>4) 1-66. (canceled)<br>5) 1-66. (canceled)<br>1-66. (canceled)<br>7) 1-66. (canceled)<br>8) 1-66. (canceled)<br>9) 1-66. (canceled)<br>10) 1-66. (canceled)<br>11) 1-66. (canceled)<br>12) 1-66. (canceled)<br>13) 1-66. (canceled)<br>14) 1-66. (canceled)<br>15) 1-66. (canceled)<br>16) 1-66. (canceled)<br>17) 1-66. (canceled)<br>18) 1-66. (canceled)<br>19) 1-66. (canceled)<br>20) 1-66. (canceled)<br>21) 1-66. (canceled)<br>22) 1-66. (canceled)<br>23) 1-66. (canceled)<br>24) 1-66. (canceled)<br>25) 1-66. (canceled)<br>26) 1-66. (canceled)<br>27) 1-66. (canceled)<br>28) 1-66. (canceled)<br>29) 1-66. (canceled)<br>30) 1-66. (canceled)<br>31) 1-66. (canceled)<br>32) 1-66. (canceled)<br>33) 1-66. (canceled)<br>34) 1-66. (canceled)<br>35) 1-66. (canceled)<br>36) 1-66. (canceled)<br>37) 1-66. (canceled)<br>38) 1-66. (canceled)<br>39) 1-66. (canceled)<br>40) 1-66. (canceled)<br>41) 1-66. (canceled)<br>42) 1-66. (canceled)<br>43) 1-66. (canceled)<br>44) 1-66. (canceled)<br>45) 1-66. (canceled)<br>46) 1-66. (canceled)<br>47) 1-66. (canceled)<br>48) 1-66. (canceled)<br>49) 1-66. (canceled)<br>50) 1-66. (canceled)<br>51) 1-66. (canceled)<br>52) 1-66. (canceled)<br>53) 1-66. (canceled)<br>54) 1-66. (canceled)<br>55) 1-66. (canceled)<br>56) 1-66. (canceled)<br>57) 1-66. (canceled)<br>58) 1-66. (canceled)<br>59) 1-66. (canceled)<br>60) 1-66. (canceled)<br>61) 1-66. (canceled)<br>62) 1-66. (canceled)<br>63) 1-66. (canceled)<br>64) 1-66. (canceled)<br>65) 1-66. (canceled)<br>1-66. (canceled)<br>67. A method of reducing noise in a transmitted signal comprised of a plurality of frames, each of said frames including a plurality of frequency bands; said method comprising the steps of: determining whether said plurality of frequency bands of at least a respective one of said plurality of frames are strong speech bands; and setting, when a count of said strong speech bands is less than a predetermined fraction of a total number of said plurality of frequency bands, a filter gain of at least said strong speech bands to a minimum value.<br>74. An apparatus of reducing noise in a transmitted signal comprised of a plurality of frames, each of said frames including a plurality of frequency bands; said apparatus comprising: means for determining whether said plurality of frequency bands of at least a respective one of said plurality of frames are strong speech bands; and means for setting, when a count of said strong speech bands is less than a predetermined fraction of a total number of said plurality of frequency bands, a filter gain of at least said strong speech bands to a minimum value.</p></layer>
<layer id = "layer427"><p><b>US20060122828A1:Highband speech coding apparatus and method for wideband speech coding system</b><br>A method of de-allocating multiple processor cores sharing a failing bank of memory is disclosed. The method allows new multiple-processor integrated circuits with on-chip shared memory to be de-allocated using existing technology designed for use with single-processor integrated circuit technology.<br><b>Independant Claims</b><br>1. A highband encoding apparatus for encoding a highband signal based on lowband encoding information in a wideband encoding system, comprising: a domain converting means for converting a domain of an input highband signal into a frequency domain; a linear prediction order determining means for determining a linear prediction order based on the lowband encoding information; a linear prediction analyzing means for analyzing a highband signal whose domain is converted into the frequency domain based on the determined linear prediction order to thereby generate a linear prediction coefficient; a linear prediction coefficient quantizing means for quantizing the linear prediction coefficient based on the lowband encoding information; and a residual signal quantizing means for obtaining a residual signal by dequantizing the quantized linear prediction coefficient and quantizing the residual signal.<br>6. A highband decoding apparatus for decoding a highband signal based on lowband encoding information in a wideband decoding system, comprising: a residual signal decoding means for decoding a residual signal from a received bit stream; a linear prediction order determining means for determining a linear prediction order based on the lowband encoding information; a linear prediction coefficient dequantizing means for dequantizing a linear prediction coefficient from the received linear prediction coefficient information by using the determined linear prediction order and the lowband encoding information; a linear prediction synthesizing means for performing linear prediction synthesis on the decoded residual signal by using the dequantized linear prediction coefficient; and a domain converting means for converting a highband signal performed linear prediction synthesis into a highband signal of a time domain.<br>11. A highband encoding method for encoding a highband signal based on lowband encoding information in a wideband encoding system, comprising the steps of: a) converting a domain of an input highband signal into a frequency domain; b) determining a linear prediction order based on the lowband encoding information; c) analyzing the highband signal whose domain is converted into the frequency domain based on the determined linear prediction order and generating a highband linear prediction coefficient; d) quantizing the linear prediction coefficient based on the lowband encoding information; and e) obtaining a residual signal by dequantizing the quantized linear prediction coefficient, and quantizing the obtained residual signal.<br>16. A highband decoding method for decoding a highband signal based on lowband encoding information in a wideband decoding system, comprising the steps of: a) decoding a residual signal from a received bit stream; b) determining a linear prediction order based on the lowband encoding information; c) dequantizing a linear prediction coefficient from the received linear prediction coefficient information based on the determined linear prediction order and the lowband encoding information; d) performing linear prediction synthesis on the decoded residual signal based on the dequantized linear prediction coefficient; and e) converting a highband signal performed linear prediction synthesis into a highband signal of a time domain.</p></layer>
<layer id = "layer428"><p><b>US8265929B2:Embedded code-excited linear prediction speech coding and decoding apparatus and method</b><br>A network access apparatus comprising a tunneling interface to collect device access information of network devices of a first computer network having a first network gateway device and device access information of network devices of a second computer network having a second network gateway device, wherein the apparatus is to send device access information of network devices of said first computer network to said second computer network upon receipt of an inquiry for request of device access information from said second computer network, and vice versa.<br><b>Independant Claims</b><br>1) A speech coding apparatus comprising: a core speech coding unit which presents a speech signal with an excitation signal; a transmission rate determination unit which allocates the number of bits that are additionally allowed due to a capacity change in a transmission channel; and an embedded excitation signal coding unit for determining which one of a multiple pulse excitation coding method and a gain compensation method is optimal for coding a residual excitation signal, that is not coded in the core speech coding unit, with the additionally allowed bits, and generating the residual excitation signal coded by the determined method, wherein the gain compensation method derives a gain compensation value for compensating a gain obtained from an algebraic codebook search, the gain compensation value being multiplied with the gain obtained from the algebraic codebook search to update the gain, wherein the embedded excitation signal coding unit comprises a multiple pulse search unit for selecting a position and a sign of multiple pulses that minimize a square error εm of the residual excitation signal, the embedded excitation signal coding unit further comprises a gain compensation unit for determining the gain compensation value that minimizes a square error εg of the residual excitation signal, and the embedded excitation signal coding unit compares εm with εg, selects the multiple pulse excitation coding method when εmg, and selects the gain compensation method when εm>εg.<br>7) A speech decoding apparatus comprising: an excitation signal reproduction unit which reconstructs a basic excitation signal using an adaptive codebook index and gain, and an algebraic codebook index and gain of a core speech coder; an embedded excitation signal reproduction unit for decoding a residual excitation signal from a bit stream added in an embedded type according to a determination made by an embedded coder as to which one of a multiple pulse excitation coding method and a gain compensation method is optimal for coding the residual excitation signal, that is not coded in the core speech coding unit, with the additionally allowed bits; and a linear prediction synthesis filter unit which reconstructs a speech signal by performing a linear prediction synthesis of the reconstructed basic excitation signal at the excitation signal reproduction unit and the decoded residual excitation signal at the embedded excitation signal reproduction unit, wherein the gain compensation method derives a gain compensation value for compensating a gain obtained from an algebraic codebook search, the gain compensation value being multiplied with the gain obtained from the algebraic codebook search to update the gain, and wherein the embedded coder selects a position and a sign of multiple pulses that minimize a square error εm of the residual excitation signal, determines the gain compensation value that minimizes a square error εg of the residual excitation signal, compares εm with εg, selects the multiple pulse excitation coding method when εmg, and selects the gain compensation method when εm>εg.<br>10) A speech coding method comprising the steps of: a) presenting, by a speech coding apparatus, a speech signal with an excitation signal; b) allocating, by the speech coding apparatus, the number of bits that are additionally allowed due to a capacity change in a transmission channel; and c) determining, by the speech coding apparatus, which one of a multiple pulse excitation coding method and a gain compensation method is optimal for coding a residual excitation signal, that is not coded in the core speech coding unit, with the additionally allowed bits, and generating the residual excitation signal coded by the determined method, wherein the gain compensation method derives a gain compensation value for compensating a gain obtained from an algebraic codebook search, the gain compensation value being multiplied with the gain obtained from the algebraic codebook search to update the gain, wherein the step c) comprises: c1) calculating the residual excitation signal, c2) determining a pulse position and a sign which minimize a square error εm of the residual excitation signal; c3) determining the gain compensation value which minimizes a square error εg of the residual excitation signal; and c4) comparing εm with εg, selecting the multiple pulse excitation coding method when εmg, and selecting the gain compensation method when εm>εg.<br>16) A speech decoding method comprising the steps of: a) reconstructing, by a speech decoding apparatus, a basic excitation signal using an adaptive codebook index and gain, and an algebraic codebook index and gain of a speech coder; b) decoding, by the speech decoding apparatus, a residual excitation signal from a bit stream added in an embedded type according to a determination made by an embedded coder as to which one of a multiple pulse excitation coding method and a gain compensation method is optimal for coding the residual excitation signal, that is not coded in the core speech coding unit, with the additionally allowed bits; and c) reconstructing, by the speech decoding apparatus, a speech signal by performing a linear prediction synthesis of the reconstructed basic excitation signal and the decoded residual excitation signal, wherein the gain compensation method derives a gain compensation value for compensating a gain obtained from an algebraic codebook search, the gain compensation value being multiplied with the gain obtained from the algebraic codebook search to update the gain, wherein the embedded coder selects a position and a sign of multiple pulses that minimize a square error εm of the residual excitation signal, determines the gain compensation value that minimizes a square error εg of the residual excitation signal, compares εm with εg, selects the multiple pulse excitation coding method when εmg, and selects the gain compensation method when εm>εg.</p></layer>
<layer id = "layer429"><p><b>US8155965B2:Time warping frames inside the vocoder by modifying the residual</b><br>The invention provides methods related to evaluating the methylation status of a polynucleotide that includes an internal control.<br><b>Independant Claims</b><br>1) A method communicating speech, comprising: receiving a residual speech signal, wherein the residual speech signal is based on speech segments that were encoded using prototype pitch period (PPP), code-excited linear prediction (CELP), noise-excited linear prediction (NELP) or ⅛ frame coding; time-warping a residual speech segment in the residual speech signal by adding or subtracting at least one sample to the residual speech segment, wherein one of a plurality of different time-warping methods is selected based on whether the speech segment was encoded using prototype pitch period, code-excited linear prediction, noise-excited linear prediction or ⅛ frame coding, wherein if the speech segment was encoded using CELP, the time warping method comprises: estimating pitch delays in the residual speech signal; dividing the residual speech signal into pitch periods, wherein boundaries of said pitch periods are determined using pitch delays at various points in the residual speech signal; overlapping said pitch periods if said residual speech signal is decreased; adding said pitch periods if said residual speech signal is increased; and generating a synthesized speech signal based on said time-warped residual speech signal.<br>17) A vocoder having at least one input and at least one output, comprising: a decoder that receives a residual speech signal, wherein the residual speech signal is based on speech segments that were encoded using prototype pitch period (PPP), code-excited linear prediction (CELP), noise-excited linear prediction (NELP) or ⅛ frame coding; and wherein the decoder comprises a synthesizer having at least one input operably connected to said at least one output of said encoder and at least one output operably connected to said at least one output of the vocoder, and a memory, wherein the decoder is adapted to execute software instructions stored in said memory comprising time-warping a residual speech segment in the residual speech signal by adding or subtracting at least one sample to the residual speech segment, wherein one of a plurality of different time-warping methods is selected based on whether the speech segment was encoded using prototype pitch period, code-excited linear prediction, noise-excited linear prediction or ⅛ frame coding, wherein if the speech segment was encoded using CELP, the time warping method comprises: estimating pitch delays in the residual speech signal; dividing the residual speech signal into pitch periods, wherein boundaries of said pitch periods are determined using pitch delays at various points in the residual speech signal; overlapping said pitch periods if said residual speech signal is decreased; and adding said pitch periods if said residual speech signal is increased.<br>34) A vocoder comprising: means for receiving a residual speech signal, wherein the residual speech signal is based on speech segments that were encoded using prototype pitch period (PPP), code-excited linear prediction (CELP), noise-excited linear prediction (NELP) or ⅛ frame coding to produce a residual signal; means for time-warping a residual speech segment in the residual speech signal by adding or subtracting at least one sample to the residual speech segment, wherein one of a plurality of different time-warping methods is selected based on whether the speech segment was encoded using prototype pitch period, code-excited linear prediction, noise-excited linear prediction or ⅛ frame coding, wherein if the speech segment was encoded using CELP, the time warping method comprises: estimating pitch delays in the residual speech signal; dividing the residual speech signal into pitch periods, wherein boundaries of said pitch periods are determined using pitch delays at various points in the residual speech signal; overlapping said pitch periods if said residual speech signal is decreased; adding said pitch periods if said residual speech signal is increased; and means for generating a synthesized speech signal based on said time-warped residual speech signal.<br>35) A processor readable medium for communicating speech, comprising instructions for: receiving a residual speech signal, wherein the residual speech signal is based on speech segments that were encoded using prototype pitch period (PPP), code-excited linear prediction (CELP), noise-excited linear prediction (NELP) or ⅛ frame coding to produce a residual signal; time-warping a residual speech segment in the residual speech signal by adding or subtracting at least one sample to the residual speech segment, wherein one of a plurality of different time-warping methods is selected based on whether the speech segment was encoded using prototype pitch period, code-excited linear prediction, noise-excited linear prediction or ⅛ frame coding, wherein if the speech segment was encoded using CELP, the time warping method comprises: estimating pitch delays in the residual speech signal; dividing the residual speech signal into pitch periods, wherein boundaries of said pitch periods are determined using pitch delays at various points in the residual speech signal; overlapping said pitch periods if said residual speech signal is decreased; adding said pitch periods if said residual speech signal is increased; and generating a synthesized speech signal based on said time-warped residual speech signal.</p></layer>
<layer id = "layer430"><p><b>US8484036B2:Systems, methods, and apparatus for wideband speech coding</b><br>A digital photographing apparatus includes an optical system, an optical image stabilization (OIS) unit adapted to move the optical system, and a digital signal processor in communication with the OIS unit. The digital signal processor sets an operating ratio of the OIS unit by reducing the operating ratio to a previously set value of 100% or below after a still image or a moving picture is captured, and the OIS unit moves the optical system while a live view mode is turned on.<br><b>Independant Claims</b><br>39) An apparatus for signal processing, comprising: means for generating a highband excitation signal based on a narrowband excitation signal, wherein said means for generating a highband excitation signal includes: means for applying a nonlinear function to a signal that is based on the narrowband excitation signal to generate a spectrally extended signal; means for performing a linear prediction coding analysis operation on the spectrally extended signal to generate a plurality of filter coefficients; means for performing a filtering operation, based on the filter coefficients, on the spectrally extended signal to generate a spectrally flattened signal; means for modulating a noise signal according to a time-domain envelope of a signal based on the spectrally flattened signal to generate a modulated noise signal; and means for mixing a signal that is based on the spectrally flattened signal with the modulated noise signal to generate a mixed signal, wherein the highband excitation signal is based on the mixed signal.<br>1) A method of signal processing, said method comprising: generating, by a signal processing apparatus, a highband excitation signal based on a narrowband excitation signal, wherein said narrowband excitation signal is based on a result of a first linear prediction analysis operation on a narrowband signal, and wherein said generating a highband excitation signal includes: applying, by the signal processing apparatus, a nonlinear function to a signal that is based on the narrowband excitation signal to generate a spectrally extended signal; performing, by the signal processing apparatus, a second linear prediction analysis operation on the spectrally extended signal to generate a plurality of filter coefficients; based on the filter coefficients, performing, by the signal processing apparatus, a filtering operation on the spectrally extended signal to generate a spectrally flattened signal; and mixing, by the signal processing apparatus, a signal that is based on the spectrally flattened signal with a modulated noise signal to generate a mixed signal, wherein the highband excitation signal is based on the mixed signal, and wherein the modulated noise signal is based on a result of modulating a noise signal according to a time-domain envelope of a signal that is based on the spectrally flattened signal.<br>21) An apparatus comprising: a highband excitation generator configured to generate a highband excitation signal based on a narrowband excitation signal, wherein said highband excitation generator includes: a spectrum extender configured to apply a nonlinear function to a signal that is based on the narrowband excitation signal to generate a spectrally extended signal, wherein said spectrum extender includes a spectral flattener having: a linear prediction analysis module configured to calculate a plurality of filter coefficients from the spectrally extended signal; and an analysis filter configured to filter the spectrally extended signal, based on the plurality of filter coefficients, to generate a spectrally flattened signal; a first combiner configured to modulate a noise signal according to a time-domain envelope of a signal based on the spectrally flattened signal to generate a modulated noise signal; and a second combiner configured to mix a signal that is based on the spectrally flattened signal with the modulated noise signal to generate a mixed signal, and wherein said highband excitation generator is configured to generate the highband excitation signal based on the mixed signal.</p></layer>
<layer id = "layer431"><p><b>USRE46082E1:Method and apparatus for low bit rate encoding and decoding</b><br><b>Independant Claims</b><br>1) A method of low bit rate encoding comprising: transforming input audio signals in a time domain into spectral signals in a frequency domain; extracting spectrum components from the spectral signals in the frequency domain, and quantizing the spectrum components based on a psychoacoustic analysis of the spectral signals; extracting residual-spectrum components other than the spectrum components from the spectral signals in the frequency domain, and calculating and quantizing a noise level corresponding to noise components of the residual-spectrum components based on the psychoacoustic analysis of the spectral signals; and encoding the quantized spectrum components and the quantized noise level losslessly, without the noise components, and outputting encoded bitstreams.<br>10) A computer-readable storage medium encoded with processing instructions for causing a processor to execute a method of low bit rate encoding, the method comprising: transforming an input audio signal from the time domain to the frequency domain; extracting spectrum components from a spectral signal in a frequency domain, and quantizing the spectrum components based on a psychoacoustic analysis of the spectral signals; extracting residual-spectrum components other than the spectrum components from the spectral signal in the frequency domain, and calculating and quantizing a noise level corresponding to noise components of the residual-spectrum components based on the psychoacoustic analysis of the spectral signals; and encoding the quantized spectrum components and the quantized noise level losslessly, without the noise components, and outputting encoded bitstreams.<br>11) A method of low bit rate decoding, comprising: decoding input bitstreams into spectral signals losslessly lossless-decoding, performed by at least one processor, a bitstream to obtain quantized spectrum components ; dequantizing the quantized spectrum components , of decoded spectral signals, surrounded by spectrum components during an encoding of the input bitstream that were quantized to zero within the encoding ; dequantizing a noise level of additional information of the decoded spectral signals and a subband from the bitstream in order to obtain a dequantized noise level; generating a respective noise components component, using the dequantized noise level , for residue each spectrum components component set to zero other than the each spectrum components component set to non-zero ; and generating spectral signals in a frequency domain using the dequantized replacing each of spectrum components and the components set to zero with its respective noise components component; and generating a digital audio signal, based on the replacing and the spectrum component set to non-zero of the subband for audio reproduction, wherein in the replacing, a frequency range of spectrum components set to zero around the spectrum component set to non-zero for which their noise components are to be replaced is determined based on a frame length .<br>13) An apparatus for low bit rate decoding, comprising: a lossless decoding unit implemented by a processor that decodes input bitstreams into spectral signals losslessly lossless-decodes a bitstream to obtain quantized spectrum components ; a spectrum component dequantizing unit implemented by the processor that dequantizes the quantized spectrum components , of the decoded spectral signals, surrounded by spectrum components during an encoding of the input bitstream that were quantized to zero within the encoding ; a noise component processing unit implemented by the processor that dequantizes a noise level of additional information of the decoded spectral signals a subband from the bitstream in order to obtain a dequantized noise level and generates a respective noise components component using the dequantized noise level, for residue each spectrum components component set to zero other than the each spectrum components component set to non-zero ; a spectrum combining unit implemented by the processor that combines replaces each of the dequantized spectrum components and the components set to zero with its respective noise components component to be output as a spectral signals signal in a frequency domain; and a signal generating unit implemented by the processor that generates spectral signals in a time domain from the spectral signals in the frequency domain a digital audio signal, based on the replacing and the spectrum component set to non-zero of the subband for audio reproduction, wherein in the replacing, a frequency range of spectrum components set to zero around the spectrum component set to non-zero for which their noise components are to be replaced is determined based on a frame length .<br>15) A non-transitory computer-readable storage medium encoded with processing instructions for causing a processor to execute a method of low bit rate decoding, comprising: decoding input bitstreams into spectral signals losslessly lossless-decoding, performed by at least one processor, a bitstream to obtain quantized spectrum components ; dequantizing the quantized spectrum components , of decoded spectral signals, surrounded by spectrum components during an encoding of the input bitstream that were quantized to zero within the encoding ; dequantizing a noise level of additional information of the decoded spectral signals and a subband from the bitstream in order to obtain a dequantized noise level; generating a respective noise components component, using the dequantized noise level, for each spectrum components component set to zero other than the each spectrum components quantized component set to non-zero; and generating spectral signals in a frequency domain using the dequantized replacing each of spectrum components and the set to zero with its respective noise components component; and generating a digital audio signal, based on the replacing and the spectrum component set to non-zero of the subband for audio reproduction, wherein in the replacing, a frequency range of spectrum components set to zero around the spectrum component set to non-zero for which their noise components are to be replaced is determined based on a frame length .<br>7) An apparatus for low bit rate encoding, comprising: a spectrum component processing unit that extracts spectrum components from a spectral signal in a frequency domain and quantizes the spectrum components; a psychoacoustic modeling unit performing a psychoacoustic analysis of the spectral signals; a noise component processing unit that extracts residual-spectrum components other than the spectrum components from the spectral signal in the frequency domain, and calculates and quantizes noise levels corresponding to noise components of the residual-spectrum components based on the psychoacoustic analysis performed by the psychoacoustic modeling unit; and a lossless encoding unit that losslessly encodes the spectrum components and the noise level, without the noise components and outputs encoded bitstreams.</p></layer>
<layer id = "layer432"><p><b>US20060184362A1:Speech analyzing system with adaptive noise codebook</b><br>In a coding apparatus and a decoding apparatus, the performance of codes is improved by optimizing a degree sequence and a quantization step size. The coding apparatus includes a degree sequence calculator for calculating a degree sequence indicating the distribution of the number of 1s in the parity check matrix, a parity check matrix generator for producing a parity check matrix on the basis of the degree sequence calculated by the degree sequence calculator, and an encoder for coding the input data using the parity check matrix generated by the parity check matrix generator. The degree sequence calculator optimizes the degree sequence such that when, in the decoding apparatus for decoding coded data, a received value and a message are represented by a small number of bits, the error probability after decoding is minimized for a given variance of noise or the allowable variance of noise is maximized for a given error probability after decoding.<br><b>Independant Claims</b><br>1. A method comprising: providing a speech codebook including a plurality of speech codebook entries corresponding to speech sounds; providing a noise codebook including a plurality of noise codebook entries corresponding to noise sounds; receiving an audio signal including noise sounds; updating an entry in the noise codebook based on the noise sounds in the received audio signal; and identifying speech sounds in the audio signal using the speech codebook and the noise codebook.<br>42. A device comprising: a receiver for receiving an audio signal; a first database for storing a plurality of speech codebook entries representative of a plurality of speech sounds; a second database for storing a plurality of noise codebook entries representative of a plurality of noise sounds; a first processor for updating an entry in the noise codebook based on noise sounds in the audio signal; and a second processor for identifying speech sounds in the audio signal as a function of the speech codebook entries and the noise codebook entries.</p></layer>
<layer id = "layer433"><p><b>US20060149535A1:Method for controlling speed of audio signals</b><br>The system and method for testing thermal insulation uses a cryostatic insulation tester having a vacuum chamber and a cold mass including a test chamber and upper and lower guard chambers adjacent thereto. The thermal insulation is positioned within the vacuum chamber and adjacent the cold mass. Cryogenic liquid is supplied to the test chamber, upper guard and lower guard to create a first gas layer in an upper portion of the lower guard chamber and a second gas layer in an upper portion of the test chamber. Temperatures are sensed within the vacuum chamber to test the thermal insulation.<br><b>Independant Claims</b><br>1. A time scale modification (TSM)-based method for controlling the speed of audio signals using an optimized absolute magnitude difference function (AMDF) and an overlap and add (OLA), the method comprising: differently setting the number of frame sets depending on a TSM speed rate to set the interval of a speed rate; determining the number of frame sets to be TSM-processed so as to adjust the speed rate; and performing a TSM process only when the TSM process is required for the frame set determined to adjust the speed rate, and performing speed processing such that an input frame becomes an output frame otherwise.<br>11. A method for controlling the speed of audio signals, the method comprising: reading a sample of an audio file; searching/comparing pitches from a predetermined pitch search range; and increasing or reducing the pitches depending on a speed rate, wherein the pitch search range is in a range between Pmax and Pmin, the Pmax has a value of 25/3x (sample rate/1000), and the Pmin has a value of 5/3x (sample rate/1000).</p></layer>
<layer id = "layer434"><p><b>US20060149532A1:Method and apparatus for enhancing loudness of a speech signal</b><br>To control movement of a member to be driven by using a scale having a plurality of indices at a predetermined interval, and a sensor which is attached to the member to be driven along the scale and detects the indices, a time until the next index is detected is predicted on the basis of the output waveform of the sensor. Then, a signal concerning the current position of the member is generated on the basis of the predicted time. The current position of the member can be controlled with high precision even during acceleration/deceleration.<br><b>Independant Claims</b><br>1. A method of increasing the perceived loudness of a processed speech signal, the processed speech signal corresponding to a natural speech signal and having formant regions and non-formant regions and a natural energy level, the method comprising: expanding the formant regions of the processed speech signal beyond a natural bandwidth; and restoring an energy level of the processed speech signal to the natural energy level.<br>10. A speech filter, comprising, an analysis portion having a set of filter coefficients determined by warped linear prediction analysis including pole displacement, the analysis portion having unit delay elements; a synthesis portion having a set of filter coefficients determined by warped linear prediction synthesis including pole displacement, the synthesis portion having unit delay elements; and a locally recurrent feedback element having a scaling value coupled to the unit delay elements of the analysis and synthesis portions thereby producing non-linear frequency resolution.<br>13. A method of processing a speech signal comprising expanding formant regions of the speech signal on a critical band scale using a warped pole displacement filter.</p></layer>
<layer id = "layer435"><p><b>US20070116300A1:Channel decoding for wireless telephones with multiple microphones and multiple description transmission</b><br>A system for determining properties of settling suspensions includes a settling container, a mixer, and devices for ultrasonic interrogation transverse to the settling direction. A computer system controls operation of the mixer and the interrogation devices and records the response to the interrogating as a function of settling time, which is then used to determine suspension properties. Attenuation versus settling time for dilute suspensions, such as dilute wood pulp suspension, exhibits a peak at different settling times for suspensions having different properties, and the location of this peak is used as one mechanism for characterizing suspensions. Alternatively or in addition, a plurality of ultrasound receivers are arranged at different angles to a common transmitter to receive scattering responses at a variety of angles during particle settling. Angular differences in scattering as a function of settling time are also used to characterize the suspension.<br><b>Independant Claims</b><br>1. A wireless telephone, comprising: a receiver module that receives a plurality of versions of a voice signal, each version of the voice signal comprising a plurality of speech frames; a channel decoder configured to decode a speech parameter associated with a speech frame from one of the plurality of versions of the voice signal, wherein decoding the speech parameter includes selecting an optimal bit sequence from a plurality of candidate bit sequences and wherein the selection of the optimal bit sequence is based in part on a corresponding speech frame from another version of the plurality of versions of the voice signal; a speech decoder that decodes at least one of the plurality of versions of the voice signal based on the speech parameter to generate an output signal; and a speaker that receives the output signal and produces a sound pressure wave corresponding thereto.<br>6. A multiple-description transmission system, comprising: (a) a first wireless telephone comprising (i) a microphone array, each microphone in the array configured to receive voice input from a user and to produce a voice signal corresponding thereto, (ii) an encoder coupled to the microphone array and configured to encode each voice signal, and (iii) a transmitter coupled to the encoder and configured to transmit each encoded voice signal; and (b) a second wireless telephone comprising (i) a receiver module that receives each transmitted voice signal, each transmitted voice signal comprising a plurality of speech frames; (ii) a channel decoder configured to decode a speech parameter associated with a speech frame from one of the transmitted voice signals, wherein decoding the speech parameter includes selecting an optimal bit sequence from a plurality of candidate bit sequences and wherein the selection of the optimal bit sequence is based in part on a corresponding speech frame from another transmitted voice signal; (iii) a speech decoder that decodes at least one of the transmitted voice signals based on the speech parameter to generate an output signal; and (iv) a speaker that receives the output signal and produces a sound pressure wave corresponding thereto.<br>18. A method in a wireless telephone, comprising: (a) receiving a plurality of versions of a voice signal, each version of the voice signal comprising a plurality of speech frames; (b) decoding a speech parameter associated with a speech frame from one of the plurality of versions of the voice signal, wherein decoding the speech parameter includes selecting an optimal bit sequence from a plurality of candidate bit sequences and wherein the selection of the optimal bit sequence is based in part on a corresponding speech frame from another version of the plurality of versions of the voice signal; (c) decoding at least one of the plurality of versions of the voice signal based on the speech parameter to generate an output signal; and (d) producing a sound pressure wave corresponding to the output signal.</p></layer>
<layer id = "layer436"><p><b>US20060241940A1:Quantization of speech and audio coding parameters using partial information on atypical subsequences</b><br>Hydrophobic, oil-absorbing polymeric compositions, prepared from high levels of hydrophobic monomers, are provided for transferring oily substances and hydrophobic materials to and from various surfaces in a heterogeneous medium. A reversible process is described for transferring oily substances and hydrophobic materials to and from various surfaces in a heterogeneous medium using oil-absorbing films, solid particles or dispersions of aqueous emulsion polymers prepared from hydrophobic monomers.<br><b>Independant Claims</b><br>1. A method comprising: partially classifying a first plurality of subsequences in a target vector into a number of selected groups; creating a refined fidelity criterion for each subsequence of the first plurality of subsequences based on information derived from classification; dividing a target vector into a second plurality of subsequences; and encoding the second plurality of subsequences, including quantizing the second plurality of subsequences given the refined fidelity criterion.<br>33. An article of manufacture comprising one or more computer readable media storing instructions which, when executed by a system, causes the system to perform a method comprising: partially classifying a first plurality of subsequences in the target vector into a number of selected groups; creating a refined fidelity criterion for each subsequence of the first plurality of subsequences based on information derived from classification; dividing a target vector into a second plurality of subsequences; and encoding the second plurality of subsequences, including quantizing the second plurality of subsequences given the refined fidelity criterion.<br>34. A method comprising: receiving a bitstream having encoded information; decoding classification information from the bitstream, the classification information created during encoding by partially classifying subsequences in a target vector; creating a fidelity criterion for each subsequence of the first plurality of subsequences based on decoded classification information; and decoding a first plurality of encoded subsequences from the bitstream based on a known order and the fidelity criterion.<br>53. An article of manufacture comprising one or more computer readable media storing instructions which, when executed by a system, causes the system to perform a method comprising: receiving a bitstream having encoded information; decoding classification information from the bitstream, the classification information created during encoding by partially classifying subsequences in a target vector; creating a fidelity criteria for each subsequence of the first plurality of subsequences based on decoded classification information; and decoding a first plurality of encoded subsequences from the bitstream based on a known order and the fidelity criteria.</p></layer>
<layer id = "layer437"><p><b>US20100036656A1:AUDIO SWITCHING DEVICE AND AUDIO SWITCHING METHOD</b><br>The invention relates to a damping system, in particular in the form of a hydraulic cabin spring system, having at least one hydraulically triggerable actuating part (<b>20</b>) and having at least one hydraulic accumulator (<b>26</b>) which is connected to the assignable actuating part (<b>20</b>). In that, by means of a proportional throttle valve (<b>10</b>), proportional damping for the respective actuating part (<b>20</b>) is achieved, variable proportional damping which can react to events in a manner specific to the user can be implemented.<br><b>Independant Claims</b><br>1. A speech switching apparatus that outputs a mixed signal in which a narrow-band speech signal and wide-band speech signal are mixed when switching a band of an output speech signal, comprising: a mixing section that mixes the narrow-band speech signal and the wide-band speech signal while changing a mixing ratio of the narrow-band speech signal and the wide-band speech signal over time, and obtains the mixed signal; and a setting section that variably sets a degree of change over time of the mixing ratio.<br>21. A speech switching method that outputs a mixed signal in which a narrow-band speech signal and wide-band speech signal are mixed when switching a band of an output speech signal, comprising: a changing step of changing a degree of change over time of a mixing ratio of the narrow-band speech signal and the wide-band speech signal; and a mixing step of mixing the narrow-band speech signal and the wide-band speech signal while changing the mixing ratio over time to a changed degree, and obtaining the mixed signal.</p></layer>
<layer id = "layer438"><p><b>US8311840B2:Frequency extension of harmonic signals</b><br>A cooking appliance includes a glass cooktop panel and a cooktop frame. A radiant heating element is positioned between the cooktop frame and the glass cooktop panel. The heating element has an upper surface biased toward a lower surface of the glass cooktop panel. A screwless spring clip is coupled to both the heating element and the cooktop frame so as to secure the heating element to the cooktop frame.<br><b>Independant Claims</b><br>1) A computer-implemented method of extending harmonics of a band-limited harmonic signal through the use of a processor, the method comprising: transforming, through the use of a processor, a band-limited harmonic signal from a time domain to a frequency domain to obtain a complex spectrum of the band-limited harmonic signal; performing, through the use of the processor, a non-linear transformation on the complex spectrum of the band-limited harmonic signal in the frequency domain which extends harmonic content of the band-limited harmonic signal to frequencies above an upper frequency limit of the band-limited harmonics signal, where the non-linear transformation comprises performing a linear convolution; and inverse transforming, through the use of the processor, the extended complex spectrum of the band-limited harmonic signal back into the time domain.<br>11) A computer-implemented harmonic extension method comprising: receiving a band-limited harmonic signal having significant signal energies at regular frequency intervals within a limited frequency band defined by a passband lower frequency limit and a passband upper frequency limit; transforming, through the use of a processor, the band-limited harmonic signal from a time domain to a frequency domain to obtain a complex spectrum of the band-limited harmonic signal; performing, through the use of the processor, a first non-linear transformation of the complex spectrum of the band-limited harmonic signal in the frequency domain which extends harmonic content of the band-limited harmonic signal to frequencies below the passband lower frequency limit where a lower extended spectrum has harmonic energy at at least one harmonic frequency at which harmonic energy was absent in the band-limited harmonic signal, where the first non-linear transformation comprises performing a linear convolution on the complex spectrum of the band-limited harmonic signal with a mirrored complex conjugate of the complex spectrum of the band-limited harmonic signal; performing, through the use of the processor, a second non-linear transformation of the complex spectrum of the band-limited harmonic signal in the frequency domain which extends harmonic content of the band-limited harmonic signal to frequencies above the passband upper frequency limit where an upper extended spectrum has harmonic energy at at least one harmonic frequency at which harmonic energy was absent in the band-limited harmonic signal, where the second non-linear transformation comprises performing a linear convolution on the complex spectrum of the band-limited harmonic signal with itself; and transforming, through the use of the processor, the lower extended spectrum and the upper extended spectrum into the time domain.<br>21) A system for extending harmonics and a spectral envelope of a band-limited harmonic signal and combining an extended signal with the band-limited harmonic signal, the system comprising: means for receiving a band-limited harmonic signal; a signal processor having a forward transform module that transforms the band-limited harmonic signal from a time domain into a complex spectrum of the band-limited harmonic signal in a frequency domain; a harmonic generation module that performs a non-linear transformation of the complex spectrum of the band-limited harmonic signal in the frequency domain that extends harmonic content of the band-limited harmonic signal to frequencies above an upper frequency limit of the band-limited harmonic signal, the non-linear transformation comprising a linear convolution in the frequency domain; a spectral envelope extender module to ensure the spectral envelope of the harmonically extended spectrum of the band-limited harmonic signal is complimentary to that of the band-limited signal; a combiner module that combines the harmonically extended spectrum of the band-limited harmonic signal with a spectrum of the band-limited harmonic signal to create a final frequency extended harmonic spectrum; and a reverse transform module for transforming the final frequency extended harmonic spectrum back to the time domain.<br>25) A system for extending harmonics of a band-limited harmonic signal, the system comprising: means for receiving a band-limited harmonic signal; a signal processor having a forward transform module that transforms the band-limited harmonic signal from a time domain into a complex spectrum of the band-limited harmonic signal in a frequency domain; and a harmonic generation module that performs a first non-linear transformation of the complex spectrum of the band-limited harmonic signal in the frequency domain, the first non-linear transformation comprising a first linear convolution in the frequency domain that extends harmonic content of the band-limited harmonic signal to a frequency above an upper frequency limit of the band-limited harmonic signal, and that performs a second non-linear transformation of the complex spectrum of the band-limited harmonic signal in the frequency domain, the second non-linear transformation comprising a second linear convolution in the frequency domain that extends harmonic content of the band-limited harmonic signal to a frequency below a lower frequency limit of the band-limited harmonic signal; and a reverse transform module that transforms harmonic content of the band-limited harmonic signal extended to the frequency above the upper frequency limit of the band-limited harmonic signal and harmonic content of the band-limited harmonic signal extended to the frequency below the lower frequency limit of the band-limited harmonic signal into the time domain.<br>17) A system for extending harmonics of a band-limited harmonic signal, the system comprising: means for receiving a band-limited harmonic signal; a signal processor having a forward transform module that transforms the band-limited harmonic signal from a time domain into a complex spectrum of the band-limited harmonic signal in a frequency domain; and a harmonic generation module that performs a non-linear transformation of the complex spectrum of the band-limited harmonic signal in the frequency domain, the non-linear transformation comprising a linear convolution in the frequency domain that extends harmonic content of the band-limited harmonic signal to a frequency above an upper frequency limit of the band-limited harmonic signal; and a reverse transform module that transforms the harmonically extended spectrum of the band-limited harmonic signal back to the time domain.</p></layer>
<layer id = "layer439"><p><b>US9043214B2:Systems, methods, and apparatus for gain factor attenuation</b><br><b>Independant Claims</b><br>1) A method of signal processing, said method being implemented by a wireless communications device, the method comprising: calculating an envelope of a first signal that is based on a low-frequency portion of a speech signal; calculating an envelope of a second signal that is based on a high-frequency portion of the speech signal; calculating a plurality of gain factor values according to a time-varying relation between the calculated envelopes, wherein each of the plurality of gain factor values is based on a calculated value of the time-varying relation over a different corresponding time period, and wherein the time-varying relation is one among a difference between the calculated envelopes and a ratio between the calculated envelopes; calculating a value of a change in a relation between the calculated envelopes, wherein the change is a change over time; and based on the calculated value of the change, attenuating at least one of the plurality of gain factor values.<br>18) An apparatus comprising: a first envelope calculator configured and arranged to calculate an envelope of a first signal that is based on a low-frequency portion of a speech signal; a second envelope calculator configured and arranged to calculate an envelope of a second signal that is based on a high-frequency portion of the speech signal; a factor calculator configured and arranged to calculate a plurality of gain factor values according to a time-varying relation between the calculated envelopes, wherein each of the plurality of gain factor values is based on a calculated value of the time-varying relation over a different corresponding time period, and wherein the time-varying relation is one among a difference between the calculated envelopes and a ratio between the calculated envelopes; and a gain factor attenuator configured and arranged to calculate a value of a change in a relation between the calculated envelopes, wherein the change is a change over time, and to attenuate at least one of the plurality of gain factor values based on the calculated value of the change.<br>29) An apparatus comprising: means for calculating an envelope of a first signal that is based on a low-frequency portion of a speech signal; means for calculating an envelope of a second signal that is based on a high-frequency portion of the speech signal; means for calculating a plurality of gain factor values according to a time-varying relation between the calculated envelopes, wherein each of the plurality of gain factor values is based on a calculated value of the time-varying relation over a different corresponding time period, and wherein the time-varying relation is one among a difference between the calculated envelopes and a ratio between the calculated envelopes; means for calculating a value of a change in a relation between the calculated envelopes, wherein the change is a change over time; and means for attenuating at least one of the plurality of gain factor values based on the calculated value of the change.<br>40) A non-transitory processor-readable medium having machine-executable instructions thereon, the instructions comprising: code for calculating an envelope of a first signal that is based on a low-frequency portion of a speech signal; code for calculating an envelope of a second signal that is based on a high-frequency portion of the speech signal; code for calculating a plurality of gain factor values according to a time-varying relation between the calculated envelopes, wherein each of the plurality of gain factor values is based on a calculated value of the time-varying relation over a different corresponding time period, and wherein the time-varying relation is one among a difference between the calculated envelopes and a ratio between the calculated envelopes; code for calculating a value of a change in a relation between the calculated envelopes, wherein the change is a change over time; and code for attenuating at least one of the plurality of gain factor values based on the calculated value of the change.</p></layer>
<layer id = "layer440"><p><b>US8219391B2:Speech analyzing system with speech codebook</b><br>In a method of rewarding players for completing a team challenge, an initiation of a team challenge by a player of an online social game is detected. Based on an online social network of the player, an option for the friend of the player to participate in the team challenge is generated. A completion of the team challenge by the player and the friend of the player is detected. A reward is provided to at least one of the player and the friend of the player based on the detecting of the completion of the team challenge.<br><b>Independant Claims</b><br>1) A method for processing a signal, comprising the steps of: receiving an input sound signal including speech and environmental noise; temporally parsing the input sound signal into input frame sequences of at least three input frames, wherein an input frame represents a segment of a waveform of the input sound signal; providing a speech codebook including a plurality of entries corresponding to speech spectral trajectories of reference frame sequences that include at least three reference frames, wherein a reference frame represents a segment of a waveform of a reference sound signal, wherein the reference frame sequence corresponding to the entries are derived from allowable sequences of at least three reference frames, and wherein the speech codebook substantially lacks entries corresponding to (1) reference frame sequences that include a single unvoiced frame between a pair of voiced frames, and (2) reference frame sequences that include a single voiced frame between a pair of unvoiced frames; identifying phones within the speech based on a comparison of an input frame sequence with a plurality of the speech spectral trajectories of reference frame sequences; and encoding the phones.<br>23) A device comprising: a receiver for receiving an input sound signal including speech and environmental noise; a first processor for temporally parsing the input sound signal into input frame sequences of at least three input frames, wherein an input frame represents a segment of a waveform of the input sound signal; a first memory for storing a plurality of speech codebook entries corresponding to speech spectral trajectories of reference frame sequences that include at least three reference frames, wherein a reference frame represents a segment of a waveform of a reference sound signal, wherein the reference frame sequence corresponding to the entries are derived from allowable sequences of at least three reference frames, and wherein the speech codebook substantially lacks entries corresponding to (1) reference frame sequences that include a single unvoiced frame between a pair of voiced frames, and (2) reference frame sequences that include a single voiced frame between a pair of unvoiced frames; a second processor for identifying phones within the speech based on a comparison of an input frame sequence with a plurality of the speech spectral trajectories of reference frame sequences; and a third processor for encoding the phones.</p></layer>
<layer id = "layer441"><p><b>US8265940B2:Method and device for the artificial extension of the bandwidth of speech signals</b><br>A charging apparatus including a mounting portion on which a plurality of information processing apparatuses are mounted, a power transmission unit that transmits power in a non-contact manner to each of the plurality of information processing apparatuses placed on the mounting portion, and a control unit that receives a charge order instruction from at least one of the plurality of information processing apparatuses, and controls the power transmission unit to transmit power to each of the plurality of information processing apparatuses in an order determined based on the received charge order instruction.<br><b>Independant Claims</b><br>1) A method for artificial extension of bandwidth of speech signals, comprising: encoding by a process comprising: providing a wideband input speech signal, the wideband input speech signal having an extension band outside of non-extended band; determining signal components within the extension band of the wideband input speech signal, the signal components being required for bandwidth extension into the extension band of the wideband input speech signal; determining spectral envelopes of the signal components; determining temporal envelopes of the signal components, the temporal envelopes being determined independently of the spectral envelopes, without using the spectral envelopes as an input; and encoding information for the temporal envelopes and the spectral envelopes to produce encoded information for extending the bandwidth; and decoding the encoded information and reconstructing the temporal envelopes and the spectral envelopes from the encoded information to thereby produce an output speech signal with extended bandwidth, wherein decoding and reconstructing comprise: producing an excitation signal in a decoder from an input signal transmitted to the decoder; determining a first correction factor from decoded information of the temporal envelopes and from the excitation signal; in a first reconstruction, forming reconstructed temporal envelopes by multiplying the first correction factor with the excitation signal; filtering the reconstructed temporal envelopes to produce pulse responses while filtering; and in a second reconstruction, forming reconstructed spectral envelopes from the pulse responses and the reconstructed temporal envelopes.<br>18) A device for artificial extension of bandwidth of speech signals comprising: an encoder device comprising: a first determination unit to determine signal components within an extension band of a wideband input speech signal; a second determination unit to determine spectral envelopes for the signal components; a third determination unit to determine temporal envelopes for the signal components, the temporal envelopes being determined independently of the spectral envelopes, without using the spectral envelopes as an input; and an encoder to encode the temporal envelopes and the spectral envelopes, and produce encoded information; and a decoder to decode the encoded information and regenerate the temporal envelopes and the spectral envelopes and produce a bandwidth-extended output speech signal, wherein the decoder comprises: an excitation signal generator to generate an excitation signal from an input signal transmitted to the decoder; a first correction unit to determine a first correction factor from decoded information of the temporal envelopes and from the excitation signal, and to form reconstructed temporal envelopes by multiplying the first correction factor with the excitation signal; and a second correction unit to filter the reconstructed temporal envelopes to produce pulse responses while filtering, and to form reconstructed spectral envelopes from the pulse responses and the reconstructed temporal envelopes.<br>20) A method for artificial extension of bandwidth of speech signals, comprising: providing a wideband input speech signal, the wideband input speech signal having an extension band outside of non-extended band; determining signal components within the extension band of the wideband input speech signal, the signal components being required for bandwidth extension into the extension band of the wideband input speech signal; determining temporal envelopes of the signal components; determining spectral envelopes of the signal components independently of the temporal envelopes; encoding information for the temporal envelopes and the spectral envelopes to produce encoded information for extending the bandwidth; and decoding the encoded information and reconstructing the temporal envelopes and the spectral envelopes from the encoded information to thereby produce an output speech signal with extended bandwidth, the decoding and reconstructing comprising: producing an excitation signal in a decoder from an input signal transmitted to the decoder; determining a first correction factor from decoded information of the temporal envelopes and from the excitation signal; in a first reconstruction, forming reconstructed temporal envelopes by multiplying the first correction factor with the excitation signal; filtering the reconstructed temporal envelopes to produce pulse responses while filtering; and in a second reconstruction, forming reconstructed spectral envelopes from the pulse responses and the reconstructed temporal envelopes.</p></layer>
<layer id = "layer442"><p><b>US8180818B2:Partially complex modulated filter bank</b><br>According to one embodiment, a magnetic head has a main magnetic pole, a write-shield constituting the main magnetic pole and a magnetic circuit, and a spin torque oscillation element provided between the main magnetic pole and the write-shield. The spin torque oscillation element is provided with a first oscillation layer, a nonmagnetic spin sink layer, a second oscillation layer, a nonmagnetic intermediate layer, and a spin injection layer provided in sequence from the write-shield side to the main magnetic pole side. The nonmagnetic spin sink layer is formed of at least one element selected from the group consisting of Ru, Rh, Ta, W, Cr, Ir, Mo, Re, Nb, Pt, and Pd.<br><b>Independant Claims</b><br>1) Apparatus for processing a plurality of real-valued subband signals, the plurality of real-valued subband signals comprising a first real-valued subband signal and a second real-valued subband signal, to obtain a complex-valued subband signal, comprising: a multiband filter for providing a real-valued intermediate subband signal based on filtering the first real-valued subband signal to obtain a first filtered subband signal and the second real-valued subband signal to obtain a second filtered subband signal and based on by combining the first filtered subband signal and the second filtered subband signal to obtain the real-valued intermediate subband signal; and a calculator for providing the complex-valued subband signal by combining the real-valued subband signal from the plurality of real-valued subband signals as a real part of the complex-valued subband signal and a signal based on the intermediate subband signal as an imaginary part of the complex-valued subband signal, wherein the plurality of real-valued subband signals is output by a real QMF analysis bank.<br>18) Method for processing a plurality of real-valued subband signals, the plurality of real-valued subband signals comprising a first real-valued subband signal and a second real-valued subband signal to obtain a complex-valued subband signal, comprising: filtering, by a multiband filter, the first real-valued subband signal to obtain a first filtered subband signal and the second real-valued subband signal to obtain a second filtered subband signal; combining the first filtered subband signal and the second filtered subband signal when deriving a real-valued intermediate subband signal; and combining, by a calculator, a real-valued subband signal from the plurality of real-valued subband signals as a real part of a complex-valued subband signal and a signal which is based on the intermediate subband signal as an imaginary part of the complex-valued subband signal, wherein the plurality of real-valued subband signals is output by a real QMF analysis bank.</p></layer>
<layer id = "layer443"><p><b>US20060217975A1:Audio coding and decoding apparatuses and methods, and recording media storing the methods</b><br>A method of operating a combustion apparatus such as an internal combustion engine is described, in which the apparatus includes at least one combustion chamber with an inlet port for primary combustion air, an apparatus to introduce into the combustion chamber primary fuel for combustion with the primary air, an exhaust port for combustion products, and an exhaust system for exhausting the combustion products to atmosphere, the method including introducing into the exhaust system secondary air, mechanically acting upon the secondary air and products of combustion in the exhaust system in the presence of a catalyst, to produce a reformed fuel, introducing the reformed fuel into the combustion chamber for combustion with primary fuel and primary air.<br><b>Independant Claims</b><br>1. An audio coding method comprising: detecting harmonics of a high-band audio signal or wideband error audio signal of an input audio signal; determining an order of the detected harmonics; and coding the detected harmonics based on the determined order of the detected harmonics.<br>9. An audio coding apparatus comprising: a harmonic detecting unit detecting harmonics of a high-band audio signal or wideband error audio signal of an input audio signal; a harmonic order determining unit determining an order of the detected harmonics; and a harmonic coding unit coding the harmonics based on the determined order of the detected harmonics.<br>17. An audio decoding method comprising: decoding a received bitstream corresponding to a coded high-band audio signal or wideband error audio signal for each layer of the received bitstream; and outputting a decoded result for each layer as a high-band audio signal or wideband error audio signal restored in each layer.<br>22. An audio decoding apparatus comprising: a bit unpacking unit, which, when a bitstream corresponding to a coded high-band audio signal or wideband error audio signal is received, unpacks and outputs the received bitstream; and a harmonic decoding unit which decodes the bitstream outputted in each layer from the bit packing unit in layer units.<br>24. A recording medium on which a program for performing an audio coding method is recorded, the audio coding method comprising: detecting harmonics of a high-band audio signal or wideband error audio signal of an input audio signal; determining an order of the detected harmonics; and coding the detected harmonics based on the determined order of the detected harmonics.<br>25. A recording medium on which a program for performing an audio decoding method is recorded, the audio decoding method comprising: decoding a received bitstream corresponding to a coded high-band audio signal or wideband error audio signal for each layer of the received bitstream; and outputting decoded result for each layer as a high-band audio signal or wideband error audio signal restored of each layer.<br>26. A wideband audio system, comprising: an audio coding section having a high-band or wideband error audio coding unit which outputs a bitstream, the audio coding section comprising a harmonic detecting unit detecting harmonics of a high-band audio signal or wideband error audio signal of an input audio signal, a harmonic order determining unit determining an order of the detected harmonics, and a harmonic coding unit coding the harmonics based on the determined order of the detected harmonics; and an audio decoding section having high-band or wideband error audio decoding unit comprising a bit unpacking unit, which unpacks and outputs the bitstream output from coded high-band or wideband error audio coding unit, and a harmonic decoding unit which decodes the bitstream outputted in each layer from the bit packing unit in layer units.</p></layer>
<layer id = "layer444"><p><b>US20060217973A1:Adaptive voice mode extension for a voice activity detector</b><br>A method and system for diagnosing left ventricular hypertrophy (“LVH”) based on ECG data. An LVH system provides an indication of the likelihood that a patient has LVH based on an analysis of the patient's ECG data. The LVH system estimates the left ventricular mass index (“LVMI”) for the patient based on gender-specific formulae that use time-voltage data derived from the ECG data. After the LVH system calculates the estimated LVMI for the patient, it then classifies the estimated LVMI to indicate the likelihood that the patient has LVH. The LVH system may then select various statements of condition and rationale based on the patient's classification.<br><b>Independant Claims</b><br>1. A voice activity detection method for indicating an active voice mode and an inactive voice mode, said method comprising: receiving an input signal having a plurality of frames; determining whether each of said plurality of frames includes an active voice signal or an inactive voice signal; resetting an inactive voice counter and incrementing an active voice counter for each of said plurality of frames that is determined to include said active voice signal; resetting said active voice counter and incrementing said inactive voice counter for each of said plurality of frames that is determined to include said inactive voice signal; setting a voice flag if said active voice counter exceeds a first threshold value; resetting said voice flag if said inactive voice counter exceeds a second threshold value; detecting a first transition from said inactive voice signal to said active voice signal; indicating said active voice mode in response to said detecting said first transition; detecting a second transition from said active voice signal to said inactive voice signal following said first transition; continuing to indicate said active voice mode for a first period of time after said detecting said second transition if said voice flag is set and for a second period of time after said detecting said second transition if said voice flag is reset, wherein said first period of time is longer than said second period of time; and indicating said inactive voice mode after said continuing.<br>7. A voice activity detector (VAD) for indicating an active voice mode and an inactive voice mode, said VAD comprising: an input configured to receive an input signal having a plurality of frames; and an output configured to indicate said active voice mode or said inactive voice mode; wherein said VAD is configured to determine whether each of said plurality of frames includes an active voice signal or an inactive voice signal; wherein said VAD is configured to reset an inactive voice counter and increments an active voice counter for each of said plurality of frames that said VAD determines to include said active voice signal; wherein said VAD is configured to reset said active voice counter and increments said inactive voice counter for each of said plurality of frames that said VAD determines to include said inactive voice signal; wherein said VAD is configured to set a voice flag if said active voice counter exceeds a first threshold value; wherein said VAD is configured to reset said voice flag if said inactive voice counter exceeds a second threshold value; wherein said VAD is configured to detect a first transition from said inactive voice signal to said active voice signal; wherein said VAD is configured to indicate said active voice mode in response to said detecting said first transition; wherein said VAD is configured to detect a second transition from said active voice signal to said inactive voice signal following said first transition; wherein said VAD is configured to continue to indicate said active voice mode for a first period of time after said detecting said second transition if said voice flag is set and for a second period of time after said detecting said second transition if said voice flag is reset, wherein said first period of time is longer than said second period of time; and wherein said VAD is configured to indicate said inactive voice mode after said continuing.<br>13. A voice activity detection method for indicating an active voice mode and an inactive voice mode, said method comprising: receiving a first portion of an input signal; determining that said first portion of said input signal includes an active voice signal; indicating said active voice mode in response to said determining that said first portion of said input signal includes said active voice signal; receiving a second portion of said input signal immediately following said first portion of said input signal; determining that said second portion of said input signal includes an inactive voice signal; extending said indicating said active voice mode for a period of time after said determining that said second portion of said input signal includes said inactive voice signal, wherein said period of time varies based on one or more conditions; and indicating said inactive voice mode after expiration of said period of time.<br>20. A voice activity detector (VAD) for indicating an active voice mode and an inactive voice mode, said VAD comprising: an input configured to receive a first portion of an input signal; and an output configured to indicate said active voice mode or said inactive voice mode; wherein said VAD is configured to determine that said first portion of said input signal includes an active voice signal; wherein said VAD is configured to indicate said active voice mode in response to determining that said first portion of said input signal includes said active voice signal; wherein said input is configured to receive a second portion of said input signal immediately following said first portion of said input signal; wherein said VAD is configured to determine that said second portion of said input signal includes an inactive voice signal; wherein said VAD is configured to extend indicating said active voice mode for a period of time after said determining that said second portion of said input signal includes said inactive voice signal, wherein said period of time varies based on one or more conditions; and wherein said VAD is configured to indicate said inactive voice mode after expiration of said period of time.</p></layer>
<layer id = "layer445"><p><b>US8566086B2:System for adaptive enhancement of speech signals</b><br>In one embodiment, a method includes storing a cost assigned to a physical computing device in a storage device. The physical computing device is found in a physical infrastructure of a data center. The method determines an instantiation of a virtual machine in a virtual infrastructure. Information for a provisioning of the virtual machine with the physical computing device in the physical infrastructure of the data center is then received. The cost assigned to the physical computing device from the storage device is determined where the cost is used to determine a charge for the virtual machine based on usage of the physical computing device.<br><b>Independant Claims</b><br>14) A computer-implemented method of enhancing a frequency response of a speech signal comprising: performing, through the use of a processor, a frequency sub-band analysis on successive overlapping windowed buffers of the speech signal to generate a compressed dB spectrum of the received speech signal for each successive overlapped windowed buffer; generating, through the use of the processor, a background noise estimate across the frequency sub-bands; generating, through the use of the processor, a background noise spectral shape correction factor by subtracting the background noise estimate from a target background noise spectral shape; and adding, through the use of the processor, the background noise spectral shape correction factor to a spectrum corresponding to one of the successive overlapping windowed buffers.<br>8) The method of cleaning 1 where the target spectral shape corresponds to an ideal spectral shape of a speech signal input to a voice recognition system.<br>18) A computer-implemented method of enhancing a frequency response of a speech signal comprising: performing, through the use of a processor, a frequency sub-band analysis on successive overlapping windowed buffers of said speech signal to generate a compressed dB spectrum of the received speech signal for each successive overlapped windowed buffer; adapting a running average of a spectral shape of speech based on a current compressed dB spectrum corresponding to one of the successive overlapping windowed buffers; subtracting, through the use of the processor, the adapted running average of the spectral shape of speech from a target spectral shape, the difference between the target spectral shape and the adapted running average of the spectral shape of speech comprising a spectral shape correction factor; generating, through the use of the processor, a background noise estimate across the frequency sub-bands; calculating, through the use of the processor, a background noise spectral shape correction factor corresponding to a difference between the background noise estimate and a target background noise spectral shape; calculating, through the use of the processor, an overall spectral shape correction factor based on the speech spectral shape correction factor and the background noise spectral shape correction factor; and adding, through the use of the processor, the overall spectral shape correction factor to a spectrum corresponding to one of the successive overlapping windowed buffers, where the step of calculating, through the use of the processor, an overall spectral correction factor comprises inversely weighting the speech spectral shape correction factor and the background noise spectral shape correction factor according to a long term SNR estimate.<br>10) A system for enhancing the frequency response of a speech signal comprising: a microphone for capturing a speech signal; an A/D converter for converting the speech signal into a digital speech signal; and a processor adapted to continuously update a running average of a spectral shape of the speech signal received at the microphone, to subtract the continuously updated running average of the spectral shape of the speech signal from a target spectral shape, the difference between the target spectral shape and the adapted running average of the spectral shape of speech comprising a speech spectral shape correction factor, and to adjust the speech signal using the speech spectral shape correction factor.<br>1) A computer-implemented method of enhancing a frequency response of a received speech signal, the method comprising: performing, through the use of a processor, a frequency sub-band analysis on successive overlapping windowed buffers of the received speech signal to generate a compressed dB spectrum of the received speech signal for each successive overlapping windowed buffer; adapting a running average of a spectral shape of speech based on a current compressed dB spectrum corresponding to one of the successive overlapping windowed buffers; subtracting, through the use of the processor, the adapted running average of the spectral shape of speech from a target spectral shape, the difference between the target spectral shape and the adapted running average of the spectral shape of speech comprising a spectral shape correction factor; and adding, through the use of the processor, the spectral shape correction factor to the current compressed dB spectrum.</p></layer>
<layer id = "layer446"><p><b>US20060247922A1:System for improving speech quality and intelligibility</b><br>A structure which ensures against deterioration of an underlying silicide layer over which a refractory material layer is deposited by physical vapor deposition (PVD) or chemical vapor deposition (CVD) is realized by first providing a continuous polysilicon layer prior to the refractory material deposition. The continuous polysilicon layer, preferably no thicker than 50 Å, serves a sacrificial purpose and prevents damage to an underlying silicide layer by blocking interaction between any fluorine and the underlying silicide that is released when the refractory material is formed.<br><b>Independant Claims</b><br>1. A method of improving intelligibility of a speech signal comprising: identifying a frequency passband having a passband lower frequency limit and a passband upper frequency limit; defining a threshold frequency within the passband; receiving a speech signal having a frequency spectrum, a highest frequency component of which is greater than the passband upper frequency limit; compressing a portion of the speech signal spectrum in a first frequency range between the threshold frequency and the highest frequency component of the speech signal into a frequency range between the threshold frequency and the passband upper frequency limit.<br>11. A method of improving intelligibility of a speech signal comprising: receiving a passband limited signal having a lower frequency limit and an upper frequency limit; defining a threshold frequency within the passband of the received speech signal; defining an expanded signal upper frequency limit; performing a frequency expansion on a portion of the received speech signal such that frequency components of the received speech signal in the frequency range between the threshold frequency and the upper frequency limit of the passband are expanded to fill the frequency range between the threshold frequency and the expanded signal upper frequency limit; and audibly reproducing the expanded speech signal.<br>16. A system for improving the intelligibility of a transmitted speech signal, the system comprising: a high frequency encoder adapted to compress high frequency components of a speech signal which are outside a passband of a communication channel into a frequency range within the passband of the communication channel, while leaving lower frequency components of the speech signal substantially unchanged; and a transmitter for transmitting speech signals compressed by the high frequency encoder over the communication channel.<br>21. A high frequency encoder comprising: an A/D converter for converting an analog speech signal to a digital time-domain speech signal; a time-domain-to-frequency-domain transform for transforming the time-domain speech signal to a frequency-domain speech signal; a high frequency compressor for spectrally transposing high frequency components of the frequency-domain speech signal to lower frequencies to for a compressed frequency-domain speech signal; a frequency-domain-to-time-domain transform for transforming the compressed frequency domain speech signal into compressed time-domain speech signal; and a down sampler for sampling the compressed time-domain signal at a sample rate appropriate for the highest frequency of the compressed time-domain speech signal.<br>24. A method of improving intelligibility of a speech signal comprising: identifying a frequency passband; receiving a speech signal having a frequency spectrum, a highest frequency component of which is greater than an upper frequency limit of the passband; applying non-linear frequency compression throughout the frequency spectrum of the speech signal by applying a frequency compression function in which minimal compression is applied to a lower frequency range of the speech signal spectrum and significantly greater compression is applied to an upper frequency range of the speech signal spectrum such that a compressed speech signal spectrum is within the passband.</p></layer>
<layer id = "layer447"><p><b>US8521521B2:System for suppressing passing tire hiss</b><br>The present invention provides a heterocyclic compound of formula (I), a pharmaceutically acceptable salt thereof, a prodrug thereof or a hydrate thereof, wherein A, A′ B, D, R<sup>1</sup>, R<sup>2 </sup>and R<sup>3 </sup>are as defined herein, a pharmaceutical composition comprising a compound of formula (I) as an active ingredient, methods of production, and methods of use thereof. Particularly, the present invention provides a compound of formula (I) useful for treating or preventing a disease, condition or disorder associated with protein kinases, preferably Janus Kinase family.<br><b>Independant Claims</b><br>18) A non-transitory computer-readable medium with instructions stored thereon, where the instructions are executable by a processor to cause the processor to perform the steps of: comparing an input signal to a passing tire hiss model; identifying whether a noise in the input signal is passing tire hiss based on the comparison between the input signal and the passing tire hiss model; and attenuating at least a portion of the identified passing tire hiss from the input signal to generate an output signal with reduced passing tire hiss noise.<br>10) A method of attenuating passing tire hiss noise, comprising: receiving an input signal; identifying, by a noise detector that comprises a processor configured to run logic to detect passing tire hiss, whether a noise in the input signal is passing tire hiss based on a comparison between the input signal and a passing tire hiss model; and attenuating at least a portion of the identified passing tire hiss from the input signal to generate an output signal with reduced passing tire hiss noise.<br>1) A passing tire hiss noise attenuation system, comprising: a noise detector configured to compare an input signal to a passing tire hiss model and identify whether a noise in the input signal is passing tire hiss; and a noise attenuator coupled with the noise detector and configured to attenuate at least a portion of the identified passing tire hiss from the input signal to generate an output signal with reduced passing tire hiss noise.</p></layer>
<layer id = "layer448"><p><b>US20060100868A1:Minimization of transient noises in a voice signal</b><br>A filter <b>42 </b>comprises a cylindrical filter body <b>45 </b>which is disposed in a suction passage <b>41</b>, a lid portion <b>47 </b>which closes an opening <b>45</b><i>b </i>positioned in a downstream side of the suction passage <b>41 </b>in the filter body <b>45</b>, communication holes <b>48 </b>which penetrate through the filter body <b>45 </b>and communicate the inside of the filter body <b>45 </b>with the outside thereof, and filter elements <b>49, 50 </b>which are disposed downstream of the communication holes <b>48 </b>and the lid portion <b>47</b>, in the filter body <b>45</b>; wherein a gap between an outer circumferential surface <b>45</b><i>c </i>of the filter body <b>45 </b>and an inner circumferential surface <b>45</b><i>a </i>of the suction passage <b>41 </b>is closed upstream of the communication holes <b>48. </b><br><b>Independant Claims</b><br>1. A system for suppressing transient road noises from a signal comprising a transient road noise detector adapted to detect the presence of transient road noise in the signal; and a transient road noise attenuator for substantially removing road transient noise detected in the received signal.<br>10. A transient road noise detector for detecting the presence of transient road noise in a signal, the transient road noise detector comprising: an analog to digital converter for converting a received signal into a digital signal; a windowing function generator for dividing the signal into a plurality of individual analysis windows; a transform module for transforming the individual analysis windows from time domain signals to frequency domain short term spectra; and a modeler for at least one of generating and storing model attributes of transient road noise, and comparing attributes of the short term spectra of the transformed analysis windows to the model attributes to determine whether a transient road noise is present in the received signal.<br>21. A method of removing transient road noises from a signal comprising: modeling characteristics of transient road noises; analyzing the signal to determine whether characteristics of the signal correspond to the modeled characteristics of transient road noises; and substantially removing from the signal the characteristics of the received signal that correspond to the modeled characteristics of transient road noises.</p></layer>
<layer id = "layer449"><p><b>US8520861B2:Signal processing system for tonal noise robustness</b><br>A real-time portable and rapid detection assay to identify the presence of biologically active toxins such as <i>botulinum </i>toxins. The proteolytic activity of BoNT/A is measured using a peptide cleavage assay, where a fluorescent substrate is cleaved by BoNT/A, resulting in increased fluorescence. This fluorescence can be monitored in real-time using a fluorescence detection instrument, such as a real-time PCR system that has been modified to implement a detection algorithm specific to the identification of the target toxin.<br><b>Independant Claims</b><br>5) A signal processing system comprising: a memory comprising: a smoothing program which smoothes an input signal in a frequency-based direction by applying an attenuation to a tonal noise peak in the input signal to obtain a smoothed signal, where the attenuation comprises a windowed average of the input signal, where the smoothing program compares signal components of the input signal to a magnitude threshold to identify an outlying signal component that exceeds the magnitude threshold, and where the smoothing program excludes the outlying signal component in determining the windowed average; a background noise estimate; and a blending program which combines the smoothed signal with the input signal based on the background noise estimate to produce an output signal, where the blending program comprises a first blending rule configured to output the input signal as the output signal in response to a determination that the background noise estimate satisfies a first predetermined condition; and where the blending program comprises a second blending rule configured to output the smoothed signal as the output signal in response to a determination that the background noise estimate satisfies a second predetermined condition different than the first predetermined condition; and a processor coupled to the memory which executes the smoothing program and blending program.<br>18) A product comprising: a non-transitory machine readable medium a machine readable medium; and instructions stored on the medium that cause a processing system to: obtain a background noise estimate; smooth an input signal in a frequency-based direction to attenuate tonal noise peaks in the input signal to obtain a smoothed signal, where the instructions which attenuate tonal noise peaks comprise instructions that cause the processing system to: determine a first windowed average of the input signal to obtain a first averaged signal; determine a second windowed average of the first averaged signal by selecting a window of signal components starting at an index point in the first averaged signal; compare at least one of the signal components to the first windowed average of the input signal at the index point to identify an outlying signal component that exceeds the first windowed average of the input signal at the index point; and exclude the outlying signal component in determining the second windowed average; and apply blending rules to combine the smoothed signal with the input signal, based on the background noise estimate, to form an output signal, where the blending rules comprise a first blending rule configured to output the input signal as the output signal in response to a determination that the background noise estimate satisfies a first predetermined condition; and where the blending rules comprise a second blending rule configured to output the smoothed signal as the output signal in response to a determination that the background noise estimate satisfies a second predetermined condition different than the first predetermined condition.<br>1) A signal pre-processing method comprising: obtaining an input signal comprising a tonal noise peak; smoothing the input signal in a frequency-based direction to attenuate the tonal noise peak in the input signal and obtain a smoothed signal, where smoothing the input signal comprises: determining a first windowed average of the input signal to obtain a first averaged signal; determining a second windowed average of the first averaged signal by selecting a window of signal components starting at an index point in the first averaged signal; comparing at least one of the signal components to the first windowed average of the input signal at the index point to identify an outlying signal component that exceeds the first windowed average of the input signal at the index point; and excluding the outlying signal component in determining the second windowed average; obtaining a background noise estimate; and blending the smoothed signal with the input signal based on the background noise estimate to obtain an output signal, where blending comprises: outputting the input signal as the output signal in response to a determination that the background noise estimate satisfies a first predetermined condition; and outputting the smoothed signal as the output signal in response to a determination that the background noise estimate satisfies a second predetermined condition different than the first predetermined condition.<br>12) A signal pre-processing system comprising: a memory comprising: an input signal representation comprising tonal noise peaks and desired signal peaks; a background noise estimate; a signal-to-noise ratio (SNR) estimate based on the input signal representation and the background noise estimate; a multi-pass windowing program operable to successively apply averaging windows to the input signal representation to smooth the input signal representation in a frequency-based direction to attenuate the tonal noise peaks and the desired signal peaks and obtain a smoothed signal representation; an upper SNR threshold; a lower SNR threshold; a blending program for generating an output signal component from an input signal component of the input signal representation and a smoothed signal component of the smoothed signal representation, the blending program implementing at least the following blending rules: set the output signal component to the input signal component, when the SNR estimate is greater than the upper SNR threshold; set the output signal component to the smoothed signal component, when the SNR estimate is less than the lower SNR threshold; and set the output signal component by applying a blending function of the input signal component and the smoothed signal component, when the SNR estimate falls between the upper SNR threshold and the lower SNR threshold; and a processor coupled to the memory which executes the multi-pass windowing program and the blending program.</p></layer>
<layer id = "layer450"><p><b>US20060265210A1:Constructing broad-band acoustic signals from lower-band acoustic signals</b><br><b>Independant Claims</b><br>1. A method for constructing a broad-band acoustic signal from a lower-band acoustic signal, comprising: generating envelope spectra and harmonic spectra from an input broad-band training acoustic signal; training corresponding non-negative envelope bases for the envelope spectra and non-negative harmonic bases for the harmonic spectra using convolutive non-negative matrix factorization; generating higher-band frequencies for an input lower-band acoustic signal according to the non-negative envelope bases and the non-negative harmonic bases; and combining the input lower-band acoustic signal with the generated higher-band frequencies to produce an output broad-band acoustic signal.<br>26. The methods of 24 or 25, further comprising: combining the reconstructed phase and magnitude of the upper-frequency magnitude spectrum; determining an inverse Fourier transform to derive the upper frequency signal; and combining the upper frequency signal with the input lower-band signal to produce an output broad-band acoustic signal.</p></layer>
<layer id = "layer451"><p><b>US8364477B2:Method and apparatus for increasing speech intelligibility in noisy environments</b><br>Respective lines forming a positive-polarity signal pixel circuit part, such as a Vdd line <b>102</b>, a Cs<b>1</b>-connecting line <b>104</b> and a line <b>106</b> for a data line Di+, and respective lines forming a negative-polarity signal pixel circuit part, such as a Vdd line <b>103</b>, a Cs<b>2</b>-connecting line <b>105</b> and a line <b>107</b> for a data line Di−, are arranged symmetrically to each other with respect to a pixel center line II-II′, respectively. Since the Vdd line <b>102</b> and the Vdd line <b>103</b> are positioned at right and left ends in one pixel, they serve as guard patterns to restrict crosstalk originating in either a Cs<b>1</b>-connecting line or a Cs<b>2</b>-connecting line of adjacent left and right pixels. The line <b>106</b> for the data line Di+ and the line <b>107</b> for the data line Di− are arranged in the vicinity of a central portion of the pixel.<br><b>Independant Claims</b><br>16) An audio apparatus adapted for outputting speech in a noisy environment, the audio apparatus comprising: a speaker for outputting the speech; a microphone for receiving ambient noise from the noisy environment; a source of audio to be output into the noisy environment; a processor coupled to the source of audio, the speaker, and the microphone, wherein the processor is programmed to: determine if one or more voice formants are present in each ith audio segment of a plurality of audio segments; if one or more formants are determined to be present in the ith audio segment: select a perceptual frequency scale band (L) including at least one of the one or more formants from a plurality of perceptual frequency scale bands of a perceptual scale ambient noise spectrum of the noisy environment; compare, to a threshold, a signal-to-noise ratio of the perceptual frequency scale band, and if the signal-to-noise ratio is less than the threshold, increase a formant enhancement gain for the perceptual frequency scale band; compute a summed signal-to-noise ratio across at least a portion of the perceptual scale ambient noise spectrum wherein a plurality of speech magnitudes are used as signal magnitudes; scale a set of overall gains that include at least the formant enhancement gains as a function of the summed signal-to-noise ratio; smooth the set of overall gains; filter the ith audio segment with the set of overall gains; and output the ith audio segment into the noisy environment.<br>1) A method of improving intelligibility of speech that is included in audio that is emitted into a noisy environment, the method comprising: determining if one or more voice formants are present in each ith audio segment of a plurality of audio segments; if one or more formants are determined to be present in the ith audio segment: selecting a perceptual frequency scale band (L) including at least one of the one or more formants from a plurality of perceptual frequency scale bands of a perceptual scale ambient noise spectrum of the noisy environment; comparing, to a threshold, a signal-to-noise ratio of the perceptual frequency scale band, and if the signal-to-noise ratio is less than the threshold, increasing a formant enhancement gain for the perceptual frequency scale band; computing a summed signal-to-noise ratio across at least a portion of the perceptual scale ambient noise spectrum wherein a plurality of speech magnitudes in each of the plurality of perceptual frequency scale bands are used as signal magnitudes; scaling a set of overall gains that include at least the formant enhancement gains as a function of the summed signal-to-noise ratio; smoothing the set of overall gains; filtering the ith audio segment with the set of overall gains; and outputting the ith audio segment into the noisy environment.</p></layer>
<layer id = "layer452"><p><b>US20060271355A1:SUB-BAND VOICE CODEC WITH MULTI-STAGE CODEBOOKS AND REDUNDANT CODING</b><br>A VVA mode LCD has a liquid crystal (LC) layer of a negative dielectric anisotropy between lower and upper substrates. A pixel electrode is formed on the lower substrate. A color resin layer is formed on the upper substrate and has a V-shaped valley and jagged valleys, which are perpendicular to and shallower in depth than the V-shaped valley. A counter electrode is formed on the color resin layer and has a V-shaped valley and jagged valleys perpendicular to the V-shaped valleys. A first vertical orientation layer is formed between the pixel electrode and the LC layer. A second vertical orientation layer is formed between the counter electrode and the LC layer. First and second polarizers are attached to the outer and inner faces of the upper and lower substrates, respectively. The polarization axis of each intersects. The jagged valleys are provided to the V-shaped valleys via halftone exposure.<br><b>Independant Claims</b><br>1. A method comprising: at an audio processing tool, processing a bit stream for an audio signal, wherein the bit stream comprises: main coded information encoded according to a coding technique for a current frame that references a segment of a previous frame to be used in decoding the current frame; and redundant coded information for decoding the current frame according to the coding technique, the redundant coded information comprising signal history information associated with the referenced segment of the previous frame and selected in order to support decoding of the current frame according to the coding technique with reference to the signal history information; and outputting a result.<br>8. A method comprising: at an audio processing tool, processing a bit stream for an audio signal, wherein the bit stream comprises: main coded information for a current coded unit that references a segment of a previous coded unit to be used in decoding the current coded unit; and redundant coded information for decoding the current coded unit, the redundant coded information comprising one or more parameters for one or more extra codebook stages to be used in decoding the current coded unit only if the previous coded unit is not available; and outputting a result.<br>15. A method comprising: at an audio processing tool, processing a bit stream for an audio signal comprising a plurality of coded audio units, wherein each coded unit of the plurality of coded units comprises a field indicating: whether the coded unit comprises main encoded information representing a segment of the audio signal; and whether the coded unit comprises redundant coded information representing the segment of the audio signal and which can be used in decoding corresponding main encoded information for the segment.</p></layer>
<layer id = "layer453"><p><b>US8838441B2:Time warped modified transform coding of audio signals</b><br>In a recessed fluorescent luminaire an improved combination hinge and latch mechanism which includes a plurality of inverted L-shaped latch members with raised curved cam portions on the upper ends thereof rotatably secured to the frame of the lighttransmitting luminaire door or closure. The luminaire housing includes laterally extending flanges on the side walls adjacent the bottom or open end having apertures therethrough at locations complementary to the locations of the latch members on the door. Curved leaf springs overlie the apertures and are constructed and arranged to cooperate with the curved cam portion of the latch member to releasably retain the latch members in a latched position. When the latches on one side of the luminaire are released the latches on the opposite side serve as hinges through their rotatable connection to the door frame.<br/><br><b>Independant Claims</b><br>1) Audio encoder for receiving an audio input signal and for generating a bit stream to be transmitted to a decoder, comprising: a processor and a non-transitory storage medium having instructions thereon, which when executed by the processor, cause the audio encoder to perform: estimating a warp parameter sequence; receiving the warp parameter sequence and for deriving a time warped spectral representation of the audio input signal; receiving the audio input signal; encoding the warp parameter sequence to reduce its size during transmission within the bit stream; receiving the time-warped spectral representation for quantization to obtain an encoded time-warped spectral representation of the audio input signal, wherein the encoder is controlled by the perceptual model calculator; and receiving and multiplexing the encoded warp parameter sequence and the encoded time-warped spectral representation of the audio input signal.<br>13) Method of audio encoding, comprising: receiving an audio input signal; estimating a warp parameter sequence; deriving a time warped spectral representation of the audio input signal using the warp parameter sequence; encoding the warp parameter sequence to reduce its size during transmission within the bit stream; quantizing the time-warped spectral representation to obtain an encoded time-warped spectral representation of the audio input signal, wherein quantizing is controlled by a perceptual model calculator; and multiplexing the encoded warp parameter sequence and the encoded time-warped spectral representation of the audio input signal.<br>14) Method of time-warped transform decoding for deriving a reconstructed audio signal, comprising: de-multiplexing a bit stream into an encoded warp parameter sequence and an encoded representation of the time-warped spectral representation; decoding the encoded warp parameter sequence to derive a reconstruction of the warp parameter sequence; decoding the encoded representation of the time-warped spectral representation to derive a time-warped spectral representation of an audio signal; and deriving the reconstructed audio output signal using a time-warped overlapped transform coding using the reconstruction of the warp parameter sequence and the time-warped spectral representation of the audio signal.<br>8) Time-warped transform decoder for deriving a reconstructed audio signal, comprising: a processor and a non-transitory storage medium having instructions thereon, which when executed by the processor, cause the audio encoder to perform: de-multiplexing a bit stream into an encoded warp parameter sequence and an encoded representation of the time-warped spectral representation; decoding the encoded warp parameter sequence to derive a reconstruction of the warp parameter sequence; decoding the encoded representation of the time-warped spectral representation to derive a time-warped spectral representation of an audio signal; and receiving the reconstruction of the warp parameter sequence and the time-warped spectral representation of the audio signal and for deriving the reconstructed audio output signal using a time-warped overlapped transform coding.</p></layer>
<layer id = "layer454"><p><b>US8554564B2:Speech end-pointer</b><br>Described is a remote control method of a multi-mode remote controller, comprising the following steps of: determining a current control mode, the remote controller comprising various control modes; obtaining a touch control signal of a user on a touch screen; and analyzing the touch control signal, generating a remote control instruction corresponding to the touch control signal under the current control mode, and sending the instruction to a user terminal, so that the user terminal operates currently displayed content. It is further provided a multi-mode remote controller, a user terminal and a system. Seamless automatic switching among multiple control modes in the remote controller with a touch screen can be realized, so as to meet various interaction requirements of different kinds of users.<br><b>Independant Claims</b><br>1) A speech end-pointer system, comprising: a computer processor; a voice triggering module configured to identify a portion of an audio stream comprising a speech segment; and a rule module in communication with the voice triggering module, the rule module comprising a plurality of rules used by the computer processor to analyze the audio stream and detect a beginning and an end of the speech segment, where the plurality of rules comprises one or more rules based on an energy counter; where the beginning of the speech segment and the end of the speech segment represent boundaries between speech and non-speech portions of the audio stream; and where the computer processor is configured to determine whether a frame of the audio stream has energy above a background noise level and increment the energy counter by a length of the frame in response to a determination that the frame has energy above the background noise level.<br>12) A speech end-pointing method, comprising: receiving an audio stream; analyzing energy and noise characteristics of a frame of the audio stream by a computer processor to determine whether the frame has energy above a background noise level; incrementing an energy counter by a length of the frame in response to a determination by the computer processor that the frame has energy above the background noise level; incrementing a lack of energy counter by the length of the frame in response to a determination by the computer processor that the frame does not have energy above the background noise level; and applying a plurality of rules by the computer processor to detect a beginning and an end of a speech segment of the audio stream based on the energy counter and the lack of energy counter.<br>20) A non-transitory computer-readable medium with instructions stored thereon, where the instructions are executable by a computer processor to cause the computer processor to perform the steps of: receiving an audio stream; analyzing energy and noise characteristics of a frame of the audio stream to determine whether the frame has energy above a background noise level; incrementing an energy counter by a length of the frame in response to a determination that the frame has energy above the background noise level; incrementing a lack of energy counter by the length of the frame in response to a determination that the frame does not have energy above the background noise level; and applying a plurality of rules to detect a beginning and an end of a speech segment of the audio stream based on the energy counter and the lack of energy counter.</p></layer>
<layer id = "layer455"><p><b>US8315863B2:Post filter, decoder, and post filtering method</b><br>An object of the present invention is to provide a total reflection measuring apparatus which, while visually observing a specific minute area of a measurement object, is capable of efficiently obtaining optical data on the basis of the total reflection measurement. A microscopic total reflection measuring apparatus of the present invention comprises a Cassegrain mirror <b>12</b> having a Cassegrain primary mirror <b>16</b> and a Cassegrain secondary mirror <b>18</b>, which condenses an incident light beam <b>30</b> on a measurement object <b>20</b> by making an incident light beam successively reflected by the secondary mirror <b>18</b> and the primary mirror <b>16</b>, and which obtains a reflected light beam <b>32</b> from the measurement object <b>20</b> by making the reflected light beam <b>32</b> successively reflected by the primary mirror <b>16</b> and the secondary mirror <b>18</b>. And, a total reflection prism <b>14</b> is arranged below the Cassegrain secondary mirror <b>18</b>. And the incident light beam includes a visible light beam for visual observation and a measurement light beam for acquisition of analysis information, and present invention comprises a visible light filter which separates at least one of the incident light beam to the total reflection prism and the reflected light beam from the total reflection prism <b>14</b> into a total reflection area B and a normal reflection area A, and which removes, from the one of the incident light beam and the reflected light beam, the visible light beam in the total reflection area B.<br><b>Independant Claims</b><br>1) A post filter that reduces quantization noise in a decoded signal of a signal subjected to layered coding according to a coding scheme providing a plurality of layers, the post filter comprising: a band determiner that selects among frequency bands of the decoded signal a first frequency band corresponding to a layer which is not used for coding among the plurality of layers and a second frequency band different from the first frequency band; a spectrum corrector that corrects, for defining a corrected spectrum, a first spectrum corresponding to the second frequency band such that changes of the first spectrum in a frequency domain are reduced more than changes of a second spectrum corresponding to the first frequency band; and a filter, being one of a circuit and a processor, that filters the decoded signal using a coefficient derived from the corrected spectrum.<br>14) A decoding apparatus that reduces quantization noise in a decoded signal of a signal subjected to layered coding according to a coding scheme providing a plurality of layers, the decoding apparatus comprising: a band determiner that selects among frequency bands of the decoded signal a first frequency band corresponding to a layer which is not used for coding among the plurality of layers and a second frequency band different from the first frequency band; a spectrum corrector that corrects, for defining a corrected spectrum, a first spectrum corresponding to the second frequency band such that changes of the first spectrum in a frequency domain are reduced more than changes of a second spectrum corresponding to the first frequency band; and a filter, being one of a circuit and a processor, that filters the decoded signal using a coefficient derived from the corrected spectrum.<br>15) A post filtering method of reducing quantization noise in a decoded signal of a signal subjected to layered coding according to a coding scheme providing a plurality of layers, the post filtering method comprising: selecting, among frequency bands of the decoded signal, a first frequency band corresponding to a layer which is not used for coding among the plurality of layers and a second frequency band different from the first frequency band; correcting, for defining a corrected spectrum, a first spectrum corresponding to the second frequency band such that changes of the first spectrum in a frequency domain are reduced more than changes of a second spectrum corresponding to the first frequency band; and filtering, with one of a processor and a circuit, the decoded signal using a coefficient derived from the corrected spectrum.</p></layer>
<layer id = "layer456"><p><b>US20090253418A1:System for conference call and corresponding devices, method and program products</b><br>A variable drive apparatus is disclosed. The variable drive apparatus includes a hub about an axis and a plurality of sectors that are movable in a radial direction relative to the axis. The position of the sectors relative to the axis can, among other things, change a drive ratio associated with the apparatus. A variable drive system is also disclosed.<br><b>Independant Claims</b><br>1-57. (canceled)<br>2) 1-57. (canceled)<br>3) 1-57. (canceled)<br>4) 1-57. (canceled)<br>1-57. (canceled)<br>6) 1-57. (canceled)<br>1-57. (canceled)<br>8) 1-57. (canceled)<br>9) 1-57. (canceled)<br>10) 1-57. (canceled)<br>11) 1-57. (canceled)<br>12) 1-57. (canceled)<br>13) 1-57. (canceled)<br>14) 1-57. (canceled)<br>15) 1-57. (canceled)<br>16) 1-57. (canceled)<br>17) 1-57. (canceled)<br>18) 1-57. (canceled)<br>19) 1-57. (canceled)<br>20) 1-57. (canceled)<br>21) 1-57. (canceled)<br>22) 1-57. (canceled)<br>23) 1-57. (canceled)<br>24) 1-57. (canceled)<br>25) 1-57. (canceled)<br>26) 1-57. (canceled)<br>27) 1-57. (canceled)<br>28) 1-57. (canceled)<br>29) 1-57. (canceled)<br>30) 1-57. (canceled)<br>31) 1-57. (canceled)<br>32) 1-57. (canceled)<br>33) 1-57. (canceled)<br>34) 1-57. (canceled)<br>35) 1-57. (canceled)<br>36) 1-57. (canceled)<br>37) 1-57. (canceled)<br>38) 1-57. (canceled)<br>39) 1-57. (canceled)<br>40) 1-57. (canceled)<br>41) 1-57. (canceled)<br>42) 1-57. (canceled)<br>43) 1-57. (canceled)<br>44) 1-57. (canceled)<br>45) 1-57. (canceled)<br>46) 1-57. (canceled)<br>47) 1-57. (canceled)<br>48) 1-57. (canceled)<br>49) 1-57. (canceled)<br>50) 1-57. (canceled)<br>51) 1-57. (canceled)<br>52) 1-57. (canceled)<br>53) 1-57. (canceled)<br>54) 1-57. (canceled)<br>55) 1-57. (canceled)<br>56) 1-57. (canceled)<br>1-57. (canceled)<br>58. System for a conference call, which includes at least one portable audio device arranged in an common acoustic space which device is equipped with audio components for inputting and outputting an audible sound and at least one communication module, at least one base station device to which at least the said one portable audio device is interconnected and which base station device is connected to the communication network in order to perform the conference call from the said common acoustic space, characterized in that at least part of the portable audio devices are personal mobile devices which audio components are arranged to pick the audible sound from the said common acoustic space.<br>59. Portable audio device for a conference call, which is equipped with audio components for inputting and outputting an audible sound from a common acoustic space and at least one communication module in order to be interconnected with at least one base station device that is connected to the communication network in order to perform the conference call from the common acoustic space, characterized in that the portable audio device is a personal mobile device which audio components are arranged to pick the audible sound from the said common acoustic space.<br>64. Base station device for conference call system that is arranged at least partly to a common acoustic space and which base station device is equipped with possible audio components for inputting and outputting an audible sound and to which at least part of the portable audio devices are interconnected as clients and which base station device is connected to the communication network in order to perform the conference call from the said common acoustic space, characterized in that the said base station device is a personal mobile device which audio components are arranged to pick the audible sound from the said common acoustic space.<br>72. Method for performing a conference call, in which at least one portable audio device arranged in an common acoustic space which device is equipped with audio components for inputting and outputting an audible sound and at least one communication module, at least one base station device to which at least the said one portable audio device is interconnected and which base station device is connected to the communication network in order to perform the conference call from the said common acoustic space, characterized in that at least part of the portable audio devices are personal mobile devices which audio components are arranged to pick the audible sound from the said common acoustic space.<br>81. Program product for performing a conference call client device functionality that is intended to be interconnect to a base station device, which program product include a storing means and a program code executable by processor and written in the storing means, characterized in that the program code is arranged in connection with a personal mobile device that is equipped with audio components including a microphone and a loudspeaker and which program code includes first code means configured to pick an audible sound from an common acoustic space by using of the microphone of the said personal mobile device and second code means configured to process the microphone signal produced from the audible sound by the speech enhancement functions of the personal audio device.<br>82. Program product for performing a conference call base station functionality for at least one portable audio device, which program product include a storing means and a program code executable by processor and written in the storing means, characterized in that at least part of the program code is arranged in connection with a personal mobile device that is equipped with a possible loudspeaker and a microphone and which program code includes first code means configured to pick an audible sound from an common acoustic space by using of the microphone of the said base station device and second code means configured to process the loudspeaker signals intended to be outputted by the loudspeakers of the portable audio devices by the speech enhancement functions of the base station device.</p></layer>
<layer id = "layer457"><p><b>US8150682B2:Adaptive filter pitch extraction</b><br>An apparatus for sequential deposition of an intermixed thin film layer and a sublimated source material on a photovoltaic (PV) module substrate is provided, along with associated processes. The process can include introducing a substrate into a deposition chamber, wherein a window layer (e.g., a cadmium sulfide layer) is on a surface of the substrate. A sulfur-containing gas can be supplied to the deposition chamber. In addition, a source vapor can be supplied to the deposition chamber, wherein the source material comprises cadmium telluride. The sulfur-containing gas and the source vapor can be present within the deposition chamber to form an intermixed layer on the window layer. In one particular embodiment, for example, the intermixed layer generally can have an increasing tellurium concentration and decreasing sulfur concentration extending away from the window layer.<br><b>Independant Claims</b><br>1) A system for estimating pitch, comprising: a discrete input configured to receive a speech signal; a delay unit coupled with the discrete input and configured to delay the speech signal; an adaptive filter coupled with the delay unit and configured to process the speech signal output from the delay unit; and a pitch estimator comprising a processor configured to analyze adaptive filter coefficients that define a transfer function of the adaptive filter and estimate a pitch of the speech signal based on the adaptive filter coefficients.<br>11) A system for estimating pitch, comprising: an adaptive filter that comprises adaptive filter coefficients and an input configured to receive a speech signal, where the adaptive filter coefficients define a transfer function of the adaptive filter; and a pitch estimator comprising a processor configured to analyze the adaptive filter coefficients and estimate a pitch of the speech signal based on the adaptive filter coefficients.<br>15) A method for estimating pitch, the method comprising: receiving a speech signal; delaying the speech signal; passing the delayed speech signal through an adaptive filter; obtaining adaptive filter coefficients that define a transfer function of the adaptive filter; and analyzing the adaptive filter coefficients by a processor to estimate a pitch of the speech signal based on the adaptive filter coefficients.</p></layer>
<layer id = "layer458"><p><b>US8219389B2:System for improving speech intelligibility through high frequency compression</b><br>The present invention provides arylpiperazine derivatives having Formula I which can be advantageously used for treating schizophrenia and related psychoses such as acute manic, bipolar disorder, autistic disorder and depression. <chemistry id="CHEM-US-00001" num="00001"><img id="EMI-C00001" he="27.60mm" wi="72.39mm" file="US08431570-20130430-C00001.TIF" alt="embedded image" img-content="chem" img-format="tif"/></chemistry><br><b>Independant Claims</b><br>1) A system, comprising: a computer processor; a frequency transformer configured to convert a speech signal into a spectrum of frequencies; and a spectral compressor regulated by the computer processor and coupled with the frequency transformer, where the spectral compressor is configured to define a lower cutoff frequency within a frequency passband having a passband upper frequency limit, where the spectral compressor is configured to compress a pre-selected high frequency band of the speech signal between the lower cutoff frequency and a frequency component above the passband upper frequency limit, and where the spectral compressor is configured to map the compressed high frequency band to a lower frequency range below the passband upper frequency limit in response to a determination that a signal-to-noise ratio of the speech signal in the lower frequency range before compression is less than a signal-to-noise ratio of the speech signal in the lower frequency range after compression.<br>11) A method, comprising: identifying a frequency passband having a passband upper frequency limit; defining a lower cutoff frequency within the frequency passband; receiving a speech signal having a frequency spectrum, a highest frequency component of which is greater than the passband upper frequency limit; calculating a signal-to-noise ratio of the speech signal in a first frequency range between the lower cutoff frequency and the passband upper frequency limit; and compressing a portion of the speech signal spectrum in a second frequency range between the lower cutoff frequency and the highest frequency component of the speech signal into the first frequency range between the lower cutoff frequency and the passband upper frequency limit in response to a determination that the signal-to-noise ratio of the speech signal in the first frequency range before compression is less than a signal-to-noise ratio of the speech signal in the first frequency range after compression.<br>17) A non-transitory computer-readable medium with instructions stored thereon, where the instructions are executable by a processor to cause the processor to perform the steps of: identifying a frequency passband having a passband upper frequency limit; defining a lower cutoff frequency within the frequency passband; receiving a speech signal having a frequency spectrum, a highest frequency component of which is greater than the passband upper frequency limit; calculating a signal-to-noise ratio of the speech signal in a first frequency range between the lower cutoff frequency and the passband upper frequency limit; and compressing a portion of the speech signal spectrum in a second frequency range between the lower cutoff frequency and the highest frequency component of the speech signal into the first frequency range between the lower cutoff frequency and the passband upper frequency limit in response to a determination that the signal-to-noise ratio of the speech signal in the first frequency range before compression is less than a signal-to-noise ratio of the speech signal in the first frequency range after compression.</p></layer>
<layer id = "layer459"><p><b>US20060136199A1:Advanced periodic signal enhancement</b><br>A waste disposal and recovery system for disposal of expanded polystyrene foam and recovery of a usable resin. The system includes a first tank and a second tank in flow communication. Within the second tank may be a plurality of settlement compartments with a filtration system. An organic solvent is used to dissolve the expanded polystyrene foam which forms a waste solution. The waste solution is directed to the second tank where it is separated into resin and the organic solvent. The solvent may be recycled for use in dissolving more expanded polystyrene foam while the resin may be removed for storage, shipment or sale.<br><b>Independant Claims</b><br>1. An enhancement speech system that improves the perceptual quality of a processed speech segment, comprising: a discrete input; a delay unit that digitally delays a signal received through the discrete input; a spectral modifier coupled to the delay unit programmed to substantially flatten the spectral character of a background noise; an adaptive filter coupled to the spectral modifier that adapts filter characteristics to match a response to the signal received through the discrete input before the signal is delayed; and a programmable filter coupled to the delay unit having a transfer function functionally related to a transfer function of the adaptive filter.<br>14. An enhancement speech system that improves the perceptual quality of a processed speech segment, comprising: a discrete input; a delay unit that digitally delays a discrete signal received through the discrete input; a spectral modifier coupled to the delay unit programmed to substantially flatten a portion of the spectral character of a detected background noise; an adaptive filter coupled to the spectral modifier that adapts coefficients to match a response to the signal received through the discrete input before the signal is delayed; and a programmable filter coupled to the delay unit having a transfer function functionally related to a transfer function of the adaptive filter.<br>19. A method of enhancing the perceptual quality of a processed speech segment, comprising: delaying an input signal; modifying the spectral characteristic of the input signal by substantially flattening the spectral characteristics of a background noise; adapting the coefficients of a filter to match the response of the input signal; adapting the coefficients of a programmable filter so that the transfer function of the programmable filter is functionally related to the transfer function of the filter.</p></layer>
<layer id = "layer460"><p><b>US8175869B2:Method, apparatus, and medium for classifying speech signal and method, apparatus, and medium for encoding speech signal using the same</b><br>A pouch formed from sheet material that is commonly referred to as a drape. The pouch is formed by folding the drape, which has a tacky surface, on itself and placing fasteners through holes punched in the drape which ensures the pouch maintains is maintained. The pouch catches medical instruments that may slide off of the drape, preventing the medical instruments from failing to the floor and becoming contaminated.<br><b>Independant Claims</b><br>1) A method of classifying a speech signal comprising: calculating from an input signal in block units classification parameters including an energy parameter of the input signal, a cross-correlation parameter between a specific block of a present frame and the input signal, and an integrated cross-correlation parameter obtained by accumulating the cross-correlation parameter until a sign of a slope of the integrated cross-correlation parameter changes; calculating a plurality of classification criteria from the classification parameters; and classifying a level of the input signal using the plurality of classification criteria, wherein the method is performed using at least one processor.<br>12) An apparatus for classifying a speech signal comprising: a parameter calculating unit which calculates classification parameters from an input signal in block units, the classification parameters including an energy parameter of the input signal, a cross-correlation parameter between a specific block of a present frame and the input signal, and an integrated cross-correlation parameter obtained by accumulating the cross-correlation parameter until a sign of a slope of the integrated cross-correlation parameter changes; a classification criteria calculating unit which calculates a plurality of classification criteria from the classification parameters; and a signal level classifying unit which classifies a level of the input signal using the plurality of classification criteria.<br>23) A method for encoding a speech signal comprising: calculating classification parameters from an input signal in block units, calculating a plurality of classification criteria from the classification parameters, and classifying the input signal using the plurality of classification criteria, the classification parameters including an energy parameter of the input signal, a cross-correlation parameter between a specific block of a present frame and the input signal, and an integrated cross-correlation parameter obtained by accumulating the cross-correlation parameter until a sign of a slope of the integrated cross-correlation parameter changes; adjusting a bit rate of the present frame according to a result of classifying the input signal; and encoding the input signal according to the adjusted bit rate and outputting a bit stream, wherein the method is performed using at least one processor.<br>25) An apparatus for encoding a speech signal comprising: a signal classifying unit which calculates classification parameters from an input signal in block units, calculates a plurality of classification criteria from the classification parameters, and classifies the input signal using the plurality of classification criteria, the classification parameters including an energy parameter of the input signal, a cross-correlation parameter between a specific block of a present frame and the input signal, and an integrated cross-correlation parameter obtained by accumulating the cross-correlation parameter until a sign of a slope of the integrated cross-correlation parameter changes; a bit rate adjusting unit which adjusts a bit rate of the present frame according to a result of classifying the input signal; and an encoding unit which encodes the input signal according to the adjusted bit rate and outputting a bit stream.<br>27) A non-transitory computer-readable medium having embodied thereon a computer program for executing a method comprising: calculating classification parameters from an input signal in block units, the classification parameters including an energy parameter of the input signal, a cross-correlation parameter between a specific block of a present frame and the input signal, and an integrated cross-correlation parameter obtained by accumulating the cross-correlation parameter until a sign of a slope of the integrated cross-correlation parameter changes; calculating a plurality of classification criteria from the classification parameters; and classifying a level of the input signal using the plurality of classification criteria.<br>28) A non-transitory computer-readable medium having embodied thereon a computer program for executing a method comprising: calculating a classification parameter from an input signal in block units, calculating a plurality of classification criteria from the classification parameters, and classifying the input signal using the plurality of classification criteria, the classification parameter including an energy parameter of the input signal, a cross-correlation parameter between a specific block of a present frame and the input signal, and an integrated cross-correlation parameter obtained by accumulating the cross-correlation parameter until a sign of a slope of the integrated cross-correlation parameter changes; adjusting a bit rate of the present frame according to results of classifying the input signal; and encoding the input signal according to the adjusted bit rate and outputting a bit stream.</p></layer>
<layer id = "layer461"><p><b>US20070150269A1:Bandwidth extension of narrowband speech</b><br>A method and apparatus for processing mail is provided. Mail is placed into an input bin having a conveyor that conveys the mail towards a feeder. The feeder serially feeds the envelopes by engaging the lead envelope in the stack of mail and displacing the lead envelope transverse the stack of mail. The mail is then cut on a side edge and the top edge to cut open each envelope. A transport conveys the cut envelopes to an extractor. The extractor opens the edge-severed mail and presents the contents of the envelopes to an operator who manually extracts the contents. The operator drops the extracted contents onto a conveyor that conveys the contents to an imaging station. The contents are automatically separated and imaged to obtain image data for the contents. The contents are then sorted into a plurality of output bins.<br><b>Independant Claims</b><br>1. A system that extends the bandwidth of a narrowband speech signal comprising: a high-band generator that generates a high frequency spectrum based on a narrowband spectrum; a background noise generator that generates a high frequency background noise spectrum based on a background noise within the narrowband spectrum; and a summer coupled to the high-band generator and background noise generator that combines the high frequency band and narrowband spectrum with high frequency background noise spectrum.<br>14. A system that extends the bandwidth of a narrowband speech signal comprising: a spectrum extractor that obtains a narrowband speech spectrum from a narrowband spectrum; a convolver configured to generate a high frequency spectrum by convolving the narrowband speech spectrum with itself; a high frequency envelope generator configured to generate a high frequency spectral envelope from the narrowband spectrum; a spectral envelope extender that estimates a high frequency background noise based on the narrowband spectrum; and a summer configured to combine the narrowband spectrum, the high frequency spectrum, and the high frequency background noise.<br>18. A method of extending a narrowband speech signal into a wideband signal comprising: extracting a narrowband spectrum that lies above a background noise band spectrum; extending the narrowband spectrum into a high frequency band spectrum; generating a high frequency band spectral envelope; adjusting a portion of the energy of the high frequency band spectrum to a portion of the energy in the narrowband spectrum; generating a high frequency background noise spectrum; and adding the adjusted high frequency band spectrum to the narrowband spectrum and the generated background noise spectrum.</p></layer>
<layer id = "layer462"><p><b>US8190429B2:Providing a codebook for bandwidth extension of an acoustic signal</b><br>A balanced brake control system is provided for use in aircraft. An embodiment of the invention is presented for an aircraft having struts with both inboard and outboard braked wheels on the struts. In the detailed embodiment, an equalizer circuit is interposed between right and left brake pedals on an input side thereof and right and left inboard and outboard brakes on an output side thereof. This equalizer circuit ensures a first equal application of brake pressure to the right inboard and outboard brakes and a second equal application of brake pressure to the left inboard and outboard brakes, dependent upon pilot control of brake pedals. The first and second equal applications of brake pressure may differ to accommodate differential braking.<br><b>Independant Claims</b><br>1) A computer-implemented method for providing a codebook spectral envelope for bandwidth extension of an acoustic signal comprising: using a computer to upsample a spectral envelope, where the spectral envelope is limited to a restricted frequency band with a lower limit frequency and an upper limit frequency; and using the computer to modify the upsampled spectral envelope to determine the codebook spectral envelope, wherein modifying the upsampled spectral envelope includes padding the magnitude of the upsampled spectral envelope outside the restricted frequency band to at least one predetermined threshold value.<br>12) A computer-implemented method for providing an acoustic signal with extended bandwidth comprises: providing the acoustic signal where the acoustic signal is restricted to a restricted frequency band with a lower limit frequency and an upper limit frequency; providing a first codebook comprising a first set of spectral envelopes, each spectral envelope in the first set padded outside the restricted frequency band to at least one predetermined threshold value; providing a second codebook comprising a second set of spectral envelopes corresponding with the first set of spectral envelopes, where each spectral envelope of the second set of spectral envelopes has an extended bandwidth compared to a corresponding spectral envelope from the first set of spectral envelopes; using a computer to determine a spectral envelope of the acoustic signal, including modifying the spectral envelope of the acoustic signal such that the magnitude of the spectral envelope outside the restricted frequency band is padded to at least one predetermined threshold value; using the computer to compare the modified spectral envelope of the acoustic signal with the spectral envelopes from the first codebook; using the computer to select a spectral envelope from the first codebook based on the comparison with the spectral envelope of the acoustic signal; using the computer to selecting a spectral envelope from the second codebook corresponding to the selected spectral envelope from the first codebook; and providing an extension signal based on the selected spectral envelope of the second codebook.<br>20) A system for providing an acoustic signal with extended bandwidth comprising: a receiver that receives the acoustic signal, the acoustic signal limited to a restricted frequency band with a lower limit frequency and an upper limit frequency; a determiner that generates a spectral envelope of the acoustic signal, including modifying the spectral envelope of the acoustic signal such that the magnitude of the spectral envelope outside the frequency band is padded to at least one predetermined threshold value; a first codebook comprising a first set of spectral envelopes, each spectral envelope in the first set padded outside the restricted frequency band to at least one predetermined threshold value; a second codebook comprising a second set of spectral envelopes corresponding with the first set of spectral envelopes, where each spectral envelope of the second set of spectral envelopes has an extended bandwidth compared to a corresponding spectral envelope from the first set of spectral envelopes; a bandwidth extender that receives the modified spectral envelope of the acoustic signal, the first codebook, and the second codebook, where the band width extender selects a spectral envelope from the first codebook based on a comparison with the modified spectral envelope of the acoustic signal; and a generator that provides an extension signal based on a spectral envelope from the second codebook corresponding to the selected spectral envelope from the first codebook.</p></layer>
<layer id = "layer463"><p><b>US20080221906A1:Speech coding system and method</b><br>An apparatus for mounting electronic parts and a method of mounting electronic parts capable of effectively performing image capturing at the time of position recognition of the electronic parts. In the apparatus, when images of electronic parts are taken for position recognition of the parts in the mounting of a plurality of the electronic parts held by a mounting head on a circuit board, it is adapted such that pixel signals are output only from specific necessary pixels. More specifically, pixel selecting information for allowing image signals to be selectively output from a plurality of specific pixels of a photodetecting section (<b>10</b>) of a CMOS area sensor is generated based on mounting schedule data (<b>16</b>C) related to a mounting sequence of the electronic parts and part data of the electronic parts stored in data storage (<b>16</b>). A pixel selector (<b>11</b>) is operated in accordance with the pixel selecting information, and thus the image signals are output from the selected specific pixels.<br><b>Independant Claims</b><br>1. A system for enhancing a signal regenerated from an encoded audio signal, comprising: a decoder arranged to receive the encoded audio signal and produce a decoded audio signal; feature extraction means arranged to receive at least one of the decoded and encoded audio signal and extract at least one feature from at least one of the decoded and encoded audio signal; mapping means arranged to map said at least one feature to an enhancement signal and operable to generate and output said enhancement signal, whereby the enhancement signal has a frequency band that is within the decoded audio signal frequency band; and mixing means arranged to receive said decoded audio signal and said enhancement signal and mix said enhancement signal with said decoded audio signal.<br>30. A method of enhancing a signal regenerated from an encoded audio signal, comprising: receiving the encoded audio signal at a terminal; producing a decoded audio signal; extracting at least one feature from at least one of the decoded and encoded audio signal; mapping said at least one feature to an enhancement signal and generating said enhancement signal, whereby said enhancement signal has a frequency band that is within the decoded audio signal frequency band; and mixing said enhancement signal and said decoded audio signal.</p></layer>
<layer id = "layer464"><p><b>US8271267B2:Scalable speech coding/decoding apparatus, method, and medium having mixed structure</b><br>An electric massage bed includes a bed frame having a plurality of support brackets, a plurality of mattress sets each having a retaining plate mounted on one of the support brackets of the bed frame and a mattress supported by the retaining plate, and a vibrating motor mounted on a bottom side of the retaining plate of one of the mattress sets. When the vibration generated from the vibrating motor is transmitted to the associated mattress of the mattress set that is equipped with the vibrating motor, the unexpected vibration won't occur in the other mattress sets because the mattress sets are spaced from each other, thereby enhancing the comfort of a user lying down on the mattresses.<br><b>Independant Claims</b><br>1) A scalable speech coding apparatus having a mixed structure, the apparatus comprising: a band divider to divide a speech input signal into a low-band signal and a high-band signal according to a specific frequency, and outputting the low-band signal and the high-band signal; a low-band coder to output a low-band first index by coding the low-band signal, to transmit information required for coding the high-band signal to a high-band coder, and to transmit a error signal obtained from the low-band signal and a signal generated during coding the low-band signal; a high-band coder to output a high-band second index obtained when the high-band signal is coded by using information received from the low-band coder, and to transmit a second error signal obtained from the high-band signal and a signal generated during coding the high-band signal; a wide-band coder to obtain a wide-band third index from the first and second error signals using a modified discrete cosine transform (MDCT); and a bit-stream generator to output a scalable bit-stream composed of the low-band first index received from the low-band coder, the high-band second index received from the high-band coder, and the wide-band third index received from the wide-band coder.<br>7) A scalable speech coding method having a mixed structure, the method comprising: (a) dividing a speech input signal into a low-band signal and a high-band signal according to a specific frequency, and outputting the low-band signal and the high-band signal; (b) generating and outputting a low-band first index by coding the output low-band signal, and outputting specific information required for coding the high-band signal and a first error signal obtained from the low-band signal; (c) coding the output high-band signal by using the specific information, and outputting a high-band second index and a second error signal obtained from the high-band signal; (d) obtaining a wide-band third index from the first and second error signals using a modified discrete cosine transform (MDCT); and (e) outputting a scalable bit-stream composed of the low-band first index, the high-band second index, and the wide-band third index.<br>13) A scalable speech decoding apparatus having a mixed structure, the apparatus comprising: a bit-stream divider to receive a scalable bit-stream transmitted at a specific transmission rate according to a network condition, and to generate a low-band signal, a high-band signal, and a wide band signal by dividing the scalable bit-stream according to a frequency band used in reproduction; a low-band decoder to receive the low-band signal into which the scalable bitstream is divided by the bit-stream divider, to decode and output the received low-band signal, and to transmit specific information required for decoding a high-band signal among coefficients decoded in a low-band; a high-band decoder to decode and output the high-band signal into which the scalable bit-stream is divided by the bitstream divider, using the specific information; a wide-band decoder to decode the wide-band signal into which the scalable bitstream is divided by the bit-stream divider, and to divide and output the decoded wide-band signal into a low-band signal and a high-band signal according to a specific frequency; and a band combiner to output a wide-band synthetic signal of a combined band using a signal output from the low-band decoder, a signal output from the high-band decoder, the low-band signal output from the wide-band decoder, and the high-band signal output from the wide-band decoder.<br>17) A scalable speech decoding method having a mixed structure, the method comprising: (a) receiving a scalable bit-stream transmitted at a specific transmission rate according to a network condition, and dividing and outputting the scalable bit-stream into a low-band signal, a high-band signal, and a wide-band signal according to a frequency band used for reproduction; (b) receiving the low-band signal of the scalable bitstream, decoding and outputting the received low-band signal, and outputting information on a pitch signal among coefficients decoded in a low-band; (c) receiving the high-band signal of the scalable bitstream and the pitch signal information, and decoding and outputting the high-band signal by using the pitch signal information; (d) receiving and decoding the wide-band signal of the scalable bitstream, and dividing and outputting the decoded wide-band signal into a low-band signal and a high-band signal according to a specific frequency; and (e) outputting a wide-band synthetic signal of a combined band by using a signal output in (b), a signal output in (c), a low-band signal output in (d), and a high-band signal output in (d).<br>29) A scalable speech coding method having a mixed structure, the apparatus comprising: dividing a speech input signal into a low-band signal and a high-band signal according to a specific frequency, and outputting the low-band signal and the high-band signal; outputting a low-band first index by coding a low-band signal, outputting information required for coding a high-band signal, and outputting a first error signal obtained from the low-band signal; outputting a high-band second index obtained when the high-band signal is coded by using the information required for coding a high-band signal, and outputting a second error signal obtained from the high-band signal; obtaining a wide-band third index from the first and second error signals using a modified discrete cosine transform (MDCT); and outputting a scalable bit-stream composed of the low-band first index, the high-band second index, and the wide-band third index.<br>31) A scalable speech decoding method having a mixed structure for decoding a scalable bit-stream, the method comprising: (a) receiving a low-band signal of the scalable bitstream, decoding and outputting the received low-band signal, and outputting information on a pitch signal among coefficients decoded in a low-band; (b) receiving a high-band signal of the scalable bitstream and the pitch signal information, and decoding and outputting the high-band signal by using the pitch signal information; (c) receiving and decoding a wide-band signal of the scalable bitstream, and dividing and outputting the decoded wide-band signal into a low-band signal and a high-band signal according to a specific frequency; and (d) outputting a wide-band synthetic signal of a combined band by using a signal output in (a), a signal output in (b), a low-band signal output in (c), and a high-band signal output in (c).</p></layer>
<layer id = "layer465"><p><b>US8160889B2:System for providing an acoustic signal with extended bandwidth</b><br>A rotational antenna includes a stationary feed which is disposed in a substantially vertical orientation. A parabolic dish is rotationally mounted about the stationary feed in a state of being tipped with respect to the stationary, substantially vertically oriented feed. The rotational parabolic antenna may alternatively be provided with a rotating radio frequency (RF) and acoustic feed. Other embodiments are disclosed.<br><b>Independant Claims</b><br>1) A digital-controller-implemented method for providing increased bandwidth, in a digitally sampled acoustic speech signal having a restricted bandwidth, so as to improve intelligibility of the speech signal, the method comprising: using a digital-controller-implemented spectral shifter, coupled to the speech signal to generate digitally an upper bandwidth extension signal in which at least a portion of the speech signal is shifted upwardly by a predetermined shifting frequency value, and wherein the spectral shifter is configured to perform a cosine modulation of the speech signal; using a first digital-controller-implemented high pass filter, coupled to an output of the spectral shifter, so as to digitally generate a filtered upper bandwidth extension signal by filtering the upper bandwidth extension signal to remove frequency components below a shifter output cutoff frequency; using a second digital-controller-implemented high pass filter, disposed between the speech signal and the spectral shifter, to remove frequency components to the spectral shifter that are below a shifter input cutoff frequency; and generating digitally an extended bandwidth speech signal based on the speech signal and the filtered upper bandwidth extension signal.<br>20) A non-transitory computer readable medium encoded with computer executable instructions that, when loaded into memory associated with a suitably configured digital controller in a digital device, causes the device to perform a method for providing increased bandwidth, in a digitally sampled acoustic speech signal having a restricted bandwidth, so as to improve intelligibility of the speech signal, the method comprising: using a digital-controller-implemented spectral shifter, coupled to the speech signal to generate digitally an upper bandwidth extension signal in which at least a portion of the speech signal is shifted upwardly by a predetermined shifting frequency value, and wherein the spectral shifter is configured to perform a cosine modulation of the speech signal; using a first digital-controller-implemented high pass filter, coupled to an output of the spectral shifter, so as to digitally generate a filtered upper bandwidth extension signal by filtering the upper bandwidth extension signal to remove frequency components below a cutoff frequency; using a second digital-controller-implemented high pass filter, disposed between the speech signal and the spectral shifter, to remove frequency components to the spectral shifter that are below a shifter input cutoff frequency; and generating an extended bandwidth speech signal based on the speech signal and the filtered upper bandwidth extension signal.</p></layer>
<layer id = "layer466"><p><b>US20180012608A1:INFORMATION SIGNAL ENCODING</b><br><b>Independant Claims</b><br>1) An apparatus for decoding an information signal from an encoded information signal, the apparatus configured to decode from the encoded information signal one or more first linear prediction coefficients, one or more second linear prediction coefficients and a quantized prediction error; dequantize the quantized prediction error for attaining a dequantized prediction error; determine a predicted signal based on the one or more second linear prediction coefficients; reconstruct a prefiltered signal by combining the predicted signal and the dequantized prediction error; feed back the prefiltered signal and perform the prediction of the prefiltered signal based on the prefiltered signal, a filter configured to filter the prefiltered signal using the one or more second linear prediction coefficients so as to attain the information signal, wherein the information signal is an audio signal, and wherein at apparatus comprises a hardware implementation.<br>7) A method for decoding an information signal from an encoded information signal, comprising: decoding from the encoded information signal one or more first linear prediction coefficients, one or more second linear prediction coefficients and a quantized prediction error; dequantizing the quantized prediction error to attain a dequantized prediction error; determining a predicted signal based on the one or more second linear prediction coefficients; reconstructing a prefiltered signal by combining the predicted signal and the dequantized prediction error, wherein the prediction of the prefiltered signal is performed based on a feedback of the prefiltered signal, and filtering the prefiltered signal using the one or more second linear prediction coefficients so as to attain the information signal, wherein the information signal is an audio signal.</p></layer>
<layer id = "layer467"><p><b>US8374861B2:Voice activity detector</b><br>A multi-network environment adaptive media streaming method and apparatus. The method of transmitting media streaming includes encoding content to generate media data consisting of a plurality of layers; separating the generated media data into layers; and transmitting the media data separated into layers to a media receiving apparatus in a streaming format over a plurality of networks.<br><b>Independant Claims</b><br>10) A voice activity detection method, comprising: dividing, by a processor, a signal into a plurality of wide bands; dividing, by the processor, each of the wide bands into a plurality of bins; determining, by the processor, a noise estimate for each of the wide bands; calculating, by the processor for each of the wide bands, a variance of a signal-to-noise ratio across the bins of each of the wide bands based on the signal and the noise estimate for each of the wide bands; combining, by the processor, the variances calculated for each of the wide bands to derive a value; performing, by the processor, a comparison between the value and a threshold; and identifying, by the processor, whether the signal contains speech based on the comparison between the value and the threshold.<br>1) A voice activity detection method, comprising: calculating, by a processor, a variance of a signal-to-noise ratio across a plurality of portions of a signal; calculating, by the processor, a value based on the variance of the signal-to-noise ratio; performing, by the processor, a comparison between the value and a threshold; and identifying, by the processor, whether the signal contains speech based on the comparison between the value and the threshold.<br>13) A noise detection system, comprising: a computer memory that stores a measurement of a variance of a signal-to-noise ratio across a plurality of portions of a signal; and a processor coupled with the computer memory; where the processor is configured to access the measurement of the variance of a signal-to-noise ratio from the computer memory; where the processor is configured to calculate a value based on the variance of the signal-to-noise ratio; where the processor is configured to perform a comparison between the value and a threshold; and where the processor is configured to identify whether the signal contains speech based on the comparison between the value and the threshold.</p></layer>
<layer id = "layer468"><p><b>US20070136056A1:Noise Pre-Processor for Enhanced Variable Rate Speech Codec</b><br>The concepts discussed herein address a system, method, and computer product by which an e-mail is automatically formatted. An e-mail is sent by an e-mail client and received by a server for processing outbound and inbound e-mail including a SMTP server, POP3/IMAP server, or another server in communication with the SMTP server, POP3/IMAP server, or both. The server receives the e-mail message from the e-mail client and text-parses the received e-mail for identifying an e-mail attribute. Next, the system formats the received e-mail message in accordance with a predetermined format corresponding to the identified e-mail attribute, which is sent to intended recipient(s).<br><b>Independant Claims</b><br>1. A method of pre-processing speech input signals for noise comprising the steps of: forming a Fast Fourier transform of sampled speech input signals transforming said sampled speech input signals from time domain to frequency domain; filtering said frequency domain data into a plurality of adjacent frequency channels spanning a range of frequencies of human speech; forming an energy estimate for each channel; smoothing said energy estimate for each channel by weighted summing of a current energy estimate for said channel and a prior smoothed energy estimate for said channel as follows SEChi,n=α*EChi,n+(1−α)SEChi,n-1  where: SEChi,n is the smoothed energy estimate for channel i at time n; EChi,n is the current energy estimate for channel i at time n; and α is an adaptive smoothing constant; forming a signal to noise ratio estimate for said channel dependent upon a corresponding smoothed energy estimate; forming a voice metric for each channel dependent upon a corresponding signal to noise ratio estimate; and forming a channel gain for each channel dependent upon a corresponding voice metric; wherein said smoothing said energy estimate for each channel moves said adaptive smoothing constant toward a first smoothing constant if said prior signal to noise ratio estimate for more than a predetermined number of channels is above a signal to noise ratio threshold and moves said adaptive smoothing constant toward a second smoothing constant less than or equal to said first smoothing constant if said prior signal to noise ratio estimate for less than said predetermined number of channels is above said signal to noise ratio threshold.</p></layer>
<layer id = "layer469"><p><b>US20070156399A1:Noise reducer, noise reducing method, and recording medium</b><br>A method and system for depositing a film with tunable optical and etch resistant properties on a substrate by plasma-enhanced chemical vapor deposition. A chamber has a plasma source and a substrate holder coupled to a RF source. A substrate is placed on the substrate holder. The TERA layer is deposited on the substrate. The amount of RF power provided by the RF source is selected such that the rate of deposition of at least one portion of the TERA layer is greater than when no RF power is applied the substrate holder.<br><b>Independant Claims</b><br>1. A noise reducer comprising: a speech accepting part for accepting a speech on which a noise is superimposed and converting it into a signal on a time axis of the speech; a signal converting part for converting the signal on the time axis of the speech into a signal on a frequency axis; an amplitude calculating part for calculating an amplitude component for each predetermined frequency band of the signal on the frequency axis converted by the signal converting part; a coefficient calculating part for calculating a noise reduction coefficient to reduce the noise for each frequency band on the basis of the amplitude component calculated by the amplitude calculating part; a noise reducing part for multiplying the signal on the frequency axis of the original signal by the calculated noise reduction coefficient to reduce the noise component in the converted signal on the frequency axis; and a signal restoring part for restoring the signal on the frequency axis of which noise component is reduced into the signal on the time axis; wherein the signal restoring part restores a signal on a frequency axis in which a signal corresponding to a frequency band of which target value estimated by the noise target value is larger than the value of the amplitude component of the signal on the frequency axis of which noise component is reduced by the noise reducing part is corrected to a signal corresponding to the target value estimated by the noise target value estimating part, into a signal on a time axis.<br>3. A noise reducer comprising a processor capable for performing the steps of: accepting the speech having the noise superimposed thereon and converting it into a signal on a time axis of the speech; converting the signal on the time axis of the speech into a signal on a frequency axis; calculating an amplitude component of a speech for each predetermined frequency band of the converted signal on the frequency axis; calculating a noise reduction coefficient for reducing the noise for each frequency band on the basis of the calculated amplitude component; reducing the noise component in the converted signal on the frequency axis by multiplying the signal on the frequency axis of the original signal by the calculated noise reduction coefficient; restoring the signal on the frequency axis of which noise component is reduced into a signal on a time axis; and restoring a signal on a frequency axis in which a signal corresponding to a frequency band of which target value estimated by the noise target value is larger than the value of the amplitude component of the signal on the frequency axis of which noise component is reduced by the noise reducing part is corrected to a signal corresponding to the target value estimated by the noise target value estimating part, into a signal on a time axis.<br>5. A noise reducing method comprising the steps of: accepting the speech having the noise superimposed thereon and converting it into a signal on a time axis of the speech; converting the signal on the time axis of the speech into a signal on a frequency axis; calculating an amplitude component of a speech for each predetermined frequency band of the converted signal on the frequency axis; calculating a noise reduction coefficient for reducing the noise for each frequency band on the basis of the calculated amplitude component; reducing the noise component in the converted signal on the frequency axis by multiplying the signal on the frequency axis of the original signal by the calculated noise reduction coefficient; restoring the signal on the frequency axis of which noise component is reduced into a signal on a time axis; estimating a target value of the remaining noise for each frequency band on the basis of the accepted speech; and restoring a signal on a frequency axis in which a signal corresponding to a frequency band of which target value estimated by the noise target value is larger than the value of the amplitude component of the signal on the frequency axis of which noise component is reduced by the noise reducing part is corrected to a signal corresponding to the target value estimated by the noise target value estimating part, into a signal on a time axis.<br>7. A recording medium, storing a computer program, wherein the computer program stored in the recording medium comprises the steps of: causing the computer to accept a speech on which a noise is superimposed and convert it into the signal on the time axis of the speech; causing the computer to convert the signal on the time axis into the signal on the frequency axis; causing the computer to calculate an amplitude component for each predetermined frequency band of the converted signal on the frequency axis; causing the computer to calculate a noise reduction coefficient that reduces the noise for each frequency band on the basis of the calculated amplitude component; causing the computer to reduce the noise component in the converted signal on the frequency axis by multiplying the signal on the frequency axis of the original signal by the calculated noise reduction coefficient; causing the computer to restore the signal on the frequency axis of which noise component is reduced into the signal on the time axis; causing the computer to estimate a target value of the remaining noise for each frequency band on the basis of the accepted speech; and causing the computer to restore a signal on a frequency axis in which a signal corresponding to a frequency band of which target value estimated by the noise target value is larger than the value of the amplitude component of the signal on the frequency axis of which noise component is reduced by the noise reducing part is corrected to a signal corresponding to the target value estimated by the noise target value estimating part into a signal on a time axis.</p></layer>
<layer id = "layer470"><p><b>US8447594B2:Multicodebook source-dependent coding and decoding</b><br>A power-supply design system for designing a power supply of electronic equipment apparatuses. The system includes an input device for inputting circuit information about the power supply of the electronic equipment apparatus; a current deviation computation unit that computes an electric current deviation which indicates electric current variation of the electronic equipment apparatus, based on the circuit information input using the input device, and dispersion information that indicates a dispersion of an electric current variation, which corresponds to the circuit information; a target impedance computation unit that computes a target impedance as a target for the power supply indicated by the circuit information, based on the electric current deviation computed by the current deviation computation unit and a permissible range of a voltage variation, where the permissible range is indicated by the circuit information; and an output device that outputs the target impedance computed by the target impedance computation unit.<br><b>Independant Claims</b><br>1) A method for coding audio data, comprising: grouping data into frames; classifying the frames into classes; for each class, transforming the frames belonging to the class into filter parameter vectors; for each class, computing a filter codebook based on the filter parameter vectors belonging to the class; segmenting each frame into subframes; for each class, transforming the subframes belonging to the class into source parameter vectors, which are extracted from the subframes by applying a filtering transformation based on the filter codebook computed for a corresponding class; for each class, computing a source codebook based on the source parameter vectors belonging to the class; and coding the data based on the computed filter and source codebooks.<br>22) A coder, for coding audio data, comprising a processing system and a memory with software code portions stored thereon, the software code portions when executed by the processing system being configured to cause the processing system to: group data into frames; classify the frames into classes; for each class, transform the frames belonging to the class into filter parameter vectors; for each class, compute a filter codebook based on the filter parameter vectors belonging to the class; segment each frame into subframes; for each class, transform the subframes belonging to the class into source parameter vectors, which are extracted from the subframes by applying a filtering transformation based on the filter codebook computed for a corresponding class; for each class, compute a source codebook based on the source parameter vectors belonging to the class; and code the data based on the computed filter and source codebooks.</p></layer>
<layer id = "layer471"><p><b>US20070233472A1:Voice modifier for speech processing systems</b><br>The present invention relates to apparatus for methods for endovascularly replacing a patient's heart valve. The apparatus includes an expandable anchor with leaflet engagement elements on the proximal end of the anchor and a replacement valve. The leaflet engagement elements can be used to prevent distal migration and insure proper positioning of the apparatus.<br><b>Independant Claims</b><br>1. A method for modifying a speech signal, the method comprising: receiving Mth order linear predictive coding (LPC) coefficients representative of an input speech signal; converting the Mth order LPC coefficients to Mth order line spectral pairs (LSPs); multiplying the Mth order LSPs by a scale factor to produce scaled Mth order LSPs; removing any pair of scaled LSP with at least one coefficient in the pair above a frequency threshold to produce a Pth order set of LSPs, where P<M; converting the Pth order set of scaled LSPs to a Pth order set of LPCs; padding the Pth order set of LPCs with M-P zeros; converting the Pth order set of LPCs padded with zeros to a second Mth order set of LSPs; and processing the second Mth order set of LSPs and at least a third set of Mth order LSPs of another frame.<br>12. An apparatus comprising: a modifier configured to: receive Mth order linear predictive coding (LPC) coefficients representative of an input speech signal; convert the Mth order LPC coefficients to Mth order line spectral pairs (LSPs); multiply the Mth order LSPs by a scale factor to produce scaled Mth order LSPs; remove any pairs of scaled LSPs with at least one coefficient above a frequency threshold to produce a Pth order set of LSPs, where P<M; convert the Pth order set of scaled LSPs to a Pth order set of LPCs; pad the Pth order set of LPCs with M-P zeros; convert the Pth order set of LPCs padded with zeros to a second Mth order set of LSPs; and process the second Mth order set of LSPs and at least a third set of Mth order LSPs of another frame.<br>26. An apparatus comprising a processor and a memory configured to store a set of instructions executable by the processor, the set of instructions comprising: receiving Mth order linear predictive coding (LPC) coefficients representative of an input speech signal; converting the Mth order LPC coefficients to Mth order line spectral pairs (LSPs); multiplying the Mth order LSPs by a scale factor to produce scaled Mth order LSPs; removing any pairs of scaled LSPs with at least one coefficient above a frequency threshold to produce a Pth order set of LSPs, where P<M; converting the Pth order set of scaled LSPs to a Pth order set of LPCs; padding the Pth order set of LPCs with M-P zeros; converting the Pth order set of LPCs padded with zeros to a second Mth order set of LSPs; and processing the second Mth order set of LSPs and at least a third set of Mth order LSPs of another frame.</p></layer>
<layer id = "layer472"><p><b>US9584083B2:Loudness modification of multichannel audio signals</b><br><b>Independant Claims</b><br>1) A method for processing an audio signal having at least a first channel and a second channel, the method comprising: determining a first gain to scale a loudness of the first channel from a first loudness to a second loudness, each of the first loudness and the second loudness being a respective value of a nonlinear function of a power of the first channel; and determining a second gain to scale a loudness of the second channel from a third loudness to a fourth loudness, each of the third loudness and the fourth loudness being a respective value of a nonlinear function of a power of the second channel; wherein the first gain and the second gain are selected so that a first ratio between the second loudness and the first loudness equals a second ratio between the fourth loudness and the third loudness; where the method is performed by one or more computing devices.<br>13) A non-transitory computer readable medium, storing software instructions for processing an audio signal having a first channel and a second channel, which when executed by one or more processors cause performance of the steps of: determining a first gain to scale a loudness of the first channel from a first loudness to a second loudness, each of the first loudness and the second loudness being a respective value of a nonlinear function of a power of the first channel; and determining a second gain to scale a loudness of the second channel from a third loudness to a fourth loudness, each of the third loudness and the fourth loudness being a respective value of a nonlinear function of a power of the second channel; wherein the first gain and the second gain are selected so that a first ratio between the second loudness and the first loudness equals a second ratio between the fourth loudness and the third loudness.<br>7) An apparatus for processing an audio signal having a first channel and a second channel, the apparatus comprising: a subsystem, implemented at least partially in hardware that determines a first gain to scale a loudness of the first channel from a first loudness to a second loudness, each of the first loudness and the second loudness being a respective value of a nonlinear function of a power of the first channel; and a subsystem, implemented at least partially in hardware that determines a second gain to scale a loudness of the second channel from a third loudness to a fourth loudness, each of the third loudness and the fourth loudness being a respective value of a nonlinear function of a power of the second channel; wherein the first gain and the second gain are selected so that a first ratio between the second loudness and the first loudness equals a second ratio between the fourth loudness and the third loudness.</p></layer>
<layer id = "layer473"><p><b>US20070171931A1:ARBITRARY AVERAGE DATA RATES FOR VARIABLE RATE CODERS</b><br>An air spring actuated brake assembly for a railway vehicle braking system is provided which comprises an air spring disposed between a mounting member for attachment to the rigid structure of the braking system and a push rod attached thereto for longitudinal movement in an outward direction upon actuation thereof to initiate a braking sequence of the railway vehicle braking system. The air spring actuated brake assembly of the present invention allows for improved control of the brake shoe forces including visual travel measurement indication which is especially desirable during light load conditions. Additionally the air spring actuated brake assembly of the invention allows for the visual inspection and simple replacement of an inflatable spring should an air leak in the actuator occur. Currently used brake assemblies employing cylinder type actuators may be retrofitted with the air spring actuator of the invention.<br><b>Independant Claims</b><br>1. A method for achieving an arbitrary average data rate for a variable rate coder, comprising: selecting a first composite rate less than the arbitrary average data rate; selecting a second composite rate greater than the arbitrary average data rate; calculating a reallocation fraction based on the first and second composite rates; and based on the reallocation fraction, reassigning a plurality of frames assigned to a first component rate of the first composite rate to a second component rate of the first composite rate, wherein the second component rate is different than the first component rate.<br>7. A computer program product comprising computer-readable medium comprising: code for causing at least one computer to select a first composite rate less than the arbitrary average data rate; code for causing at least one computer to select a second composite rate greater than the arbitrary average data rate; code for causing at least one computer to calculate a reallocation fraction based on the first and second composite rates; and code for causing at least one computer to reassign, based on the reallocation fraction, a plurality of frames assigned to a first component rate of the first composite rate to a second component rate of the first composite rate, wherein the second component rate is different than the first component rate.<br>8. An apparatus for achieving an arbitrary average data rate for a variable rate coder, said apparatus comprising: a rate selector configured to select a first composite rate less than the arbitrary average data rate and a second composite rate greater than the arbitrary average data rate; a calculator configured to calculate a reallocation fraction based on the first and second composite rates; and a frame reassignment module configured to reassign, based on the reallocation fraction, a plurality of frames assigned to a first component rate of the first composite rate to a second component rate of the first composite rate, wherein the second component rate is different than the first component rate.<br>10. A method for achieving an arbitrary capacity for a network, comprising: determining a capacity operating point for the network; setting an arbitrary average data rate for a set of devices accessing the network, the arbitrary average data rate being set in accordance with the capacity operating point; selecting first and second initial composite rates surrounding the arbitrary average data rate; based on the selected initial composite rates, calculating a reallocation fraction; instructing at least one of the set of devices to reassign, based on the reallocation fraction, a plurality of frames assigned to a first component rate of the first composite rate to a second component rate of the first composite rate, wherein the second component rate is different than the first component rate.<br>11. A method for encoding frames according to a target rate, said method comprising: selecting a composite rate from among a set of composite rates, wherein each of the set of composite rates includes a first allocation of frames to a first component rate of the selected composite rate and a second allocation of frames to a second component rate of the selected composite rate; based on the target rate and the selected composite rate, calculating a reallocation fraction; based on the reallocation fraction and the first allocation of the selected composite rate, reallocating a plurality of frames from the first component rate of the selected composite rate to the second component rate of the selected composite rate.<br>17. A computer program product comprising computer-readable medium comprising: code for causing at least one computer to select a composite rate from among a set of composite rates, wherein each of the set of composite rates includes a first allocation of frames to a first component rate of the selected composite rate and a second allocation of frames to a second component rate of the selected composite rate; code for causing at least one computer to calculate a reallocation fraction based on the target rate and the selected composite rate; code for causing at least one computer to reallocate, based on the reallocation fraction and the first allocation of the selected composite rate, frames from the first component rate of the selected composite rate to the second component rate of the selected composite rate.<br>18. An apparatus for encoding frames according to a target rate, said apparatus comprising: a rate selector configured to select a composite rate from among a set of composite rates, wherein each of the set of composite rates includes a first allocation of frames to a first component rate of the selected composite rate and a second allocation of frames to a second component rate of the selected composite rate; a calculator configured to calculate a reallocation fraction based on the target rate and the selected composite rate; and a frame reassignment module configured to reassign, based on the reallocation fraction and the first allocation of the selected composite rate, frames from the first component rate of the selected composite rate to the second component rate of the selected composite rate.</p></layer>
<layer id = "layer474"><p><b>US8504181B2:Audio signal loudness measurement and modification in the MDCT domain</b><br>A scratch-resistant glass substrate is prepared by forming a phase-transformable, scratch-resistant layer over a major surface of the substrate. The phase-transformable layer can comprise the metastable, tetragonal polymorph of zirconium oxide. Under the application of an applied scratch, such as during a scratch event, the tetragonal phase can undergo a phase-transformation and concomitant volume expansion to the monoclinic phase. The volume expansion can reduce and soften the physical dimensions of the scratch, which can make the scratch less visible.<br><b>Independant Claims</b><br>1) A method for processing an audio signal represented by the Modified Discrete Cosine Transform (MDCT) of a time-sampled real signal, comprising measuring in the MDCT domain the perceived loudness of the MDCT-transformed audio signal, wherein said measuring includes computing an estimate of the power spectrum of the MDCT-transformed audio signal, wherein said computing an estimate employs weighting to compensate for the MDCT's representation of only one of the quadrature components of the transformed audio signal and smoothing time constants commensurate with the integration time of human loudness perception or slower, and modifying in the MDCT domain, at least in part in response to said measuring, the perceived loudness of the transformed audio signal, wherein said modifying includes gain modifying frequency bands of the MDCT-transformed audio signal, the rate of change of the gain across frequency being constrained by a smoothing function that limits the degree of aliasing distortion.</p></layer>
<layer id = "layer475"><p><b>US20190222186A1:Audio Control Using Auditory Event Detection</b><br><b>Independant Claims</b><br>7) An audio processing apparatus, the apparatus comprising:an input interface for receiving the audio signal, the audio signal comprising at least one channel of audio content;an analysis filter bank for dividing the audio signal into a plurality of subband signals, each of the plurality of subband signals including at least one subband sample;a processor that:derives a characteristic of the audio signal, wherein the characteristic is a power measure of the audio signal;smoothes the power measure to generate a smoothed power measure of the audio signal, wherein the power measure is smoothed based on a low-pass filter;detects a location of an auditory event boundary by monitoring the smoothed power measure, wherein an audio portion between consecutive auditory event boundaries constitutes an auditory event;generates a gain vector based on the location of an auditory event boundary, andapplies the gain vector to a version of the plurality of subband signals to produce modified subband signals; anda synthesis filterbank that combines the modified subband signals to produce a modified audio signal,wherein the detecting further includes applying a threshold to the smoothed power measure to detect the location of the auditory event boundary,wherein the detecting further includes comparing the smoothed power measure with a second smoothed power measure of the audio signal,wherein the power measure or the second power measure is based on a difference measure, andwherein auditory event is associated with a transient.<br>1) A method for processing an audio signal in an audio processing apparatus, the method comprising:receiving the audio signal, the audio signal comprising at least one channel of audio content;dividing the audio signal into a plurality of subband signals with an analysis filterbank, each of the plurality of subband signals including at least one subband sample;deriving a characteristic of the audio signal, wherein the characteristic is a power measure of the audio signal;smoothing the power measure to generate a smoothed power measure of the audio signal, wherein the smoothing is based on a low-pass filter;detecting a location of an auditory event boundary by monitoring the smoothed power measure, wherein an audio portion between consecutive auditory event boundaries constitutes an auditory event;generating a gain vector based on a location of the auditory event boundary;applying the gain vector to a version of the plurality of subband signals to generate modified subband signals; andsynthesizing the modified subband signals with a synthesis filterbank to produce a modified audio signal,wherein the detecting further includes applying a threshold to the smoothed power measure to detect the location of the auditory event boundary,wherein the detecting further includes comparing the smoothed power measure with a second smoothed power measure of the audio signal,wherein the power measure or the second power measure is based on a difference measure,wherein auditory event is associated with a transient, andwherein the audio processing apparatus is implemented at least in part with hardware.</p></layer>
<layer id = "layer476"><p><b>US8095360B2:Speech post-processing using MDCT coefficients</b><br>Forming a capacitor structure includes forming a first dielectric layer over a conductive region, wherein the first dielectric layer has a first conductive layer at a top surface of the first dielectric layer; forming a first opening in the first dielectric layer over the conductive region, wherein the first opening exposes a first sidewall of the first conductive layer; forming a second conductive layer within the first opening, wherein the second conductive layer contacts the first sidewall of the first conductive layer; removing a portion of the second conductive layer from the bottom of the first opening; forming an insulating layer within the first opening; removing a portion of the insulating layer from the bottom of the first opening; extending the first opening through the first dielectric layer to expose the conductive region; and filling the first opening with a conductive material, wherein the conductive material contacts the conductive region.<br><b>Independant Claims</b><br>1) A method of post-processing a speech signal having a high-band frequency range and a low-band frequency range to generate a post-processed speech signal, the method comprising: applying a time-domain post-processing to the speech signal, using LPC (Linear Prediction Coding) coefficients, for the low-band frequency range of the speech signal; applying a frequency-domain post-processing to the speech signal, using MDCT (Modified Discrete Cosine Transform) coefficients, for the high-band frequency range of the speech signal; wherein applying the frequency-domain post-processing includes: decoding an encoded speech signal to obtain MDCT coefficients representative of the speech signal divided into a plurality of sub-bands; generating an envelope for each sub-band of the plurality of sub-bands as an average magnitude of the MDCT coefficients of the sub-band; generating an envelope modification factor for each sub-band of the plurality of sub-bands using the MDCT coefficients of the sub-band; determining a gain based on the envelope and the envelope modification factor of the sub-bands; generating a fine structure modification factor for each MDCT coefficient in each sub-band of the plurality of sub-band using the MDCT coefficients of the sub-band; modifying the MDCT coefficients in each sub-band by multiplying by the gain, the envelope modification factor of the sub-band and the fine structure modification factor of the MDCT coefficient of the sub-band to provide post-processed MDCT coefficients; generating the post-processed speech signal using the post-processed MDCT coefficients; and converting the post-processed speech signal from a digital form into an analog form using an digital-to-analog converter.<br>6) A speech post-processor for post-processing a speech signal having a high-band frequency range and a low-band frequency range to generate a post-processed speech signal, the speech post-processor comprising: software and circuitry for: applying a time-domain post-processing to the speech signal, using LPC (Linear Prediction Coding) coefficients, for the low-band frequency range of the speech signal; applying a frequency-domain post-processing to the speech signal, using MDCT (Modified Discrete Cosine Transform) coefficients, for the high-band frequency range of the speech signal; wherein applying the frequency-domain post-processing includes: decoding an encoded speech signal to obtain MDCT coefficients representative of the speech signal divided into a plurality of sub-bands; generating an envelope for each sub-band of the plurality of sub-bands as an average magnitude of the MDCT coefficients of the sub-band; generating an envelope modification factor for each sub-band of the plurality of sub-bands using the MDCT coefficients of the sub-band; determining a gain based on the envelope and the envelope modification factor of the sub-bands; generating a fine structure modification factor for each MDCT coefficient in each sub-band of the plurality of sub-band using the MDCT coefficients of the sub-band; modifying the MDCT coefficients in each sub-band by multiplying by the gain, the envelope modification factor of the sub-band and the fine structure modification factor of the MDCT coefficient of the sub-band to provide post-processed MDCT coefficients; generating the post-processed speech signal using the post-processed MDCT coefficients; and converting the post-processed speech signal from a digital form into an analog form using an digital-to-analog converter.</p></layer>
<layer id = "layer477"><p><b>US8145477B2:Systems, methods, and apparatus for computationally efficient, iterative alignment of speech waveforms</b><br>The invention is a lighter cover for use with a cigarette lighter, the cover including a bottle opener for removing crimped crown-type caps from bottles and a pull-tab opener for lifting a pull-tab on a beverage can.<br><b>Independant Claims</b><br>1) A method of aligning two periodic speech waveforms, under the control of an electronic device, said method comprising: shifting a first one of two periodic speech waveforms by a non-zero value within an alignment range, prior to calculating a first and a second correlation measure; evaluating a result of a trigonometric function of an angle, comprising evaluating a single cosine and a single sine; (I) calculating the first correlation measure, between (A) the first one of two periodic speech waveforms, as shifted by a first phase shift, and (B) a second one of the two periodic speech waveforms using the result of the trigonometric function; and (II) calculating the second correlation measure, between (C) the first one of the two periodic speech waveforms, as shifted by a second phase shift, and (D) the second one of the two periodic speech waveforms using the result of the trigonometric function, wherein the first and second phase shifts are equal in magnitude and opposite in direction, wherein cross-correlations for multiple different phase shifts are determined using the single cosine and the single sine.<br>16) An apparatus configured to align two periodic speech waveforms, said apparatus comprising: means for shifting a first one of two periodic speech waveforms by a non-zero value within an alignment range, prior to calculating a first and a second correlation measure; means for evaluating a result of a trigonometric function of an angle, comprising evaluating a single cosine and a single sine; means for calculating, (1) the first correlation measure between (A) a first one of the two periodic speech waveforms, as shifted by a first phase shift, and (B) a second one of the two periodic speech waveforms using the result of the trigonometric function and (2) the second correlation measure between (C) the first one of the two periodic speech waveforms, as shifted by a second phase shift, and (D) the second one of the two periodic speech waveforms using the result of the trigonometric function, wherein cross-correlations for multiple different phase shifts are determined using the single cosine and the single sine.<br>26) An apparatus configured to align two periodic speech waveforms, said apparatus comprising: a shifter configured to shift a first one of two periodic speech waveforms by a non-zero value within an alignment range, prior to calculating a first and a second correlation measure; a trigonometric function evaluator configured to evaluate a result of trigonometric function of an angle by evaluating a single cosine and a single sine; and a calculator configured to calculate, (1) the first correlation measure between (A) a first one of the two periodic speech waveforms, as shifted by a first phase shift and (B) a second one of the two periodic speech waveforms using the result of the trigonometric function, and (2) the second correlation measure between (C) the first one of the two periodic speech waveforms, as shifted by a second phase shift, and (D) the second one of the two periodic speech waveforms using the result of the trigonometric function, wherein cross-correlations for multiple different phase shifts are determined using the single cosine and the single sine.<br>36) A method of aligning two periodic speech waveforms, said method comprising: prior to a first iteration, shifting a first one of two periodic speech waveforms by a first shift value; performing the first iteration over a first evaluation range with a first resolution in order to obtain a first index value; after the first iteration and prior to a second iteration, shifting the first one of two periodic speech waveforms by a second shift value, wherein the second shift value is based on the first index value; and performing the second iteration over a second evaluation range with a second resolution in order to obtain a second index value, wherein the second evaluation range is smaller than the first evaluation range and the second resolution is higher than the first resolution.<br>41) An apparatus configured to align two periodic speech waveforms, said apparatus comprising: prior to a first iteration, means for shifting a first one of two periodic speech waveforms by a first shift value; means for performing the first iteration over a first evaluation range with a first resolution in order to obtain a first index value; after the first iteration and prior to a second iteration, means for shifting the first one of two periodic speech waveforms by a second shift value, wherein the second shift value is based on the first index value; and means for performing the second iteration over a second evaluation range with a second resolution in order to obtain a second index value, wherein the second evaluation range is smaller than the first evaluation range and the second resolution is higher than the first resolution.<br>45) An apparatus configured to align two periodic speech waveforms, said apparatus comprising a processor configured to: (1) shift a first one of two periodic speech waveforms by a first shift value prior to a first iteration; (2) perform the first iteration over a first evaluation range with a first resolution in order to obtain a first index value; (3) shift the first one of two periodic speech waveforms by a second shift value after the first iteration and prior to a second iteration; and (4) perform the second iteration over a second evaluation range with a second resolution in order to obtain a second index value, wherein the second shift value is based on the first index value and wherein the second evaluation range is smaller than the first evaluation range and the second resolution is higher than the first resolution.</p></layer>
<layer id = "layer478"><p><b>US8788275B2:Decoding method and apparatus for an audio signal through high frequency compensation</b><br>The technology disclosed relates to a platform for ultra-fast, ad-hoc data exploration and faceted navigation on integrated, heterogeneous data sets. The disclosed method of declarative specification of visualization queries, display formats and bindings represents queries, widgets and bindings combined on a dashboard in real time, with flexible display options for analyzing data and conveying analysis results.<br><b>Independant Claims</b><br>5) A decoding method for decoding a first encoded data that is encoded from a low-frequency component of an audio signal, and a second encoded data that is used when creating a high-frequency component of an audio signal from a low-frequency component and encoded in accordance with a certain bandwidth, into the audio signal, the decoding method comprising: high-frequency component detecting, using a microprocessor, including dividing the high-frequency component into bands with a certain interval range correspondingly to the certain bandwidth, and detecting magnitude of power of the high-frequency components corresponding to each of the bands; determining, using a microprocessor, a band of a compensation subject which is a high-frequency component to be compensated based on an interval range of the high-frequency components divided at the high-frequency component detecting; acquiring a difference value by subtracting a power corresponding to the band of the compensation subject from a power corresponding to an adjacent band; acquiring a change rate by dividing the difference value by a bandwidth of the band of the compensation subject; acquiring an energy of a subdivided band by dividing the power corresponding to the band of the compensation subject by the bandwidth of the band of the compensation subject; acquiring a compensating power by adding the energy of the subdivided band to a value which is computed by multiplying the change rate by a frequency change within the band of the compensation subject; compensating, using a microprocessor, the compensation subject in accordance with the compensating power; and decoding the low-frequency component decoded from the first encoded data, and the high-frequency components compensated at the compensating, into the audio signal.<br>1) A decoding apparatus that decodes a first encoded data that is encoded from a low-frequency component of an audio signal, and a second encoded data that is used when creating a high-frequency component of an audio signal from a low-frequency component and encoded in accordance with a certain bandwidth, into the audio signal, the decoding apparatus comprising: a high-frequency component detecting unit that divides the high-frequency component into bands with a certain interval range correspondingly to the certain bandwidth, and detects magnitude of power of the high-frequency components corresponding to each of the bands; a compensation-band determining unit that determines a band of a compensation subject which is a high-frequency component to be compensated based on an interval range of the high-frequency components divided by the high-frequency component detecting unit; a high-frequency component compensating unit that acquires a difference value by subtracting a power corresponding to the band of the compensation subject from a power corresponding to an adjacent band, acquires a change rate by dividing the difference value by a bandwidth of the band of the compensation subject, acquires an energy of a subdivided band by dividing the power corresponding to the band of the compensation subject by the bandwidth of the band of the compensation subject, acquires a compensating power by adding the energy of the subdivided band to a value which is computed by multiplying the change rate by a frequency change within the band of the compensation subject, and compensates the compensation subject in accordance with the compensating power; and a decoding unit that decodes the low-frequency component decoded from the first encoded data, and the high-frequency components compensated by the high-frequency component compensating unit, into the audio signal.</p></layer>
<layer id = "layer479"><p><b>US8738373B2:Frame signal correcting method and apparatus without distortion</b><br>A portable media storage device is provided. The device includes persistent digital storage programmed to contain digital media content. Two or more connectors of different types can be provided for engagement with a variety of electronic reader devices. The media storage devices can be sold at retail, alongside alternative traditional formats for consumption of the same media.<br><b>Independant Claims</b><br>1) A signal processing apparatus comprising: a processor and a memory storing program code, the processor executing the program code to implement: a first means that converts a first frame signal of a predetermined length to which a predetermined window function is performed into a frequency spectrum signal; a second means that performs a noise suppressing to the frequency spectrum signal to generate a noise suppressed frequency spectrum signal; a third means that converts the noise suppressed frequency spectrum signal into a second frame signal of a time domain by adjusting a predetermined correcting signal having a same frame length as the second frame signal so that amplitudes of both ends of the correcting signal substantially become equal to amplitudes of both or one of the frame ends of the second frame signal, a fourth means that provides a corrected frame signal before frame synthesizing by subtracting the adjusted correcting signal from the second frame signal, so that amplitudes of both or one of the frame ends of the second frame signal are made zero, wherein the correcting signal is made by adding time domain signals each having a different frequency component, in which a frequency component of a waveform function of the added correcting signal corresponds to a low frequency component to be corrected in the second frame signal.<br>7) A signal processing apparatus comprising: a processor and a memory storing program code, the processor executing the program code to implement: a first means that converts a first frame signal of a predetermined length to which a predetermined window function is performed into a frequency spectrum signal; a second means that performs a noise suppressing to the frequency spectrum signal to generate a noise suppressed frequency spectrum signal; a third means that converts the noise suppressed frequency spectrum signal into a second frame signal of a time domain; and a fourth means that calculates an amplitude correction amount given by a square root of a difference between a power of a signal obtained by removing amplitudes of both or one of the frame ends of the second frame signal from the second frame signal and by a power of the noise suppressed frequency spectrum signal, and further calculates a corrected amplitude component for a low frequency component or a direct current component of the noise suppressed frequency spectrum signal by adding the amplitude correction amount to the low frequency component or the direct current component of the noise suppressed frequency spectrum signal, and converts the corrected amplitude component into a corrected frame signal of a time domain before frame synthesizing, wherein the corrected amplitude component is utilized to generate a correcting signal is made by adding time domain signals each having a different frequency component, in which a frequency component of a waveform function of the added correcting signal corresponds to a low frequency component to be corrected in the second frame signal.</p></layer>
<layer id = "layer480"><p><b>US9324333B2:Systems, methods, and apparatus for wideband encoding and decoding of inactive frames</b><br><b>Independant Claims</b><br>1) A method of processing an encoded speech signal in a decoder comprising a filter bank, said method comprising: receiving the encoded speech signal by the decoder; based on information from a first encoded frame of the encoded speech signal, obtaining a description of a spectral envelope of the first encoded frame of the encoded speech signal over (A) a first frequency band and (B) a second frequency band different than the first frequency band by the decoder; based on information from a second encoded frame of the encoded speech signal, obtaining a description of a spectral envelope of the second encoded frame of the encoded speech signal over the first frequency band by the decoder, wherein the first encoded frame and the second encoded frame are inactive frames; based on information from the first encoded frame, obtaining a description of a spectral envelope of the second encoded frame over the second frequency band by the decoder; and combining the obtained description of the spectral envelope of the second encoded frame over the first frequency band with the obtained description of the second encoded frame over the second frequency band to produce a decoded signal by the filter bank, wherein the first encoded frame is encoded according to a wideband coding scheme, wherein the second encoded frame is encoded according to a narrowband coding scheme, wherein the second encoded frame occurs after the first encoded frame, wherein the first encoded frame and the second encoded frame are not consecutive frames of the encoded speech signal, and wherein all frames of the encoded speech signal between the first encoded frame and the second encoded frame are inactive frames.<br>15) An apparatus for processing an encoded speech signal, said apparatus comprising: a speech decoder configured to: receive the encoded speech signal; obtain, based on information from a first encoded frame of the encoded speech signal, a description of a spectral envelope of first encoded frame of the encoded speech signal over (A) a first frequency band and (B) a second frequency band different than the first frequency band; obtain, based on information from a second encoded frame of the encoded speech signal, a description of a spectral envelope of the second encoded frame of the encoded speech signal over the first frequency band, wherein the first encoded frame and the second encoded frame are inactive frames; and obtain, based on information from the first encoded frame, a description of a spectral envelope of the second encoded frame over the second frequency band; and a filter bank configured to combine the obtained description of the spectral envelope of the second encoded frame over the first frequency band with the obtained description of the second encoded frame over the second frequency band to produce a decoded signal, wherein the first encoded frame is encoded according to a wideband coding scheme, wherein the second encoded frame is encoded according to a narrowband coding scheme, wherein the second encoded frame occurs after the first encoded frame, wherein the first encoded frame and the second encoded frame are not consecutive frames of the encoded speech signal, and wherein all frames of the encoded speech signal between the first encoded frame and the second encoded frame are inactive frames.<br>9) An apparatus for processing an encoded speech signal, said apparatus comprising: means for receiving the encoded speech signal; means for obtaining, based on information from a first encoded frame of the encoded speech signal, a description of a spectral envelope of the first encoded frame of the encoded speech signal over (A) a first frequency band and (B) a second frequency band different than the first frequency band; means for obtaining, based on information from a second encoded frame of the encoded speech signal, a description of a spectral envelope of the second encoded frame of the encoded speech signal over the first frequency band, wherein the first encoded frame and the second encoded frame are inactive frames; means for obtaining, based on information from the first encoded frame, a description of a spectral envelope of the second encoded frame over the second frequency band; and means for combining the obtained description of the spectral envelope of the second encoded frame over the first frequency band with the obtained description of the second encoded frame over the second frequency band to produce a decoded signal, wherein the first encoded frame is encoded according to a wideband coding scheme, wherein the second encoded frame is encoded according to a narrowband coding scheme, wherein the second encoded frame occurs after the first encoded frame, wherein the first encoded frame and the second encoded frame are not consecutive frames of the encoded speech signal, and wherein all frames of the encoded speech signal between the first encoded frame and the second encoded frame are inactive frames.</p></layer>
<layer id = "layer481"><p><b>US8612220B2:Quantization after linear transformation combining the audio signals of a sound scene, and related coder</b><br>Described herein are polarizing articles and methods of making the same. The methods are useful in preparing polarizing articles having high durability and increased polarizing efficiency. The polarizing articles are useful in any article where it is desirable to reduce or remove glare.<br><b>Independant Claims</b><br>7) A hardware quantization module that quantizes at least components each determined as a function of a plurality of audio signals of a sound scene and computable by applying a multichannel linear transformation to said audio signals, said hardware quantization module being adapted to: determine each of at least some of said components as a function of a plurality of audio signals of a sound scene by applying a multichannel linear transformation to said audio signals, wherein a quantization function applied to said components in a given frequency band is determined by testing a condition relating to at least one audio signal and depending at least on a comparison performed between: a psychoacoustic masking threshold relating to the audio signal in the given frequency band, and a value determined as a function of an inverse multichannel linear transformation and of errors of quantization of the components by said function on the given frequency band.<br>9) A non-transitory computer readable medium comprising computer instructions for execution on a processor that are to be installed in a quantization module, said instructions for implementing a method, the method comprising: determining each of at least some of said components as a function of a plurality of audio signals of a sound scene by applying a multichannel linear transformation to said audio signals, wherein a quantization function applied to said components in a given frequency band is determined by testing a condition relating to at least one audio signal and depending at least on a comparison performed between: a psychoacoustic masking threshold relating to the audio signal in the given frequency band, and a value determined as a function of an inverse multichannel linear transformation and of errors of quantization of the components by said function on the given frequency band.<br>10) Coded data, determined following the implementation of a quantization method, the method comprising: determining each of at least some of said components as a function of a plurality of audio signals of a sound scene by applying a multichannel linear transformation to said audio signals, wherein a quantization function applied to said components in a given frequency band is determined by testing a condition relating to at least one audio signal and depending at least on a comparison performed between: a psychoacoustic masking threshold relating to the audio signal in the given frequency band, and a value determined as a function of an inverse multichannel linear transformation and of errors of quantization of the components by said function on the given frequency band.<br>1) A method for quantizing components, the method comprising: determining each of at least some of said components as a function of a plurality of audio signals of a sound scene by applying a multichannel linear transformation to said audio signals, wherein a quantization function applied to said components in a given frequency band is determined by testing a condition relating to at least one audio signal and depending at least on a comparison performed between: a psychoacoustic masking threshold relating to the audio signal in the given frequency band, and a value determined as a function of an inverse multichannel linear transformation and of errors of quantization of the components by said function on the given frequency band.</p></layer>
<layer id = "layer482"><p><b>US8725499B2:Systems, methods, and apparatus for signal change detection</b><br>The invention generally relates to systems and methods for transferring ions for analysis. In certain embodiments, the invention provides a system for analyzing a sample including an ionizing source for converting molecules of a sample into gas phase ions in a region at about atmospheric pressure, an ion analysis device, and an ion transfer member operably coupled to a gas flow generating device, in which the gas flow generating device produces a laminar gas flow that transfers the gas phase ions through the ion transfer member to an inlet of the ion analysis device.<br><b>Independant Claims</b><br>1) A method of processing a speech signal, said method comprising: generating, by a sequence generator of a computer, a sequence of spectral tilt values that is based on a plurality of inactive frames of the speech signal, wherein the sequence of spectral tilt values comprises a sequence of reflection coefficients, wherein each of the spectral tilt values is based on at least one reflection coefficient of a corresponding inactive frame of the speech signal, the at least one reflection coefficient comprising at least one of a first reflection coefficient of the corresponding inactive frame or a second reflection coefficient of the corresponding inactive frame; calculating, by a calculator of the computer, a change among at least two of the reflection coefficient-based spectral tilt values; and for an inactive frame among the plurality of inactive frames, deciding, by a comparator of the computer, whether to transmit a description for the frame, wherein said deciding whether to transmit a description for the frame is based on the calculated change.<br>24) A non-transitory computer-readable medium, said medium comprising instructions that when executed cause at least one computer to: generate a sequence of spectral tilt values that is based on a plurality of inactive frames of a speech signal, wherein the sequence of spectral tilt values comprises a sequence of reflection coefficients, wherein each of the spectral tilt values is based on at least one reflection coefficient of a corresponding inactive frame of the speech signal, the at least one reflection coefficient comprising at least one of a first reflection coefficient of the corresponding inactive frame or a second reflection coefficient of the corresponding inactive frame; calculate a change among at least two of the reflection coefficient-based spectral tilt values; and decide, for an inactive frame among the plurality of inactive frames, and based on the calculated change, whether to transmit a description for the frame.<br>33) An apparatus for processing a speech signal, said apparatus comprising: a sequence generator configured to generate a sequence of spectral tilt values that is based on a plurality of inactive frames of the speech signal, wherein the sequence of spectral tilt values comprises a sequence of reflection coefficients, wherein each of the spectral tilt values is based on at least one reflection coefficient of a corresponding inactive frame of the speech signal, the at least one reflection coefficient comprising at least one of a first reflection coefficient of the corresponding inactive frame or a second reflection coefficient of the corresponding inactive frame; a calculator configured to calculate a change among at least two of the reflection coefficient-based spectral tilt values; and a comparator configured to decide, for an inactive frame among the plurality of inactive frames, and based on the calculated change, whether to transmit a description for the frame.<br>41) An apparatus for processing a speech signal, said apparatus comprising: means for generating a sequence of spectral tilt values that is based on a plurality of inactive frames of the speech signal, wherein the sequence of spectral tilt values comprises a sequence of reflection coefficients, wherein each of the spectral tilt values is based on at least one reflection coefficient of a corresponding inactive frame of the speech signal, the at least one reflection coefficient comprising at least one of a first reflection coefficient of the corresponding inactive frame or a second reflection coefficient of the corresponding inactive frame; means for calculating a change among at least two of the reflection coefficient-based spectral tilt values; and means for deciding, for an inactive frame among the plurality of inactive frames, and based on the calculated change, whether to transmit a description for the frame.<br>46) A method of processing a speech signal, said method comprising: generating, by a sequence generator of a computer, a sequence of spectral tilt values that is based on a plurality of inactive frames of the speech signal, wherein the sequence of spectral tilt values comprises a sequence of reflection coefficients, wherein each of the spectral tilt values is based on at least one reflection coefficient of a corresponding inactive frame of the speech signal, the at least one reflection coefficient comprising at least one of a first reflection coefficient of the corresponding inactive frame or a second reflection coefficient of the corresponding inactive frame; calculating, by a calculator of the computer, a change among at least two of the reflection coefficient-based spectral tilt values; and for an inactive frame among the plurality of inactive frames, deciding, by a comparator of the computer, whether to transmit a description for the frame, wherein said deciding whether to transmit a description for the frame is based on the calculated change, and wherein said generating a sequence of spectral tilt values comprises, for at least some of the plurality of inactive frames, generating a corresponding spectral tilt value among the sequence of spectral tilt values according to a distance in time between the inactive frame and a preceding active frame of the speech signal.</p></layer>
<layer id = "layer483"><p><b>US8849656B2:System enhancement of speech signals</b><br>A furniture glide includes an upper portion for mounting to a furniture leg and a lower portion having a plow base. The plow base includes a lower pad segment having an outer wall that extends downwardly to a bottom sliding surface for sliding on a floor. The outer wall is substantially perpendicular to the sliding surface, forming a sharp outer edge that acts as a plow when the furniture glide is slid along the floor to push dirt or other debris out of the path of the furniture glide. In another embodiment the lower portion of the glide is a two-piece sub-assembly which includes a mounting member having vibration absorbing and/or sound deadening properties.<br><b>Independant Claims</b><br>1) A signal processing method comprising: detecting a speaker's utterance by at least one first microphone to obtain a first microphone signal; detecting the speaker's utterance by at least one second microphone to obtain a second microphone signal wherein the second microphone detects less interference from a source of interference as compared to the first microphone; determining a signal-to-noise ratio of the first microphone signal; and synthesizing at least one part of the first microphone signal for which the determined signal-to-noise ratio is below a predetermined level based on the second microphone signal.<br>16) A non-transitory computer-readable storage medium that stores instructions that, when executed by processor, cause the processor to enhance speech communication by executing software that causes the following acts comprising: detecting a speaker's utterance by at least one first microphone to obtain a first microphone signal; detecting the speaker's utterance by at least one second microphone to obtain a second microphone signal, wherein the second microphone detects less interference from a source of interference as compared to the first microphone; determining a signal-to-noise ratio of the first microphone signal; and synthesizing at least one part of the first microphone signal for which the determined signal-to-noise ratio is below a predetermined level based on the second microphone signal.</p></layer>
<layer id = "layer484"><p><b>US20080004869A1:Audio Encoder, Audio Decoder and Audio Processor Having a Dynamically Variable Warping Characteristic</b><br>An analyzing apparatus is described, a representative one of which includes: rotatable table arranged with a plurality of holes for accommodating the reaction container which includes a specimen and a reagent; and a container transferring section, arranged on the rotatable table, for transferring the reaction container.<br><b>Independant Claims</b><br>1. Audio encoder for encoding an audio signal, comprising: a pre-filter for generating a pre-filtered audio signal, the pre-filter having a variable warping characteristic, the warping characteristic being controllable in response to a time-varying control signal, the control signal indicating a small or no warping characteristic or a comparatively high warping characteristic; a controller for providing the time-varying control signal, the time-varying control signal depending on the audio signal; and a controllable encoding processor for processing the pre-filtered audio signal to obtain an encoded audio signal, wherein the encoding processor is adapted to process the pre-filtered audio signal in accordance with a first coding algorithm adapted to a specific signal pattern, or in accordance with a second different encoding algorithm suitable for encoding a general audio signal.<br>25. Audio decoder for decoding an encoded audio signal, the encoded audio signal having a first portion encoded in accordance with a first coding algorithm adapted to a specific signal pattern, and having a second portion encoded in accordance with a different second coding algorithm suitable for encoding a general audio signal, comprising: a detector for detecting a coding algorithm underlying the first portion or the second portion; a decoding processor for decoding, in response to the detector, the first portion using the first coding algorithm to obtain a first decoded time portion and for decoding the second portion using the second coding algorithm to obtain a second decoded time portion; and a post-filter having a variable warping characteristic being controllable between a first state having a small or no warping characteristic and a second state having a comparatively high warping characteristic.<br>43. Encoded audio signal having a first-time portion encoded in accordance with a first coding algorithm adapted to a specific signal pattern, and having a second time portion encoded in accordance with a different second coding algorithm suitable for encoding a general audio signal.<br>45. Method of encoding an audio signal, comprising: generating a pre-filtered audio signal, the pre-filter having a variable warping characteristic, the warping characteristic being controllable in response to a time-varying control signal, the control signal indicating a small or no warping characteristic or a comparatively high warping characteristic; providing the time-varying control signal, the time-varying control signal depending on the audio signal; and processing the pre-filtered audio signal to obtain an encoded audio signal, in accordance with a first coding algorithm adapted to a specific signal pattern, or in accordance with a second different encoding algorithm suitable for encoding a general audio signal.<br>46. Method of decoding an encoded audio signal, the encoded audio signal having a first portion encoded in accordance with a first coding algorithm adapted to a specific signal pattern, and having a second portion encoded in accordance with a different second coding algorithm suitable for encoding a general audio signal, comprising: detecting a coding algorithm underlying the first portion or the second portion; decoding, in response to the step of detecting, the first portion using the first coding algorithm to obtain a first decoded time portion and decoding the second portion using the second coding algorithm to obtain a second decoded time portion; and post-filtering using a variable warping characteristic being controllable between a first state having a small or no warping characteristic and a second state having a comparatively high warping characteristic.<br>47. Audio processor for processing an audio signal, comprising: a filter for generating a filtered audio signal, the filter having a variable warping characteristic, the warping characteristic being controllable in response to a time-varying control signal, the control signal indicating a small or no warping characteristic or a comparatively high warping characteristic; and to a time-varying control signal, the control signal indicating a small or no warping characteristic or a comparatively high warping characteristic; and a controller for providing the time-varying control signal the time-varying control signal depending on the audio signal.<br>48. Method of processing an audio signal, comprising: generating a filtered audio signal using a filter, the filter having a variable warping characteristic, the warping characteristic being controllable in response to a time-varying control signal, the control signal indicating a small or no warping characteristic or a comparatively high warping characteristic; and providing the time-varying control signal, the time-varying control signal depending on the audio signal.</p></layer>
<layer id = "layer485"><p><b>US8364492B2:Apparatus, method and program for giving warning in connection with inputting of unvoiced speech</b><br>A novel maize variety designated X95A825A and seed, plants and plant parts thereof, produced by crossing Pioneer Hi-Bred International, Inc. proprietary inbred maize varieties. Methods for producing a maize plant that comprises crossing hybrid maize variety X95A825A with another maize plant. Methods for producing a maize plant containing in its genetic material one or more traits introgressed into X95A825A through backcross conversion and/or transformation, and to the maize seed, plant and plant part produced thereby. This invention relates to the maize variety X95A825A, the seed, the plant produced from the seed, and variants, mutants, and minor modifications of maize variety X95A825A. This invention further relates to methods for producing maize varieties derived from maize variety X95A825A.<br><b>Independant Claims</b><br>9) A method for receiving an unvoiced speech, the method comprising: receiving a signal from an unvoiced speech input device that receives an unvoiced speech; receiving a signal from an ordinary speech input device that receives an ordinary speech; determining whether or not the signal received from the unvoiced speech input device is an ordinary speech, using the signal received from the unvoiced speech input device and the signal received from the ordinary speech input device; and outputting an alarm, when it is determined that an ordinary speech is input, wherein in determining that an ordinary speech is input, the method comprises: determining whether or not the signal received from the unvoiced speech input device is an ordinary speech, based on a power of the signal received from the unvoiced speech input device and a power of the signal received from the ordinary speech input device, determining whether or not the signal received from the unvoiced speech input device is an ordinary speech, based on a value of an autocorrelation function of the signal received from the unvoiced speech input device, in case the power of the signal received from the unvoiced speech input device and the power of the signal received from the ordinary speech input device are respectively greater than or equal to preset first and second threshold values, determining whether or not the signal received from the unvoiced speech input device is an ordinary speech, based on a value of a cross correlation function between the signal received from the unvoiced speech input device and the signal received from the ordinary speech input device, in case the value of the autocorrelation function of the signal received from the unvoiced speech input device is greater than or equal to a preset third threshold value, and determining that the signal received from the unvoiced speech input device is an ordinary speech, in case the value of the cross correlation function between the signal received from the unvoiced speech input device and the signal received from the ordinary speech input device is greater than or equal to a preset fourth threshold value.<br>10) A non-transitory computer readable medium comprising instructions that causes a computer composing an unvoiced speech receiving apparatus to execute the processing of: receiving a signal from an unvoiced speech input device and a signal from an ordinary speech input device; determining, using the signal received from the unvoiced speech input device and the signal received from the ordinary speech input device, whether or not the signal received from the unvoiced speech input device is an ordinary speech; and outputting an alarm, when it is determined that an ordinary speech is input, wherein the processing of determining that an ordinary speech is input comprises: determining whether or not the signal received from the unvoiced speech input device is an ordinary speech, based on a power of the signal received from the unvoiced speech input device and a power of the signal received from the ordinary speech input device, determining whether or not the signal received from the unvoiced speech input device is an ordinary speech, based on a value of an autocorrelation function of the signal received from the unvoiced speech input device, in case the power of the signal received from the unvoiced speech input device and the power of the signal received from the ordinary speech input device are respectively greater than or equal to preset first and second threshold values, determining whether or not the signal received from the unvoiced speech input device is an ordinary speech, based on a value of a cross correlation function between the signal received from the unvoiced speech input device and the signal received from the ordinary speech input device, in case the value of the autocorrelation function of the signal received from the unvoiced speech input device is greater than or equal to a preset third threshold value, and determining that the signal received from the unvoiced speech input device is an ordinary speech, in case the value of the cross correlation function between the signal received from the unvoiced speech input device and the signal received from the ordinary speech input device is greater than or equal to a preset fourth threshold value.<br>1) An apparatus for giving an alarm in connection with inputting unvoiced speech, the apparatus comprising: an input unit including an unvoiced speech input device that receives an unvoiced speech, and an ordinary speech input device that receives an ordinary speech; a decision unit that determines whether or not a signal received from the unvoiced speech input device is an ordinary speech, using a signal received from the unvoiced speech input device and a signal received from the ordinary speech input device; and, an alarm unit that outputs an alarm, when a result of the decision made by the decision unit indicates that an ordinary speech is input, wherein the decision unit determines whether or not the signal received from the unvoiced speech input device is an ordinary speech, based on a power of the signal received from the unvoiced speech input device and a power of the signal received from the ordinary speech input device, the decision unit determines whether or not the signal received from the unvoiced speech input device is an ordinary speech, based on a value of an autocorrelation function of the signal received from the unvoiced speech input device, in case the power of the signal received from the unvoiced speech input device and the power of the signal received from the ordinary speech input device are respectively greater than or equal to preset first and second threshold values, the decision unit determines whether or not the signal received from the unvoiced speech input device is an ordinary speech, based on a value of a cross correlation function between the signal received from the unvoiced speech input device and the signal received from the ordinary speech input device, in case the value of the autocorrelation function of the signal received from the unvoiced speech input device is greater than or equal to a preset third threshold value, and the decision unit determines that the signal received from the unvoiced speech input device is an ordinary speech, in case the value of the cross correlation function between the signal received from the unvoiced speech input device and the signal received from the ordinary speech input device is greater than or equal to a preset fourth threshold value.</p></layer>
<layer id = "layer486"><p><b>US8239190B2:Time-warping frames of wideband vocoder</b><br>An exercise device is provided with a frame assembly including an inclined first leg including a stop member proximate a bottom end, and a mounting member at a top end; and an inclined second leg and including a support tube, a sliding tube slidably put on the support tube and having a top end pivotably secured to the mounting member, and a resilient detent in the support tube for locking the sliding and support tubes before and after length adjustment of the second leg; two opposite handlebars; and a sliding assembly including a sliding member slidably mounted on the first leg and being capable of sliding in a range from a position proximate the mounting member to the stop member, a left knee rest secured to left side of the sliding member, and a right knee rest secured to right side of the sliding member.<br><b>Independant Claims</b><br>1) A method of communicating speech, comprising: time-warping a residual low band speech signal to an expanded or compressed version of the residual low band speech signal; time-warping a high band speech signal to an expanded or compressed version of the high band speech signal, wherein the time-warping of the high band speech signal comprises: determining a plurality of pitch periods from the residual low band speech signal; overlap/adding one or more pitch periods of the high band speech signal if the high band speech signal is compressed, using the pitch periods from the residual low band speech signal; and overlap/adding or repeating one or more pitch periods of the high band speech signal if the high band speech signal is expanded, using the pitch periods from the residual low band speech signal; and merging a synthesized version of the time-warped residual low band and the time-warped high band speech signals to give an entire time-warped speech signal.<br>17) A vocoder having at least one input and at least one output, comprising: an encoder comprising a filter having at least one input operably connected to the input of the vocoder and at least one output; and a decoder comprising: a synthesizer having at least one input operably connected to the at least one output of the encoder and at least one output operably connected to the at least one output of the vocoder; and a memory, wherein the decoder is adapted to execute software instructions stored in the memory comprising: time-warping a residual low band speech signal to an expanded or compressed version of the residual low band speech signal; time-warping a high band speech signal to an expanded or compressed version of the high band speech signal, wherein the time-warping software instruction of the high band speech signal comprises: determining a plurality of pitch periods from the residual low band speech signal, overlap/adding one or more pitch periods of the high band speech signal if the high band speech signal is compressed, using the pitch periods from the residual low band speech signal; and overlap/adding or repeating one or more pitch periods of the high band speech signal if the high band speech signal is expanded, using the pitch periods from the residual low band speech signal; and merging a synthesized version the time-warped residual low band and the time-warped high band speech signals to give an entire time-warped speech signal.<br>35) An apparatus configured to communicate speech, said apparatus comprising: means for time-warping a residual low band speech signal to an expanded or compressed version of the residual low band speech signal; means for time-warping a high band speech signal to an expanded or compressed version of the high band speech signal, wherein the time-warping of the high band speech signal comprises: means for determining a plurality of pitch periods from the residual low band speech signal; means for overlapping/adding one or more pitch periods of the high band speech signal if the high band speech signal is compressed, using the pitch periods from the residual low band speech signal; and means for overlapping/adding or repeating one or more pitch periods of the high band speech signal if the high band speech signal is expanded, using the pitch periods from the residual low band speech signal; and means for merging a synthesized version of the time-warped residual low band and the time-warped high band speech signals to give an entire time-warped speech signal.</p></layer>
<layer id = "layer487"><p><b>US8532984B2:Systems, methods, and apparatus for wideband encoding and decoding of active frames</b><br>The present invention is directed to sufficiently reduce the level of EMI which occurs from a switching FET in a DC/DC converter and minimize deterioration in efficiency of a power supply. A DC/DC converter includes a switching circuit for driving a switching FET for increasing or decreasing voltage, and a switching circuit for driving a ringing frequency changing circuit. One end of a capacitor is connected to a drain of the switching FET for increasing or decreasing voltage, and the other end of the capacitor is connected to a drain of an FET for the ringing frequency changing circuit. A source of the FET for the ringing frequency changing circuit is connected to GND, and a control circuit is provided which makes the ringing frequency changing circuit valid so that a ringing frequency becomes low only in a ringing frequency component exerting large influence on deterioration in EMI.<br><b>Independant Claims</b><br>13) An apparatus for processing a speech signal, said apparatus comprising: means for producing, based on a first active frame of the speech signal, a first speech packet that includes a description of a spectral envelope, over (A) a first frequency band and (B) a second frequency band that extends above the first frequency band, of a portion of the speech signal that includes the first active frame; means for producing, based on a second active frame of the speech signal that occurs in the speech signal immediately after said first active frame, a second speech packet that includes a description of a spectral envelope, over the first frequency band, of a portion of the speech signal that includes the second active frame; and means for producing an encoded frame that contains (A) the second speech packet and (B) a burst of an information signal that is separate from the speech signal, wherein the second speech packet does not include a description of a spectral envelope over the second frequency band.<br>33) A non-transitory computer-readable medium, said medium comprising: code for causing at least one computer to obtain, based on information from a first speech packet from an encoded speech signal, a description of a spectral envelope of a first frame of a speech signal over (A) a first frequency band and (B) a second frequency band different than the first frequency band; code for causing at least one computer to obtain, based on information from a second speech packet from the encoded speech signal, a description of a spectral envelope of a second frame of the speech signal over the first frequency band; code for causing at least one computer to calculate, based on information from an encoded frame of the encoded speech signal, a burst of an information signal that is separate from the speech signal, wherein the encoded frame includes the second speech packet; and code for causing at least one computer to obtain, based on a presence of the burst in the encoded frame, and based on information from the first speech packet, a description of a spectral envelope of the second frame over the second frequency band; and code for causing at least one computer to obtain, based on information from the second speech packet, information relating to a pitch component of the second frame for the first frequency band.<br>44) A method of processing a speech signal, said method comprising: based on a first frame of the speech signal, generating a rate selection signal that indicates a wideband coding scheme; based on information from a mask file, generating a dimming control signal; based on a state of the dimming control signal that corresponds to the first frame, overriding the wideband coding scheme selection to select a narrowband coding scheme; and encoding the first frame according to the narrowband coding scheme.<br>16) A non-transitory computer-readable medium, said medium comprising: code for causing at least one computer to produce, based on a first active frame of the speech signal, a first speech packet that includes a description of a spectral envelope, over (A) a first frequency band and (B) a second frequency band that extends above the first frequency band, of a portion of the speech signal that includes the first active frame; code for causing at least one computer to produce, based on a second active frame of the speech signal that occurs in the speech signal immediately after said first active frame, a second speech packet that includes a description of a spectral envelope, over the first frequency band, of a portion of the speech signal that includes the second active frame; and code for causing at least one computer to produce an encoded frame that contains (A) the second speech packet and (B) a burst of an information signal that is separate from the speech signal, wherein the second speech packet does not include a description of a spectral envelope over the second frequency band.<br>27) An apparatus for processing speech packets, said apparatus comprising: means for obtaining, based on information from a first speech packet from an encoded speech signal, a description of a spectral envelope of a first frame of a speech signal over (A) a first frequency band and (B) a second frequency band different than the first frequency band; means for obtaining, based on information from a second speech packet from the encoded speech signal, a description of a spectral envelope of a second frame of the speech signal over the first frequency band; means for obtaining, based on information from an encoded frame of the encoded speech signal, a burst of an information signal that is separate from the speech signal, wherein the encoded frame includes the second speech packet; and means for obtaining, based on a presence of the burst in the encoded frame, and based on information from the first speech packet, a description of a spectral envelope of the second frame over the second frequency band; and means for obtaining, based on information from the second speech packet, information relating to a pitch component of the second frame for the first frequency band.<br>37) A speech decoder configured to calculate a decoded speech signal based on an encoded speech signal, said speech decoder comprising: control logic configured to generate a control signal comprising a sequence of values that is based on coding indices of speech packets from the encoded speech signal, each value of the sequence corresponding to a frame period of the decoded speech signal; and a packet decoder configured (A) to calculate, in response to a value of the control signal having a first state, a corresponding decoded frame based on a description of a spectral envelope of the decoded frame over (1) a first frequency band and (2) a second frequency band that extends above the first frequency band, the description being based on information from a speech packet from the encoded speech signal, and (B) to calculate, in response to a value of the control signal having a second state different than the first state, a corresponding decoded frame based on (1) a description of a spectral envelope of the decoded frame over the first frequency band, the description being based on information from a speech packet from the encoded speech signal, and (2) a description of a spectral envelope of the decoded frame over the second frequency band, the description being based on information from at least one speech packet that occurs in the encoded speech signal before the speech packet, wherein said control logic is configured to set a value of the control signal to have the second state if a corresponding frame of the encoded speech signal includes a burst of an information signal that is separate from the decoded speech signal, and wherein at least one among said control logic and said packet decoder includes a processor.<br>18) A method of processing speech packets, said method comprising: based on information from a first speech packet from an encoded speech signal, obtaining a description of a spectral envelope of a first frame of a speech signal over (A) a first frequency band and (B) a second frequency band different than the first frequency band; based on information from a second speech packet from the encoded speech signal, obtaining a description of a spectral envelope of a second frame of the speech signal over the first frequency band; obtaining, from an encoded frame of the encoded speech signal, a burst of an information signal that is separate from the speech signal, wherein the encoded frame includes the second speech packet; and based on a presence of the burst in the encoded frame, and based on information from the first speech packet, obtaining a description of a spectral envelope of the second frame over the second frequency band; and based on information from the second speech packet, obtaining information relating to a pitch component of the second frame for the first frequency band.<br>1) A method of processing a speech signal, said method comprising: based on a first active frame of the speech signal, producing a first speech packet that includes a description of a spectral envelope, over (A) a first frequency band and (B) a second frequency band that extends above the first frequency band, of a portion of the speech signal that includes the first active frame; based on a second active frame of the speech signal that occurs in the speech signal immediately after said first active frame, producing a second speech packet that includes a description of a spectral envelope, over the first frequency band, of a portion of the speech signal that includes the second active frame; and producing an encoded frame that contains (A) the second speech packet and (B) a burst of an information signal that is separate from the speech signal, wherein the second speech packet does not include a description of a spectral envelope over the second frequency band.<br>11) A speech encoder, said speech encoder comprising: a packet encoder configured to produce (A), based on a first active frame of a speech signal and in response to a first state of a rate control signal, a first speech packet that includes a description of a spectral envelope over (1) a first frequency band and (2) a second frequency band that extends above the first frequency band and (B), based on a second active frame of the speech signal and in response to a second state of the rate control signal different than the first state, a second speech packet that includes a description of a spectral envelope over the first frequency band; and a frame formatter arranged to receive the first and second speech packets and configured to produce (A), in response to a first state of a dimming control signal, a first encoded frame that contains the first speech packet and (B), in response to a second state of the dimming control signal different than the first state, a second encoded frame that contains the second speech packet and a burst of an information signal that is separate from the speech signal, wherein the first and second encoded frames have the same length, the first speech packet occupies at least eighty percent of the first encoded frame, and the second speech packet occupies not more than half of the second encoded frame, and wherein said second active frame occurs immediately after said first active frame in the speech signal, and wherein the second speech packet does not include a description of a spectral envelope over the second frequency band, and wherein at least one among said packet encoder and said frame formatter includes a processor.</p></layer>
<layer id = "layer488"><p><b>US8706507B2:Arbitrary shaping of temporal noise envelope without side-information utilizing unchanged quantization</b><br>A non-breakable display device, electronic appliance, or lighting device is provided. A bendable display device in which a first flexible substrate and a second flexible substrate provided with transistors overlap each other with a bonding layer therebetween is fabricated. The display device is bent so that the first substrate is positioned on the inner side (the valley side) and the second substrate is positioned on the outer side (the mountain side).<br><b>Independant Claims</b><br>1) A digital audio transform encoding method employing transform blocks for encoding a discrete time-domain signal, the method employing quantization of a frequency-domain representation of the discrete time-domain signal, comprising deriving (20, 22), in the frequency domain, a measure of frequency-domain quantization error (E(k)), filtering (24), in the frequency domain, the measure of quantization error to produce a filtered measure of quantization error, and applying (26), in the frequency domain, the filtered measure of quantization error as a feedback signal to the frequency-domain representation of the discrete time-domain signal prior to frequency-domain quantization (20), whereby the filtering parameters of said filtering affect the temporal shaping of quantization noise within a transform block and with unchanged quantization so as to have an arbitrary shape in the time domain resolution when the quantized frequency-domain representation of the discrete time-domain signal is inversely transformed from the frequency domain back to the time domain.<br>12) A method for frequency-domain noise-feedback quantizing in a digital audio transform encoder employing transform blocks, comprising combining (26) a frequency domain signal derived from a time-domain audio signal with a frequency-domain noise feedback signal to generate a frequency-domain quantizer input signal, quantizing (20) the frequency domain quantizer input signal to generate a frequency-domain quantizer output signal, combining (22) the frequency-domain quantizer input signal and the frequency-domain quantizer output signal to generate a frequency-domain quantization error signal, and filtering (24) the frequency-domain quantization error signal to generate the frequency -domain noise feedback signal for affecting the temporal shaping of quantization noise within a transform block and with unchanged quantizing resolution as to have an arbitrary shape in the time domain.<br>18) A frequency-domain noise-feedback quantizer for use in a digital audio transform encoder employing transform blocks, comprising a first combiner (26) that combines a frequency-domain signal derived from a time-domain audio signal with a frequency-domain noise feedback signal to generate a frequency domain quantizer input signal, a quantizer (20) that quantizes the frequency-domain quantizer input signal to generate a frequency-domain quantizer output signal, a second combiner (22) that combines the frequency-domain quantizer input signal and the frequency-domain quantizer output signal to generate a quantization error signal, and a noise feedback filter (24) that filters the frequency-domain quantization error signal to generate the frequency-domain noise feedback signal for affecting the temporal shape of quantization noise within a transform block and with unchanged quantizer resolution so as to have an arbitrary shape in the time domain.</p></layer>
<layer id = "layer489"><p><b>US9076453B2:Methods and arrangements in a telecommunications network</b><br><b>Independant Claims</b><br>1) A method for controlling a postfilter for improving perceived quality of speech reconstructed at a speech decoder, the method comprises the steps of: measuring, using a processor, stationarity of a speech signal reconstructed at a decoder, by determining a spectral distance between adjacent frames of the speech signal, adaptively determining, using the processor, a coefficient to a postfilter control parameter, such that when the spectral distance is determined to be high, a degree of deemphasizing of spectral valleys in a spectral envelope of the reconstructed speech signal is reduced compared with a situation when the spectral distance is determined to be low, and transmitting, using the processor, the determined coefficient to the postfilter, such that the postfilter can process the reconstructed speech signal by applying the determined coefficient to the postfilter control parameter to obtain an enhanced speech signal.<br>11) A postfilter control apparatus to be associated with a postfilter for improving perceived quality of speech reconstructed at a speech decoder, the postfilter control apparatus comprises: a postfilter processor; a non-transitory computer-readable storage medium, coupled to the postfilter processor, said non-transitory computer-readable storage medium further comprising computer-readable instructions, when executed by the postfilter processor, are configured for: measuring stationarity of a speech signal reconstructed at the speech decoder by determining a spectral distance between adjacent frames of the speech signal adaptively determining a coefficient to a postfilter control parameter, such that when a spectral distance is determined to be high, a degree of deemphasizing of spectral valleys in a spectral envelope of the reconstructed speech signal is reduced compared with a situation when a spectral distance is determined to be low, and transmitting the determined coefficient to a postfilter, such that the postfilter can process the reconstructed speech signal by applying the determined coefficient to the postfilter control parameter to obtain an enhanced speech signal.<br>16) A postfilter for improving perceived quality of speech reconstructed at a speech decoder, the postfilter comprises: a processor for receiving a determined coefficient to the postfilter from a postfilter control apparatus, wherein the postfilter control apparatus is configured to measure stationarity of a speech signal reconstructed at the speech decoder by determining a spectral distance between adjacent frames of the speech signal and adaptively determining a coefficient to a postfilter control parameter, such that when a spectral distance is determined to be high, a degree of deemphasizing of spectral valleys in a spectral envelope of the reconstructed speech signal is reduced compared with a situation when a spectral distance is determined to be low, and a processor for processing the reconstructed speech signal by applying the determined coefficient to the postfilter control parameter to obtain an enhanced speech signal.<br>6) A method in a postfilter for improving perceived quality of speech reconstructed at a speech decoder, the method comprises the steps of: receiving, using a processor, a determined coefficient to the postfilter from a postfilter control apparatus, where the postfilter control apparatus is configured to measure stationarity of a speech signal reconstructed at the speech decoder by determining a spectral distance between adjacent frames of the speech signal, and adaptively determining a coefficient to a postfilter control parameter, such that when a spectral distance is determined to be high, a degree of deemphasizing of spectral valleys in a spectral envelope of the reconstructed speech signal is reduced compared with a situation when a spectral distance is determined to be low, and processing, using the processor, the reconstructed speech signal by applying the determined coefficient to the postfilter control parameter to obtain an enhanced speech signal.</p></layer>
<layer id = "layer490"><p><b>US20080033718A1:Classification-Based Frame Loss Concealment for Audio Signals</b><br>An audio system is provided that comprises a headphone for reading music information or the like recorded in a memory card attached to an external interface to reproduce audio signal and for outputting sound conforming to the audio signal; and a remote control unit for transmitting control signal for controlling reproduction function or the like of the music information of the headphone to the headphone due to infrared rays. In the audio system, the control signal of infrared rays of less data amount compared with the audio signal or the like is transmitted. Accordingly, circuit configuration and component configuration can be made simpler, the remote control unit can be downsized, and the headphone and the remote control unit can be made wireless, resulting in an easier handling.<br><b>Independant Claims</b><br>1. A method for performing frame loss concealment (FLC) in an audio decoder, comprising: performing a first analysis on a previously-decoded portion of an audio signal; classifying a lost frame as either speech or music based on the results of the first analysis; performing a second analysis on the previously-decoded portion of the audio signal; and selecting either a first FLC technique or a second FLC technique for replacing the lost frame based on the classification and the results of the second analysis.<br>10. A system for performing frame loss concealment (FLC) in an audio decoder, comprising: a signal classifier configured to perform a first analysis on a previously-decoded portion of an audio signal and to classify a lost frame as either speech or music based on the results of the first analysis; and decision logic coupled to the signal classifier, the decision logic configured to perform a second analysis on the previously-decoded portion of the audio signal and to select either a first FLC technique or a second FLC technique for replacing the lost frame based on the classification and the results of the second analysis.<br>19. A method for performing frame loss concealment in an audio decoder, comprising: (a) generating an extrapolated signal comprising a plurality of audio samples, wherein generating each sample of the extrapolated signal comprises: (i) extrapolating an audio sample based on a previously-received frame of an audio signal and a pitch period; and (ii) simultaneously with the extrapolation, overlap-adding a sample from an audio fade-out signal provided by the decoder; and (b) using the extrapolated signal to produce a replacement frame.<br>22. A system for performing frame loss concealment in an audio decoder, comprising: (a) first logic configured to generate an extrapolated signal comprising a plurality of audio samples, wherein generating each sample of the extrapolated signal comprises extrapolating an audio sample based on a previously-received frame of an audio signal and a pitch period and simultaneously with the extrapolation, overlap-adding a sample from an audio fade-out signal provided by the decoder; and (b) second logic configured to use the extrapolated signal to produce a replacement frame.</p></layer>
<layer id = "layer491"><p><b>US9009048B2:Method, medium, and system detecting speech using energy levels of speech frames</b><br><b>Independant Claims</b><br>1) A speech recognition method, comprising: detecting, using at least one processing device, energy changes between a plurality of frames distinguishing portions of a signal, each of the plurality of frames having time lengths less than a whole time length of the signal; and identifying speech segments and/or non-speech segments from the plurality of frames based on the detected energy changes between the plurality of frames by assigning a predetermined weight to a segment in which an energy level of a respective frame is changed and when an energy difference exists between two neighboring frames.<br>11) At least one non-transitory recording medium comprising computer readable code to control at least one processing element to implement a speech recognition method, comprising: detecting, using at least one processing device, energy changes between a plurality of frames distinguishing portions of a signal, each of the plurality of frames having time lengths less than a whole time length of the signal; and identifying speech segments and/or non-speech segments from the plurality of frames based on the detected energy changes between the plurality of frames by assigning a predetermined weight to a segment in which an energy level of a respective frame is changed and when an energy difference exists between two neighboring frames.<br>12) A speech recognition system including at least one processing device, the system comprising: a change detector to detect, using the at least one processing device, energy changes between a plurality of frames distinguishing portions of a signal, each of the plurality of frames having lengths less than a whole time length of the signal; and a determiner to identify speech segments and/or non-speech segments from the plurality of frames based on the detected energy changes between the plurality of frames by assigning a predetermined weight to a segment in which an energy level of a respective frame is changed and when an energy difference exists between two neighboring frames.<br>18) A speech recognition system, comprising: an A/D converter to convert an analog input signal including speech and/or non-speech signals transmitted through an audio transducer into a digital input signal; a frame generator to generate a plurality of frames corresponding to the digital input signal; a phoneme detector to generate a phoneme sequence from the frames; a vocabulary recognition device to extract a phoneme sequence most similar to the phoneme detector generated phoneme sequence from a dictionary that stores reference phoneme sequences; a speech segment detection device including a determiner to detect energy changes between the frames distinguishing portions of the signal, each of the frames having time lengths less than a whole time length of the signal, and to identify a speech segment from the frames based on the detected energy changes between the frames by assigning a predetermined weight to a segment in which an energy level of a respective frame is changed and when an energy difference exists between two neighboring frames; and a phoneme sequence editor to edit the phoneme detector generated phoneme sequence based on information on speech segments provided from the speech segment detection device.</p></layer>
<layer id = "layer492"><p><b>US8214206B2:Constrained and controlled decoding after packet loss</b><br>Radio network resources are dynamically optimized based on the type of user equipment. A method, a radio network node, a core network node and a computer program product are provided for managing radio resources in a radio access network formed of cells and having terminals connected to it. A radio resource management action is performed based on determined terminal type information. In particular, the terminal type is a smartphone. The radio resource management action includes load balancing between cells and/or network tuning.<br><b>Independant Claims</b><br>1) A method for reducing audible artifacts in an audio output signal generated by decoding a received frame in a series of frames representing an encoded audio signal in a predictive coding system, comprising: determining if the received frame is one of a predefined number of received frames that follow a lost frame in the series of the frames; altering from a state associated with normal decoding at least one parameter or signal associated with the decoding of the received frame responsive to determining that the received frame is one of the predefined number of received frames, wherein the at least one parameter or signal relates to a scale factor associated with an adaptive quantizer, a stability margin for a low-band pole section of an adaptive predictor, a partial reconstructed signal, or a reconstructed signal; decoding the received frame in accordance with the at least one parameter or signal to generate a decoded audio signal; and generating the audio output signal based on the decoded audio signal.<br>16) A system for reducing audible artifacts in an audio output signal generated by decoding a received frame in a series of frames representing an encoded audio signal in a predictive coding system, comprising: constraint and control logic configured to determine if the received frame is one of a predefined number of received frames that follow a lost frame in the series of the frames and to alter from a state associated with normal decoding at least one parameter or signal associated with the decoding of the received frame responsive to determining that the received frame is one of the predefined number of received frames, wherein the at least one parameter or signal relates to a scale factor associated with an adaptive quantizer, a stability margin for a low-band pole section of an adaptive predictor, a partial reconstructed signal, or a reconstructed signal; a decoder configured to decode the bit stream in accordance with the at least one parameter or signal to generate a decoded audio signal; and logic configured to generate the audio output signal based on the decoded audio signal.<br>31) A computer program product comprising a computer-readable storage device having computer program logic recorded thereon for enabling a processor to reduce audible artifacts in an audio output signal generated by decoding a received frame in a series of frames representing an encoded audio signal in a predictive coding system, the computer program logic comprising: first means for enabling the processor to determine if the received frame is one of a predefined number of received frames that follow a lost frame in the series of the frames; second means for enabling the processor to alter from a state associated with normal decoding at least one parameter or signal associated with the decoding of the received frame responsive to determining that the received frame is one of the predefined number of received frames, wherein the at least one parameter or signal relates to a scale factor associated with an adaptive quantizer, a stability margin for a low-band pole section of an adaptive predictor, a partial reconstructed signal, or a reconstructed signal; third means for enabling the processor to decode the received frame in accordance with the at least one parameter or signal to generate a decoded audio signal; and fourth means for enabling the processor to generate the audio output signal based on the decoded audio signal.</p></layer>
<layer id = "layer493"><p><b>US8346546B2:Packet loss concealment based on forced waveform alignment after packet loss</b><br>Disclosed herein is a topical therapeutic composition and method for the palliative treatment of irritated or inflamed perianal tissue. The therapeutic composition comprises olive oil and tea tree oil. The palliative treatment of the invention involves application of the composition to irritated or inflamed perianal tissue. The composition and method of the invention can be employed in the palliative treatment of such human maladies as hemorrhoids, fissures and pruritis ani.<br><b>Independant Claims</b><br>17) A method for concealing a lost segment in a speech or audio signal that comprises a series of segments, the method comprising: determining if one or more segments that follow the lost segment in the series of segments are available; if one or more segments that follow the lost segment in the series of segments are available, determining if the segment that precedes the lost segment and the first of the one or more segments that follow the lost segments are deemed voiced segments; performing packet loss concealment using periodic waveform extrapolation based on a segment that precedes the lost segment in the series of segments and on the one or more segments that follow the lost segment responsive to a determination that the one or more segments that follow the lost segment are available and to a determination that the segment that precedes the lost segment and the first of the one or more segments that follow the lost segment are deemed voiced segments; and performing packet loss concealment using waveform extrapolation based on the segment that precedes the lost segment but not on any segments that follow the lost segment responsive to a determination that the one or more segments that follow the lost segment are not available or to a determination that either the segment that precedes the lost segment or the first of the one or more segments that follow the lost segment is not deemed a voiced segment; wherein at least one of the determining or performing steps is performed by a processor.<br>9) A computer program product comprising a computer-readable storage unit having computer program logic recorded thereon for enabling a processor to conceal a lost segment in a speech or audio signal that comprises a series of segments, the computer program logic comprising: first means for enabling the processor to generate an extrapolated waveform based on a segment that precedes the lost segment in the series of segments and on one or more segments that follow the lost segment in the series of segments; second means for enabling the processor to generate a replacement waveform for the lost segment based on a first portion of the extrapolated waveform; and third means for enabling the processor to overlap-add a second portion of the extrapolated waveform with a decoded waveform associated with the one or more segments following the lost segment in the series of segments; wherein the first means comprises: means for enabling the processor to perform a first-pass periodic waveform extrapolation using a pitch period associated with the segment that precedes the lost segment to generate a first-pass extrapolated waveform; means for enabling the processor to identify a time lag between the first-pass extrapolated waveform and the decoded waveform associated with the one or more segments that follow the lost segment; means for enabling the processor to calculate a pitch contour based on the identified time lag; and means for enabling the processor to perform a second-pass periodic waveform extrapolation using the pitch contour to generate the extrapolated waveform.<br>1) A method for concealing a lost segment in a speech or audio signal that comprises a series of segments, the method comprising: (a) generating an extrapolated waveform based on a segment that precedes the lost segment in the series of segments and on one or more segments that follow the lost segment in the series of segments; (b) generating a replacement waveform for the lost segment based on a first portion of the extrapolated waveform; and (c) overlap-adding a second portion of the extrapolated waveform with a decoded waveform associated with the one or more segments following the lost segment in the series of segments; wherein step (a) comprises: performing a first-pass periodic waveform extrapolation using a pitch period associated with the segment that precedes the lost segment to generate a first-pass extrapolated waveform; identifying a time lag between the first-pass extrapolated waveform and the decoded waveform associated with the one or more segments that follow the lost segment; calculating a pitch contour based on the identified time lag; and performing a second-pass periodic waveform extrapolation using the pitch contour to generate the extrapolated waveform; and wherein at least one of steps (a), (b) and (c) is performed by a processor.<br>18) A computer program product comprising a computer-readable storage unit having computer program logic recorded thereon for enabling a processor to conceal a lost segment in a speech or audio signal that comprises a series of segments, the computer program logic comprising: first means for enabling the processor to determine if one or more segments that follow the lost segment in the series of segments are available; second means for enabling the processor to determine if the segment that precedes the lost segment and the first of the one or more segments that follow the lost segments are deemed voiced segments if one or more segments that follow the lost segment in the series of segments are available; third means for enabling the processor to perform packet loss concealment using periodic waveform extrapolation based on a segment that precedes the lost segment in the series of segments and on the one or more segments that follow the lost segment responsive to a determination that the one or more segments that follow the lost segment are available and to a determination that the segment that precedes the lost segment and the first of the one or more segments that follow the lost segment are deemed voiced segments; and fourth means for enabling the processor to perform packet loss concealment using waveform extrapolation based on the segment that precedes the lost segment but not on any segments that follow the lost segment responsive to a determination that the one or more segments that follow the lost segment are not available or to a determination that either the segment that precedes the lost segment or the first of the one or more segments that follow the lost segment is not deemed a voiced segment.</p></layer>
<layer id = "layer494"><p><b>US8271270B2:Method, apparatus and system for encoding and decoding broadband voice signal</b><br>Provided are processes for making multi-layer chip carriers comprising an asymmetric cross-linked polymeric dielectric film.<br><b>Independant Claims</b><br>1) A method performed on a coding apparatus, the method comprising: extracting a linear prediction coefficient (LPC) from a broadband voice signal; removing, using a processor of the coding apparatus, an envelope from the broadband voice signal using the LPC to obtain a linear prediction (LP) residual signal; pitch-searching a spectrum of the LP residual signal; extracting a plurality of spectral magnitudes and phases of the LP residual signal, which correspond to a damping factor, by adding the damping factor to a matching pursuit algorithm; obtaining, from among the extracted plurality of spectral magnitudes and phases, a first spectral magnitude and a first phase at which a power value of the LP residual signal is minimized; and quantizing the first spectral magnitude and the first phase, wherein the damping factor is determined according to a ratio of a parameter of a current frame to a parameter of a previous frame, and wherein the extracting the plurality of spectral magnitudes and phases of the LP residual signal comprises: setting a plurality of candidate frequencies derived from the frequencies obtained by pitch-searching the LP residual signal using the frequency damping factor; calculating a sinusoidal dictionary value by obtaining, from among the plurality of candidate frequencies, a frequency and a phase at which an error value is minimized, with respect to each frequency obtained by pitch-searching, and accumulating the sinusoidal dictionary value calculated with respect to each frequency obtained by pitch-searching; generating a final residual signal by subtracting the accumulated sinusoidal dictionary value from a target signal, which is the LP residual signal; and detecting a frequency damping factor which corresponds to the first spectral magnitude and the first phase at which a power value of the final residual signal is minimized with respect to each frequency obtained by pitch-searching.<br>13) An encoder for encoding a broadband voice signal in a broadband voice encoding system, the encoder including at least one central processing unit (CPU), the encoder comprising: a linear prediction coefficient (LPC) analyzer which extracts, using the at least one CPU, an LPC from the broadband voice signal; an LPC inverse filter which outputs a linear prediction (LP) residual signal obtained by removing an envelope from the broadband voice signal using the LPC; a pitch searching unit which pitch-searches a spectrum of the LP residual signal; a sinusoidal analyzer which extracts a plurality of spectral magnitudes and phases of the LP residual signal, which correspond to a damping factor, by adding the damping factor to a matching pursuit algorithm, and obtains a first spectral magnitude and a first phase, at which a power value of the LP residual signal is minimized, from among the extracted plurality of spectral magnitudes and phases; and a phase and spectral magnitude quantizer which quantizes the first spectral magnitude and the first phase, wherein the damping factor is determined according to a ratio of a parameter of a current frame to a parameter of a previous frame, and wherein the sinusoidal analyzer comprises: a frequency damping factor application unit which sets a plurality of candidate frequencies derived from the frequencies obtained by pitch-searching the LP residual signal using the frequency damping factor; an error minimization unit which obtains a frequency and a phase, at which an error value is minimized, from among the plurality of candidate frequencies with respect to each frequency obtained by pitch-searching; a dictionary component generator which obtains a sinusoidal dictionary value based on the frequency and the phase output from the error minimization unit; an accumulator which receives the sinusoidal dictionary value generated with respect to each frequency obtained by pitch-searching the dictionary component generator and accumulates the sinusoidal dictionary value; a calculator which generates a final residual signal by subtracting the accumulated sinusoidal dictionary value from the LP residual signal; and a damping factor selector which detects a frequency damping factor which corresponds to the first spectral magnitude and the first phase at which a power value of the final residual signal is minimized with respect to each frequency obtained by pitch-searching.<br>22) A broadband voice encoding and decoding system comprising: a broadband voice encoder which includes at least one central processing unit (CPU) and obtains a linear prediction (LP) residual signal by removing an envelope from a broadband voice signal using a linear prediction coefficient (LPC) extracted from the broadband voice signal, extracts a plurality of spectral magnitudes and phases of the LP residual signal, which correspond to a damping factor, by adding the damping factor to a matching pursuit algorithm, obtains a first spectral magnitude and a first phase, at which a power value of the LP residual signal is minimized, from among the extracted plurality of spectral magnitudes and phases, and quantizes the first spectral magnitude and the first phase, wherein the damping factor is determined according to a ratio of a parameter of a current frame to a parameter of a previous frame; and a broadband voice decoder which decodes the broadband voice signal by decoding the quantized first spectral magnitude, the quantized first phase, and the quantized damping factor and synthesizing the LP residual signal, and wherein the extracting the plurality of spectral magnitudes and phases of the LP residual signal of the broadband voice encoder comprises: setting a plurality of candidate frequencies derived from the frequencies obtained by pitch-searching the LP residual signal using the frequency damping factor; calculating a sinusoidal dictionary value by obtaining, from among the plurality of candidate frequencies, a frequency and a phase at which an error value is minimized, with respect to each frequency obtained by pitch-searching, and accumulating the sinusoidal dictionary value calculated with respect to each frequency obtained by pitch-searching; generating a final residual signal by subtracting the accumulated sinusoidal dictionary value from a target signal, which is the LP residual signal; and detecting a frequency damping factor which corresponds to the first spectral magnitude and the first phase at which a power value of the final residual signal is minimized with respect to each frequency obtained by pitch-searching.<br>23) A non-transitory computer readable storage medium storing a computer readable program for executing a method comprising: extracting a linear prediction coefficient (LPC) from the broadband voice signal; removing an envelope from the broadband voice signal using the LPC to obtain a linear prediction (LP) residual signal; pitch-searching a spectrum of the LP residual signal; extracting a plurality of spectral magnitudes and phases of the LP residual signal, which correspond to a damping factor, by adding the damping factor to a matching pursuit algorithm; obtaining, from among the extracted plurality of spectral magnitudes and phases, a first spectral magnitude and a first phase at which a power value of the LP residual signal is minimized; and quantizing the first spectral magnitude and the first phase, wherein the damping factor is determined according to a ratio of a parameter of a current frame to a parameter of a previous frame, and wherein the extracting the plurality of spectral magnitudes and phases of the LP residual signal comprises: setting a plurality of candidate frequencies derived from the frequencies obtained by pitch-searching the LP residual signal using the frequency damping factor; calculating a sinusoidal dictionary value by obtaining, from among the plurality of candidate frequencies, a frequency and a phase at which an error value is minimized, with respect to each frequency obtained by pitch-searching, and accumulating the sinusoidal dictionary value calculated with respect to each frequency obtained by pitch-searching; generating a final residual signal by subtracting the accumulated sinusoidal dictionary value from a target signal, which is the LP residual signal; and detecting a frequency damping factor which corresponds to the first spectral magnitude and the first phase at which a power value of the final residual signal is minimized with respect to each frequency obtained by pitch-searching.</p></layer>
<layer id = "layer495"><p><b>US8239191B2:Speech encoding apparatus and speech encoding method</b><br>A virtual business mobile device can be provisioned on a personal mobile device, by binding a mobile application for provisioning the business mobile device to a privileged component of a host operating system of the personal mobile device, wherein the binding enables a hypervisor component and a management service component of the mobile application to execute in a privileged mode. The mobile application is then able to download a virtual phone image for the business mobile device and security-related policy settings relating to use of the business mobile device from a mobile management server, wherein the hypervisor component is able to launch a virtual machine for the business mobile device based on the virtual phone image. Once the virtual phone image has been downloaded, the management service component initiates a periodic attempt to establish a connection with the mobile management server to comply with the downloaded security-related policy settings.<br><b>Independant Claims</b><br>1) A speech encoding apparatus comprising: a linear prediction analyzing section that performs a linear prediction analysis with respect to a speech signal to generate a linear prediction coefficient; a quantizing section that quantizes the linear prediction coefficient; a perceptual weighting section that performs perceptual weighting filtering with respect to an input speech signal to generate a perceptual weighted speech signal using a transfer function including a tilt compensation coefficient for adjusting a spectral slope of a quantization noise; a tilt compensation coefficient control section that controls the tilt compensation coefficient using a signal to noise ratio of the speech signal in a first frequency band; and an excitation search section that performs an excitation search of an adaptive codebook and fixed codebook to generate an excitation signal using the perceptual weighted speech signal.<br>12) A speech encoding apparatus comprising: a linear prediction analyzing section that performs a linear prediction analysis with respect to a speech signal to generate a linear prediction coefficient; a quantizing section that quantizes the linear prediction coefficient; a perceptual weighting section that performs perceptual weighting filtering with respect to an input speech signal to generate a perceptual weighted speech signal using a transfer function including a tilt compensation coefficient for adjusting a spectral slope of a quantization noise; and a weight coefficient control section that controls a weight coefficient forming a linear prediction inverse filter that performs perceptual weighting filtering with respect to an input speech signal in the perceptual weighting section, using the signal to noise ratio of the speech signal, wherein the weight coefficient control section comprises: an energy calculating section that calculates an energy of the speech signal; a noise period energy calculating section that calculates an energy of a noise period in the speech signal; and a calculating section that calculates an adjustment coefficient and calculates the weight coefficient by multiplying a linear prediction coefficient of a noise period in the speech signal by an adjustment coefficient, the adjustment coefficient increasing when the signal to noise ratio of the speech signal is equal to or greater than a first threshold and the signal to noise ratio of the speech signal is higher, and decreasing when the signal to noise ratio of the speech signal is less than the first threshold and the signal to noise ratio of the speech signal is lower.<br>14) A speech encoding method comprising the steps of: performing a linear prediction analysis with respect to a speech signal to generate a linear prediction coefficient; quantizing the linear prediction coefficient; performing perceptual weighting filtering with respect to an input speech signal to generate a perceptual weighted speech signal using a transfer function including a tilt compensation coefficient for adjusting a spectral slope of a quantization noise; controlling the tilt compensation coefficient using a signal to noise ratio in a first frequency band of the speech signal; and performing an excitation search of an adaptive codebook and fixed codebook to generate an excitation signal using the perceptual weighted speech signal.</p></layer>
<layer id = "layer496"><p><b>US20080010062A1:ADAPTIVE ENCODING AND DECODING METHODS AND APPARATUSES</b><br>An anti-static structure applied to a computer includes a chassis made of conductive material, a main board secured to the chassis having a CPU electrically connected thereto, a heat sink arranged on the CPU having a top surface, and a static transmission wire electrically connecting the top surface of the heat sink to the main board.<br><b>Independant Claims</b><br>1. An adaptive encoding method comprising: splitting an input signal into a low-frequency band signal and a high-frequency band signal; performing forward adaptive linear prediction on the low-frequency band signal and thus filtering the low-frequency band signal; selectively performing backward adaptive linear prediction or long-term prediction on the filtered low-frequency band signal according to an analysis result of the low-frequency band signal; transforming the low-frequency band signal, on which backward adaptive linear prediction or long-term prediction has been performed, into a signal in a frequency domain and quantizing the signal; and encoding the high-frequency band signal using the low-frequency band signal, on which backward adaptive linear prediction or long-term prediction has been performed, or the quantized signal.<br>7. A computer-readable recording medium having recorded thereon a program to execute an adaptive encoding method, the method comprising: splitting an input signal into a low-frequency band signal and a high-frequency band signal; performing forward adaptive linear prediction on the low-frequency band signal and thus filtering the low-frequency band signal; selectively performing backward adaptive linear prediction or long-term prediction on the filtered low-frequency band signal according to an analysis result of the low-frequency band signal; transforming the low-frequency band signal, on which backward adaptive linear prediction or long-term prediction has been performed, into a signal in a frequency domain and quantizing the signal; and encoding the high-frequency band signal using the low-frequency band signal, on which backward adaptive linear prediction or long-term prediction has been performed, or the quantized signal.<br>13. An adaptive decoding method comprising: inversely quantizing a quantized low-frequency band signal and inversely transforming the inversely quantized low-frequency band signal into a signal in a time domain; synthesizing a result of backward adaptive linear prediction or long-term prediction with the signal in the time domain if an encoding end has performed backward adaptive linear prediction or long-term prediction; synthesizing a result of forward adaptive linear prediction of the encoding end with a signal obtained after the synthesizing of the result of backward adaptive linear prediction or long-term prediction with the signal in the time domain; and decoding a high-frequency band signal using the result of long-term prediction or the result of synthesizing the result of forward adaptive linear prediction of the encoding end with the signal.<br>18. A computer-readable recording medium having recorded thereon a program to execute adaptive decoding method, the method comprising: inversely quantizing a quantized low-frequency band signal and inversely transforming the inversely quantized low-frequency band signal into a signal in a time domain; synthesizing a result of backward adaptive linear prediction or long-term prediction with the signal in the time domain if an encoding end has performed backward adaptive linear prediction or long-term prediction; synthesizing a result of forward adaptive linear prediction of the encoding end with a signal obtained after the synthesizing of the result of backward adaptive linear prediction or long-term prediction with the signal in the time domain; and decoding a high-frequency band signal using the result of long-term prediction or the result of synthesizing the result of forward adaptive linear prediction of the encoding end with the signal.<br>23. An adaptive encoding method comprising: performing forward adaptive linear prediction on an input signal and thus filtering the input signal; selectively performing backward adaptive linear prediction or long-term prediction on the filtered signal according to an analysis result of the input signal; and transforming the input signal, on which backward adaptive linear prediction or long-term prediction has been performed, into a signal in a frequency domain and quantizing the signal.<br>24. A computer-readable recording medium having stored thereon a program to execute an adaptive encoding method, the method comprising: performing forward adaptive linear prediction on an input signal and thus filtering the input signal; selectively performing backward adaptive linear prediction or long-term prediction on the filtered signal according to an analysis result of the input signal; and transforming the input signal, on which backward adaptive linear prediction or long-term prediction has been performed, into a signal in a frequency domain and quantizing the signal.<br>25. An adaptive decoding method comprising: inversely quantizing an input signal quantized by an encoding end and inversely transforming the inversely quantized signal into a signal in a time domain; synthesizing a result of backward adaptive linear prediction or long-term prediction with the signal in the time domain if the encoding end has performed backward adaptive linear prediction or long-term prediction; synthesizing a result of forward adaptive linear prediction of the encoding end with a signal obtained after the synthesizing of the result of backward adaptive linear prediction or long-term prediction with the signal in the time domain.<br>26. A computer-readable recording medium having stored thereon a program to execute an adaptive decoding method, the method comprising inversely quantizing an input signal quantized by an encoding end and inversely transforming the inversely quantized signal into a signal in a time domain; synthesizing a result of backward adaptive linear prediction or long-term prediction with the signal in the time domain if the encoding end has performed backward adaptive linear prediction or long-term prediction; synthesizing a result of forward adaptive linear prediction of the encoding end with a signal obtained after the synthesizing of the result of backward adaptive linear prediction or long-term prediction with the signal in the time domain.<br>27. An adaptive encoding apparatus comprising: a band splitting unit to split an input signal into a low-frequency band signal and a high-frequency band signal; a forward adaptive linear prediction (FA-LP) filtering unit to perform forward adaptive linear prediction on the low-frequency band signal and thus filtering the low-frequency band signal; a selective performance unit to selectively perform backward adaptive linear prediction or long-term prediction on the filtered low-frequency band signal according to an analysis result of the low-frequency band signal; a transform encoding unit to transform the low-frequency band signal, on which backward adaptive linear prediction or long-term prediction has been performed, into a signal in a frequency domain and quantizing the signal; and a high-frequency band encoding unit to encode the high-frequency band signal using the low-frequency band signal, on which backward adaptive linear prediction or long-term prediction has been performed, or the quantized signal.<br>33. An adaptive decoding apparatus comprising: an inverse quantization/inverse transform unit inversely quantizing a quantized low-frequency band signal and inversely transforming the inversely quantized low-frequency band signal into a signal in a time domain; a first synthesis unit synthesizing a result of backward adaptive linear prediction or long-term prediction with the signal in the time domain if an encoding end has performed backward adaptive linear prediction or long-term prediction; a second synthesis unit synthesizing a result of forward adaptive linear prediction of the encoding end with an output of the first synthesis unit; and a high-frequency band decoding unit decoding a high-frequency band signal using the result of long-term prediction or an output of the second synthesis unit.<br>38. An adaptive encoding apparatus comprising: an FA-LP filtering unit to perform forward adaptive linear prediction on an input signal and thus filter the input signal; a selective performance unit to selectively perform backward adaptive linear prediction or long-term prediction on the filtered signal according to an analysis result of the input signal; and a transform encoding unit to transform the input signal, on which backward adaptive linear prediction or long-term prediction has been performed, into a signal in a frequency domain and to quantize the signal.<br>39. An adaptive decoding apparatus comprising: an inverse quantization/inverse transform unit to inversely quantize an input signal quantized by an encoding end and to inversely transform the inversely quantized signal into a signal in a time domain; a first synthesis unit to synthesize a result of backward adaptive linear prediction or long-term prediction with the signal in the time domain if the encoding end has performed backward adaptive linear prediction or long-term prediction; a second synthesis unit to synthesize a result of forward adaptive linear prediction of the encoding end with a signal obtained after the synthesizing of the result of backward adaptive linear prediction or long-term prediction with the signal in the time domain.<br>40. A speech and music signal processing system to process a speech or music signal, the processing system comprising: an encoding unit to encode an input signal according to determined characteristics of the input signal; and a decoding unit to decode the encoded signal according to determined characteristics of the input signal.<br>41. A method of processing speech and music signals, the method comprising: encoding an input signal according to determined characteristics of the input signal; and decoding the encoded signal according to determined characteristics of the input signal.</p></layer>
<layer id = "layer497"><p><b>US20080140391A1:Method for Varying Speech Speed</b><br>In an embodiment, techniques for sustaining session connections are provided. The techniques send heartbeat messages when not sending a message may cause the session connection to close because of a timeout condition. Heartbeat messages are valid transport layer messages that will be ignored by protocols at higher levels of a data communications stack. As an example, the techniques may send a TCP message containing only a carriage return and line feed (“CRLF”) in its payload. Because the TCP layer considers a message containing only a CRLF to be a valid TCP message, intermediary computing devices such as proxy servers may not interpret heartbeat messages as “keep alive” messages, and may sustain session connections.<br><b>Independant Claims</b><br>1. A method for varying speech speed, comprising the steps of: receiving an original speech signal; calculating a pitch period of the original speech signal; defining search ranges according to the pitch period; finding a maximum within each of the search ranges of the original speech signal; dividing the original speech signal into a plurality of speech sections according to the maxima; obtaining a speed-varied speech signal by applying a speed-varying algorithm to each of the speech sections according to a speed-varying command; and outputting the speed-varied speech signal.</p></layer>
<layer id = "layer498"><p><b>US8712765B2:Parameter decoding apparatus and parameter decoding method</b><br>An electronic device includes a power supply, a processor, a storage, and a detection circuit. The power supply provides driving voltage to the processor and the storage. The processor is capable of generating different instructions for processing the data stored in the storage. The detection circuit connected to the power supply and the processor detects whether the driving voltage is less than a reference voltage. When the driving voltage is less than the reference voltage, the detection circuit generates a control signal for controlling the processor to be disabled.<br><b>Independant Claims</b><br>1) A parameter decoding apparatus that includes a processor connected to a memory, the parameter decoding apparatus comprising: a prediction residue decoder that finds a quantized prediction residue based on encoded information included in a current frame subject to decoding, a moving-average predictor that produces a predicted parameter by multiplying a predictive coefficient with a past quantized prediction residue; and an adder that decodes a parameter by adding said quantized prediction residue and said predicted parameter, wherein said prediction residue decoder, when said current frame is erased, finds a current-frame quantized prediction residue from a weighted linear sum of a parameter decoded in the past and a future-frame quantized prediction residue.<br>3) A parameter decoding method comprising: finding a quantized prediction residue based on encoding information included in a current frame subject to decoding, producing a predicted parameter by multiplying a predictive coefficient with a past quantized prediction residue; and decoding a parameter by adding said quantized prediction residue and said predicted parameter, wherein, in the finding, when said current frame is erased, a current-frame quantized prediction residue is found from a weighted linear sum of a parameter decoded in the past and a future-frame quantized prediction residue, and wherein at least one of the finding, the producing and the decoding is performed by a processor.</p></layer>
<layer id = "layer499"><p><b>US8639500B2:Method, medium, and apparatus with bandwidth extension encoding and/or decoding</b><br>A printed wiring board including solder pads excellent in frequency characteristic is provided. To do so, each solder pad<b>73</b>is formed by providing a single tin layer<b>74</b>on a conductor circuit<b>158</b>or a via<b>160</b>. Therefore, a signal propagation rate can be increased, as compared with a printed wiring board of the prior art on which two metal layers are formed. In addition, due to lack of nickel layers, manufacturing cost can be decreased and electric characteristics can be enhanced.<br><b>Independant Claims</b><br>19) A bandwidth extension decoding apparatus comprising: a spectrum generator generating a spectrum for frequencies higher than a predetermined frequency of a signal, wherein the spectrum for the frequencies higher than the predetermined frequency is generated from a spectrum of an excitation signal extracted from the signal by removal of an envelope from low-frequencies of the signal; and a spectrum applying unit decoding a gain value, and applying the decoded gain value to the generated spectrum; and a processing unit processing the spectrum to which the gain value has been applied, based on a comparison of a tonality of the spectrum to which the gain value has been applied and a decoded tonality of a spectrum of a region, of the signal, whose frequencies are higher than the predetermined frequency, wherein the tonality of the spectrum to which the gain value has been applied is calculated by calculating a Spectral Flatness Measure (SFM) value of the spectrum to which the gain value has been applied and the tonality of the spectrum of the region is calculated by calculating a Spectral Flatness Measure (SFM) value of the spectrum of the region.<br>1) A bandwidth extension encoding method comprising: generating, using at least one processing device, a spectrum for frequencies higher than a predetermined frequency of a signal, wherein the spectrum for the frequencies higher than the predetermined frequency is generated from an extracted excitation signal of low-frequencies of the signal through a removal of an envelope from the low-frequencies of the signal; and comparing the generated spectrum with a spectrum of a region, of the signal, whose frequencies are higher than the predetermined frequency, to generate a gain value and adjusting the gain value based on a tonality analysis of the generated spectrum and the spectrum of the region, wherein the tonality analysis comprises comparing a tonality of the generated spectrum and a tonality of the spectrum of the region, the tonality being determined by calculating a Spectral Flatness Measure (SFM) value.<br>7) A bandwidth extension decoding method comprising: generating, using at least one processing device, a spectrum for frequencies higher than a predetermined frequency of a signal, wherein the spectrum for the frequencies higher than the predetermined frequency is generated from a spectrum of an excitation signal extracted from the signal by removal of an envelope from low-frequencies of the signal; and decoding a gain value, applying the gain value to the generated spectrum, and processing the spectrum to which the gain value has been applied, based on a comparison of a tonality of the spectrum to which the gain value has been applied and a decoded tonality of a spectrum of a region, of the signal, whose frequencies are higher than the predetermined frequency, wherein the tonality of the spectrum to which the gain value has been applied is calculated by calculating a Spectral Flatness Measure (SFM) value of the spectrum to which the gain value has been applied and the tonality of the spectrum of the region is calculated by calculating a Spectral Flatness Measure (SFM) value of the spectrum of the region.<br>9) A bandwidth extension decoding method comprising: removing, using at least one processing device, an envelope from a low-frequency signal wherein the low-frequency signal belongs to a frequency region whose frequencies are lower than a predetermined frequency to extract an excitation signal and transform the excitation signal to a frequency domain; generating a spectrum which belongs to a region whose frequencies are higher than the predetermined frequency by processing a spectrum of the excitation signal; decoding a gain value, and applying the gain value to the generated spectrum; decoding a tonality of a high-frequency signal corresponding to a region whose frequencies are higher than the predetermined frequency, wherein the tonality of the high-frequency signal is determined by calculating a Spectral Flatness Measure (SFM) value; calculating a tonality of the spectrum to which the gain value is applied, wherein calculating the tonality of the spectrum comprises calculating a Spectral Flatness Measure (SFM) value; comparing the tonality of the high-frequency signal with the tonality of the spectrum, and calculating an amount of noise that is to be added to the spectrum to which the gain value is applied, according to the result of the comparison; and adding the amount of noise to the spectrum to which the gain value is applied.<br>21) A bandwidth extension decoding apparatus comprising: an excitation signal extractor removing an envelope from a low-frequency signal wherein the low-frequency signal belongs to a frequency region whose frequencies are lower than a predetermined frequency, to extract an excitation signal, and transforming the excitation signal to a frequency domain; a spectrum generator generating a spectrum which belongs to a frequency region whose frequencies are higher than the predetermined frequency, by processing a spectrum of the transformed excitation signal; a spectrum applying unit decoding a gain value, and applying the decoded gain value to the generated spectrum; a tonality decoding unit decoding a tonality of a high-frequency signal corresponding to a region whose frequencies are higher than a predetermined frequency, wherein the tonality of the high-frequency signal is determined by calculating a Spectral Flatness Measure (SFM) value; a tonality calculating unit calculating a tonality of the spectrum to which the gain value is applied, wherein calculating the tonality of the spectrum comprises calculating a Spectral Flatness Measure (SFM) value; a noise calculating unit comparing the decoded tonality with the calculated tonality, and calculating an amount of noise that is to be added to the spectrum to which the gain value is applied; and a noise adding unit adding the amount of noise to the spectrum to which the gain value is applied.<br>31) A high frequency signal decoding method comprising: obtaining energy values of frequency spectrum from a received bitstream; generating a noise signal in units of frequency bands in consideration of the obtained energy values of frequency spectrum; generating a high frequency band by using a decoded low frequency band; and adding the noise signal to the high frequency band.<br>2) A bandwidth extension encoding method comprising: removing, using at least one processing device, an envelope from a low-frequency signal wherein the low-frequency signal belongs to a frequency region whose frequencies are lower than a predetermined frequency to extract an excitation signal from the low-frequency signal and transform the excitation signal to a frequency domain; generating a spectrum which belongs to a region whose frequencies are higher than the predetermined frequency by processing a spectrum of the excitation signal; comparing the generated spectrum with a spectrum of a high-frequency signal corresponding to the region whose frequencies are higher than the predetermined frequency, and calculating a gain value; calculating a tonality of the generated spectrum and a tonality of a spectrum of the high-frequency signal, and comparing the tonality of the generated spectrum with the tonality of the spectrum of the high-frequency signal, wherein calculating a tonality of a spectrum comprises calculating a Spectral Flatness Measure (SFM) value of the spectrum; and adjusting the gain value according to the result of the comparison.<br>13) A bandwidth extension encoding apparatus comprising: a spectrum generator generating a spectrum for frequencies higher than a predetermined frequency of a signal, wherein the spectrum for the frequencies higher than the predetermined frequency is generated from an extracted excitation signal of low-frequencies of the signal through a removal of an envelope from the low-frequencies of the signal; and a gain value calculator comparing a region, of the signal, whose frequencies are higher than the predetermined frequency, to generate a gain value and adjusting the gain value based on a tonality analysis of the generated spectrum and the spectrum of the region, wherein the tonality analysis comprises comparing a tonality of the generated spectrum and a tonality of the spectrum of the region, the tonality being determined by calculating a Spectral Flatness Measure (SFM) value.<br>14) A bandwidth extension encoding apparatus comprising: an excitation signal extractor removing an envelope from a low-frequency signal wherein the low-frequency signal belongs to a frequency region whose frequencies are lower than a predetermined frequency, to extract an excitation signal, and transforming the excitation signal to a frequency domain; a spectrum generator generating a spectrum which belongs to a frequency region whose frequencies are higher than the predetermined frequency, by processing a spectrum of the excitation signal; a gain value calculator comparing the generated spectrum with a spectrum of a high frequency signal corresponding to a region whose frequencies are higher than the predetermined frequency, and calculating a gain value; a tonality comparator calculating a tonality of the generated spectrum and a tonality of a spectrum of the high-frequency signal, and comparing the tonality of the generated spectrum with the tonality of the spectrum of the high-frequency signal, wherein calculating a tonality of a spectrum comprises calculating a Spectral Flatness Measure (SFM) value of the spectrum; and a gain value adjusting unit adjusting the gain value, according to the result of the comparison.</p></layer>
<layer id = "layer500"><p><b>US10325604B2:Frame error concealment method and apparatus and error concealment scheme construction method and apparatus</b><br><b>Independant Claims</b><br>3) An apparatus for concealing frame losses, the apparatus comprising:a receiving unit configured to receive an input signal including a current frame and a previous frame; andat least one processor configured to:if an error occurs in at least one of the current frame and the previous frame of the input signal received from the receiving unit, select an error concealment scheme for the current frame from among a plurality of error concealment schemes including a scheme related to repetition, based on a plurality of parameters including whether an error occurs in the previous frame and which error concealment scheme is selected in the previous frame;conceal the current frame, based on the selected error concealment scheme for the current frame; andgenerate a reconstructed signal based on at least the concealed current frame, as an output signal including at least one of audio characteristic and speech characteristic,wherein the input signal has one or a combination of audio characteristic and speech characteristic.<br>1) A method of concealing frame losses, the method comprising:receiving an input signal including a current frame and a previous frame;if an error occurs in at least one of the current frame and the previous frame, selecting, by at least one processing device, an error concealment scheme for the current frame from among a plurality of error concealment schemes including a scheme related to repetition, based on a plurality of parameters including whether an error occurs in the previous frame and which error concealment scheme is selected in the previous frame;concealing, by the at least one processing device, the current frame, based on the selected error concealment scheme for the current frame;generating a reconstructed signal based on at least the concealed current frame, as an output signal including at least one of audio characteristic and speech characteristic,wherein the input signal has one or a combination of audio characteristic and speech characteristic.</p></layer>
<layer id = "layer501"><p><b>US8280731B2:Noise variance estimator for speech enhancement</b><br>Modular spinal prosthesis having one of both of adaptable and configurable components are provided. The modular spinal prosthesis described herein provide an artificial articular configuration to replace damaged, worn or otherwise removed spinal facet elements.<br><b>Independant Claims</b><br>1) A method for enhancing speech components of an audio signal composed of speech and noise components, comprising transforming the audio signal from the time domain to a plurality of subbands in the frequency domain, wherein each of said plurality of subbands is presumed to have a speech component and a noise component, said noise component having an amplitude and a variance at time index m, wherein said amplitude of the noise component is estimated by exploiting statistical differences that distinguish between the speech component and the noise component, processing each of said plurality of subbands, said processing including applying a gain factor, wherein said gain factor is derived at least in part from an estimation of said variance in noise components, wherein the estimation comprises at each time index m, updating said estimation of variance in noise components of the subband signal from an average of past estimates of the amplitude of noise components in the subband signal, and wherein said past estimates of the amplitude of noise components in the subband signal having values greater than a threshold are excluded from or underweighted in said weighted average, and transforming the processed subband signal from the frequency domain to the time domain to provide an audio signal in which speech components are enhanced.</p></layer>
<layer id = "layer502"><p><b>US20050065782A1:Hybrid speech coding and system</b><br>A system and method for providing full-duplex data communications between an electric power distribution station and a power consumer via the power distribution line providing electric power is provided. A first information transmitter, coupled to the power distribution circuit, provides first information signals concurrently with the power signal to the power consumer via the power distribution line. A first information receiver, coupled to a power consumer device powered by the electrical power signal, receives the first information signals via the electric power distribution line. A second information transmitter coupled to the power consumer device provides second information signals concurrently with the electrical power signal. A second information receiver, coupled to the power distribution circuit, receives the second information signals via the electric power distribution line. The information signals transmitted on the power distribution line can be transmitted at a frequency lower than the frequency of the transmitted power signal.<br><b>Independant Claims</b><br>1. A method of encoding speech with, comprising: (a) encoding speech frames of a first mode with waveform coefficients; and (b) encoding speech frames of a second mode with magnitudes of waveform coefficient plus an alignment phase; (c) wherein said encoding of step (b) includes a second alignment phase for a frame of said second mode immediately following a frame of said first mode.</p></layer>
<layer id = "layer503"><p><b>US20080208575A1:Split-band encoding and decoding of an audio signal</b><br>A method and apparatus for deriving key characteristics for superior performance in a job includes deriving a set of behaviorally-related competencies relevant to most jobs, surveying persons knowledgeable about the job based on the set of competencies, and defining the job in terms of the most significant competencies identified by the surveys.<br><b>Independant Claims</b><br>1. A method comprising: determining a value representative of a background noise level in an audio signal that is to be encoded; determining a gain value for a higher frequency band of at least two frequency bands of the audio signal; and determining a correction factor for the determined gain value based on the determined value representative of the background noise level.<br>9. A method comprising: determining a gain value for a higher frequency band of at least two frequency bands of an audio signal based on a received codebook index; correcting the determined gain value based on a received correction factor for the gain value; and reconstructing the higher frequency band of the audio signal based on the corrected gain value.<br>10. An apparatus comprising: a determination component configured to determine a value representative of a background noise level in an audio signal that is to be encoded; a determination component configured to determine a gain value for a higher frequency band of at least two frequency bands of the audio signal; and a determination component configured to determine a correction factor for the determined gain value based on the determined value representative of the background noise level.<br>19. An apparatus comprising: a determination component configured to determine a gain value for a higher frequency band of at least two frequency bands of an audio signal based on a received codebook index; a correction component configured to correct the determined gain value based on a received correction factor for the gain value; and a reconstruction component configured to reconstruct the higher frequency band of the audio signal based on the corrected gain value.<br>31. An apparatus comprising: means for determining a value representative of a background noise level in an audio signal that is to be encoded; means for determining a gain value for a higher frequency band of at least two frequency bands of the audio signal; and means for determining a correction factor for the determined gain value based on the determined value representative of the background noise level.<br>32. An apparatus comprising: means for determining a gain value for a higher frequency band of at least two frequency bands of an audio signal based on a received codebook index; means for correcting the determined gain value based on a received correction factor for the gain value; and means for reconstructing the higher frequency band of the audio signal based on the corrected gain value.</p></layer>
<layer id = "layer504"><p><b>US20090299757A1:METHOD AND APPARATUS FOR ENCODING AND DECODING</b><br>Various embodiments of a computer-implemented method, system and computer program product maintain a cache in a distributed environment comprising a front-end server and a back-end server. One or more data sources are accessible to the back-end server. The front-end server and the back-end server support a first query language having more functionality than a second query language supported by a replication component. The data of the front-end cache is described at the front-end server using said first query language. A shadow cache that matches the front-end cache is created at the back-end server. The back-end server changes data in the shadow cache in response to changes in at least a portion of the data in one or more data sources. Data is replicated between the shadow cache and the front-end cache. The data that is replicated from the shadow cache to the front-end cache is described using the second query language.<br><b>Independant Claims</b><br>1-16. (canceled)<br>2) 1-16. (canceled)<br>3) 1-16. (canceled)<br>4) 1-16. (canceled)<br>5) 1-16. (canceled)<br>1-16. (canceled)<br>7) 1-16. (canceled)<br>8) 1-16. (canceled)<br>9) 1-16. (canceled)<br>10) 1-16. (canceled)<br>11) 1-16. (canceled)<br>12) 1-16. (canceled)<br>13) 1-16. (canceled)<br>14) 1-16. (canceled)<br>15) 1-16. (canceled)<br>1-16. (canceled)<br>17. An encoding method, comprising: obtaining, according to a data length of a first overlapped portion between encoding data of a current frame and encoding data of a previous frame, first encoding data corresponding to the data length of the first overlapped portion from the previous frame, if the previous frame is encoded in a first encoding mode and the current frame is to be encoded in a second encoding mode; and encoding, in the second encoding mode, the first encoding data corresponding to the data length of the first overlapped portion from the previous frame and encoding data of the current frame.<br>23. An encoding apparatus, comprising an encoding mode switching recognition unit, a previous encoding frame overlapped data obtaining unit, and a second encoding unit, wherein: the encoding mode switching recognition unit is configured to determine that a previous frame is encoded in a first encoding mode and a current frame is to be encoded in a second encoding mode; the previous encoding frame overlapped data obtaining unit is configured to obtain, according to a data length of a first overlapped portion between encoding data of the current frame and encoding data of the previous frame, first encoding data corresponding to the data length of the first overlapped portion from the previous frame, if the encoding mode switching recognition unit determines that the previous frame is encoded in the first encoding mode and the current frame is to be encoded in the second encoding mode; and the second encoding unit is configured to encode, in the second encoding mode, the first encoding data obtained by the previous encoding frame overlapped data obtaining unit and encoding data of the current frame.<br>26. A decoding method, comprising: decoding a received code stream, and when it is determined that a previous frame is decoded in a first decoding mode and a current frame is decoded in a second decoding mode, obtaining, according to a data length of a third overlapped portion between decoding data of the current frame and decoding data of the previous frame, third decoding data corresponding to the data length of the third overlapped portion from the decoding data of the previous frame; and overlapping the third decoding data and the decoding data of the current frame.<br>30. A decoding apparatus, comprising: a decoding mode switching recognition unit, a previous decoding frame overlapped data obtaining unit and a second decoding unit, wherein: the decoding mode switching recognition unit is configured to determine that a previous frame in a received code stream is decoded in a first decoding mode and a current frame in the received code stream is decoded in a second decoding mode; the previous decoding frame overlapped data obtaining unit is configured to obtain, according to a data length of a third overlapped portion between decoding data of the current frame and decoding data of the previous frame, third decoding data corresponding to the data length of the third overlapped portion from the decoding data of the previous frame, if the decoding mode switching recognition unit determines that the previous frame is decoded in the first decoding mode and the current frame is decoded in the second decoding mode; and the second decoding unit is configured to decode the received code stream, and to overlap the third decoding data obtained by the previous decoding frame overlapped data obtaining unit and decoding data of the current frame.<br>34. A system, comprising: an encoding apparatus, configured to obtain, according to a data length of a first overlapped portion between encoding data of a current frame and encoding data of a previous frame, first encoding data corresponding to the data length of the first overlapped portion from the previous frame, if the previous frame is encoded in the first encoding mode and the current frame is to be encoded in the second encoding mode, and to encode, in the second encoding mode, the first encoding data corresponding to the data length of the first overlapped portion from the previous frame and encoding data of the current frame, to output encoded code stream; a decoding apparatus, configured to decode a received code stream, and to obtain, according to a data length of a third overlapped portion between decoding data of a current frame and decoding data of a previous frame, third decoding data corresponding to the data length of the third overlapped portion from the decoding data of the previous frame, if the previous frame in the received code stream is decoded in the first decoding mode and the current frame in the received code stream is decoded in the second decoding mode; and to overlap the third decoding data and decoding data of the current frame.</p></layer>
<layer id = "layer505"><p><b>US8195450B2:Decoder with embedded silence and background noise compression</b><br>Some embodiments include methods of forming memory cells utilizing various arrangements of conductive lines, electrodes and programmable material; with the programmable material containing high k dielectric material directly against multivalent metal oxide. Some embodiments include arrays of memory cells, with the memory cells including programmable material containing high k dielectric material directly against multivalent metal oxide.<br><b>Independant Claims</b><br>1) A method of decoding a narrowband inactive speech and a wideband inactive speech for generating an inactive speech, the method comprising: receiving the narrowband inactive speech; receiving the wideband inactive speech; generating a first auxiliary signal by a narrowband inactive speech decoder based on the narrowband inactive speech; generating a second auxiliary signal by a wideband inactive speech decoder based on the wideband inactive speech; decoding the narrowband inactive speech using the narrowband inactive speech decoder to generate a decoded narrowband inactive speech based on the second auxiliary signal; decoding the wideband inactive speech using the wideband inactive speech decoder to generate a decoded wideband inactive speech based on the first auxiliary signal; and constructing the inactive speech using the decoded narrowband inactive speech and the decoded wideband inactive speech.<br>7) A speech decoder adapted to decode a narrowband inactive speech and a wideband inactive speech for generating an inactive speech, the speech decoder comprising: a microprocessor configured to: receive the narrowband inactive speech; receive the wideband inactive speech; generate a first auxiliary signal by a narrowband inactive speech decoder based on the narrowband inactive speech; generate a second auxiliary signal by a wideband inactive speech decoder based on the wideband inactive speech; decode the narrowband inactive speech using the narrowband inactive speech decoder to generate a decoded narrowband inactive speech based on the second auxiliary signal; decode the wideband inactive speech using the wideband inactive speech decoder to generate a decoded wideband inactive speech based on the first auxiliary signal; and construct the inactive speech using the decoded narrowband inactive speech and the decoded wideband inactive speech.</p></layer>
<layer id = "layer506"><p><b>US8775166B2:Coding/decoding method, system and apparatus</b><br>Some embodiments of the invention provide a novel architecture for debugging devices. This architecture includes numerous devices that without user intervention automatically detect and report bug events to a set of servers that aggregate and process the bug events. When a device detects a potential bug event, the device in some embodiments generates a description of the potential bug event, and sends the generated description to the server set through a network. In addition to generating such a description, the device in some embodiments directs one or more of its modules to gather and store a collection of one or more data sets that are relevant to the potential bug event, in case the event has to be further analyzed by the server set. In the discussion below, the generated bug-event description is referred to as the event signature, while the gathered collection of data sets for an event is referred to as the event's data archive. The server set aggregates and processes the bug-event signatures that it receives from the various devices. For only a subset of the reported bug-event signatures, the server set then directs the devices that sent these signatures to also send the data archives that these devices have gathered and stored for the events associated with these signatures. These data archives can be further analyzed to identify the root causes of the bug events.<br><b>Independant Claims</b><br>1) An encoding method, comprising: extracting core layer characteristic parameters and enhancement layer characteristic parameters of a background noise signal; encoding the core layer characteristic parameters and enhancement layer characteristic parameters to obtain a core layer codestream and an enhancement layer codestream; and dividing the background noise signal into a lower band background noise signal and a higher band background noise signal; wherein extracting the core layer characteristic parameters and enhancement layer characteristic parameters of the background noise signal comprises: extracting the core layer characteristic parameters of the lower band background noise signal and extracting the higher band enhancement layer characteristic parameters of the higher band background noise signal.<br>14) A decoding method, comprising: extracting a core layer codestream and an enhancement layer codestream from a Silence Insertion Descriptor (SID) frame; parsing core layer characteristic parameters from the core layer codestream; parsing enhancement layer characteristic parameters from the enhancement layer codestream; and decoding the core layer characteristic parameters and enhancement layer characteristic parameters to obtain a reconstructed core layer background noise signal and a reconstructed enhancement layer background noise signal; wherein the extracting the enhancement layer codestream from the SID frame comprises extracting a higher band enhancement layer codestream from the SID frame; wherein parsing the enhancement layer characteristic parameters from the enhancement layer codestream comprises paring higher band enhancement layer characteristic parameters from the enhancement layer codestream; and wherein the higher band enhancement layer characteristic parameters comprise at least one of time-domain envelopes and frequency-domain envelopes.<br>19) A non-transitory computer readable media comprising computer readable instructions that when combined with a processor cause the processor to function as an encoding-unit configured to perform an encoding process the encoding unit comprising: a core layer characteristic parameter encoding unit, configured to extract core layer characteristic parameters from a background noise signal received from a voice activity detector (VAD), and to transmit the core layer characteristic parameters to an encoding unit; an enhancement layer characteristic parameter encoding unit, configured to extract enhancement layer characteristic parameters from the background noise signal, and to transmit the enhancement layer characteristic parameters to the encoding unit; and the encoding unit, configured to encode the received core layer characteristic parameters and enhancement layer characteristic parameters to obtain a core layer codestream and an enhancement layer codestream; wherein the enhancement layer characteristic parameter encoding unit comprises at least one of a lower band enhancement layer characteristic parameter encoding unit and a higher band enhancement layer characteristic parameter encoding unit; wherein the lower band enhancement layer characteristic parameter encoding unit is configured to extract lower band enhancement layer characteristic parameters from the background noise signal and to transmit the lower band enhancement layer characteristic parameters to the encoding unit; wherein the higher band enhancement layer characteristic parameter encoding unit is configured to extract higher band enhancement layer characteristic parameters from the background noise signal and to transmit the higher band enhancement layer characteristic parameters to the encoding unit, wherein the higher band enhancement layer characteristic parameters comprise at least one of time-domain envelopes and frequency-domain envelopes; and wherein the encoding unit is configured to encode the received lower band enhancement layer characteristic parameters and higher band enhancement layer characteristic parameters to obtain the core layer codestream and enhancement layer codestream.<br>2) An encoding method, comprising: extracting core layer characteristic parameters and enhancement layer characteristic parameters of a background noise signal; encoding the core layer characteristic parameters and enhancement layer characteristic parameters to obtain a core layer codestream and an enhancement layer codestream; and dividing the background noise signal into a lower band background noise signal and a higher band background noise signal; wherein extracting the core layer characteristic parameters and enhancement layer characteristic parameters of the background noise signal comprises: extracting the lower band enhancement layer characteristic parameters and core layer characteristic parameters of the lower band background noise signal; and extracting the higher band enhancement layer characteristic parameters of the higher band background noise signal.<br>22) A non-transitory computer readable media comprising computer readable instructions that when combined with a processor cause the processor to function as a decoding unit configured to perform a decoding process the decoding unit comprising: a SID frame parsing unit, configured to receive a SID frame of a background noise signal received from a discontinuous transmission (DTX) unit, to extract a core layer codestream and an enhancement layer codestream; to transmit the core layer codestream to a core layer characteristic parameter decoding unit; and to transmit the enhancement layer codestream to an enhancement layer characteristic parameter decoding unit; the core layer characteristic parameter decoding unit, configured to extract core layer characteristic parameters from the core layer codestream and to decode the core layer characteristic parameters to obtain a reconstructed core layer background noise signal; and the enhancement layer characteristic parameter decoding unit, configured to extract enhancement layer characteristic parameters from the enhancement layer codestream and to decode the enhancement layer characteristic parameters to obtain a reconstructed enhancement layer background noise signal; wherein the enhancement layer characteristic parameter decoding unit comprises at least one of a lower band enhancement layer characteristic parameter decoding unit and a higher band enhancement layer characteristic parameter decoding unit; wherein the lower band enhancement layer characteristic parameter decoding unit is configured to extract lower band enhancement layer characteristic parameters from the enhancement layer codestream, and to decode the lower band enhancement layer characteristic parameters to obtain the reconstructed enhancement layer background noise signal; wherein the higher band enhancement layer characteristic parameter decoding unit is configured to extract higher band enhancement layer characteristic parameters from the enhancement layer codestream, and to decode the higher band enhancement layer characteristic parameters to obtain the reconstructed enhancement layer background noise signal; and wherein the higher band enhancement layer characteristic parameters comprise at least one of time-domain envelopes and frequency-domain envelopes.<br>3) A decoding method comprising: extracting a core layer codestream and an enhancement layer codestream from a Silence Insertion Descriptor (SID) frame; parsing core layer characteristic parameters from the core layer codestream; parsing enhancement layer characteristic parameters from the enhancement layer codestream; and decoding the core layer characteristic parameters and enhancement layer characteristic parameters to obtain a reconstructed core layer background noise signal and a reconstructed enhancement layer background noise signal; wherein extracting the enhancement layer codestream from the SID frame comprises extracting a lower band enhancement layer codestream from the SID frame; and parsing the enhancement layer characteristic parameters from the enhancement layer codestream comprises parsing lower band enhancement layer characteristic parameters from the enhancement layer codestream.<br>4) A non-transitory computer readable media comprising computer readable instructions that when combined with a processor cause the processor to function as an encoding unit configured to perform an encoding process, wherein the encoding unit comprises: a core layer characteristic parameter encoding unit, configured to extract core layer characteristic parameters from a background noise signal received from a voice activity detector (VAD), and to transmit the core layer characteristic parameters to an encoding unit; an enhancement layer characteristic parameter encoding unit configured to extract enhancement layer characteristic parameters from the background noise signal and to transmit the enhancement layer characteristic parameters to the encoding unit; and the encoding unit configured to encode the received core layer characteristic parameters and enhancement layer characteristic parameters to obtain a core layer codestream and an enhancement layer codestream; wherein the enhancement layer characteristic parameter encoding unit comprises at least one of a lower band enhancement layer characteristic parameter encoding unit and a higher band enhancement layer characteristic parameter encoding unit; wherein the lower band enhancement layer characteristic parameter encoding unit is configured to extract lower band enhancement layer characteristic parameters from the background noise signal and to transmit the lower band enhancement layer characteristic parameters to the encoding unit; wherein the higher band enhancement layer characteristic parameter encoding unit is configured to extract higher band enhancement layer characteristic parameters from the background noise signal and to transmit the higher band enhancement layer characteristic parameters to the encoding unit; and wherein the encoding unit is configured to encode the received lower band enhancement layer characteristic parameters and higher band enhancement layer characteristic parameters to obtain the core layer codestream and enhancement layer codestream.<br>5) A non-transitory computer readable media comprising computer readable instructions that when combined with a processor cause the processor to function as a decoding unit configured to perform a decoding process, the decoding unit comprising: a SID frame parsing unit, configured to receive a SID frame of a background noise signal received from a discontinuous transmission (DTX) unit to extract a core layer codestream and an enhancement layer codestream; to transmit the core layer codestream to a core layer characteristic parameter decoding unit; and to transmit the enhancement layer codestream to an enhancement layer characteristic parameter decoding unit; the core layer characteristic parameter decoding unit, configured to extract core layer characteristic parameters from the core layer codestream and to decode the core layer characteristic parameters to obtain a reconstructed core layer background noise signal; and the enhancement layer characteristic parameter decoding unit configured to extract enhancement layer characteristic parameters from the enhancement layer codestream and to decode the enhancement layer characteristic parameters to obtain a reconstructed enhancement layer background noise signal; wherein the enhancement layer characteristic parameter decoding unit comprises at least one of a lower band enhancement layer characteristic parameter decoding unit and a higher band enhancement layer characteristic parameter decoding unit; wherein the lower band enhancement layer characteristic parameter decoding unit is configured to extract lower band enhancement layer characteristic parameters from the enhancement layer codestream, and to decode the lower band enhancement layer characteristic parameters to obtain the reconstructed enhancement layer background noise signal; and wherein the higher band enhancement layer characteristic parameter decoding unit is configured to extract higher band enhancement layer characteristic parameters from the enhancement layer codestream, and to decode the higher band enhancement layer characteristic parameters to obtain the reconstructed enhancement layer background noise signal.<br>8) An encoding method, comprising: extracting core layer characteristic parameters and enhancement layer characteristic parameters of a background noise signal; encoding the core layer characteristic parameters and enhancement layer characteristic parameters to obtain a core layer codestream and an enhancement layer codestream; and dividing the background noise signal into a lower band background noise signal and a higher band background noise signal; wherein extracting the core layer characteristic parameters and enhancement layer characteristic parameters of the background noise signal comprises: extracting the core layer characteristic parameters of the lower band background noise signal and extracting the higher band enhancement layer characteristic parameters of the higher band background noise signal; and wherein the higher band enhancement layer characteristic parameters comprise at least one of time-domain envelopes and frequency-domain envelopes.</p></layer>
<layer id = "layer507"><p><b>US8706480B2:Audio encoder for encoding an audio signal having an impulse-like portion and stationary portion, encoding methods, decoder, decoding method, and encoding audio signal</b><br>A method and system for sharing knowledge may include receiving information input into a database and organizing items of information in the database. Some embodiments may also include collecting ratings and comments associated with each item of information and allowing users to access and sort items of information according to selected rating criteria in order to find the most reliable and/or valuable information from the database. The described system and method may allow individual members to easily locate the items of information from a collectively generated knowledge base that is presented in accordance with that individual's personal measure of value in the information.<br><b>Independant Claims</b><br>1) Audio encoder for encoding an audio signal comprising an impulse-like portion and a stationary portion, comprising: an impulse extractor configured for extracting the impulse-like portion from the audio signal, the impulse-extractor comprising an impulse coder for encoding the impulse-like portions to acquire an encoded impulse-like signal; a signal encoder configured for encoding a residual signal derived from the audio signal to acquire an encoded residual signal, the residual signal being derived from the audio signal so that the impulse-like portion is reduced or eliminated from the audio signal; and an output interface configured for outputting the encoded impulse-like signal and the encoded residual signal, to provide an encoded signal, wherein the impulse encoder is configured for not providing an encoded impulse-like signal, when the impulse extractor is not able to find an impulse portion in the audio signal.<br>24) Method of encoding an audio signal comprising an impulse-like portion and a stationary portion, comprising: extracting the impulse-like portion from the audio signal, the extracting comprising encoding the impulse-like portions to acquire an encoded impulse-like signal; encoding a residual signal derived from the audio signal to acquire an encoded residual signal, the residual signal being derived from the audio signal so that the impulse-like portion is reduced or eliminated from the audio signal; and outputting, by transmitting or storing, the encoded impulse-like signal and the encoded residual signal, to provide an encoded signal, wherein the impulse encoding is not performed, when the impulse-extracting does not find an impulse portion in the audio signal.<br>25) Decoder for decoding an encoded audio signal comprising an encoded impulse-like signal and an encoded residual signal, comprising: an impulse decoder configured for decoding the encoded impulse-like signal using a decoding algorithm adapted to a coding algorithm used for generating the encoded impulse-like signal, wherein a decoded impulse-like signal is acquired; a signal decoder configured for decoding the encoded residual signal using a decoding algorithm adapted to a coding algorithm used for generating the encoded residual signal, wherein a decoded residual signal is acquired; and a signal combiner configured for combining the decoded impulse-like signal and the decoded residual signal to provide a decoded output signal, wherein the signal decoder and the impulse decoder are operative to provide output values related to the same time instant of a decoded signal, wherein the impulse decoder is operative to receive the encoded impulse-like signal and provide the decoded impulse-like signal at specified time portions separated by periods in which the signal decoder provides the decoded residual signal and the impulse decoder does not provide the decoded impulse-like signal, so that the decoded output signal comprises the periods in which the decoded output signal is identical to the decoded residual signal and the decoded output signal comprises the specified time portions in which the decoded output signal comprises the decoded residual signal and the decoded impulse-like signal or comprises the decoded impulse-like signal only.<br>31) Method of decoding an encoded audio signal comprising an encoded impulse-like signal and an encoded residual signal, comprising: decoding the encoded impulse-like signal using a decoding algorithm adapted to a coding algorithm used for generating the encoded impulse-like signal, wherein a decoded impulse-like signal is acquired; decoding the encoded residual signal using a decoding algorithm adapted to a coding algorithm used for generating the encoded residual signal, wherein a decoded residual signal is acquired; and combining the decoded impulse-like signal and the decoded residual signal to provide a decoded output signal, wherein the decoding is operative to provide output values related to the same time instant of a decoded signal, wherein, in decoding the encoded impulse-like signal, the encoded impulse-like signal is received and the decoded impulse-like signal is provided at specified time portions separated by periods in which the decoding the encoded residual signal provides the decoded residual signal and the decoding the encoded impulse-like signal does not provide the decoded impulse-like signal, so that the decoded output signal comprises the periods, in which the decoded output signal is identical to the decoded residual signal and the decoded output signal comprises the specified time portions in which the decoded output signal comprises the decoded residual signal and the decoded impulse-like signal or comprises the impulse-like signal only.<br>32) Non-transitory storage medium having stored thereon a computer program comprising instructions, which when executed by a processor, cause the processor to perform a method of encoding an audio signal comprising an impulse-like portion and a stationary portion, comprising: extracting the impulse-like portion from the audio signal, the extracting comprising encoding the impulse-like portions to acquire an encoded impulse-like signal; encoding a residual signal derived from the audio signal to acquire an encoded residual signal, the residual signal being derived from the audio signal so that the impulse-like portion is reduced or eliminated from the audio signal; and outputting, by transmitting or storing, the encoded impulse-like signal and the encoded residual signal, to provide an encoded signal, wherein the impulse encoding is not performed, when the impulse-extracting does not find an impulse portion in the audio signal, when running on a processor.<br>33) Non-transitory storage medium having stored thereon a computer program comprising instructions, which when executed by a processor, cause the processor to perform a method of decoding an encoded audio signal comprising an encoded impulse-like signal and an encoded residual signal, comprising: decoding the encoded impulse-like signal using a decoding algorithm adapted to a coding algorithm used for generating the encoded impulse-like signal, wherein a decoded impulse-like signal is acquired; decoding the encoded residual signal using a decoding algorithm adapted to a coding algorithm used for generating the encoded residual signal, wherein a decoded residual signal is acquired; and combining the decoded impulse-like signal and the decoded residual signal to provide a decoded output signal, wherein the decoding are operative to provide output values related to the same time instant of a decoded signal, wherein, in decoding the encoded impulse-like signal, the encoded impulse-like signal is received and the decoded impulse-like signal is provided at specified time portions separated by periods in which the decoding the encoded residual signal provides the decoded residual signal and the decoding the encoded impulse-like signal does not provide the decoded impulse-like signal, so that the decoded output signal comprises the periods, in which the decoded output signal is identical to the decoded residual signal and the decoded output signal comprises the specified time portions in which the decoded output signal comprises the decoded residual signal and the decoded impulse-like signal or comprises the impulse-like signal only, when running on a processor.</p></layer>
<layer id = "layer508"><p><b>US8200499B2:High-frequency bandwidth extension in the time domain</b><br>Described are techniques for performing a data storage management task. A presentation technology service layer renders a user interface for user interaction in accordance with one or more rendering techniques. A user interaction template service layer includes one or more templates. Each of the templates describes processing to perform the data storage management task. A user interface data model mapping service layer communicates with at least one of a business logic service layer and a data storage interface layer to perform one or more operations in connection with the data storage management task and to map data received therefrom in a form for use by the user interface in accordance with a user interface data model.<br><b>Independant Claims</b><br>1) A system that extends the high-frequency spectrum of a narrowband audio signal in the time domain: an interface configured to receive a narrowband audio signal; a squaring circuit that squares a segment of the narrowband audio signal to extend harmonics of vowels by introducing a non linearity in the received narrowband audio signal in the time domain; a random noise generator that generates consonants by introducing random-noise in the received narrowband audio signal in the time domain; a plurality of filters that pass a portion of the frequencies on the non-linearity and the random noise; a first amplifier that adjusts an envelope of the filtered portion of the random noise to an estimate of a high pass filtered version of the received narrowband audio signal; and a second amplifier that adjusts an envelope of the filtered portion of the non-linearity to a level of an envelope of the high pass filtered version of the received narrowband audio signal.<br>11) A method of extending a high-frequency spectrum of a narrowband signal, comprising: receiving a narrowband signal at an interface; evaluating a portion of the narrowband signal to determine a speech characteristic in that portion of the narrowband signal; generating a high-frequency time domain spectrum based on the determined speech characteristic in the evaluated portion of the narrowband signal; and combining the generated high-frequency time domain spectrum with the narrowband signal to create an extended signal, where the high-frequency time domain spectrum comprises squaring the evaluated portion of the narrowband signal when the speech characteristic in the evaluated portion of the narrowband signal represents a vowel.<br>15) A method of extending a high-frequency spectrum of a narrowband signal, comprising: receiving a narrowband signal at an interface; evaluating a portion of the narrowband signal to determine a speech characteristic in that portion of the narrowband signal; generating a high-frequency time domain spectrum based on the determined speech characteristic in the evaluated portion of the narrowband signal; and combining the generated high-frequency time domain spectrum with the narrowband signal to create an extended signal, where the high-frequency time domain spectrum comprises a random generated signal when the speech characteristic in the evaluated portion of the narrowband signal represents a consonant.</p></layer>
<layer id = "layer509"><p><b>US20180033453A1:Voice Activity Detector for Audio Signals</b><br><b>Independant Claims</b><br>1) A method for determining voice activity in an audio signal, the method comprising: receiving a frame of an input audio signal, the input audio signal having a sample rate;spitting the audio signal into a plurality of subbands by way of a sequence of filter banks, the plurality of subbands including at least a lowest subband and a highest subband; filtering the lowest subband with a linear filter to reduce an energy of the lowest subband;estimating a noise level for at least some of the plurality of subbands such that in each subband, a noise level estimator tracks the background noise level and a Signal-to-Noise Ratio (SNR) valuecalculating a signal to noise ratio value for at least some of the plurality of subbands; anddetermining a speech activity level based at least in part on an average of the calculated signal to noise ratio values and an average of an energy of at least some of the plurality of subbands,wherein the method is performed with one or more computing devices.</p></layer>
<layer id = "layer510"><p><b>US8311842B2:Method and apparatus for expanding bandwidth of voice signal</b><br>A method for controlling a computer system includes acquiring video of a subject, and obtaining from the video a time-resolved sequence of depth maps. A geometric model of the subject is fit to each depth map in the sequence and tracked into a subsequent depth map in the sequence. From the subsequent depth map, a background section is selected for exclusion. The background section is one that lacks coherent motion and is located more than a threshold distance from the coordinates of the geometric model tracked in. Then, a subsequent geometric model of the subject is fit to the depth map with the background section excluded.<br><b>Independant Claims</b><br>7) An apparatus for expanding a bandwidth of an input narrowband voice signal, the apparatus comprising: a Degree of Difficulty of Bandwidth Expansion (DDBWE) calculator for analyzing the narrowband voice signal separately for each frame, calculating a Degree of Voicing (DV) included in the narrowband voice signal and a Degree of Stationary (DS) concerning time-varying characteristic for the narrowband voice signal depending on the analysis, and calculating DDBWE of the narrowband voice signal by using a product of DV, a product of DS and a α which is a weighting parameter for adjusting a ratio of DV and DS; and a bandwidth expander for controlling bandwidth expansion adaptively according to DDBWE, wherein DDBWE is defined as a value obtained by subtracting from ‘1’, a sum of the product of DV and α and the product of DS and a value obtained by subtracting α from 1, where α has a value between ‘0’ and ‘1’.<br>1) A method for expanding a bandwidth of an input narrowband voice signal, the method comprising the steps of: analyzing the narrowband voice signal separately for each frame, and calculating a Degree of Voicing (DV) included in the narrowband voice signal and a Degree of Stationary (DS) concerning time-varying characteristic for the narrowband voice signal depending on the analysis; calculating a Degree of Difficulty of Bandwidth Expansion (DDBWE) of the narrowband voice signal by using a product of DV, a product of DS and a α which is a weighting parameter for adjusting a ratio of DV and DS; and controlling bandwidth expansion adaptively according to DDBWE, wherein DDBWE is defined as a value obtained by subtracting from ‘1’, a sum of the product of DV and α and the product of DS and a value obtained by subtracting α from 1, where α has a value between ‘0’ and ‘1’.</p></layer>
<layer id = "layer511"><p><b>US8554548B2:Speech decoding apparatus and speech decoding method including high band emphasis processing</b><br>A method for detecting and tracking multiple fingers in a two dimensional set of results using oversampling hill climbing and descent with range.<br><b>Independant Claims</b><br>1) A speech decoding apparatus comprising: a speech decoder that decodes encoded data acquired by encoding a speech signal to acquire a decoded speech signal; a mode deciding processor that decides, at regular intervals, whether or not a mode of the decoded speech signal comprises a stationary noise period; a power calculator that calculates a power of the decoded speech signal; a signal to noise ratio (SNR) calculator that calculates a SNR of the decoded speech signal using a mode decision result of the mode deciding processor and the power of the decoded speech signal; and a post filter that performs post filtering processing including high band emphasis processing of an excitation signal, using the SNR, wherein the high band emphasis processing is performed such that a level of high band emphasis becomes higher when the SNR decreases.<br>5) A speech decoding method performed by a processor comprising: decoding encoded data acquired by encoding a speech signal to acquire a decoded speech signal; deciding, at regular intervals, whether or not a mode of the decoded speech signal comprises a stationary noise period; calculating a power of the decoded speech signal; calculating a signal to noise ratio (SNR) of the decoded speech signal using a mode decision result of the mode deciding section and the power of the decoded speech signal; and performing post filtering processing including high band emphasis processing of an excitation signal, using the SNR, wherein the high band emphasis processing is performed such that a level of high band emphasis becomes higher when the SNR decreases.</p></layer>
<layer id = "layer512"><p><b>US8457953B2:Method and arrangement for smoothing of stationary background noise</b><br>Provided is a liquid crystal display device. The liquid crystal display device comprises a liquid crystal panel, a backlight unit, and a driving unit. The liquid crystal panel comprises a plurality of display areas defined therein. The backlight unit is disposed under the liquid crystal panel. The backlight unit comprises a plurality of light emitting areas corresponding to the respective display areas defined therein. The driving unit controls intensity of light emitted from the light emitting areas. Here, the backlight unit comprises light guide plates disposed in two or more light emitting areas.<br><b>Independant Claims</b><br>1) A method of smoothing background noise in a telecommunication speech session, comprising receiving and decoding a signal representative of a speech session, said signal comprising both a speech component and a background noise component; determining LPC parameters for said received signal; determining an excitation signal for said received signal; synthesizing and outputting an output signal based on said LPC parameters and said excitation signal, characterized by: modifying said determined set of LPC parameters by providing a low pass filtered set of LPC parameters, and determining a weighted combination of said low pass filtered set and said determined set of LPC parameters, and performing said synthesis and outputting step based on said modified set of LPC parameters to provide a smoothed output signal; modifying said determined excitation signal by reducing power and spectral fluctuations of the excitation signal and thus provide a smoothed output signal.<br>9) A smoothing apparatus, comprising means for receiving and decoding a signal representative of a speech session, said signal comprising both a speech component and a background noise component; means for determining LPC parameters for said received signal; means for determining an excitation signal for said received signal; means for synthesizing an output signal based on said LPC parameters and said excitation signal, comprising: means for modifying said determined set of LPC parameters by providing a low pass filtered set of LPC parameters, said means being adapted to determine a weighted combination of said low pass filtered set and said determined set of LPC parameters, and said synthesis means are adapted to synthesize said output signal based on said modified set of LPC parameters to provide a smoothed output signal, and means for modifying said determined excitation signal by reducing power and spectral fluctuations of the excitation signal and thus provide a smoothed output signal.</p></layer>
<layer id = "layer513"><p><b>US20160155457A1:METHOD AND ARRANGEMENT FOR CONTROLLING SMOOTHING OF STATIONARY BACKGROUND NOISE</b><br><b>Independant Claims</b><br>7) A speech encoder, comprising:processing circuitry configured to determine voice activity of an input speech signal;the processing circuitry configured to determine a noisiness parameter for an inactive speech signal, wherein said noisiness parameter is based on a ratio of prediction gains of two Linear Predictive Coder (LPC) prediction filters with different orders;the processing circuitry configured to quantize the noisiness parameter; andthe processing circuitry configured to encode the speech signal for transmission.<br>25) A speech decoder, comprising:processing circuitry configured to receive and decode a coded speech signal;the processing circuitry further configured to obtain a voice activity indication and a noisiness parameter for said speech signal, said noisiness parameter being based on a ratio of prediction gains of two Linear Predictive Coder (LPC) prediction filters with different orders; andthe processing circuitry further configured to adaptively smoothe background noise of said decoded speech signal based on said obtained noisiness parameter, wherein said processing circuitry is adapted to be indirectly controlled by said noisiness parameter.<br>11) An anti-swirling method for coded background noise, the method comprising:receiving and decoding a coded speech signal;obtaining a voice activity indication and a noisiness parameter for said speech signal, wherein said noisiness parameter is based on a ratio of prediction gains of two Linear Predictive Coder (LPC) prediction filters with different orders; andadaptively smoothing background noise of said decoded speech signal based on said obtained noisiness parameter, wherein said smoothing operation is indirectly controlled by said noisiness parameter.<br>1) A method for coding of information for enhancing a background noise representation, the method comprising:determining voice activity of an input speech signal;determining a noisiness parameter for an inactive speech signal, wherein said noisiness parameter is based on a ratio of prediction gains of two Linear Predictive Coder (LPC) prediction filters with different orders;quantizing the noisiness parameter; andencoding the quantized noisiness parameter for transmission.</p></layer>
<layer id = "layer514"><p><b>US8396574B2:Audio processing using auditory scene analysis and spectral skewness</b><br>The invention provides a solution to the problem of delivering molecules in a physiologically relevant manner to direct cell fate. For example, a Notch ligand molecule is presented in a microenvironment that mimics the environment encountered in vivo. Accordingly, the invention features a cell delivery vehicle comprising a biocompatible hydrogel or polymer and a composition that binds to a Notch receptor and methods of directing cell fate, e.g., stem cell differentiation, using such compositions.<br><b>Independant Claims</b><br>1) A method for controlling the loudness of auditory events in an audio signal for controlling gain changes in the audio signal in an automatic gain control or dynamic range control signal processing, comprising dividing said audio signal into auditory events, each tending to be perceived as separate and distinct, by detecting changes in spectral composition with respect to time, said dividing including detecting the location and strength of auditory event boundaries in said audio signal, obtaining a dynamically-changing measure of the spectral skewness of said audio signal, wherein spectral skewness is a statistical measure of the asymmetry of the probability distribution of the audio signal spectrum, modifying the strength of auditory event boundaries in response to said measure, such that the less the spectrum is skewed at the location of an auditory event boundary, the more the strength of the auditory event boundary is reduced, and controlling the loudness of auditory events in response to the location and skewness-modified strength of said auditory event boundaries such that the reduction of the strength of the auditory event boundary reduces the gain change of the audio signal during quiet background sounds.</p></layer>
<layer id = "layer515"><p><b>US8200481B2:Method and device for performing frame erasure concealment to higher-band signal</b><br>A verification system for verifying an integrated circuit design is provided. The verification system includes a functional block finding module configured to identify potential sensitive circuits in the integrated circuit design; and a search module. The search module is configured to find sensitive circuits from the potential sensitive circuits; and verify the sensitive circuits.<br><b>Independant Claims</b><br>1) A method for performing a frame erasure concealment to a higher-band signal, comprising: calculating, by a device for performing a frame erasure concealment to a higher-band signal, a periodic intensity of the higher-band signal with respect to pitch period information of a lower-band signal; judging, by the device for performing the frame erasure concealment to the higher-band signal whether the periodic intensity is higher than or equal to a preconfigured threshold, if the periodic intensity is higher than or equal to the preconfigured threshold, performing the frame erasure concealment to the higher-band signal of a current lost frame with a pitch period repetition based method, and if the periodic intensity is lower than the preconfigured threshold, performing the frame erasure concealment to the higher-band signal of the current lost frame with a previous frame data repetition based method; wherein the higher-band signal is a voice signal.<br>16) A device for performing a frame erasure concealment to a higher-band signal, wherein the higher-band signal is a voice signal and the device comprises: a periodic intensity calculation module, configured to calculate a periodic intensity of the higher-band signal with respect to pitch period information of a lower-band signal, judge whether the periodic intensity is higher than or equal to a preconfigured threshold, if the periodic intensity is higher than or equal to the preconfigured threshold, transmit the higher-band signal of a current lost frame to a pitch period repetition module, if the periodic intensity is lower than the preconfigured threshold, transmit the higher-band signal of the current lost frame to a previous frame data repetition module; the pitch period repetition module, configured to perform the frame erasure concealment to the higher-band signal of the current lost frame with a pitch period repetition based method; and the previous frame data repetition module, configured to perform the frame erasure concealment to the higher-band signal of the current lost frame with a previous frame data repetition based method.<br>20) A speech decoder, comprising: a bitstream demultiplex module, configured to demultiplex an input bitstream into a lower-band bitstream and a higher-band bitstream; a lower-band decoder and a higher-band decoder, configured to decode the lower-band bitstream and the higher-band bitstream to a lower-band signal and a higher-band signal respectively; wherein the lower-band signal and the higher-band signal are voice signals; a frame erasure concealment device for a lower-band signal, configured to perform a frame erasure concealment to the lower-band signal to obtain a pitch period of the lower-band signal; a frame erasure concealment device for a higher-band signal, configured to calculate a periodic intensity of the higher-band signal with respect to pitch period information of the lower-band signal, determine whether the periodic intensity of the higher-band signal is higher than or equal to a preconfigured threshold, if the periodic intensity of the higher-band signal is higher than or equal to the preconfigured threshold, use a pitch period repetition based method to perform the frame erasure concealment to the higher-band signal of a current lost frame, and if the periodic intensity of the higher-band signal is lower than the preconfigured threshold, use a previous frame data repetition based method to perform the frame erasure concealment to the higher-band signal of the current lost frame; and a synthesis Quadrature-Mirror Filterbank, configured to synthesize the lower-band signal and the higher-band signal after the frame erasure concealment, into another voice signal to be output.</p></layer>
<layer id = "layer516"><p><b>US8538763B2:Speech enhancement with noise level estimation adjustment</b><br>A multi-sensor lighting control system includes at least two light sensors. Each sensor gathers light from different sources, by comparing and contrasting the output signals from the two sensors, the controller can automate many lighting control and commissioning processes leading to easier, simpler installations and maintenance and happier customers, and removing the need for special tools. Applying automated closed loop lamp warm-up techniques, the daylight ratio and the maximum electric light contribution can be learned automatically by the system. A multi-sensor lighting control system may also provide intermediate zones of lighting control between adjacent task areas with different lighting requirements.<br><b>Independant Claims</b><br>10) A non-transitory computer-readable storage medium encoded with a computer program for causing a computer to perform steps comprising: changing the audio signal from a time domain representation to a plurality of subbands in a frequency domain representation, producing K multiple subband signals, Yk(m), k=1, . . . , K, m=0, 1, . . . , ∞, where k is the subband number, and m is a time index of each subband signal, processing subbands of the audio signal, wherein a subband has a gain, said processing including controlling the gain of the audio signal in ones of said subbands, wherein the gain in a subband is reduced as a level of estimated noise components increases with respect to the level of speech components, wherein the level of estimated noise components is determined at least in part by obtaining and monitoring the signal-to-noise ratio in the subband and increasing the estimated noise components level in the subband by a predetermined amount when the signal-to-noise ratio in the subband exceeds a limit for more than a defined time, the change of the gain in a subband being performed according to a set of parameters continuously updated for each time index m, said parameters being dependent only on their respective prior value at time index (m−1), characteristics of the subband at time index m, and a set of predetermined constants, and said defined time being updated according to a counter, said counter being robust with respect to false alarms and resets due to temporary signal fluctuations by introducing a hand-off counter, and changing the processed audio signal from the frequency domain to the time domain to provide an audio signal in which speech components are enhanced.<br>1) A method for enhancing speech components of an audio signal composed of speech and noise components, comprising: using a processor and a memory to perform steps comprising: changing the audio signal from a time domain representation to a plurality of subbands in a frequency domain representation producing K multiple subband signals, Yk(m), k=1, . . . , K, m=0, 1, . . . , ∞, where k is a subband number, and m is a time index of each subband signal, processing the subbands of the audio signal, wherein a subband has a gain, said processing including controlling the gain of the audio signal in ones of said subbands, wherein the gain in a subband is reduced as a level of estimated noise components increases with respect to the level of speech components, the change of the gain in a subband being performed according to a set of parameters continuously updated for each time index m, said parameters being dependent only on their respective prior value at time index (m−1), characteristics of the subband at time index m, and a set of predetermined constants, wherein the level of estimated noise components is determined at least in part by comparing an estimated noise components level with the level of the audio signal in the subband and increasing the estimated noise components level in the subband by a predetermined amount when the audio signal level in the subband exceeds the estimated noise components level in the subband by a limit for more than a defined time, wherein said defined time is updated according to a counter, said counter being robust with respect to false alarms and resets due to temporary signal fluctuations by introducing a hand-off counter, and changing the processed audio signal from the frequency domain to the time domain to provide an audio signal in which speech components are enhanced.<br>4) A method for enhancing speech components of an audio signal composed of speech and noise components, comprising: using a processor and a memory to perform steps comprising: changing the audio signal from a time domain representation to a plurality of subbands in a frequency domain representation, producing K multiple subband signals, Yk(m), k=1, . . . , K, m=0, 1, . . . , ∞, where k is the subband number, and m is a time index of each subband signal, processing subbands of the audio signal, wherein a subband has a gain, said processing including controlling the gain of the audio signal in ones of said subbands, wherein the gain in a subband is reduced as a level of estimated noise components increases with respect to the level of speech components, wherein the level of estimated noise components is determined at least in part by obtaining and monitoring the signal-to-noise ratio in the subband and increasing the estimated noise components level in the subband by a predetermined amount when the signal-to-noise ratio in the subband exceeds a limit for more than a defined time, the change of the gain in a subband being performed according to a set of parameters continuously updated for each time index m, said parameters being dependent only on their respective prior value at time index (m−1), characteristics of the subband at time index m, and a set of predetermined constants, and said defined time being updated according to a counter, said counter being robust with respect to false alarms and resets due to temporary signal fluctuations by introducing a hand-off counter, and changing the processed audio signal from the frequency domain to the time domain to provide an audio signal in which speech components are enhanced.<br>7) A non-transitory computer-readable storage medium encoded with a computer program for causing a computer to perform steps comprising: changing the audio signal from a time domain representation to a plurality of subbands in a frequency domain representation producing K multiple subband signals, Yk(m), k=1, . . . , K, m=0, 1, . . . , ∞, where k is a subband number, and m is a time index of each subband signal, processing the subbands of the audio signal, wherein a subband has a gain, said processing including controlling the gain of the audio signal in ones of said subbands, wherein the gain in a subband is reduced as a level of estimated noise components increases with respect to the level of speech components, the change of the gain in a subband being performed according to a set of parameters continuously updated for each time index m, said parameters being dependent only on their respective prior value at time index (m−1), characteristics of the subband at time index m, and a set of predetermined constants, wherein the level of estimated noise components is determined at least in part by comparing an estimated noise components level with the level of the audio signal in the subband and increasing the estimated noise components level in the subband by a predetermined amount when the audio signal level in the subband exceeds the estimated noise components level in the subband by a limit for more than a defined time, wherein said defined time is updated according to a counter, said counter being robust with respect to false alarms and resets due to temporary signal fluctuations by introducing a hand-off counter, and changing the processed audio signal from the frequency domain to the time domain to provide an audio signal in which speech components are enhanced.</p></layer>
<layer id = "layer517"><p><b>US8095374B2:Method and apparatus for improving the quality of speech signals</b><br>Co-topo-polymeric indicator compositions and methods for making and using the same are provided. Indicator compositions of the invention include a polymer and undergo a color change, which may be reversible or irreversible, in response to an applied stimulus, e.g., temperature. Aspects of methods of producing the compositions include setting a fluid co-topo-polymeric precursor composition into a solid product and then subjecting the solid product (either immediately or after a delay period) to polymerizing conditions to produce the desired indicator composition. Also provided are indicator devices that include the indicator compositions of the invention. The compositions of the invention find use in a variety of different applications.<br><b>Independant Claims</b><br>1) A network device comprising: an input interface; a generation unit configured to generate a bandwidth extended signal derived from a far-end speech communication signal received at the input interface; a controller configured to control power of the bandwidth extended signal relative to power of the far-end speech communication signal; and an output interface to which the bandwidth extended signal is provided.<br>18) A network device based method for bandwidth extension, the method comprising: receiving a signal including a far-end speech communication; generating a bandwidth extended signal derived from the received speech communication signal; controlling power of the bandwidth extended signal relative to power of the far-end speech communication signal; and providing the bandwidth extended signal to an output of the network device.<br>36) A network device based method, the method comprising: receiving an input signal; generating an output signal, the output signal representing a wider bandwidth version of a speech communication represented by the input signal; controlling power of the bandwidth extended signal relative to power of the far-end speech communication signal; and providing the output signal to an output of the network device.<br>55) A network device based method, the method comprising: receiving an input signal at an input interface of the network device; decoding the input signal; determining an interval in the input signal when speech is not present in the input signal; generating a derivative signal having at least one component at a frequency that is outside a bandwidth of the input signal, the at least one component being derived from the decoded input signal; determining a gain for the derivative signal to generate a gain-determined derivative signal, a lower level of gain being determined for the derivative signal during the interval as compared to a level of gain applied to the derivative signal prior to the interval; delaying the decoded input signal to generate a delayed input signal; combining the gain-determined derivative signal with the delayed input signal to generate an output signal, the output signal representing a wider bandwidth version of a speech communication represented by the input signal; encoding the output signal; and providing the encoded output signal to an output interface of the network device.</p></layer>
<layer id = "layer518"><p><b>US8982744B2:Method and system for a subband acoustic echo canceller with integrated voice activity detection</b><br><b>Independant Claims</b><br>24) A non-transitory computer readable storage having stored thereon, a computer program having at least one code section, the at least one code section being executable by a machine for causing the machine to perform a method for a wireless system control, comprising: in a receiver: while receiving wirelessly communicated audio signals, determining a voice activity based on a subband analysis of received wirelessly communicated audio signals; adjusting an amount of power used for a wireless reception in said receiver based on said voice activity; generating a plurality of subbands for said subband analysis; processing a second subset of said plurality of subbands; and generating a comfort noise based on said processed second subset of said plurality of subbands.<br>1) A method for a wireless system control, the method comprising: in a receiver: while receiving wirelessly communicated audio signals, determining a voice activity based on a subband analysis of said wirelessly communicated audio signals; adjusting an amount of power used for a wireless reception in said receiver based on said voice activity; generating a plurality of subbands for said subband analysis; processing a second subset of said plurality of subbands; and generating a comfort noise based on said processed second subset of said plurality of subbands.<br>13) A system for a wireless system control, the system comprising: a receiver that handles processing of wirelessly communicated audio signals, said receiver comprising: acoustic echo canceller circuitry operable to, while receiving wirelessly communicated audio signals, determining a voice activity based on a subband analysis of wirelessly communicated audio signals; generating a plurality of subbands for said subband analysis; processing a second subset of said plurality of subbands: and generating a comfort noise based on said second subset of said plurality of subbands; and communications circuitry operable to adjust an amount of power used for a wireless reception in said receiver based on said voice activity.</p></layer>
<layer id = "layer519"><p><b>US9653088B2:Systems, methods, and apparatus for signal encoding using pitch-regularizing and non-pitch-regularizing coding</b><br><b>Independant Claims</b><br>1) A method of processing frames of an audio signal, said method comprising: classifying each of a first frame of the audio signal and a second frame of the audio signal as a frame type from a set of frame types comprising a voiced speech frame, an unvoiced speech frame, a transitional frame, a generic audio frame, and an inactive frame containing only one or more of background noise and silence; encoding the first frame of the audio signal according to a relaxed code excited linear prediction (RCELP) coding scheme to produce a first encoded frame; encoding the second frame of the audio signal according to a non-pitch-regularizing (non-PR) coding scheme to produce a second encoded frame, wherein the second frame is a generic audio frame, and wherein the second frame follows and is consecutive to the first frame in the audio signal, and wherein said encoding the first frame includes time-modifying, based on a time shift, a segment of a first signal that is based on the first frame, said time-modifying including one among (A) time-shifting the segment of the first frame according to the time shift and (B) time-warping the segment of the first signal based on the time shift, and wherein said time-modifying a segment of a first signal includes changing a position of a pitch pulse of the segment relative to another pitch pulse of the first signal, and wherein said encoding the second frame includes time-modifying, based on the time shift, a segment of a second signal that is based on the second frame, wherein the time shift is applied to at least one sample of the segment of the second signal by a same shift value as at least one sample of the segment of the first signal, said time-modifying including one among (A) time-shifting the segment of the second frame according to the time shift and (B) time-warping the segment of the second signal based on the time shift; and transmitting the first encoded frame and the second encoded frame to a decoder that synthesizes the first encoded frame and the second encoded frame and outputs a synthesized audio signal.<br>16) An apparatus for processing frames of an audio signal, said apparatus comprising: means for classifying each of a first frame of the audio signal and a second frame of the audio signal as a frame type from a set of frame types comprising a voiced speech frame, an unvoiced speech frame, a transitional frame, a generic audio frame, and an inactive frame containing only one or more of background noise and silence; means for encoding the first frame of the audio signal according to a relaxed code excited linear prediction (RCELP) coding scheme to produce a first encoded frame; means for encoding the second frame of the audio signal according to a non-pitch-regularizing (non-PR) coding scheme to produce a second encoded frame, wherein the second frame is a generic audio frame, and wherein the second frame follows and is consecutive to the first frame in the audio signal, and wherein said means for encoding the first frame includes means for time-modifying, based on a time shift, a segment of a first signal that is based on the first frame, said means for time-modifying being configured to perform one among (A) time-shifting the segment of the first frame according to the time shift and (B) time-warping the segment of the first signal based on the time shift, and wherein said means for time-modifying a segment of a first signal is configured to change a position of a pitch pulse of the segment relative to another pitch pulse of the first signal, and wherein said means for encoding the second frame includes means for time-modifying, based on the time shift, a segment of a second signal that is based on the second frame, wherein the time shift is applied to at least one sample of the segment of the second signal by a same shift value as at least one sample of the segment of the first signal, said means for time-modifying being configured to perform one among (A) time-shifting the segment of the second frame according to the time shift and (B) time-warping the segment of the second signal based on the time shift; and means for transmitting the first encoded frame and the second encoded frame to a means for decoding having means for synthesizing the first encoded frame and the second encoded frame and means for outputting a synthesized audio signal.<br>24) An apparatus for processing frames of an audio signal, said apparatus comprising: a processor comprising a first frame encoder and a second frame encoder, wherein the processor is configured to classify each of a first frame of the audio signal and a second frame of the audio signal as a frame type from a set of frame types comprising a voiced speech frame, an unvoiced speech frame, a transitional frame, a generic audio frame, and an inactive frame containing only one or more of background noise and silence; the first frame encoder configured to encode the first frame of the audio signal according to a relaxed code excited linear prediction (RCELP) coding scheme to produce a first encoded frame; the second frame encoder configured to encode the second frame of the audio signal according to a non-pitch-regularizing (non-PR) coding scheme to produce a second encoded frame, wherein the second frame is a generic audio frame, and wherein the second frame follows and is consecutive to the first frame in the audio signal, and wherein said first frame encoder includes a first time modifier configured to time-modify, based on a time shift, a segment of a first signal that is based on the first frame, said first time modifier being configured to perform one among (A) time-shifting the segment of the first frame according to the time shift and (B) time-warping the segment of the first signal based on the time shift, and wherein said first time modifier is configured to change a position of a pitch pulse of the segment relative to another pitch pulse of the first signal, and wherein said second frame encoder includes a second time modifier configured to time-modify, based on the time shift, a segment of a second signal that is based on the second frame, wherein the time shift is applied to at least one sample of the segment of the second signal by a same shift value as at least one sample of the segment of the first signal, said second time modifier being configured to perform one among (A) time-shifting the segment of the second frame according to the time shift and (B) time-warping the segment of the second signal based on the time shift; and a transmitter configured to transmit the first encoded frame and the second encoded frame to a decoder that is configured to synthesize the first encoded frame and the second encoded frame and output a synthesized audio signal.<br>32) A non-transitory computer-readable medium comprising instructions which when executed by a processor cause the processor to: classify each of a first frame of an audio signal and a second frame of the audio signal as a frame type from a set of frame types comprising a voiced speech frame, an unvoiced speech frame, a transitional frame, a generic audio frame, and an inactive frame containing only one or more of background noise and silence; encode the first frame of the audio signal according to a relaxed code excited linear prediction (RCELP) coding scheme to produce a first encoded frame; encode the second frame of the audio signal according to a non-pitch-regularizing (non-PR) coding scheme to produce a second encoded frame, wherein the second frame is a generic audio frame, and wherein the second frame follows and is consecutive to the first frame in the audio signal, and wherein said instructions which when executed cause the processor to encode the first frame include instructions to time-modify, based on a time shift, a segment of a first signal that is based on the first frame, said instructions to time-modify including one among (A) instructions to time-shift the segment of the first frame according to the time shift and (B) instructions to time-warp the segment of the first signal based on the time shift, and wherein said instructions to time-modify a segment of a first signal include instructions to change a position of a pitch pulse of the segment relative to another pitch pulse of the first signal, and wherein said instructions which when executed cause the processor to encode the second frame include instructions to time-modify, based on the time shift, a segment of a second signal that is based on the second frame, wherein the time shift is applied to at least one sample of the segment of the second signal by a same shift value as at least one sample of the segment of the first signal, said instructions to time-modify including one among (A) instructions to time-shift the segment of the second frame according to the time shift and (B) instructions to time-warp the segment of the second signal based on the time shift; and transmit the first encoded frame and the second encoded frame to a decoder that synthesizes the first encoded frame and the second encoded frame and outputs a synthesized audio signal.<br>33) A method of processing frames of an audio signal, said method comprising: classifying each of a first frame of the audio signal and a second frame of the audio signal as a frame type from a set of frame types comprising a voiced speech frame, an unvoiced speech frame, a transitional frame, a generic audio frame, and an inactive frame containing only one or more of background noise and silence; encoding the first frame of the audio signal according to a first coding scheme to produce a first encoded frame, wherein the first frame is a generic audio frame; encoding the second frame of the audio signal according to a relaxed code excited linear prediction (RCELP) coding scheme to produce a second encoded frame, wherein the second frame follows and is consecutive to the first frame in the audio signal, and wherein the first coding scheme is a non-pitch-regularizing (non-PR) coding scheme, and wherein said encoding the first frame includes time-modifying, based on a first time shift, a segment of a first signal that is based on the first frame, wherein the first time shift is applied to at least one sample of the segment of the first signal by a same shift value as at least one sample of a segment of a signal of a preceding frame, said time-modifying including one among (A) time-shifting the segment of the first signal according to the first time shift and (B) time-warping the segment of the first signal based on the first time shift; and wherein said encoding the second frame includes time-modifying, based on a second time shift, a segment of a second signal that is based on the second frame, said time-modifying including one among (A) time-shifting the segment of the second signal according to the second time shift and (B) time-warping the segment of the second signal based on the second time shift, wherein said time-modifying a segment of a second signal includes changing a position of a pitch pulse of the segment relative to another pitch pulse of the second signal, and wherein the second time shift is based on information from the time-modified segment of the first signal; and transmitting the first encoded frame and the second encoded frame to a decoder that synthesizes the first encoded frame and the second encoded frame and outputs a synthesized audio signal.<br>51) An apparatus for processing frames of an audio signal, said apparatus comprising: means for classifying each of a first frame of the audio signal and a second frame of the audio signal as a frame type from a set of frame types comprising a voiced speech frame, an unvoiced speech frame, a transitional frame, a generic audio frame, and an inactive frame containing only one or more of background noise and silence; means for encoding the first frame of the audio signal according to a first coding scheme to produce a first encoded frame, wherein the first frame is a generic audio frame; means for encoding the second frame of the audio signal according to a relaxed code excited linear prediction (RCELP) coding scheme to produce a second encoded frame, wherein the second frame follows and is consecutive to the first frame in the audio signal, and wherein the first coding scheme is a non-pitch-regularizing (non-PR) coding scheme, and wherein said means for encoding the first frame includes means for time-modifying, based on a first time shift, a segment of a first signal that is based on the first frame, wherein the first time shift is applied to at least one sample of the segment of the first signal by a same shift value as at least one sample of a segment of a signal of a preceding frame, said means for time-modifying being configured to perform one among (A) time-shifting the segment of the first signal according to the first time shift and (B) time-warping the segment of the first signal based on the first time shift; and wherein said means for encoding the second frame includes means for time-modifying, based on a second time shift, a segment of a second signal that is based on the second frame, said means for time-modifying being configured to perform one among (A) time-shifting the segment of the second signal according to the second time shift and (B) time-warping the segment of the second signal based on the second time shift, wherein said means for time-modifying a segment of a second signal is configured to change a position of a pitch pulse of the segment relative to another pitch pulse of the second signal, and wherein the second time shift is based on information from the time-modified segment of the first signal; and means for transmitting the first encoded frame and the second encoded frame to a means for decoding having means for synthesizing the first encoded frame and the second encoded frame and means for outputting a synthesized audio signal.<br>61) An apparatus for processing frames of an audio signal, said apparatus comprising: a processor comprising a first frame encoder and a second frame encoder, wherein the processor is configured to classify each of a first frame of the audio signal and a second frame of the audio signal as a frame type from a set of frame types comprising a voiced speech frame, an unvoiced speech frame, a transitional frame, a generic audio frame, and an inactive frame containing only one or more of background noise and silence; the first frame encoder configured to encode the first frame of the audio signal according to a first coding scheme to produce a first encoded frame, wherein the first frame is a generic audio frame; the second frame encoder configured to encode the second frame of the audio signal according to a relaxed code excited linear prediction (RCELP) coding scheme to produce a second encoded frame, wherein the second frame follows and is consecutive to the first frame in the audio signal, and wherein the first coding scheme is a non-pitch-regularizing (non-PR) coding scheme, and wherein said first frame encoder includes a first time modifier configured to time-modify, based on a first time shift, a segment of a first signal that is based on the first frame, wherein the first time shift is applied to at least one sample of the segment of the first signal by a same shift value as at least one sample of a segment of a signal of a preceding frame, said first time modifier being configured to perform one among (A) time-shifting the segment of the first signal according to the first time shift and (B) time-warping the segment of the first signal based on the first time shift; and wherein said second frame encoder includes a second time modifier configured to time-modify, based on a second time shift, a segment of a second signal that is based on the second frame, said second time modifier being configured to perform one among (A) time-shifting the segment of the second signal according to the second time shift and (B) time-warping the segment of the second signal based on the second time shift, wherein said second time modifier is configured to change a position of a pitch pulse of the segment of a second signal relative to another pitch pulse of the second signal, and wherein the second time shift is based on information from the time-modified segment of the first signal; and a transmitter configured to transmit the first encoded frame and the second encoded frame to a decoder that is configured to synthesize the first encoded frame and the second encoded frame and output a synthesized audio signal.<br>71) A non-transitory computer-readable medium comprising instructions which when executed by a processor cause the processor to: classify each of a first frame of an audio signal and a second frame of the audio signal as a frame type from a set of frame types comprising a voiced speech frame, an unvoiced speech frame, a transitional frame, a generic audio frame, and an inactive frame containing only one or more of background noise and silence; encode the first frame of the audio signal according to a first coding scheme to produce a first encoded frame, wherein the first frame is a generic audio frame; encode the second frame of the audio signal according to a relaxed code excited linear prediction (RCELP) coding scheme to produce a second encoded frame, wherein the second frame follows and is consecutive to the first frame in the audio signal, and wherein the first coding scheme is a non-pitch-regularizing (non-PR) coding scheme, and wherein said instructions which when executed by a processor cause the processor to encode the first frame include instructions to time-modify, based on a first time shift, a segment of a first signal that is based on the first frame, wherein the first time shift is applied to at least one sample of the segment of the first signal by a same shift value as at least one sample of a segment of a signal of a preceding frame, said instructions to time-modify including one among (A) instructions to time-shift the segment of the first signal according to the first time shift and (B) instructions to time-warp the segment of the first signal based on the first time shift; and wherein said instructions which when executed by a processor cause the processor to encode the second frame include instructions to time-modify, based on a second time shift, a segment of a second signal that is based on the second frame, said instructions to time-modify including one among (A) instructions to time-shift the segment of the second signal according to the second time shift and (B) instructions to time-warp the segment of the second signal based on the second time shift, wherein said instructions to time-modify a segment of a second signal include instructions to change a position of a pitch pulse of the segment relative to another pitch pulse of the second signal, and wherein the second time shift is based on information from the time-modified segment of the first signal; and transmit the first encoded frame and the second encoded frame to a decoder that synthesizes the first encoded frame and the second encoded frame and outputs a synthesized audio signal.</p></layer>
<layer id = "layer520"><p><b>US8688441B2:Method and apparatus to facilitate provision and use of an energy value to determine a spectral envelope shape for out-of-signal bandwidth content</b><br>The present invention A process for providing an extended tubular article or one or more sections of the extended tubular article with a corrosion protecting system, wherein (a) a layer of an adhesive composition is applied to the surface of the extended tubular article or the one or more sections of the extended tubular article, and (b) a corrosion protecting layer is applied to the layer of the adhesive composition, the adhesive composition comprising a polyolefin blend, wherein the polyolefin blend comprises 30% to 100% by weight of a polyisobutene and 0% to 70% by weight of an olefin polymer, based on the total weight of the polyolefin blend, wherein said polyisobutene is has a glass transition temperature of lower than −40° C. and a number average molecular weight M<sub>n</sub>of 1300 to 1,000,000.<br><b>Independant Claims</b><br>9) An apparatus comprising: an input configured and arranged to receive a digital audio signal having a corresponding signal bandwidth; a processor operably coupled to the input and being configured and arranged to: generate an energy value that represents at least an estimate of entire energy contained in an out-of-signal bandwidth content as corresponds to the digital audio signal; generate a starting magnitude value for the out-of-signal bandwidth spectrum; normalize the energy value using the starting magnitude value; use the normalized energy value to determine a spectral envelope shape and the starting magnitude value to determine a corresponding suitable energy for the spectral envelope shape; for the out-of-signal bandwidth content as corresponds to the digital audio signal.<br>1) A method for rendering audible content in a bandwidth extension system comprising: providing, by a speech encoder in the bandwidth extension system, a digital audio signal having a corresponding signal bandwidth; generating, by a speech decoder in the bandwidth extension system, an energy value that represents at least an estimate of entire energy contained in an out-of-signal bandwidth content as corresponds to the digital audio signal; generating, by the speech decoder, a starting magnitude value for the out-of-signal bandwidth spectrum; normalizing, by the speech decoder, the energy value using the starting magnitude value; using, by the speech decoder: the normalized energy value to determine a spectral envelope shape; and the starting magnitude value to determine a corresponding suitable energy for the spectral envelope shape; for the out-of-signal bandwidth content as corresponds to the digital audio signal.</p></layer>
<layer id = "layer521"><p><b>US8990073B2:Method and device for sound activity detection and sound signal classification</b><br><b>Independant Claims</b><br>1) A method for estimating a tonal stability of a sound signal using a frequency spectrum of the sound signal, the method comprising: calculating a current residual spectrum of the sound signal by subtracting from the frequency spectrum of the sound signal a spectral floor defined by minima of the frequency spectrum; detecting a plurality of peaks in the current residual spectrum as pieces of the current residual spectrum between pairs of successive minima of the current residual spectrum; calculating a correlation map between each detected peak of the current residual spectrum and a shape in a previous residual spectrum corresponding to the position of the detected peak; and identifying the tonal stability of the sound signal based on calculating a long-term correlation map, wherein the long-term correlation map is calculated based on an update factor, the correlation map of a current frame, and an initial value of the long term correlation map.<br>30) A device for estimating a tonal stability tonal stability of a sound signal using a frequency spectrum of the sound signal, the device comprising: means for calculating a current residual spectrum of the sound signal by subtracting from the frequency spectrum of the sound signal a spectral floor defined by minima of the frequency spectrum; means for detecting a plurality of peaks in the current residual spectrum as pieces of the current residual spectrum between pairs of successive minima of the current residual spectrum; means for calculating a correlation map between each detected peak of the current residual spectrum and a shape in a previous residual spectrum corresponding to the position of the detected peak; and means for identifying the tonal stability of the sound signal based on calculating a long-term correlation map, wherein the long-term correlation map is calculated based on an update factor, the correlation map of a current frame, and an initial value of the long-term correlation map.<br>31) A device for estimating a tonal stability tonal stability of a sound signal using a frequency spectrum of the sound signal, the device comprising: a calculator of a current residual spectrum of the sound signal by subtracting from the frequency spectrum of the sound signal a spectral floor defined by minima of the frequency spectrum; a detector of a plurality of peaks in the current residual spectrum as pieces of the current residual spectrum between pairs of successive minima of the current residual spectrum; a calculator of a correlation map between each detected peak of the current residual spectrum and a shape in a previous residual spectrum corresponding to the position of the detected peak; and a calculator identifying the tonal stability of the sound signal based on calculating a long-term correlation map, wherein the long-term correlation map is calculated based on an update factor, the correlation map of a current frame, and an initial value of the long-term correlation map.</p></layer>
<layer id = "layer522"><p><b>US8788264B2:Audio encoding method, audio decoding method, audio encoding device, audio decoding device, program, and audio encoding/decoding system</b><br>Systems, methods, and computer-readable media for fault code aggregation across application-centric dimensions. In an example embodiment, a system obtains respective fault codes corresponding to one or more network devices in a network and maps the one or more network devices and/or the respective fault codes to respective logical policy entities defined in a logical policy model of the network, to yield fault code mappings. The system aggregates the one or more of the fault code mappings along respective logical policy dimensions in the network to yield an aggregation of fault codes across respective logical policy dimensions and, based on the aggregation, presents, for each of the respective logical policy dimensions, one or more hardware-level errors along the respective logical policy dimension.<br><b>Independant Claims</b><br>21) An audio encoding/decoding system comprising: an audio encoding device which generates encoded audio data by encoding an input audio signal; and an audio decoding device which generates a decoded audio signal by decoding the encoded audio data generated by said audio encoding device, wherein said audio encoding device comprises: an orthogonal transformer which transforms an input audio signal comprising a plurality of frames into a frequency signal for each frame of the plurality of frames, the plurality of frames including a current frame and a past frame which is earlier in time than the current frame, and the frequency signal being divided into a plurality of bands; a gain calculator which: calculates, for each band of the plurality of bands, an initial gain for scaling each band of the plurality of bands for the current frame; and corrects the initial gain by using a past gain for each band of the plurality of bands for the past frame, thereby calculating a corrected gain for each band of the plurality of bands for the current frame; a quantizer which generates a quantized signal by scaling and quantizing the frequency signal for the current frame by using the corrected gain for each band of the plurality of bands for the current frame; a gain encoder which generates gain information by encoding, for each band of the plurality of bands for the current frame, a difference between the corrected gain obtained by said gain calculator and the past gain as the gain information; and a multiplexer which generates encoded audio data by multiplexing, for each band of the plurality of bands for the current frame, the quantized signal obtained by said quantizer and the gain information obtained by said gain encoder, and wherein said audio decoding device comprises: a demultiplexer which demultiplexes encoded audio data which includes a plurality of frames and is input frame by frame into the audio decoding device, the plurality of frames including a current frame and a past frame which is earlier in time than the current frame, and the demultiplexing of the encoded audio data comprising demultiplexing quantized signal information and gain information for scaling the quantized signal from the encoded audio data generated by said audio encoding device, the quantized signal being divided into a plurality of bands; a memory which stores a past gain for each band of the plurality of bands for the past frame; a gain decoder which decodes a gain for each band of a plurality of bands for the current frame by using: the past gain for each band of the plurality of bands for the past frame acquired from said memory; and a differential gain included in the gain information demultiplexed by said demultiplexer; an inverse quantizer which inversely quantizes and scales the quantized signal information demultiplexed by said demultiplexer for each band of the plurality of bands for the current frame based on the gain obtained by said gain decoder, thereby generating a frequency signal for the current frame; and an orthogonal transformer which generates a decoded audio signal by orthogonally transforming the frequency signal for the current frame obtained by said inverse quantizer.<br>1) An audio encoding method comprising: in an audio encoding device: transforming an input audio signal comprising a plurality of frames into a frequency signal for each frame of the plurality of frames of the input audio signal, the plurality of frames including a current frame and a past frame which is earlier in time than the current frame, and the frequency signal being divided into a plurality of bands; calculating, for each band of the plurality of bands, an initial gain for scaling the frequency signal for the current frame; correcting the initial gain by using a past gain for each band of the plurality of bands for the past frame of the plurality of frames, thereby calculating a corrected gain for each band of the plurality of bands for the current frame; generating a quantized signal by scaling and quantizing the frequency signal for the current frame by using the corrected gain for each band of the plurality of bands for the current frame; generating gain information by encoding, for each band of the plurality of bands for the current frame, a difference between the corrected gain and the past gain as the gain information; and generating encoded audio data by multiplexing, for each band of the plurality of bands for the current frame, the quantized signal and the gain information.<br>17) An audio decoding device comprising: a demultiplexer which demultiplexes encoded audio data which includes a plurality of frames and is input frame by frame into the audio decoding device, the plurality of frames including a current frame and a past frame which is earlier in time than the current frame, and the demultiplexing of the encoded audio data comprising demultiplexing quantized signal information and gain information for scaling a quantized signal from encoded audio data, the quantized signal being divided into a plurality of bands; a memory which stores a past gain for each band of a plurality of bands for the past frame; a gain decoder which decodes a gain for each band of a plurality of bands for the current frame by using: the past gain for each band of the plurality of bands for the past frame stored in said memory; and a differential gain included in the gain information demultiplexed by said demultiplexer; an inverse quantizer which inversely quantizes and scales the quantized signal information demultiplexed by said demultiplexer for each band of the plurality of bands for the current frame based on the gain decoded by said gain decoder, thereby generating a frequency signal for the current frame; and an orthogonal transformer which generates a decoded audio signal by orthogonally transforming the frequency signal for the current frame generated by said inverse quantizer, wherein the gain information includes, for each band of the plurality of bands for the current frame, frame number information indicating the past frame, and a differential gain between the past gain of the past frame and the gain of the current frame, and wherein said gain decoder acquires, for each band of the plurality of bands for the current frame, the past gain of the past frame corresponding to the frame number information of the gain information from said memory, and calculates the gain for each band of the plurality of bands for the current frame from the past gain of the past frame and the differential gain of the gain information.<br>8) An audio decoding method comprising: in an audio decoding device: demultiplexing encoded audio data which includes a plurality of frames and is input frame by frame into the audio decoding device, the plurality of frames including a current frame and a past frame which is earlier in time than the current frame, and the demultiplexing of the encoded audio data comprising demultiplexing quantized signal information and gain information for scaling a quantized signal from the encoded audio data, the quantized signal being divided into a plurality of bands; storing in a memory, a past gain for each band of the plurality of bands for the past frame; decoding a gain for each band of the plurality of bands for the current frame by using: the past gain for each band of the plurality of bands for the past frame acquired from the memory; and a differential gain included in the demultiplexed gain information; inversely quantizing and scaling the demultiplexed and quantized signal information for each band of the plurality of bands for the current frame based on the gain obtained in the decoding of the gain, thereby generating a frequency signal for the current frame; and generating a decoded audio signal by orthogonally transforming the frequency signal for the current frame, wherein the gain information includes, for each band of the plurality of bands for the current frame, frame number information indicating the past frame, and a differential gain between the past gain of the past frame and the gain of the current frame, and wherein the decoding of the gain comprises acquiring, for each band of the plurality of bands for the current frame, the past gain of the past frame corresponding to the frame number information of the gain information from the memory, and calculating the gain for each band of the plurality of bands for the current frame from the past gain and the differential gain of the gain information.<br>10) An audio encoding device comprising: an orthogonal transformer which transforms an input audio signal comprising a plurality of frames into a frequency signal for each frame of the plurality of frames in the input audio signal, the plurality of frames including a current frame and a past frame which is earlier in time than the current frame, and the frequency signal being divided into a plurality of bands; a gain calculator which: calculates, for each band of the a plurality of bands, an initial gain for scaling each band of the plurality of bands in the frequency signal for the current frame; and corrects the initial gain by using a past gain for each band of the plurality of bands for the past frame of the plurality of frames, thereby calculating a corrected gain for each band of the plurality of bands for the current frame; a quantizer which generates a quantized signal by scaling and quantizing the frequency signal for the current frame by using the corrected gain for each band of the plurality of bands for the current frame; a gain encoder which generates gain information by encoding, for each band of the plurality of bands for the current frame, a difference between the corrected gain obtained by said gain calculator and a corresponding past gain as the gain information; and a multiplexer which generates encoded audio data by multiplexing, for each band of the plurality of bands for the current frame, the quantized signal obtained by said quantizer and the gain information obtained by said gain encoder.</p></layer>
<layer id = "layer523"><p><b>US8370135B2:Method and apparatus for encoding and decoding</b><br>It is an object of the present invention to provide a liquid crystal display device with a good display quality, and a manufacturing method of such a liquid crystal display device. A liquid crystal display device (<b>10</b>) includes a liquid crystal display panel (<b>11</b>) with a display surface (<b>20</b>) defining a recessed curved surface having curvature of 1/500- 1/50 (1/mm), and with a scattering section which is arranged parallel to the display surface (<b>20</b>), which defines a recessed curved surface having curvature of 1/500- 1/50 (1/mm), and in which a plurality of elongated regions (A-C) having different haze values are arranged in parallel with each other from a middle section of the curved surface toward both end sections in the curving direction. The haze values of the plurality of elongated regions (A-C) arranged in parallel with each other vary in a step-wise manner from the middle section of the curved surface toward the both end sections in the curving direction.<br><b>Independant Claims</b><br>1) An encoding method comprising: extracting background noise characteristic parameters within a hangover period; for a first superframe after the hangover period, performing background noise encoding based on the extracted background noise characteristic parameters within the hangover period and background noise characteristic parameters of the first superframe; for superframes after the first superframe, performing background noise characteristic parameter extraction and Discontinuous Transmission (DTX) decision for each frame in the superframes after the first superframe; and for the superframes after the first superframe, performing background noise encoding based on extracted background noise characteristic parameters of a current superframe, background noise characteristic parameters of a plurality of superframes previous to the current superframe, and a final DTX decision; wherein the process of, for the first superframe after the hangover period, performing background noise encoding based on the extracted background noise characteristic parameters within the hangover period and the background noise characteristic parameters of the first superframe comprises: within a first frame and a second frame of the first superframe after the hangover period, storing an autocorrelation coefficient of the corresponding first frame and second frame of the first superframe after the hangover period; and within the second frame of the first superframe after the hangover period, extracting an LPC filter coefficient and a residual energy Et of the first superframe based on the autocorrelation coefficients of the first frame and second frame and the extracted background noise characteristic parameters within the hangover period, and performing background noise encoding.<br>22) An encoding method comprising: extracting background noise characteristic parameters within a hangover period; for a first superframe after the hangover period, performing background noise encoding based on the extracted background noise characteristic parameters within the hangover period and background noise characteristic parameters of the first superframe; for superframes after the first superframe, performing background noise characteristic parameter extraction and Discontinuous Transmission (DTX) decision for each frame in the superframes after the first superframe; and for the superframes after the first superframe, performing background noise encoding based on extracted background noise characteristic parameters of a current superframe, background noise characteristic parameters of a plurality of superframes previous to the current superframe, and a final DTX decision; wherein the process of performing DTX decision for each frame in the superframes after the first superframe further comprises, if a frame of the current superframe has a DTX decision of 1, the DTX decision for the Lower-band component of the current superframe represents 1; and wherein, if a final DTX decision of the current superframe represents 1, the process of for superframes after the first superframe, performing background noise encoding based on the extracted background noise characteristic parameters of a current superframe, background noise characteristic parameters of a plurality of superframes previous to the current superframe, and a final DTX decision comprises: determining a smoothing factor for the current superframe, wherein if the DTX decision of the first frame of the current superframe represents zero and the DTX decision of the second frame represents 1, the smoothing factor is 0.1; otherwise, the smoothing factor is 0.5; performing parameter smoothing for the first frame and second frame of the current superframe, the smoothed parameters being the characteristic parameters of the current superframe for performing background noise encoding, wherein the parameter smoothing comprises: calculating the smoothed average Rt(j) from the stationary average autocorrelation coefficient of the first frame and the stationary average autocorrelation coefficient of the second frame, as follows: Rt(j)=smooth_rateRt,1(j)+(1−smooth_rate)Rt,2(j), where smooth_rate is the smoothing factor, Rt,1(j) is the stationary average autocorrelation coefficient of the first frame, and Rt,2(j) is the stationary average autocorrelation coefficient of the second frame; calculating an LPC filter coefficient from the smoothed average Rt(j) based on the Levinson-durbin algorithm; and calculating the smoothed average Ēt from the energy estimate of the first frame and the energy estimate of the second frame, as follows: Ēt=smooth_rateĒt,1+(1−smooth_rate)Ēt,2, where Ēt,1 is the energy estimate of the first frame and Ēt,2 is the energy estimate of the second frame.<br>18) An encoding method comprising: extracting background noise characteristic parameters within a hangover period; for a first superframe after the hangover period, performing background noise encoding based on the extracted background noise characteristic parameters within the hangover period and background noise characteristic parameters of the first superframe; for superframes after the first superframe, performing background noise characteristic parameter extraction and Discontinuous Transmission (DTX) decision for each frame in the superframes after the first superframe; and for the superframes after the first superframe, performing background noise encoding based on extracted background noise characteristic parameters of a current superframe, background noise characteristic parameters of a plurality of superframes previous to the current superframe, and a final DTX decision; wherein the process of, for superframes after the first superframe, performing background noise characteristic parameter extraction for each frame in the superframes after the first superframe comprises calculating the stationary average autocorrelation coefficient of the current frame based on the values of the autocorrelation coefficients of four recent consecutive frames, the stationary average autocorrelation coefficients being the average of the autocorrelation coefficients of two frames having intermediate norm values of autocorrelation coefficients in the four recent consecutive frames; and calculating the LPC filter coefficient and the residual energy from the stationary average autocorrelation coefficient based on the Levinson-durbin algorithm; and wherein, after the residual energy is calculated, the method further comprises performing a long-term smoothing on the residual energy to obtain the energy estimate of the current frame, the smoothing algorithm being E—LT=αE—LT+(1−α)Et,k, with 0 wherein the smoothed energy estimate of the current frame is assigned as the residual energy for quantization, as follows Et,k=E—LT,  where k=1, 2, representing the first frame and the second frame respectively.<br>10) An encoding apparatus comprising: a first extracting unit, configured to extract background noise characteristic parameters within a hangover period; a second encoding unit configured to, for a first superframe after the hangover period, perform background noise encoding based on the extracted background noise characteristic parameters within the hangover period and background noise characteristic parameters of the first superframe; a second extracting unit configured to, for superframes after the first superframe, perform background noise characteristic parameter extraction for each frame in the superframes after the first superframe; a Discontinuous Transmission (DTX) decision unit configured to, for superframes after the first superframe, perform DTX decision for each frame in the superframes after the first superframe; and a third encoding unit configured to, for the superframes after the first superframe, perform background noise encoding based on extracted background noise characteristic parameters of a current superframe, background noise characteristic parameters of a plurality of superframes previous to the current superframe, and a final DTX decision; wherein the second encoding unit comprises: an extracting module configured to, within a first frame and a second frame of the first superframe after the hangover period, store an autocorrelation coefficient of the corresponding first frame and second frame of the first superframe after the hangover period; and an encoding module configured to, within the second frame of the first superframe after the hangover period, extract an LPC filter coefficient and a residual energy Et of the first superframe based on the autocorrelation coefficients of the first frame and second frame and the extracted background noise characteristic parameters within the hangover period, and perform background noise encoding.</p></layer>
<layer id = "layer524"><p><b>US20090012786A1:Adaptive Noise Cancellation</b><br>This invention relates to methionine producing recombinant microorganisms. Specifically, this invention relates to recombinant strains of <i>Corynebacterium </i>that produce increased levels of methionine compared to their wild-type counterparts and further to methods of generating such microorganisms.<br><b>Independant Claims</b><br>1. A method of speech-free noise estimation, comprising the steps of: (a) sample and frame an audio input; (b) apply noise suppression to the frames to estimate speech content of the frames; (c) cancel the speech content from the frames to give a speech-free noise estimated frames.<br>2. A method of noise cancellation, comprising the steps of: (a) sample and frame both a primary audio input and a noise-reference audio input; (b) apply speech suppression to the noise-reference frames; (c) apply a voice activity detector to the primary frames; when there is no voice activity, update the coefficients of an adaptive noise cancellation (ANC) filter; (d) apply the ANC filter to the speech-free noise estimate to get an estimate of the primary noise; and (e) subtract the estimate of primary noise from the primary input to get the noise cancelled speech.<br>3. An adaptive audio noise canceller, comprising: (a) a primary input and a noise-reference input; (b) a speech suppressor coupled to the noise-reference input; (c) a voice activity detector (VAD) coupled to the primary input; and (d) an adaptive noise cancellation (ANC) filter coupled to the primary input, to the VAD, and to the speech suppressor, wherein the ANC filter is operable to: (i) when the VAD indicates no voice activity, update filter coefficients of the ANC filter; (ii) apply the ANC filter to the output of the speech suppressor to get an estimate of noise at the primary input; and (iii) subtract the estimate of noise at the primary input from an input signal at the primary input.</p></layer>
<layer id = "layer525"><p><b>US8332210B2:Regeneration of wideband speech</b><br>A gas turbine engine includes first and second shafts rotatable about a common axis. The gas turbine engine includes a fan, and first and second gear trains interconnected to one another and coupling the first shaft to fan.<br><b>Independant Claims</b><br>1) A method of processing a narrowband speech signal comprising speech samples in a first range of frequencies, the method comprising: generating from the narrowband speech signal, using a computing device, a highband speech signal in a second range of frequencies above the first range of frequencies; determining, using the computing device, a pitch of the highband speech signal; using the pitch to generate, using the computing device, a pitch-dependent tonality measure from samples of the highband speech signal, wherein the highband speech signal comprises successive blocks of speech samples, and wherein using the pitch to generate the pitch-dependent tonality measure is carried out by combining speech samples from a block with equivalently positioned speech samples from that block delayed by the pitch; and filtering, using the computing device, the speech samples using a gain factor derived from the tonality measure and selected to reduce the amplitude of harmonics in the highband speech signal.<br>7) A method of regenerating a wideband speech signal at a receiver which receives a narrowband speech signal in encoded form via a transmission channel, the method comprising: decoding, using a computing device, the received signal to generate speech samples of a narrowband speech signal; regenerating from the narrowband speech signal, using the computing device, a highband speech signal, the highband speech signal having frequencies of higher numerical value than frequencies of the narrowband speech signal; determining, using the computing device, a pitch of the highband speech signal; using the pitch to generate, using the computing device, a pitch-dependent tonality measure from samples of the highband speech signal, wherein using the pitch to generate the pitch-dependent tonality measure comprises combining speech samples from a block of speech samples in the highband speech signal with equivalently positioned speech samples from the block delayed by the pitch; filtering, using the computing device, the speech samples using a gain factor derived from the tonality measure and selected to reduce the amplitude of harmonics in the highband speech signal; and combining, using the computing device, the filtered highband speech signal with the narrowband speech signal to regenerate the wideband speech signal.<br>14) A system for processing a narrowband speech signal comprising speech samples in a first range of frequencies, the system comprising: means for generating from the narrowband speech signal a highband speech signal in a second range of frequencies above the first range of frequencies; means for determining a pitch of the highband speech signal; means for generating a pitch-dependent tonality measure from samples of the highband speech signal using the pitch, wherein the means for generating the pitch-dependent tonality measure comprises means for combining speech samples from a block of speech samples in the highband speech signal with equivalently positioned speech samples from the block delayed by the pitch; and means for filtering the speech samples using a gain factor derived from the tonality measure and selected to reduce the amplitude of harmonics in the highband speech signal.</p></layer>
<layer id = "layer526"><p><b>US8386243B2:Regeneration of wideband speech</b><br>The present invention relates to an oil-in-water emulsion for whipped cream and to a whipped cream obtained by whipping the emulsion. In particular, the present invention relates to a stabilized whippable oil-in-water emulsion upon increasing the trilaurin triglyceride content of its oily phase, and to the stabilized cream obtained by whipping the emulsion. The present invention further relates to the methods for obtaining this emulsion and this cream, and to the uses of an oil-in-water emulsion according to the invention or of the stabilized cream according to the invention.<br><b>Independant Claims</b><br>1) A method of regenerating wideband speech from narrowband speech, the method comprising: receiving samples of a narrowband speech signal in a first range of frequencies; modulating received samples of the narrowband speech signal with a modulation signal having a modulating frequency adapted to upshift each frequency in the first range of frequencies by an amount determined by the modulating frequency wherein the modulating frequency is selected to translate into a target band a selected frequency band within the first range of signals, wherein the modulating frequency is normalised with respect to a sampling frequency used for generating the samples of the narrowband speech signal prior to modulation of the received samples; filtering the modulated samples using a high pass filter to form a regenerated speech signal in the target band, wherein the lower limit of the high pass filter defines the lowermost frequency in the target band; and combining the narrow band speech signal with the regenerated speech signal in the target band to regenerate a wideband speech signal.<br>12) A system for generating wideband speech from narrowband speech, the system comprising: means for receiving samples of a narrowband speech signal in a first range of frequencies; means for modulating received samples of the narrowband speech signal with a modulation signal having a modulating frequency adapted to upshift each frequency in the first range of frequencies by an amount determined by the modulating frequency wherein the modulating frequency is selected to translate into a target band a selected frequency band within the first range of signals, wherein the modulating frequency is normalised with respect to a sampling frequency used for generating the samples of the narrowband speech signal prior to modulation of the received samples; a high pass filter for filtering the modulated samples to form a regenerated speech signal in a target band when the lower limit of the high pass filter is above the uppermost frequency of the narrowband speech; and means for combining the narrowband speech signal with the regenerated speech signal in the target band to regenerate a wideband speech signal.</p></layer>
<layer id = "layer527"><p><b>US8326616B2:Dynamic noise reduction using linear model fitting</b><br>A film-forming apparatus and method for the formation of silicon carbide comprising, a film-forming chamber to which a reaction gas is supplied, a temperature-measuring unit which measures a temperature within the chamber, a plurality of heating units arranged inside the chamber, an output control unit which independently controls outputs of the plurality of heating units, a substrate-transferring unit which transfers a substrate into, and out of the chamber, wherein the output control unit turns off or lowers at least one output of the plurality of heating units when the film forming process is completed, when the temperature measured by the temperature-measuring unit reaches a temperature at which the substrate-transferring unit is operable within the chamber, then at least one output of the plurality of heating units turned off or lowered, is turned on or raised, and the substrate is transferred out of the film-forming chamber by the substrate-transferring unit.<br><b>Independant Claims</b><br>16) A noise attenuation method, comprising: fitting a first line to a first portion of a sound signal; fitting a second line to a second portion of the sound signal; calculating a difference between the first line and the second line; calculating a dynamic adjustment factor based on the difference; and attenuating a portion of a noise detected in the sound signal based on the dynamic adjustment factor; where the first line is a first linear regression model and the second line is a second linear regression model, where the step of fitting the first line comprises fitting the first linear regression model to the first portion of a power spectrum of the sound signal, and where the step of fitting the second line comprises fitting the second linear regression model to the second portion of the power spectrum of the sound signal.<br>17) A non-transitory computer-readable medium with instructions stored thereon, where the instructions are executable by a processor to cause the processor to perform the steps of: fitting a first line to a first portion of a sound signal; fitting a second line to a second portion of the sound signal; calculating a difference in slope or coordinate intercept between the first line and the second line; calculating a dynamic adjustment factor based on the difference; and attenuating a portion of a noise detected in the sound signal based on the dynamic adjustment factor.<br>8) A noise attenuation system, comprising: a modeler configured to fit a first line to a first portion of a sound signal and a second line to a second portion of the sound signal; a dynamic noise adjuster configured to calculate a difference between the first line and the second line, and calculate a dynamic adjustment factor based on the difference; and a dynamic noise processor configured to attenuate a portion of a noise detected in the sound signal based on the dynamic adjustment factor; where the first line is a first linear regression model and the second line is a second linear regression model; and where the modeler is configured to fit the first linear regression model to the first portion of a power spectrum of the sound signal, and fit the second linear regression model to the second portion of the power spectrum of the sound signal.<br>9) A noise attenuation method, comprising: fitting a first line to a first portion of a sound signal; fitting a second line to a second portion of the sound signal; calculating a difference in slope or coordinate intercept between the first line and the second line; calculating a dynamic adjustment factor based on the difference; and attenuating a portion of a noise detected in the sound signal based on the dynamic adjustment factor.<br>1) A noise attenuation system, comprising: a modeler configured to fit a first line to a first portion of a sound signal and a second line to a second portion of the sound signal; a dynamic noise adjuster configured to calculate a difference in slope or coordinate intercept between the first line and the second line, and calculate a dynamic adjustment factor based on the difference; and a dynamic noise processor configured to attenuate a portion of a noise detected in the sound signal based on the dynamic adjustment factor.</p></layer>
<layer id = "layer528"><p><b>US9190068B2:Signal presence detection using bi-directional communication data</b><br><b>Independant Claims</b><br>1) An apparatus for detecting signal presence using bidirectional communication data comprising: a memory; at least one processor associated with the memory; a signal detection module, using the at least one processor, for collecting data from a transmit direction, collecting data from a receiving direction and classifying collected data from a first direction as signal or noise based in part on collected data from a second direction, the second direction different than the first direction and wherein the first direction and the second direction are each one of the transmit direction and the receiving direction, wherein the signal detection module applies voice activity detection (VAD) to analyze the collected data and to determine whether the collected data is speech, pause, voice, non-voice, or music, wherein the data received from the transmit direction and the data received from the receive direction is used to modify a threshold value determining whether data is processed as speech or noise, wherein if neither a speech threshold nor a noise threshold from the second direction indicates the data is speech or noise, the signal detection module examines additional data from both the first direction and the second direction; and a signal enhancement module, using the at least one processor, for enhancing data responsive to the classification of the collected data in the first direction, wherein the classification of the collected data in the first direction is used to enhance a data signal in the second direction.<br>11) A method for enhancing signal quality using bi-directional communication data comprising: establishing a data connection including a transmit direction and a receive direction; collecting classification data from the transmit direction; collecting classification data from the receive direction; classifying data from a first direction as signal or noise based in part on collected data from a second direction, the second direction being different than the first direction and wherein the first direction and the second direction are each one of the transmit direction and the receiving direction, wherein classifying includes applying voice activity detection (VAD) to analyze the collected data and to determine whether the collected data is speech, pause, voice, non-voice, or music, wherein the data received from the transmit direction and the data received from the receive direction is used to modify a threshold value determining whether data is processed as speech or noise, wherein if neither a speech threshold nor a noise threshold from the second direction indicates the data is speech or noise, the signal detection module examines additional data from both the first direction and the second direction; and modifying power consumption of a transmitting device responsive to the classification of the transmit direction data and the classification of the receive direction data, wherein the classification of the collected data in the first direction is used to enhance a data signal in the second direction.<br>21) A non-transitory computer readable storage medium having instructions thereon that when executed by one or more processors causes the processors to: establish a data connection including a transmit direction and a receive direction; collect classification data from the transmit direction; collect classification data from the receive direction; classify data from a first direction as signal or noise based in part on collected data from a second direction, the second direction being different than the first direction and wherein the first direction and the second direction are each one of the transmit direction and the receiving direction, wherein classifying includes applying voice activity detection (VAD) to analyze the collected data and to determine whether the collected data is speech, pause, voice, non-voice, or music, wherein the data received from the transmit direction and the data received from the receive direction is used to modify a threshold value determining whether data is processed as speech or noise, wherein if neither a speech threshold nor a noise threshold from the second direction indicates the data is speech or noise, the signal detection module examines additional data from both the first direction and the second direction; and modify power consumption of a transmitting device responsive to the classification of the transmit direction data and the classification of the receive direction data, wherein the classification of the collected data in the first direction is used to enhance a data signal in the second direction.</p></layer>
<layer id = "layer529"><p><b>US20090048846A1:Method for Expanding Audio Signal Bandwidth</b><br>A pitch adjustment device for selectively adjusting the pitch of the string(s) of a stringed musical instrument. Each string of the instrument is attached to a respective pitch adjustment device. Each pitch adjustment device comprises a tuning key to which the string is attached. The tuning key is mounted on a pivotable lever. A pull rod is attached to the lever to selectively pivot the lever. When the pull rod is actuated, it causes the lever and the tuning key to pivot, thereby adjusting the tension or pitch of the string. While the lever and tuning key pivot, the adjustment of the tuning key relative to the lever remains unchanged. Accordingly, when the pull rod is de-actuated, the lever and tuning key return to their original position and the string returns to its normal open pitch. A roller nut having a pivoting knife-edged surface is also provided.<br><b>Independant Claims</b><br>1. A method for expanding a bandwidth of an audio signal, comprising: determining a magnitude time-frequency representation |G(ω,t) for example audio signals g(t); estimating a set of frequency marginal probabilities PG(ω|z) from |G(ω,t)|; determining a magnitude time-frequency representation |X(ω,t) of an input signal audio signal x(t); determining probabilities P(z), PX(z) and PX(t|z) using PG(ω|z)|X(ω, t)|; reconstructing |Ŷ(ω,t)| according to PzPX(z)PG(ω|z)PX(t|z); and transforming |Ŷ(ω,t)| to a time domain to obtain a high-quality output audio signal ŷ(t) corresponding to the input audio signal x(t).</p></layer>
<layer id = "layer530"><p><b>US8700388B2:Audio transform coding using pitch correction</b><br>Provided is a piezoelectric/electrostrictive film type element in which the film thickness of the piezoelectric/electrostrictive film is small, the piezoelectric/electrostrictive film is dense, and the piezoelectric/electrostrictive film has good durability and insulation quality. The piezoelectric/electrostrictive film type element includes a substrate, a lower electrode film, a piezoelectric/electrostrictive film and an upper electrode film. The substrate and the lower electrode film are fixed adherently each other. The film thickness of the piezoelectric/electrostrictive film is 5 μm or less. The piezoelectric/electrostrictive film is composed of a piezoelectric/electrostrictive ceramic. The piezoelectric/electrostrictive ceramic contains lead zirconate titanate and a bismuth compound. The bismuth/lead ratio in the peripheral section inside the grain which is relatively close to the grain boundary is greater than the bismuth/lead ratio in the center section inside the grain which is relatively far from the grain boundary.<br><b>Independant Claims</b><br>1) An audio processor for generating a processed representation of an audio signal comprising a sequence of frames, the audio processor comprising: a sampler adapted to sample the audio signal within a first and a second frame of the sequence of frames, the second frame following the first frame, the sampler using information on a pitch contour of the first and the second frame to derive a first sampled representation and to sample the audio signal within the second and a third frame, the third frame following the second frame in the sequence of frames using the information on the pitch contour of the second frame and information on a pitch contour of the third frame to derive a second sampled representation; a transform window calculator adapted to derive a first scaling window for the first sampled representation and a second scaling window for the second sampled representation, the scaling windows depending on the sampling applied to derive the first sampled representation or the second sampled representation; and a windower adapted to apply the first scaling window to the first sampled representation and the second scaling window to the second sampled representation to derive a processed representation of the first, second and third audio frames of the audio signal, wherein at least one of the sampler, the transform window calculator, and the windower comprises a hardware implementation.<br>15) An audio processor for processing a first sampled representation of a first and a second frame of an audio signal comprising a sequence of frames in which the second frame follows the first frame and for processing a second sampled representation of the second frame and of a third frame of the audio signal following the second frame in the sequence of frames, comprising: a transform window calculator adapted to derive a first scaling window for the first sampled representation using information on a pitch contour of the first and the second frame and to derive a second scaling window for the second sampled representation using information on a pitch contour of the second and the third frames, wherein the scaling windows comprise an identical number of samples and wherein a first number of samples used to fade out the first scaling window differs from a second number of samples used to fade in the second scaling window; a windower adapted to apply the first scaling window to the first sampled representation and to apply the second scaling window to the second sampled representation; and a re-sampler adapted to re-sample the first scaled sampled representation to derive a first re-sampled representation using the information on the pitch contour of the first and the second frame and to re-sample the second scaled sampled representation to derive a second re-sampled representation using the information on the pitch contour of the second and the third frames, the re-sampling depending on the scaling windows derived, wherein at least one of the transform window calculator, the windower, and the re-sampler comprises a hardware implementation.<br>17) A method for generating a processed representation of an audio signal comprising a sequence of frames comprising: sampling, by a sampler, the audio signal within a first and a second frame of the sequence of frames, the second frame following the first frame, the sampling using information on a pitch contour of the first and the second frame to derive a first sampled representation; sampling, by the sampler, the audio signal within the second and a third frame, the third frame following the second frame in the sequence of frames, the sampling using the information on the pitch contour of the second frame and information on a pitch contour of the third frame to derive a second sampled representation; deriving, by a transform window calculator, a first scaling window for the first sampled representation and a second scaling window for the second sampled representation, the scaling windows depending on the samplings applied to derive the first sampled representation or the second sampled representation; and applying, by a windower, the first scaling window to the first sampled representation and applying the second scaling window to the second sampled representation, wherein at least one of the sampler, the transform window calculator, and the windower comprises a hardware implementation.<br>18) A method for processing a first sampled representation of a first and a second frame of an audio signal comprising a sequence of frames in which the second frame follows the first frame and for processing a second sampled representation of the second frame and of a third frame of the audio signal following the second frame in the sequence of frames, comprising: deriving, by a transform window calculator, a first scaling window for the first sampled representation using information on a pitch contour of the first and the second frame and deriving a second scaling window for the second sampled representation using information on a pitch contour of the second and the third frame, wherein the scaling windows are derived such that they comprise an identical number of samples, wherein a first number of samples used to fade out the first scaling window differs from a second number of samples used to fade in the second scaling window; applying, by a windower, the first scaling window to the first sampled representation and the second scaling window to the second sampled representation; and re-sampling, by a re-sampler, the first scaled sampled representation to derive a first re-sampled representation using the information on the pitch contour of the first and the second frame and re-sampling the second scaled sampled representation to derive a second re-sampled representation using the information on the pitch contour of the second and the third frame the re-sampling depending on the scaling windows derived, wherein at least one of the transform window calculator, the windower, and the re-sampler comprises a hardware implementation.<br>20) A non-transitory computer readable storage medium having stored thereon a computer program with program code for executing, when the computer program runs on a computer, a method for generating a processed representation of an audio signal comprising a sequence of frames, the method comprising: sampling the audio signal within a first and a second frame of the sequence of frames, the second frame following the first frame, the sampling using information on a pitch contour of the first and the second frame to derive a first re-sampled representation; sampling the audio signal within the second and a third frame, the third frame following the second frame in the sequence of frames, the sampling using the information on the pitch contour of the second frame and information on a pitch contour of the third frame to derive a second sampled representation; deriving a first scaling window for the first sampled representation and a second scaling window for the second sampled representation, the scaling windows depending on the samplings applied to derive the first sampled representations or the second sampled representation; and applying the first scaling window to the first sampled representation and applying the second scaling window to the second sampled representation.<br>21) A non-transitory computer readable storage medium having stored thereon a computer program with program code for executing, when the computer program runs on a computer, a method for processing a first sampled representation of a first and a second frame of an audio signal comprising a sequence of frames in which the second frame follows the first frame and for processing a second sampled representation of the second frame and of a third frame of the audio signal following the second frame in the sequence of frames, the method comprising: deriving a first scaling window for the first sampled representation using information on a pitch contour of the first and the second frame and deriving a second scaling window for the second sampled representation using information on a pitch contour of the second and the third frame, wherein the scaling windows are derived such that they comprise an identical number of samples, wherein a first number of samples used to fade out the first scaling window differs from a second number of samples used to fade in the second scaling window; applying the first scaling window to the first sampled representation and the second scaling window to the second sampled representation; and re-sampling the first scaled sampled representation to derive a first re-sampled representation using the information on the pitch contour of the first and the second frame and re-sampling the second scaled sampled representation to derive a second re-sampled representation using the information on the pitch contour of the second and the third frame the re-sampling depending on the scaling windows derived.</p></layer>
<layer id = "layer531"><p><b>US8904400B2:Processing system having a partitioning component for resource partitioning</b><br><b>Independant Claims</b><br>1) A processing system comprising: a processor for accessing a resource; a partitioning component in communication with the processor, the partitioning component configured to associate a resource partition with the resource, the resource partition having a set of partitioning rules including a minimum resource allocation and a maximum resource allocation; and where the partitioning component is configured to intercept a first resource request for the resource sent from a requesting software application and/or process to a resource allocator configured to reserve a resource, and control access to the resource requested by the requesting software application and/or process in accordance with the set of partitioning rules; and where the partitioning component provides a modified or new resource request to the resource allocator in place of the first resource request wherein the modified or new resource request is based on the set of partitioning rules including a minimum resource allocation and a maximum resource allocation.<br>22) A processing system comprising: a processor for accessing a resource; resource partitioning software executable by the processor to establish a resource partition corresponding to the resource, the resource partition having corresponding partitioning rules including a minimum resource allocation and a maximum resource allocation; and where the resource partitioning software intercepts a first resource request for the resource sent from a requesting software application to a resource allocator configured to reserve a resource, and controls access to the resource requested by the requesting software application and/or process in accordance with the corresponding partitioning rules; and where the resource partitioning software provides a modified or new resource request to the resource allocator in place of the first resource request wherein the modified or new resource request is based on the corresponding partitioning rules including a minimum resource allocation and a maximum resource allocation.<br>24) A method, comprising the steps of: associating a resource partition with a resource, the resource partition having a set of partitioning rules including a minimum resource allocation and a maximum resource allocation; intercepting a first resource request sent from a software application and/or process to a resource allocator, the first resource request including a request for access to the resource; controlling access to the resource in accordance with the set of partitioning rules associated with the resource; and providing a modified or new resource request to the resource allocator in place of the first resource request wherein the modified or new resource request is based on the set of partitioning rules including a minimum resource allocation and a maximum resource allocation.<br>27) A processing system comprising: a processor including means for associating a resource partition with a resource, the resource partition having a set of partitioning rules including a minimum resource allocation and a maximum resource allocation; means for intercepting a first resource request sent from a software application to a resource allocator, the first resource request including a request for access to the resource; means for controlling access to the resource in accordance with the set of partitioning rules associated with the resource; and means for providing a modified or new resource request to the resource allocator in place of the first resource request wherein the modified or new resource request is based on the set of partitioning rules including a minimum resource allocation and a maximum resource allocation.</p></layer>
<layer id = "layer532"><p><b>US8694310B2:Remote control server protocol system</b><br>The invention relates to a method for manufacturing a photovoltaic module comprising plurality of solar cells in a thin-layer structure, in which the following are formed consecutively in the structure: an electrode on the rear surface (<b>41</b>), a photovoltaic layer (<b>43</b>) obtained by depositing components including metal precursors and at least one element taken from Se and S and by annealing such as to convert said components into a semiconductor material, and another semiconductor layer (<b>44</b>) in order to create a pn junction with the photovoltaic layer (<b>43</b>); characterised in that the metal precursors form, on the electrode on the rear surface (<b>41</b>), a continuous layer, while said at least one element forms a layer having at least one break making it possible, at the end of the annealing step, to leave an area (<b>430</b>) of the layer of metal precursors in the metal state at said break.<br><b>Independant Claims</b><br>1) A remote control server protocol system for transporting data, comprising: a client system having a processor and a memory; a speech enhancement system in communication with the client system, where the client system communicates with the speech enhancement system remotely using a platform-independent communications protocol configured to control operation of the speech enhancement system; the client system configured to send command messages to the speech enhancement system, and the speech enhancement system configured to send response messages to the client system in response to the command messages sent from the client system; where the speech enhancement system comprises a plurality of modules, each of the modules is configured to perform a corresponding speech enhancement process, the client system is configured to tune the speech enhancement system for an acoustic environment with an adjustment of at least one parameter of the speech enhancement system in response to at least one of the command messages sent from the client system with the platform-independent communications protocol, and the speech enhancement system is configured to determine a set of the modules to create based on an initialization parameter sent from the client system with the platform-independent communications protocol, and create each module of the set of modules; and where the command messages and the response messages are sent over a single communications channel using the platform-independent communications protocol.<br>15) A non-transitory computer-readable storage medium comprising instructions executable with a processor to transport data by performing the acts of: providing a client system operable by a user; providing a speech enhancement system in communication with the client system, the speech enhancement system comprising a plurality of modules, each of the modules configured to perform a corresponding speech enhancement process; sending command messages from the client system to the speech enhancement system over a single communications channel using a platform-independent communications protocol to remotely control operation of the speech enhancement system; sending response messages from the speech enhancement system to the client system over the single communications channel using the platform-independent communications protocol in response to the command messages sent from the client system; tuning the speech enhancement system for an acoustic environment with the client system by adjusting at least one parameter of the speech enhancement system in response to at least one of the command messages; sending an initialization parameter from the client system to the speech enhancement system with the platform-independent communications protocol; determining a set of the modules to create based on the initialization parameter sent from the client system with the platform-independent communications protocol; and creating each module of the set of modules.<br>22) A method for transporting data, comprising: providing a speech enhancement system comprising a plurality of modules, each of the modules configured to perform a corresponding speech enhancement process; the speech enhancement system receiving command messages, the command messages sent over a single communications channel using a platform-independent communications protocol and configured to control operation of the speech enhancement system; sending response messages from the speech enhancement system over the single communications channel using the platform-independent communications protocol in response to the command messages received; tuning the speech enhancement system for an acoustic environment by adjusting at least one parameter of the speech enhancement system in response to at least one of the command messages; the speech enhancement system receiving an initialization parameter, the initialization parameter sent over the single communications channel using the platform-independent communications protocol; determining a set of the modules to create based on the initialization parameter; and creating each module of the set of modules.<br>23) A method for transporting data, comprising: providing a client system; sending command messages from the client system over a single communications channel using a platform-independent communications protocol to remotely control operation of an external application comprising a speech enhancement system; the client system receiving response messages sent over the single communications channel using the platform-independent communications protocol in response to the command messages sent from the client system; tuning the speech enhancement system for an acoustic environment with the client system by causing an adjustment of at least one parameter of the speech enhancement system in response to at least one of the command messages sent from the client system; sending an initialization parameter from the client system over the single communications channel using the platform-independent communications protocol; causing determination of a set of the modules to be created based on the initialization parameter; and causing each module of the set of modules to be created.<br>9) A method for transporting data, comprising: providing a client system; providing a speech enhancement system in communication with the client system, the speech enhancement system comprising a plurality of modules, each of the modules configured to perform a corresponding speech enhancement process; sending command messages from the client system to the speech enhancement system over a single communications channel using a platform-independent communications protocol to remotely control operation of the speech enhancement system; sending response messages from the speech enhancement system to the client system over the single communications channel using the platform-independent communications protocol in response to the command messages sent from the client system; tuning the speech enhancement system for an acoustic environment with the client system by adjusting at least one parameter of the speech enhancement system in response to at least one of the command messages sent from the client system with the platform-independent communications protocol; sending an initialization parameter from the client system to the speech enhancement system with the platform-independent communications protocol; determining a set of the modules to create based on the initialization parameter sent from the client system with the platform-independent communications protocol; and creating each module of the set of modules.</p></layer>
<layer id = "layer533"><p><b>US8199933B2:Calculating and adjusting the perceived loudness and/or the perceived spectral balance of an audio signal</b><br>In a coding apparatus for performing motion-compensated coding, N (M>N≧2)-arized images are converted from a coding target image and reference image as M-arized images, and a motion search is conducted using the N-arized images. During this process, the coding apparatus applies low-pass filter processing to the coding target image and the reference image before conversion of the N-arized images.<br><b>Independant Claims</b><br>1) A method for controlling a particular loudness characteristic of an audio signal, wherein the particular loudness characteristic is either an approximation of specific loudness, which is a measure of perceptual loudness as a function of frequency and time, or an approximation of partial specific loudness, which is a measure of perceptual loudness of the signal in the presence of a secondary interfering signal as a function of frequency and time, comprising obtaining an approximation to a target specific loudness, deriving frequency-variant modification parameters usable for modifying the audio signal in order to reduce the difference between its particular loudness characteristic and said approximation to a target specific loudness, and a) applying the modification parameters to the audio signal to reduce the difference between its particular loudness characteristic and said approximation to a target specific loudness, or b) transmitting or storing the modification parameters and the audio signal for temporally separated, spatially separated, or both temporally separated and spatially separated application of the modification parameters to the audio signal to reduce the difference between its particular loudness characteristic and said approximation to a target specific loudness.<br>2) A method for controlling a particular loudness characteristic of an audio signal, wherein the particular loudness characteristic is either an approximation of specific loudness, which is a measure of perceptual loudness as a function of frequency and time, or an approximation of partial specific loudness, which is a measure of perceptual loudness of the audio signal in the presence of a secondary interfering signal as a function of frequency and time, comprising receiving from a transmission or reproducing from a storage medium the audio signal and a) frequency-variant modification parameters for modifying the audio signal, the modification parameters having been derived from an approximation to a target specific loudness, or b) an approximation to a target specific loudness or a representation of the approximation to that target specific loudness, and modifying the audio signal in response to a) the received modification parameters or b) modification parameters derived from said approximation to a target specific loudness or its representation in order to reduce the difference between the particular loudness characteristic of the audio signal and said approximation to a target specific loudness.</p></layer>
<layer id = "layer534"><p><b>US8392179B2:Multimode coding of speech-like and non-speech-like signals</b><br>The present invention relates to a method for a user equipment performing a handover in a wireless communication system, and more specifically, comprises the following steps: transmitting to a serving cell a measurement report message on a target cell including an indicator related to a specific service; receiving from the serving cell a handover command message including information on the specific service, which is provided by the target cell; receiving resource allocation information on the specific service from the target cell using the information on the specific service; and transmitting a handover completion message to the target cell.<br><b>Independant Claims</b><br>24) Apparatus for code excited linear prediction (CELP) audio encoding employing an LPC synthesis filter controlled by LPC parameters, a plurality of codebooks each having codevectors, at least one codebook providing an excitation more appropriate for speech-like signals than for non-speech-like signals and at least one other codebook providing an excitation more appropriate for non-speech-like signals than for speech like signals, and a plurality of gain factors, each associated with a codebook, wherein a speech-like signal means a signal that comprises either a) a single, strong periodical component (a “voiced” speech-like signal), b) random noise with no periodicity (an “unvoiced” speech-like signal), or c) the transition between such signal types, and a non-speech-like signal means a signal that does not have the characteristics of a speech-like signal, the apparatus comprising means for applying linear predictive coding (LPC) analysis to an audio signal to produce LPC parameters, means for selecting, from at least two codebooks, codevectors and/or associated gain factors by minimizing a measure of the difference between said audio signal and a reconstruction of said audio signal derived from the codebook excitations, said at least two codebooks including said at least one codebook providing an excitation more appropriate for speech like signals and said at least one other codebook providing an excitation more appropriate for non-speech-like signals, and means for generating an output usable by a CELP audio decoder to reconstruct the audio signal, said output including LPC parameters, codevector indices, and gain factors, wherein the at least one codebook providing an excitation output more appropriate for speech-like signals than for non-speech-like signals includes a codebook that produces a noise-like excitation and a codebook that produces a periodic excitation and said at least one other codebook includes a codebook that produces a sinusoidal excitation useful for emulating a perceptual audio encoder.<br>26) Apparatus for code excited linear prediction (CELP) audio decoding employing an LPC synthesis filter controlled by LPC parameters, a plurality of codebooks each having codevectors, at least one codebook providing an excitation more appropriate for speech-like signals than for non-speech-like signals and at least one other codebook providing an excitation more appropriate for non-speech-like signals than for speech like signals, and a plurality of gain factors, each associated with a codebook, wherein a speech-like signal means a signal that comprises either a) a single, strong periodical component (a “voiced” speech-like signal), b) random noise with no periodicity (an “unvoiced” speech-like signal), or c) the transition between such signal types, and a non-speech-like signal means a signal that does not have the characteristics of a speech-like signal, the apparatus comprising means for receiving said parameters, codevector indices, and gain factors, means for deriving an excitation signal for said LPC synthesis filter from at least one codebook excitation output, and means for deriving an audio output signal from the output of said LPC filter or from the combination of the output of said LPC synthesis filter and the excitation of one or more ones of said codebooks, the combination being controlled by codevectors and/or gain factors associated with each of the codebooks, wherein the at least one codebook providing an excitation output more appropriate for speech-like signals than for non-speech-like signals includes a codebook that produces a noise-like excitation and a codebook that produces a periodic excitation and the at least one other codebook includes a codebook that produces a sinusoidal excitation useful for emulating a perceptual audio encoder.<br>25) Apparatus for code excited linear prediction (CELP) audio encoding employing an LPC synthesis filter controlled by LPC parameters, a plurality of codebooks each having codevectors, at least one codebook providing an excitation more appropriate for speech-like signals than for non-speech-like signals and at least one other codebook providing an excitation more appropriate for non-speech-like signals than for speech like signals, and a plurality of gain factors, each associated with a codebook, wherein a speech-like signal means a signal that comprises either a) a single, strong periodical component (a “voiced” speech-like signal), b) random noise with no periodicity (an “unvoiced” speech-like signal), or c) the transition between such signal types, and a non-speech-like signal means a signal that does not have the characteristics of a speech-like signal, the apparatus comprising means for separating an audio signal into speech-like and non-speech-like signal components, means for applying linear predictive coding (LPC) analysis to the speech-like signal components of the audio signal to produce LPC parameters, means for minimizing the difference between the LPC synthesis filter output and the speech-like signal components of the audio signal by varying codevector selections and/or gain factors associated with the or each codebook providing an excitation output more appropriate for speech-like signals than for non-speech-like signals, varying codevector selections and/or gain factors associated with the or each codebook providing an excitation output more appropriate for non-speech-like signals than for speech-like signals, and means for providing an output usable by a CELP audio decoder to reproduce an approximation of the audio signal, the output including codevector indices and/or gains associated with each codebook, and said LPC parameters, wherein the at least one codebook providing an excitation output more appropriate for speech-like signals than for non-speech-like signals includes a codebook that produces a noise-like excitation and a codebook that produces a periodic excitation and the at least one other codebook providing an excitation output more appropriate for non-speech-like signals than for speech-like signals includes a codebook that produces a sinusoidal excitation useful for emulating a perceptual audio encoder.<br>19) A method for code excited linear prediction (CELP) audio decoding employing an LPC synthesis filter controlled by LPC parameters, a plurality of codebooks each having codevectors, at least one codebook providing an excitation more appropriate for speech-like signals than for non-speech-like signals and at least one other codebook providing an excitation more appropriate for non-speech-like signals than for speech like signals, and a plurality of gain factors, each associated with a codebook, wherein a speech-like signal means a signal that comprises either a) a single, strong periodical component (a “voiced” speech-like signal), b) random noise with no periodicity (an “unvoiced” speech-like signal), or c) the transition between such signal types, and a non-speech-like signal means a signal that does not have the characteristics of a speech-like signal, the method comprising receiving said parameters, codevector indices, and gain factors, deriving an excitation signal for said LPC synthesis filter from at least one codebook excitation output, and deriving an audio output signal from the output of said LPC filter or from the combination of the output of said LPC synthesis filter and the excitation of one or more ones of said codebooks, the combination being controlled by codevectors and/or gain factors associated with each of the codebooks, wherein the at least one codebook providing an excitation output more appropriate for speech-like signals than for non-speech-like signals includes a codebook that produces a noise-like excitation and a codebook that produces a periodic excitation and the at least one other codebook includes a codebook that produces a sinusoidal excitation useful for emulating a perceptual audio encoder.<br>1) A method for code excited linear prediction (CELP) audio encoding employing an LPC synthesis filter controlled by LPC parameters, a plurality of codebooks each having codevectors, at least one codebook providing an excitation more appropriate for speech-like signals than for non-speech-like signals and at least one other codebook providing an excitation more appropriate for non-speech-like signals than for speech like signals, and a plurality of gain factors, each associated with a codebook, wherein a speech-like signal means a signal that comprises either a) a single, strong periodical component (a “voiced” speech-like signal), b) random noise with no periodicity (an “unvoiced” speech-like signal), or c) the transition between such signal types, and a non-speech-like signal means a signal that does not have the characteristics of a speech-like signal, the method comprising applying linear predictive coding (LPC) analysis to an audio signal to produce LPC parameters, selecting, from at least two codebooks, codevectors and/or associated gain factors by minimizing a measure of the difference between said audio signal and a reconstruction of said audio signal derived from the codebook excitations, said at least two codebooks including said at least one codebook providing an excitation more appropriate for speech like signals and said at least one other codebook providing an excitation more appropriate for non-speech-like signals, and generating an output usable by a CELP audio decoder to reconstruct the audio signal, said output including LPC parameters, codevector indices, and gain factors, wherein the at least one codebook providing an excitation output more appropriate for speech-like signals than for non-speech-like signals includes a codebook that produces a noise-like excitation and a codebook that produces a periodic excitation and said at least one other codebook includes a codebook that produces a sinusoidal excitation useful for emulating a perceptual audio encoder.<br>11) A method for code excited linear prediction (CELP) audio encoding employing an LPC synthesis filter controlled by LPC parameters, a plurality of codebooks each having codevectors, at least one codebook providing an excitation more appropriate for speech-like signals than for non-speech-like signals and at least one other codebook providing an excitation more appropriate for non-speech-like signals than for speech like signals, and a plurality of gain factors, each associated with a codebook, wherein a speech-like signal means a signal that comprises either a) a single, strong periodical component (a “voiced” speech-like signal), b) random noise with no periodicity (an “unvoiced” speech-like signal), or c) the transition between such signal types, and a non-speech-like signal means a signal that does not have the characteristics of a speech-like signal, the method comprising separating an audio signal into speech-like and non-speech-like signal components, applying linear predictive coding (LPC) analysis to the speech-like signal components of the audio signal to produce LPC parameters, minimizing the difference between the LPC synthesis filter output and the speech-like signal components of the audio signal by varying codevector selections and/or gain factors associated with the or each codebook providing an excitation output more appropriate for speech-like signals than for non-speech-like signals, varying codevector selections and/or gain factors associated with the or each codebook providing an excitation output more appropriate for non-speech-like signals than for speech-like signals, and providing an output usable by a CELP audio decoder to reproduce an approximation of the audio signal, the output including codevector indices and/or gains associated with each codebook, and said LPC parameters, wherein the at least one codebook providing an excitation output more appropriate for speech-like signals than for non-speech-like signals includes a codebook that produces a noise-like excitation and a codebook that produces a periodic excitation and the at least one other codebook providing an excitation output more appropriate for non-speech-like signals than for speech-like signals includes a codebook that produces a sinusoidal excitation useful for emulating a perceptual audio encoder.</p></layer>
<layer id = "layer535"><p><b>US8433582B2:Method and apparatus for estimating high-band energy in a bandwidth extension system</b><br>The invention provides a semiconductor device and its manufacturing method in which a memory transistor and a plurality of thin film transistors that have gate insulating films with different thicknesses are fabricated over a substrate. The invention is characterized by the structural difference between the memory transistor and the plurality of thin film transistors. Specifically, the memory transistor and some of the plurality of thin film transistors are provided to have a bottom gate structure while the other thin film transistors are provided to have a top gate structure, which enables the reduction of characteristic defects of the transistor and simplification of its manufacturing process.<br><b>Independant Claims</b><br>1) A method comprising: receiving an input digital audio signal comprising a narrow-band signal within a first band; processing the input digital audio signal to generate a processed digital audio signal; selecting a transition band within the first band, the said transition band having a width but smaller than the width of the first band, and located adjacent to an upper frequency edge of the first band; and estimating a high-band energy level corresponding to an audio signal within a second band located higher and adjacent to the first band based on the processed digital audio signal within the selected transition band wherein the estimation is done without receiving an audio signal within the second band.<br>13) An apparatus, comprising: an input configured and arranged to receive an input digital audio signal comprising a narrow-band signal received within a first bandwidth; a processor operably coupled to the input and being configured and arranged to: process the input digital audio signal to generate a processed digital audio signal; select a transition band within the first band, the said transition band having a width smaller than the width of the first band, and located adjacent to an upper frequency edge of the first band; and estimating a high-band energy level corresponding to an audio signal within a second band located higher and adjacent to the first band based on the processed digital audio signal within the selected transition band wherein the estimation is done without receiving an audio signal within the second band.</p></layer>
<layer id = "layer536"><p><b>US8606566B2:Speech enhancement through partial speech reconstruction</b><br>An agent for preventing or ameliorating skin aging, which exhibits a more excellent effect on the suppression of formation, or the amelioration, of wrinkles on the skin or sagging skin. An agent for preventing or ameliorating skin aging, containing triterpenoid saponins represented by the following formula (1) as an active ingredient, wherein at least one of R<sup>1</sup>and R<sup>2</sup>is a tigloyl group and the other represents a tigloyl group or an angeloyl group; R<sup>3</sup>represents a methyl group or a hydroxymethyl group; and R<sup>4</sup>represents Glc, Xyl or Gal. <chemistry id="CHEM-US-00001" num="00001"><img id="EMI-C00001" he="51.31mm" wi="72.90mm" file="US08853174-20141007-C00001.TIF" alt="embedded image" img-content="chem" img-format="tif"/></chemistry><br><b>Independant Claims</b><br>12) A system that reconstructs speech in real time comprising: an input filter that passes a band limited frequency in an aural bandwidth when a speech is detected; a harmonic generator programmed to reconstruct portions of speech masked by a dynamic noise from changing noise conditions within a vehicle, the harmonic generator generating harmonics of reconstructed speech that occur in a full frequency range of the input filter; a gain controller that dynamically adjusts the signal strength of the generated harmonics to a targeted level based on a signal within the aural bandwidth; a speech reconstruction filter that receives the dynamically adjusted harmonics and allows a portion of the dynamically adjusted harmonics to pass through it based on a frequency response of the speech construction filter and a threshold, the frequency response based on the dynamic noise; and a perceptual filter configured to combine an output of the speech reconstruction filter with the original input speech signal.<br>5) A system that improves speech intelligibility by reconstructing speech comprising: a first filter that passes a portion of an input signal within a varying range while substantially blocking signals above and below the varying range; a non-linear transformation controller configured to generate harmonics of reconstructed speech in the time domain; a multiplier configured to adjust the amplitudes of the harmonics based on an estimated energy in the input signal; and a second filter in communication with the multiplier having a frequency response based on a dynamic noise from changing noise conditions within a vehicle that is detected in the input signal, the second filter configured to receive the amplitude-adjusted harmonics and select a portion of the amplitude-adjusted harmonics based on the frequency response while minimizing or dampening a remaining portion.<br>18) A method that compensates for undesired changes in a speech segment, comprising: selecting a portion of a speech segment lying or occurring in an intermediate frequency band near a low frequency portion of an aural bandwidth; synthesizing harmonics of reconstructed speech using signals that lie or occur within the intermediate frequency band; adjusting the gain of the synthesized harmonics by processing a correlation between the strength of the synthesized harmonics and the strength of the original speech signal; filtering a portion of the adjusted synthesized harmonics based on a dynamic noise from changing noise conditions within a vehicle that is detected in the speech; and weighting the filtered portion of the adjusted synthesized harmonics to reconstruct the speech segment lying in the intermediate frequency band.<br>1) A system that improves speech intelligibility by reconstructing speech segments comprising: a low-frequency reconstruction controller programmed to select a predetermined portion of a time domain speech signal while substantially blocking or substantially attenuating signals above and below the selected predetermined portion; a harmonic generator coupled to the low-frequency reconstruction controller programmed to generate low-frequency harmonics of reconstructed speech in the time domain that lie within a frequency range controlled by a background noise modeler; a gain controller configured to adjust the low-frequency harmonics to substantially match the signal strength in the time domain signal; and a lowpass filter having a frequency response based on a dynamic noise from changing noise conditions within a vehicle, the lowpass filter configured to receive the adjusted low-frequency harmonics and output a selected portion of the adjusted low-frequency harmonics based on the frequency response and a threshold.</p></layer>
<layer id = "layer537"><p><b>US8473301B2:Method and apparatus for audio decoding</b><br>An air management arrangement for a late lean injection combustor system includes a combustor liner defining a combustor chamber. Also included is a sleeve surrounding at least a portion of the combustor liner, the combustor liner and the sleeve defining a cooling annulus for routing a cooling airflow from proximate an aft end of the combustor liner toward a forward end of the combustor liner. Further included is a cooling airflow divider region configured to split the cooling airflow into a first cooling airflow portion and a second cooling airflow portion, wherein the first cooling airflow portion is directed to at least one primary air-fuel injector, wherein the second cooling airflow portion is directed to at least one lean-direct injector extending through the sleeve and the cooling annulus for injection of the second cooling airflow portion into the combustor chamber.<br><b>Independant Claims</b><br>1) A method for decoding an audio signal, comprising: obtaining a lower-band signal component of an audio signal in a received code stream when the audio signal switches from a first bandwidth to a second bandwidth which is narrower than the first bandwidth; extending the lower-band signal component to obtain higher-band information; performing a time-varying fadeout process on the higher-band information obtained through extension to obtain a processed higher-band signal component; and synthesizing the processed higher-band signal component and the obtained lower-band signal component; wherein performing a time-varying fadeout process on the higher-band information further comprises: performing a separate time-varying fadeout process on the higher-band information; or performing a hybrid time-varying fadeout process on the higher-band information; wherein the higher-band information is a higher-band signal component and the step of performing a separate time-varying fadeout process on the higher-band information further comprises: performing a time-domain shaping on the higher-band signal component obtained through extension by using a time-domain gain factor; or performing a frequency-domain higher-band signal component obtained through extension by using time-varying filtering; and wherein after performing a time-domain shaping on the higher-band signal component obtained through extension by using a time-domain gain factor, the method further comprises: performing a frequency-domain time-domain shaped higher-band signal component by using time-varying filtering.<br>4) An apparatus for decoding an audio signal, comprising a processor, an obtaining unit, an extending unit, a time-varying fadeout processing unit, and a synthesizing unit; wherein: the obtaining unit is configured to obtain a lower-band signal component of an audio signal in a received code stream when the audio signal switches from a first bandwidth to a second bandwidth which is narrower than the first bandwidth, and transmit the lower-band signal component to the extending unit; the extending unit is configured to extend the lower-band signal component to obtain higher-band information, and transmit the higher-band information obtained through extension to the time-varying fadeout processing unit; the time-varying fadeout processing unit is configured to perform a time-varying fadeout process on the higher-band information obtained through extension to obtain a processed higher-band signal component, and transmit the processed higher-band signal component to the synthesizing unit; and the synthesizing unit is configured to synthesize the received processed hither-band signal component and the lower-band signal component obtained by the obtaining unit; wherein the time-varying fadeout processing unit further comprises a separate processing sub-unit or a hybrid processing sub-unit; wherein: the separate processing sub-unit is configured to perform a time-domain shaping and/or frequency-domain shaping on the higher-band signal component obtained through extension when the higher-band information obtained through extension is a higher-band signal component, and transmit the processed higher-band signal component to the synthesizing unit; and the hybrid processing sub-unit is configured to: when the higher-band information obtained through extension is a higher-band coding parameter, perform a frequency-domain shaping on the higher-band coding parameter obtained through extension; or when the higher-band information obtained through extension is a higher-band signal component divide the higher-band signal component obtained through extension into sub-bands, perform a frequency-domain shaping on the coding parameter for each sub-band, and transmit the processed higher-band signal component to the synthesizing unit; wherein the separate processing sub-unit further comprises at least one of a first sub-unit, a second sub-unit, a third sub-unit, and a fourth sub-unit; wherein: the first sub-unit is configured to perform a time-domain shaping on the higher-band signal component obtained through extension by using a time-domain gain factor, and transmit the processed higher-band signal component to the synthesizing unit; the second sub-unit is configured to perform a frequency-domain shaping on the higher-band signal component obtained through extension by using time-varying filtering, and transmit the processed higher-band signal component to the synthesizing unit; the third sub-unit is configured to perform a time-domain shaping on the higher-band signal component obtained through extension by using a time-domain gain factor, perform a frequency-domain shaping on the time-domain shaped higher-band signal component by using time-varying filtering, and transmit the processed higher-band signal component to the synthesizing unit; and the fourth sub-unit is configured to perform a frequency-domain shaping on the higher-band signal component obtained through extension by using time-varying filtering, perform a time-domain shaping on the frequency-domain shaped higher-band signal component by using a time-domain gain factor, and transmit the processed higher-band signal component to the synthesizing unit.</p></layer>
<layer id = "layer538"><p><b>US8527283B2:Method and apparatus for estimating high-band energy in a bandwidth extension system</b><br>Methods and systems for administrative management of a secure data storage network are disclosed. One system includes a secure storage appliance configured to host a plurality of volumes, each volume associated with a plurality of shares stored on a corresponding plurality of physical storage devices and having a plurality of volume management settings, wherein each volume is accessible by a group of one or more users, each user assigned an administrative access level, the volume management settings are editable by a first user from the group of one or more users associated with the volume and assigned an administrative access level sufficient to edit the volume management settings, and the volume management settings are inaccessible by a second user from outside the group of one or more users associated with the volume and assigned an administrative access level at least equal to that of the first user.<br><b>Independant Claims</b><br>1) A method comprising: receiving, by a receiver, an input digital audio signal comprising a narrow-band signal; determining, by a processor coupled to the receiver, an estimated high-band energy level corresponding to the input digital audio signal; and modifying, by the processor, the estimated high-band energy level based on the narrow-band signal characteristics; wherein the step of modifying the estimated high-band energy level comprises the step of modifying, by the processor, the estimated high-band energy level based on an occurrence of an onset; wherein the estimated high-band energy levels of a sequence of Kmax frames starting at a frame at which the onset has been detected are modified; and wherein the modifications of the estimated high-band energy levels are stopped before the Kmax-th frame is reached if a voicing level of a frame within the sequence of Kmax frames is less than a threshold.<br>3) A method comprising: receiving, by a receiver, an input digital audio signal comprising a narrow-band signal; receiving, by a processor coupled to the receiver, an estimated high-band energy level corresponding to the input digital audio signal; and modifying, by the processor, the estimated high-band energy level based on the narrow-band signal characteristics; wherein the step of modifying the estimated high-band energy level comprises the step of modifying the estimated high-band energy level based on an occurrence of an onset; wherein the estimated high-band energy levels of a sequence of Kmax frames starting at a frame at which the onset has been detected are modified; and wherein the modifications of the estimated high-band energy levels are stopped before the Kmax-th frame is reached if a voicing level of a frame within the sequence of Kmax frames is less than a threshold.<br>2) An apparatus comprising: a processor, and an estimation and control module (ECM) coupled to the processor and receiving an input digital audio signal comprising a narrow-band signal, generating an estimated high-band energy level corresponding to the input digital audio signal, and modifying the estimated high-band energy level based on the narrow-band signal characteristics wherein the step of modifying the estimated high-band energy level comprises the step of modifying the estimated high-band energy level based on an occurrence of an onset, wherein the estimated his h-band energy levels of a sequence of Kmax frames starting at a frame at witch the onset has been detected are modified, and wherein the modification of the estimated high-band energy levels are stopped before the Kmax-th frame is reached if a voicing level of a frame within the sequence of Kmax frames is less than a threshold.</p></layer>
<layer id = "layer539"><p><b>US9230555B2:Apparatus and method for generating an output audio data signal</b><br><b>Independant Claims</b><br>1) An apparatus for generating an output audio data signal, the apparatus comprising: a receiving device for receiving an input encoded audio data signal comprising a plurality of encoding layers including a base layer and a plurality of enhancement layers; a reference unit for generating reference audio data from a reference set of layers of the plurality of encoding layers; a sampling device for generating sample audio data from a set of layers smaller than the reference set of layers; a comparison processor for comparing the sample audio data to the reference audio data, the comparison reflecting a difference between a first decoded signal corresponding to the sample audio data and a second decoded signal corresponding to the reference audio data; an output device for determining whether the comparison meets a criterion and if so, generating the output audio data signal to not include audio data from a first layer, the first layer being a layer of the reference set not included in the smaller set of layers; and otherwise, generating the output audio data signal to include audio data from the first wherein the comparison is based on a perceptual model, wherein the comparison processor is configured to: generate a first perceptual indication by applying the perceptual model to the reference audio data; and generate a second perceptual indication by applying the perceptual model to the sample audio data; and the output device is arranged to determine whether the comparison meets the criterion in response to a comparison of the first perceptual indication and the second perceptual indication, wherein the perceptual model is configured to: determine an energy measure for each of a plurality of critical bands; apply a loudness compensation to the energy measure of each of the plurality of critical bands to generate a perceptual indication comprising loudness compensated energy measures for each of the critical bands; and the output device is further arranged to determine whether the comparison meets the criterion in response to a comparison of the loudness compensated energy measures for each of the critical bands for the reference audio data and the sample audio data.<br>10) A communication system including a network entity which comprises: a receiving device for receiving an input encoded audio data signal comprising a plurality of encoding layers including a base layer and a plurality of enhancement layers; a reference unit for generating reference audio data from a reference set of layers of the plurality of encoding layers; a sampling device for generating sample audio data from a set of layers smaller than the reference set of layers; a comparison processor for comparing the sample audio data itself to the reference audio data itself, the comparison reflecting a difference between a first decoded signal corresponding to the sample audio data and a second decoded signal corresponding to the reference audio data; an output device for determining whether the comparison meets a criterion and if so, generating the output audio data signal to not include audio data from a first layer, the first layer being a layer of the reference set not included in the smaller set of layers; and otherwise, generating the output audio data signal to include audio data from the first layer, wherein the comparison is based on a perceptual model, wherein the comparison processor is configured to: generate a first perceptual indication by applying the perceptual model to the reference audio data; generate a second perceptual indication by applying the perceptual model to the sample audio data; and the output device is arranged to determine whether the comparison meets the criterion in response to a comparison of the first perceptual indication and the second perceptual indication, wherein the perceptual model is configured to: determine an energy measure for each of a plurality of critical bands; apply a loudness compensation to the energy measure of each of the plurality of critical bands to generate a perceptual indication comprising loudness compensated energy measures for each of the critical bands; and the output device is further arranged to determine whether the comparison meets the criterion in response to a comparison of the loudness compensated energy measures for each of the critical bands for the reference audio data and the sample audio data.<br>13) A method for generating an output audio data signal, the method comprising: receiving an input encoded audio data signal comprising a plurality of encoding layers including a base layer and a plurality of enhancement layers; generating reference audio data from a reference set of layers of the plurality of encoding layers; generating sample audio data from a set of layers smaller than the reference set of layers; comparing the sample audio data itself to the reference audio data itself, the comparison reflecting a difference between a first decoded signal corresponding to the sample audio data and a second decoded signal corresponding to the reference audio data; determining whether the comparison meets a criterion and if so, generating the output audio data signal to not include audio data from a first layer, the first layer being a layer of the reference set not included in the smaller set of layers; and otherwise, generating the output audio data signal to include audio data from the first layer, wherein the comparison is based on a perceptual model, wherein the comparison step further comprises: generating a first perceptual indication by applying the perceptual model to the reference audio data; generating a second perceptual indication by applying the perceptual model to the sample audio data; the method further comprising determining whether the comparison meets the criterion in response to a comparison of the first perceptual indication and the second perceptual indication, wherein the perceptual model is configured to: determine an energy measure for each of a plurality of critical bands; and apply a loudness compensation to the energy measure of each of the plurality of critical bands to generate a perceptual indication comprising loudness compensated energy measures for each of the critical bands; and the method further comprises determining whether the comparison meets the criterion in response to a comparison of the loudness compensated energy measures for each of the critical bands for the reference audio data and the sample audio data.</p></layer>
<layer id = "layer540"><p><b>US8170885B2:Wideband audio signal coding/decoding device and method</b><br>A device (<b>1</b>) for receiving an ingredient cartridge (<b>2</b>) and extracting the ingredient by passing heated liquid through the cartridge, comprises: a cartridge seat (<b>10</b>) that has an open configuration for receiving and/or removing a cartridge from such device and a closed configuration for extracting the ingredient; and a force generation means (<b>46</b>) for assisting a closure or opening movement of the cartridge seat. The force generation means can be associated with a dampening means (<b>47, 48</b>) for dampening the closure or opening movement of the cartridge seat when assisted by the force generating means. The device can have a user-movable handle (<b>41</b>) that is associated with an end-of-stroke feed-back means (<b>50</b>) for providing a corresponding feed-back to a user actuating the handle.<br><b>Independant Claims</b><br>1) A wideband audio signal coding device comprising: an enhancement layer configured to extract a first spectrum parameter from an inputted wideband signal having a first bandwidth, quantize the first spectrum parameter, and convert the first spectrum parameter into a second spectrum parameter; and a coding unit configured to extract a narrowband signal from the inputted wideband signal and code the narrowband signal based on the second spectrum parameter provided from the enhancement layer, wherein the narrowband signal has a second bandwidth smaller than the first bandwidth, and wherein the enhancement layer is configured to normalize the first spectrum parameter, apply an inverse discrete cosine transform (IDCT) to the normalized first spectrum parameter, convert the IDCT applied first spectrum parameter into an exponential scale to extract a frequency component, extract a narrowband spectrum having the second bandwidth from the frequency component, apply an inverse fast Fourier transform (IFFT) to the narrowband spectrum, and convert the IFFT applied narrowband spectrum into the second spectrum parameter using a Levinson-Durbin algorithm.<br>6) A wideband audio signal decoding device comprising: a first parameter converting unit configured to convert a first spectrum parameter into a second spectrum parameter having a first bandwidth; a second parameter converting unit configured to convert the first spectrum parameter into a second spectrum parameter having a second bandwidth; a core decoder configured to decode a coded bit stream to a signal having the second bandwidth based on the second spectrum parameter having the second bandwidth to generate an excitation signal having the second bandwidth; and a high frequency generating unit configured to restore a wideband signal having the first bandwidth based on the second spectrum parameter having the first bandwidth and the excitation signal having the second bandwidth, wherein the first parameter converting unit is configured to normalize the first spectrum parameter, apply an inverse discrete cosine transform (IDCT) to the normalized first spectrum parameter, convert the IDCT applied first spectrum parameter into an exponential scale to extract a frequency component, extract a spectrum having the first bandwidth from the frequency component, apply an inverse fast Fourier transform (IFFT) to the extracted spectrum, and convert the IFFT applied spectrum into the second spectrum parameter having the first bandwidth using a Levinson-Durbin algorithm.<br>13) A wideband audio signal coding method comprising: extracting a first spectrum parameter from an inputted wideband signal having a first bandwidth; quantizing the first spectrum parameter; converting the first spectrum parameter into a second spectrum parameter; and coding a narrowband signal having the second bandwidth, which is extracted from the wideband signal having the first bandwidth, based on the second spectrum parameter, wherein the converting of the first spectrum parameter comprises: normalizing the first spectrum parameter; applying an inverse discrete cosine transform (IDCT) to the normalized first spectrum parameter; converting the IDCT applied first spectrum parameter into an exponential scale to extract a frequency component; extracting a narrowband spectrum having a predetermined bandwidth from the frequency component; applying an inverse fast Fourier transform (IFFT) to the narrowband spectrum; and converting the IFFT applied narrowband spectrum into the second spectrum parameter using a Levinson-Durbin algorithm.<br>18) A wideband audio signal decoding method comprising: converting a first spectrum parameter into a second spectrum parameter having a first bandwidth; converting the first spectrum parameter into a second spectrum parameter having a second bandwidth; decoding a coded bit stream to a signal having the second bandwidth based on the second spectrum parameter having the second bandwidth to generate an excitation signal having the second bandwidth; and restoring a wideband signal having the first bandwidth based on the second spectrum parameter having the first bandwidth and the excitation signal having the second bandwidth, wherein the converting of the first spectrum parameter comprises: normalizing the first spectrum parameter; applying an inverse discrete cosine transform (IDCT) to the normalized first spectrum parameter; converting the IDCT applied first spectrum parameter into an exponential scale to extract a frequency component; extracting a spectrum having the first bandwidth from the frequency component; applying an inverse fast Fourier transform (IFFT) to the spectrum having the first bandwidth; and converting the IFFT applied spectrum into the second spectrum parameter having the first bandwidth using a Levinson-Durbin algorithm.</p></layer>
<layer id = "layer541"><p><b>US8554557B2:Robust downlink speech and noise detector</b><br>A frequency distribution of luminances is acquired from an image data acquired by optically reading a document. A frequency distribution of luminances of a background of the document is generated using the maximum frequency of the acquired frequency distribution as the maximum frequency of the frequency distribution of the luminances of the background of the document. A difference between the generated frequency distribution of the luminances of the background of the document and the acquired frequency distribution of the luminances is acquired, and the frequency distribution of the luminances of the background of the document is corrected based on the acquired difference.<br><b>Independant Claims</b><br>1) A noise estimation process, comprising: estimating a signal magnitude of an aural signal; estimating a noise magnitude of the aural signal; setting a base adaptation rate based on a difference between the signal magnitude and the noise magnitude; generating, by a programmed processor, a noise adaptation rate by modifying the base adaptation rate by an amount that varies based on one or more factors associated with the aural signal; and modifying the estimated noise magnitude of the aural signal by the programmed processor based on the noise adaptation rate.<br>21) A non-transitory computer-readable medium with instructions stored thereon, where the instructions are executable by a processor to cause the processor to perform the steps of: estimating a signal magnitude of an aural signal; estimating a noise magnitude of the aural signal; setting a base adaptation rate based on a difference between the signal magnitude and the noise magnitude; generating a noise adaptation rate by modifying the base adaptation rate by an amount that varies based on one or more factors associated with the aural signal; and modifying the estimated noise magnitude of the aural signal based on the noise adaptation rate.<br>15) A noise estimation system, comprising: one or more magnitude estimators configured to estimate a signal magnitude of an aural signal and a noise magnitude of the aural signal; and a noise decision controller that comprises a programmed processor configured to: set a base adaptation rate based on a difference between the signal magnitude and the noise magnitude; generate a noise adaptation rate by modifying the base adaptation rate by an amount that varies based on one or more factors associated with the aural signal; and modify the estimated noise magnitude of the aural signal based on the noise adaptation rate.</p></layer>
<layer id = "layer542"><p><b>US8315853B2:MDCT domain post-filtering apparatus and method for quality enhancement of speech</b><br>An air-driven shutter device is used in an optical analyzer. The optical analyzer includes a measurement field to which a sample is supplied, a light-emitting unit measurement field for emitting measuring light to the sample, a light-receptive unit for receiving the measuring light that has passed through the sample, and a purge air supplying unit for supplying purge air. The air-driven shutter device includes a shutter and a shutter opening and closing mechanism. The shutter is disposed between the light-emitting unit and/or the light-receptive unit and the measurement field. The shutter opening and closing mechanism keeps the shutter open with pressure of the gas supplied from the purge air supplying unit, and closes the shutter when the pressure of the gas supplied from the purge air supplying unit becomes lower than a predetermined level.<br><b>Independant Claims</b><br>1) A post-filter apparatus for speech enhancement in a Modified Discrete Cosine Transform (MDCT) domain, comprising: a spectrum coefficient producer configured to produce a spectrum coefficient based on an MDCT coefficient of a current speech frame and an MDCT coefficient of a previous speech frame; a normalizer configured to normalize the produced spectrum coefficient; a transformer configured to transform the spectrum coefficient by mapping the normalized spectrum coefficient to a convex function; a filter coefficient producer configured to produce a filter coefficient while adjusting a reflection degree of the transformed spectrum coefficient; an MDCT coefficient producer configured to produce a new MDCT coefficient by multiplying the produced filter coefficient by the MDCT coefficient of the current speech frame; and an inverse transformer transforming the new MDCT coefficient into a speech signal.<br>8) A post-filtering method for speech enhancement in a Modified Discrete Cosine Transform (MDCT) domain, comprising: performing, by a processor, operations of: producing a spectrum coefficient based on an MDCT coefficient of a current speech frame, which MDCT coefficient of the current speech frame is loaded from a memory, and an MDCT coefficient of a previous speech frame; normalizing the produced spectrum coefficient; transforming the spectrum coefficient by mapping the normalized spectrum coefficient to a convex function; producing a filter coefficient while adjusting a reflection degree of the transformed spectrum coefficient; producing a new MDCT coefficient by multiplying the produced filter coefficient by the MDCT coefficient of the current speech frame; and transforming the new MDCT coefficient into a speech signal.</p></layer>
<layer id = "layer543"><p><b>US8150690B2:Speech recognition system and method with cepstral noise subtraction</b><br>An introducer sheath for placement into the vascular system of a human subject. The introducer sheath has a tubular shaft, a side arm, and a hemostasis valve with an integrated attachment mechanism for attaching and detaching a proximal end of the introducer sheath to and from the skin of the human subject.<br><b>Independant Claims</b><br>1) A speech recognition system with cepstral noise subtraction, comprising: a filterbank energy extractor, for obtaining a plurality of first feature vectors according to a voice signal; a cepstral noise subtraction device, for obtaining a first feature vector of a preset voice frame and first feature vectors of a plurality of voice frames before the preset voice frame, so as to calculate a feature mean vector, and calculate a second feature vector of a preset voice frame according to the first feature vector, the feature mean vector, a first scalar coefficient, and a second scalar coefficient of the preset voice frame; a cepstral converter, for converting the second feature vector of the preset voice frame into a cepstral feature vector; a model trainer, for calculating a model parameter according to the cepstral feature vector; and a speech recognizer, for calculating a recognized voice signal according to the cepstral feature vector and the model parameter.<br>11) A speech recognition method with cepstral noise subtraction, comprising: obtaining a plurality of first feature vectors according to a voice signal; obtaining a first feature vector of a preset voice frame and first feature vectors of a plurality of voice frames before the preset voice frame, so as to calculate a feature mean vector; calculating a second feature vector of a preset voice frame according to the first feature vector, the feature mean vector, a first scalar coefficient, and a second scalar coefficient of the preset voice frame; converting the second feature vector of the preset voice frame into a cepstral feature vector; calculating a model parameter according to the cepstral feature vector; and calculating a recognized voice signal according to the cepstral feature vector and the model parameter.</p></layer>
<layer id = "layer544"><p><b>US9264836B2:System for adjusting perceived loudness of audio signals</b><br><b>Independant Claims</b><br>1) A method of adjusting a loudness of an audio signal, the method comprising: receiving an electronic audio signal comprising two or more channels of audio; analyzing a phase between a portion of each of the two or more audio channels to determine a number of samples in the portion of the two or more audio channels that have a same phase; comparing the number of samples that have the same phase to a threshold number to determine whether the samples correspond primarily to voice or background noise; in response to determining that the samples correspond primarily to voice due to the number of samples that have the same phase meeting exceeding the threshold number, selecting a channel of the two or more audio channels, said selecting comprising: determining a dominant channel of the two or more audio channels, and selecting the dominant channel; using one or more processors to process the selected channel to determine a loudness of a portion of the audio signal; computing at least one gain based at least in part on the determined loudness; and applying the at least one gain to the electronic audio signal; and in response to determining that the samples correspond to background noise due to the number of samples that have the same phase being below the threshold number, bypassing said steps of using, computing, and applying.<br>10) A system for adjusting a loudness of an audio signal, the system comprising: a pre-processing module configured to receive an electronic audio signal comprising two or more channels of audio and to select at least one of the channels of audio; a phase analysis module configured to: analyze a phase between a portion of each of the two or more audio channels to determine a number of samples in the portion of the two or more audio channels that have a same phase; compare the number of samples that have the same phase to a threshold number to determine whether the samples correspond primarily to voice or background noise; enable the samples for loudness processing in response to a determination that the samples correspond primarily to voice due to the number of samples that have the same phase exceeding the threshold number; a loudness analysis module comprising one or more processors configured to compute the loudness of the at least one selected channel in response to the samples being enabled for loudness processing by the phase analysis module; a gain control module configured to compute at least one gain based at least in part on the loudness in response to the samples being enabled for loudness processing by the phase analysis module, said computing comprising: calculating a gain for the at least one selected channel of the audio signal based at least partly on the computed loudness, and applying the gain to each channel of the audio signal; and wherein the phase analysis module is further configured to, in response to determining that the samples correspond to background noise due to the number of samples that have the same phase being below the threshold number, bypass the loudness analysis module and gain control module.</p></layer>
<layer id = "layer545"><p><b>US8131541B2:Two microphone noise reduction system</b><br>A groundwater barrier system for preventing the generally lateral, subterranean migration of water (including both liquid and gaseous fluids) beyond an established perimeter, while providing controlled collection of same for use. The present system utilizes a barrier wall, which is formed in-ground via non-permeable membrane in sheet/roll/panel or slurry (materials can include bentonite clay). The present system will be configured to intersect the flow path of the groundwater to be routed to enhance containment or collection of the fluid. In use, the barrier of the present invention is installed by first making an excavation to accommodate the barrier system. The excavation and barrier wall is implemented to a depth so as to allow for the maximum interception with the established water table to be contained or collected, and/or processed based on benefit vs cost analysis. The barrier can also be used to prevent contaminants (including saltwater) from entering surficial freshwater aquifers.<br><b>Independant Claims</b><br>1) A method of noise reduction comprising: using analysis filter banks to decompose each of a first and a second input signal into a plurality of subbands, the first and second input signals being received by two closely spaced microphones; applying an adaptive decorrelation filter in each subband for each of the first and second signals to generate a plurality of filtered subband signals from each of the first and second input signals; adapting the filter in each subband for each of the input signals based on a step-size function associated with the subband and the input signal, wherein a direction of the step-size function associated with a subband and one of the first and second input signals is adjusted according to a phase of a cross-correlation between an input subband signal from the other of the first and second input signals and a filtered subband signal from said other of the first and second input signals; and using a synthesis filter bank to combine said plurality of filtered subband signals from the first input signal to generate a restored fullband signal.<br>8) A noise reduction system comprising: an first input from a first microphone; a second input from a second microphone closely spaced from the first microphone; an analysis filter bank coupled to the first input and arranged to decompose a first input signal into subbands; an analysis filter bank coupled to the second input and arranged to decompose a second input signal into subbands; at least one adaptive filter element arranged to be applied independently in each subband, the at least one adaptive filter element comprising an adaptive decorrelation filter element and wherein the adaptive decorrelation filter element is further arranged to control a direction of adaptation of the filter element for each subband for a first input based on a phase of a cross correlation of a second input subband signal and a second subband signal output from the adaptive decorrelation filter element; and a synthesis filter bank arranged to combine a plurality of restored subband signals output from the at least one adaptive filter element.<br>14) A method of noise reduction comprising: receiving a first signal from a first microphone; receiving a second signal from a second microphone; decomposing, in analysis filter banks the first and second signals into a plurality of subbands; for each subband, applying an adaptive decorrelation filter independently to generate a plurality of filtered subband signals from the first input signal; and combining said plurality of filtered subband signals using a synthesis filter bank to generate a restored fullband signal, wherein applying an adaptive decorrelation filter independently comprises, for each adaptation step m: computing samples of separated signals v0,k(m) and v1,k(m) corresponding to the first and second signals in a subband k based on estimates of filters of length M with coefficients āk and bk using: v0,k(m)=x0,k(m)−x1,k(m)Tāk(m−1)  v1,k(m)=x1,k(m)−x0,k(m)Tbk(m−1)  where: x0,k(m)=[x0,k(m)x0,k(m−1)Λx0,k(m−M+1)]T  x1,k(m)=[x1,k(m)x1,k(m−1)Λx1,k(m−M+1)]T  āk=[ak(0)ak(1)Λak(M−1)]T  bk=[bk(0)bk(1)Λbk(M−1)]T  and; updating the filter coefficients, using: āk(m)=āk(m−1)+μa,k(m)v1,k*(m)v0,k(m) bk(m)= bk(m−1)+μb,k(m)v0,k*(m)v1,k(m) where * denotes a complex conjugate, μa,k(m) and μb,k(m) are subband step-size functions and where: v0,k(m)[v0,k(m)v0,k(m−1)Λv0,k(m−M+1)]T  v1,k(m)[v1,k(m)v1,k(m−1)Λv1,k(m−M+1)]T  and wherein the subband step-size functions are given by: μa,k=2⁢γ⁢⁢exp⁡(-j∠⁢⁢σx⁢⁢1⁢v⁢⁢1,k)M⁡(σx⁢⁢0,k2+σx⁢⁢1,k2)×max⁡(1-σs^⁢0,k2σx⁢⁢0,k2,0)and⁢:μb,k=2⁢γexp⁡(-j∠⁢⁢σx⁢⁢0⁢v⁢⁢0,k)M⁡(σx⁢⁢0,k2+σx⁢⁢1,k2)×max⁡(1-σs^⁢1,k2σx⁢⁢1,k2,0)where⁢:σs^⁢0,k2=E⁢{s^0,k⁡(m)2}σs^⁢1,k2=E⁢{s^1,k⁡(m)2}.⁢σx⁢⁢0,k2=E⁢{x0,k⁡(m)2}σx⁢⁢1,k=E⁢{x1,k⁡(m)2}σx⁢⁢0⁢v⁢⁢0,k=E⁢{x0,k⁡(m)⁢v0,k*⁡(m)}σx⁢⁢1⁢v⁢⁢1,k=E⁢{x1,k⁡(m)⁢v1,k*⁡(m)};and where ŝ0,k(m) and ŝ1,k(m) comprise restored subband signals.</p></layer>
<layer id = "layer546"><p><b>US8275626B2:Apparatus and a method for decoding an encoded audio signal</b><br>In a method for increasing the availability of a hybrid drive having an internal combustion engine and an electric motor, the electric motor is operated as a starter of the internal combustion engine as well as a travel drive unit within the hybrid drive, and at least one operating parameter, corresponding to an operating parameter of the at least one electric motor, is ascertained. An error is identified if the at least one operating parameter value does not correspond to an operating parameter standard state, in which case the operation of the electric motor as the travel drive unit is at least partially limited. Lastly, a driving state-dependent error response is carried out depending on the instantaneous operating state of the hybrid drive.<br><b>Independant Claims</b><br>1) An apparatus for decoding an encoded audio signal, the encoded audio signal comprising a first portion encoded in accordance with a first encoding algorithm, a second portion encoded in accordance with a second encoding algorithm, BWE parameters for the first portion and the second portion and a coding mode information indicating a first decoding algorithm or a second decoding algorithm, comprising: a first decoder for decoding the first portion in accordance with the first decoding algorithm for a first time portion of the encoded signal to acquire a first decoded signal, wherein the first decoder comprises an LPC-based coder; a second decoder for decoding the second portion in accordance with the second decoding algorithm for a second time portion of the encoded signal to acquire a second decoded signal, wherein the second decoder comprises a transform-based coder; a BWE module comprising a controllable crossover frequency, the BWE module being configured for performing a bandwidth extension algorithm using the first decoded signal and the BWE parameters for the first portion, and for performing a bandwidth extension algorithm using the second decoded signal and the bandwidth extension parameter for the second portion, wherein the BWE module is configured to use a first crossover frequency for the bandwidth extension for the first decoded signal and to use a second crossover frequency for the bandwidth extension for the second decoded signal, wherein the first crossover frequency is higher than the second crossover frequency; and a controller for controlling the crossover frequency for the BWE module in accordance with the coding mode information, wherein at least one of the first decoder, the second decoder, the BWE module and the controller comprises a hardware implementation.<br>11) A method for decoding an encoded audio signal, the encoded audio signal comprising a first portion encoded in accordance with a first encoding algorithm, a second portion encoded in accordance with a second encoding algorithm, BWE parameters for the first portion and the second portion and a coding mode information indicating a first decoding algorithm or a second decoding algorithm, the method comprising: decoding the first portion in accordance with the first decoding algorithm for a first time portion of the encoded signal to acquire a first decoded signal, wherein decoding the first portion comprises using an LPC-based coder; decoding the second portion in accordance with the second decoding algorithm for a second time portion of the encoded signal to acquire a second decoded signal, wherein decoding the second portion comprises using a transform-based coder; performing a bandwidth extension algorithm by a BWE module comprising a controllable crossover frequency, using the first decoded signal and the BWE parameters for the first portion, and performing, by the BWE module comprising the controllable crossover frequency, a bandwidth extension algorithm using the second decoded signal and the bandwidth extension parameter for the second portion, wherein a first crossover frequency is used for the bandwidth extension for the first decoded signal and a second crossover frequency is used for the bandwidth extension for the second decoded signal, wherein the first crossover frequency is higher than the second crossover frequency; and controlling the crossover frequency for the BWE module in accordance with the coding mode information.<br>13) A non-transitory storage medium having stored thereon a computer program for performing, when running on a computer, the method for encoding an audio signal, said method comprising: encoding in accordance with a first encoding algorithm, the first encoding algorithm comprising a first frequency bandwidth, wherein encoding in accordance with a first encoding algorithm comprises using an LPC-based coder; encoding in accordance with a second encoding algorithm, the second encoding algorithm comprising a second frequency bandwidth being smaller than the first frequency bandwidth, wherein encoding in accordance with a second encoding algorithm comprises using a transform-based coder; indicating the first encoding algorithm for a first portion of the audio signal and the second encoding algorithm for a second portion of the audio signal, the second portion being different from the first portion; and calculating BWE parameters for the audio signal such that the BWE parameters are calculated for a band not comprising the first frequency bandwidth in the first portion of the audio signal and for a band not comprising the second frequency bandwidth in the second portion of the audio signal, wherein the first or the second frequency bandwidth is defined by a variable crossover frequency, wherein the BWE module is configured to use a first crossover frequency for calculating the BWE parameters for a signal encoded using the LPC-based coder and to use a second crossover frequency for a signal encoded using the transform-based coder, wherein the first crossover frequency is higher than the second crossover frequency.<br>12) A method for encoding an audio signal comprising: encoding in accordance with a first encoding algorithm, the first encoding algorithm comprising a first frequency bandwidth, wherein encoding in accordance with a first encoding algorithm comprises using an LPC-based coder; encoding in accordance with a second encoding algorithm, the second encoding algorithm comprising a second frequency bandwidth being smaller than the first frequency bandwidth, wherein encoding in accordance with a second encoding algorithm comprises using a transform-based coder; indicating the first encoding algorithm for a first portion of the audio signal and the second encoding algorithm for a second portion of the audio signal, the second portion being different from the first portion; and calculating BWE parameters for the audio signal such that the BWE parameters are calculated for a band not comprising the first frequency bandwidth in the first portion of the audio signal and for a band not comprising the second frequency bandwidth in the second portion of the audio signal, wherein the first or the second frequency bandwidth is defined by a variable crossover frequency, wherein the BWE module is configured to use a first crossover frequency for calculating the BWE parameters for a signal encoded using the LPC-based coder and to use a second crossover frequency for a signal encoded using the transform-based coder, wherein the first crossover frequency is higher than the second crossover frequency.<br>6) An apparatus for encoding an audio signal comprising: a first encoder which is configured to encode in accordance with a first encoding algorithm, the first encoding algorithm comprising a first frequency bandwidth, wherein the first encoder comprises an LPC-based coder; a second encoder which is configured to encode in accordance with a second encoding algorithm, the second encoding algorithm comprising a second frequency bandwidth being smaller than the first frequency bandwidth, wherein the second encoder comprises a transform-based coder; a decision stage for indicating the first encoding algorithm for a first portion of the audio signal and for indicating the second encoding algorithm for a second portion of the audio signal, the second portion being different from the first portion; and a bandwidth extension module for calculating BWE parameters for the audio signal, wherein the BWE module is configured to be controlled by the decision stage to calculate the BWE parameters for a band not comprising the first frequency bandwidth in the first portion of the audio signal and for a band not comprising the second frequency bandwidth in the second portion of the audio signal, wherein the first or the second frequency bandwidth is defined by a variable crossover frequency and wherein the decision stage is configured to output the variable crossover frequency, wherein the BWE module is configured to use a first crossover frequency for calculating the BWE parameters for a signal encoded using the first encoder and to use a second crossover frequency for a signal encoded using the second encoder, wherein the first crossover frequency is higher than the second crossover frequency.</p></layer>
<layer id = "layer547"><p><b>US8600740B2:Systems, methods and apparatus for context descriptor transmission</b><br>An antenna apparatus comprises a lower assembly and an upper assembly, which together forming a cavity to contain an RF circuit device. The upper assembly comprises a waveguide flange interface at an external surface of the upper assembly. The waveguide flange interface comprises a waveguide channel extending from the external surface to an internal surface forming a surface of the cavity. An opening of the waveguide channel at the internal surface is substantially centered about a first centerline of the upper assembly parallel with the external surface and offset from a second centerline of the upper assembly parallel with the external surface, whereby the second centerline perpendicular is to the first centerline. The upper assembly is removably attachable to the lower assembly in either of a first orientation or a second orientation, whereby the second orientation represents a 180 degree rotation of the upper assembly relative to the first orientation.<br><b>Independant Claims</b><br>34) A non-transitory computer-readable medium comprising instructions for processing a digital audio signal that includes a speech component and a context component, which when executed by a processor cause the processor to: suppress the context component from the digital audio signal to obtain a context-suppressed signal; encode a signal that is based on the context-suppressed signal to obtain an encoded audio signal; contact a server including an audio context to be combined with the encoded audio signal send the encoded audio signal to a wireless telephone over a first logical channel within a wireless signal; and send to the server, over a second logical channel within a wireless signal different than the first logical channel, (A) audio context selection information and (B) information identifying the wireless telephone, wherein the server is configured to transmit the selected audio context to the wireless telephone.<br>12) An apparatus comprising a microphone, the apparatus configured to process a digital audio signal that includes a speech component and a context component, said apparatus comprising: a context suppressor configured to suppress the context component from the digital audio signal to obtain a context-suppressed signal; an encoder configured to encode a signal that is based on the context-suppressed signal to obtain an encoded audio signal; a first protocol stack configured to send the encoded audio signal to a wireless telephone over a first wireless logical channel; and a second protocol stack different than the first protocol stack configured to send, to a server and over a second wireless logical channel different than the first logical channel, (A) audio context selection information and (B) information identifying the wireless telephone, and wherein the server is configured to transmit the selected audio context to the wireless telephone.<br>45) An electronic device configured to produce a digital audio signal having a voice component and a context component, comprising: a context suppressor configured to suppress the context component from the audio signal to obtain a context-suppressed signal; an encoder configured to encode a signal that is based on the context-suppressed signal to obtain an encoded audio signal; and a processor configured to: wirelessly send the encoded audio signal to a wireless telephone; and wirelessly send audio context selection information and information identifying the wireless telephone to a server, wherein the server is configured to transmit the selected audio context to the identified wireless telephone.<br>1) A method in an electronic device of processing a digital audio signal that is based on a signal received from a microphone that includes a speech component and a context component, said method comprising: suppressing the context component from the digital audio signal to obtain a context-suppressed signal; encoding a signal that is based on the context-suppressed signal to obtain an encoded audio signal; over a first wireless logical channel, sending the encoded audio signal from the electronic device to a wireless telephone configured to decode the encoded audio signal; contacting a server including an audio context to be combined with the encoded audio signal; and over a second wireless logical channel different than the first logical channel, sending from the electronic device to the server (A) audio context selection information and (B) information identifying the, wireless telephone, wherein the server is configured to transmit the selected audio context to the wireless telephone.<br>23) An apparatus for processing a digital audio signal that is based on a signal received from a microphone that includes a speech component and a context component, said apparatus comprising: means for suppressing the context component from the digital audio signal to obtain a context-suppressed signal; means for encoding a signal that is based on the context-suppressed signal to obtain an encoded audio signal; means for wirelessly sending the encoded audio signal to a wireless telephone over a first logical channel; and means for wirelessly sending to a server, over a second logical channel different than the first logical channel, (A) audio context selection information and (B) information identifying the wireless telephone, wherein the server is configured to transmit the selected audio context to the wireless telephone.</p></layer>
<layer id = "layer548"><p><b>US20170309283A1:AUDIO ENCODER, AUDIO DECODER, METHODS FOR ENCODING AND DECODING AN AUDIO SIGNAL, AND A COMPUTER PROGRAM</b><br><b>Independant Claims</b><br>1) An encoder (; for providing an audio stream (; on the basis of a transform-domain representation (; ; aof an input audio signal, the encoder comprising: a quantization error calculator (110; 330) configured to determine a multi-band quantization error (116; 332) over a plurality of frequency bands of the input audio signal, for which separate band gain information (228a) is available; and an audio stream provider (120; 230) configured to provide the audio stream (126; 212) such that the audio stream comprises an information describing an audio content of the frequency bands and an information describing the multi-band quantization error.<br>14) A method for providing an audio stream (; on the basis of a transform-domain representation (; ;aof an input audio signal, the method comprising: determining a multi-band quantization error over a plurality of frequency bands, for which separate band gain information is available; and providing the audio stream such that the audio stream comprises an information describing an audio content of the frequency bands and an information describing the multi-band quantization error.<br>15) A method for providing a decoded representation (; bof an audio signal on the basis of an encoded audio stream (; ), the method comprising: introducing noise into spectral components of a plurality of frequency bands, to which separate frequency band gain information is associated, on the basis of a common multi-band noise intensity value.<br>17) An audio stream (; representing an audio signal, the audio stream comprising: spectral information describing intensities of spectral components of the audio signal, wherein the spectral information is quantized with different quantization accuracies in different frequency bands; and a noise level information describing a multi-band quantization error over a plurality of frequency bands, taking into account the different quantization accuracies.<br>18) An encoder (; for providing an audio stream (; on the basis of a transform-domain representation (; ; aof an input audio signal, the encoder comprising: a quantization error calculator (110; 330) configured to determine a multi-band quantization error (116; 332) over a plurality of frequency bands of the input audio signal, for which separate band gain information (228a) is available; and an audio stream provider (120; 230) configured to provide the audio stream (126; 212) such that the audio stream comprises an information describing an audio content of the frequency bands and an information describing the multi-band quantization error; wherein the quantization error calculator (110; 330) is configured to calculate an average quantization error over a plurality of frequency bands of the input audio signal, for which separate band gain information is available, such that the quantization error information covers a plurality of frequency bands, for which separate band gain information is available.<br>19) An encoder (; for providing an audio stream (; on the basis of a transform-domain representation (; ; aof an input audio signal, the encoder comprising: a quantization error calculator (110; 330) configured to determine a multi-band quantization error (116; 332) over a plurality of frequency bands of the input audio signal, for which separate band gain information (228a) is available; and an audio stream provider (120; 230) configured to provide the audio stream (126; 212) such that the audio stream comprises an information describing an audio content of the frequency bands and an information describing the multi-band quantization error; wherein the encoder is configured to set a band gain information of a frequency band, which is completely quantized to zero, to a value representing a ratio between an energy of the frequency band completely quantized to zero and an energy of the multi-band quantization error.<br>20) An encoder (; for providing an audio stream (; on the basis of a transform-domain representation (; ; aof an input audio signal, the encoder comprising: a quantization error calculator (110; 330) configured to determine a multi-band quantization error (116; 332) over a plurality of frequency bands of the input audio signal, for which separate band gain information (228a) is available; and an audio stream provider (120; 230) configured to provide the audio stream (126; 212) such that the audio stream comprises an information describing an audio content of the frequency bands and an information describing the multi-band quantization error; wherein the quantization error calculator (330) is configured to determine the multi-band quantization error (332) over a plurality of frequency bands each comprising at least one spectral component quantized to a non-zero value while avoiding frequency bands, spectral components of which are entirely quantized to zero.<br>21) A decoder (; for providing a decoded representation (, ; bof an audio signal on the basis of an encoded audio stream (; representing spectral components of frequency bands of the audio signal, the decoder comprising: a noise filler (520; 770) configured to introduce noise into spectral components of a plurality of frequency bands, to which separate frequency band gain information is associated, on the basis of a common multi-band noise intensity value (526); wherein the decoder comprises a rescaler (780), which is configured to receive a representation of the separate frequency band gain information and unscaled inversely quantized spectral values (774), and to provide, on the basis thereof, scaled, inversely quantized spectral values (782).<br>22) A decoder (; for providing a decoded representation (, ; bof an audio signal on the basis of an encoded audio stream (; representing spectral components of frequency bands of the audio signal, the decoder comprising: a noise filler (520; 770) configured to introduce noise into spectral components of a plurality of frequency bands, to which separate frequency band gain information is associated, on the basis of a common multi-band noise intensity value (526); wherein the noise filler (520; 770) is configured to selectively decide on a per-spectral-bin basis, whether to introduce noise into individual spectral bins of a frequency band in dependence on whether the respective individual spectral bins are quantized to zero or not.<br>23) A decoder (; for providing a decoded representation (, ; bof an audio signal on the basis of an encoded audio stream (; representing spectral components of frequency bands of the audio signal, the decoder comprising: a noise filler (520; 770) configured to introduce noise into spectral components of a plurality of frequency bands, to which separate frequency band gain information is associated, on the basis of a common multi-band noise intensity value (526); wherein the noise filler (520; 770) is configured to selectively modify a frequency band gain value of a given frequency band using a noise offset value if the given frequency band is quantized to zero.<br>24) A decoder (; for providing a decoded representation (, ; bof an audio signal on the basis of an encoded audio stream (; representing spectral components of frequency bands of the audio signal, the decoder comprising: a noise filler (520; 770) configured to introduce noise into spectral components of a plurality of frequency bands, to which separate frequency band gain information is associated, on the basis of a common multi-band noise intensity value (526); wherein the noise filler (520; 770) is configured to replace spectral bin values of spectral bins quantized to zero with spectral bin noise values, magnitudes of which spectral bin noise values are dependent on the multi-band noise intensity value (526), to obtain replaced spectral bin values, only for frequency bands having a lowest spectral bin index above a predetermined spectral bin index, leaving spectral bin values of frequency bands having a lowest spectral bin index below the predetermined spectral bin index unaffected; wherein the noise filler is configured to selectively modify, for the frequency bands having a lowest spectral bin index above the predetermined spectral bin index, a band gain value of a given frequency band in dependence on a noise offset value, if the given frequency band is entirely quantized to zero; and wherein the decoder further comprises a scaler (770) configured to apply the selectively-modified or unmodified band gain values to the selectively-replaced or un-replaced spectral bin values, to obtain a scaled spectral information, which represents the audio signal.<br>7) A decoder (; for providing a decoded representation (, ; bof an audio signal on the basis of an encoded audio stream (; representing spectral components of frequency bands of the audio signal, the decoder comprising: a noise filler (520; 770) configured to introduce noise into spectral components of a plurality of frequency bands, to which separate frequency band gain information is associated, on the basis of a common multi-band noise intensity value (526).</p></layer>
<layer id = "layer549"><p><b>US9142222B2:Apparatus and method of enhancing quality of speech codec</b><br><b>Independant Claims</b><br>1) A speech codec quality improving apparatus comprising: a computer system comprising a processor and a memory; an energy calculation unit operating on the computer system and adapted to calculate an energy of a low-band decoded signal; and a scaling unit operating on the computer system and adapted to: scale a size of the decoded signal by a gain, when the gain is less than a threshold value, wherein the low-band decoded signal include a signal decoded by a low-band codec and low-band enhancement mode when the low-band enhancement mode is enabled, wherein the low-band codec uses a G.711 codec, wherein the gain based on energies of a low-band decoded signal of current and previous frame, wherein the gain is further modified in sample by sample, wherein the scaling unit performs scaling in units of samples within a frame of a decoded signal, the scaling is performed in a silent segment, wherein the energy calculation unit is adapted to calculate the energy of the low-band decoded signal in units of frames, wherein scaling the size of the decoded signal reduces human audible noises, and wherein the scaling unit is adapted to not performing scaling, when the power of the signal decoded by a wideband extension mode is greater than the power of a signal decoded by a low-band codec and a low-band enhancement mode by at least a predetermined value.<br>5) A non-transitory computer readable storage medium having processor executable instructions to: calculate an energy of the low-band decoded signal; and scale a size of the decoded signal by a gain, when the gain is less than a threshold value, wherein the low-band decoded signal include a decoded signal by a low-band codec or a decoded signal by a low-band codec and low-band enhancement mode, wherein the low-band codec uses a G.711 codec, wherein the gain is based on energies of a low-band decoded signal of current and previous frame, wherein the scaling of the size of the decoded signal performs scaling in units of samples within a frame of a decoded signal, the scaling is performed in a silent segment, wherein the gain is calculated in sample by sample by further consideration of a previous gain, wherein the calculating of the energy of the low-band decoded signal calculated the energy of the decoded signal in units of frames, wherein scaling the size of the low-band decoded signal reduces human audible noises, and wherein the scaling of the size of the decoded signal does not performing scaling, when the power of a signal decoded by a wideband extension mode is greater than the power of a signal decoded by a low-band codec and a low-band enhancement mode by at least a predetermined value.</p></layer>
<layer id = "layer550"><p><b>US8190440B2:Sub-band codec with native voice activity detection</b><br>The present invention relates to a method of tapering a toothbrush bristle which increases production efficiency. The method includes the steps of cutting bundles of toothbrush bristles; and non-directionally immersing the entire cut bundles of toothbrush bristles into a chemical solution to taper both sides of the toothbrush bristles. According to the present invention, the production efficiency of a needle-shaped bristle is increased approximately three-fold, and the loss of raw materials is greatly decreased because several processes are not performed.<br><b>Independant Claims</b><br>1) A method for encoding a frame of an audio signal, comprising: receiving a series of input audio samples representative of the frame; generating a series of sub-band samples for each of a plurality of frequency sub-bands based on the input audio samples; determining if the frame is a voice frame or a noise frame; and responsive to determining that the frame is a noise frame, encoding an index representative of a previously-processed series of sub-band samples stored in a history buffer located in an encoder that encodes the frame of the audio signal for at least one of the frequency sub-bands instead of encoding the series of sub-band samples generated for the frequency sub-band.<br>13) A method for decoding an encoded frame of an audio signal, comprising: receiving a bit stream representative of the encoded frame from an encoder; determining if the encoded frame is a voice frame or a noise frame; and responsive to determining that the encoded frame is a noise frame, extracting one or more indices from the bit stream, wherein each index is representative of a previously-processed series of sub-band samples generated for a corresponding frequency sub-band within a plurality of frequency sub-bands and stored in a history buffer located in the encoder; for each index, reading a previously-processed series of sub-band samples associated with the frequency sub-band with which the index is associated from a history buffer located in a decoder wherein the index identifies the location of the previously processed series of sub-band samples in the history buffer located in the decoder; generating a series of decoded output audio samples based on the previously-processed series of sub-band samples read from the history buffer located in the decoder.<br>19) An audio encoder, comprising: an analysis filter bank configured to receive a series of input audio samples representative of a frame of an audio signal and to generate a series of sub-band samples for each of a plurality of frequency sub-bands based on the input audio samples; scale factor determination logic configured to determine a scale factor for each frequency sub-band based on the sub-band samples generated for each frequency sub-band; a voice activity detector configured to determine if the frame is a voice frame or a noise frame based on one or more of the scale factors; and sub-band index determination logic configured to identify and encode an index representative of a previously-processed series of sub-band samples stored in a history buffer located in the audio encoder for at least one of the frequency sub-bands responsive to a determination that the frame is a noise frame; and bit packing logic configured to receive the encoded index and arrange the encoded index within a bit stream for transmission to a decoder.<br>20) An audio decoder, comprising: bit unpacking logic configured to receive a bit stream representative of an encoded frame of an audio signal from an audio encoder; a noise frame detector configured to determine if the encoded frame is a voice frame or a noise frame; a sub-band index reader configured to extract one or more indices from the bit stream responsive to a determination that the encoded frame is a noise frame, wherein each index is representative of a previously-processed series of sub-band samples generated for a corresponding frequency sub-band within a plurality of frequency sub-bands stored in a history buffer located in the encoder; a sub-band samples reader configured to read, for each index, a previously-processed series of sub-band samples associated with the frequency sub-band with which the index is associated from a history buffer located in the audio decoder responsive to a determination that the encoded frame is a noise frame, wherein the index identifies the location of the previously processed series of sub-band samples in the history buffer located in the audio decoder; and a synthesis filter bank configured to generate a series of decoded output audio samples based on the previously-processed series of sub-band samples read from the history buffer located in the audio decoder responsive to a determination that the encoded frame is a noise frame.</p></layer>
<layer id = "layer551"><p><b>US9646632B2:Time warp activation signal provider, audio signal encoder, method for providing a time warp activation signal, method for encoding an audio signal and computer programs</b><br><b>Independant Claims</b><br>1) A time warp activation signal provider for providing a time warp activation signal on the basis of a representation of an audio signal, the time warp activation signal provider comprising: an energy compaction information provider configured to provide an energy compaction information describing a compaction of energy in a time warp transformed spectrum representation of the audio signal; and a comparator configured to compare the energy compaction information with a reference value, and to provide the time warp activation signal in dependence on a result of the comparison; wherein the energy compaction information provider is configured to provide a measure of spectral flatness describing the time warp transformed spectrum representation of the audio signal as the energy compaction information.<br>10) A time warp activation signal provider for providing a time warp activation signal on the basis of a representation of an audio signal, the time warp activation signal provider comprising: an energy compaction information provider configured to provide an energy compaction information describing a compaction of energy in a time warp transformed spectrum representation of the audio signal; and a comparator configured to compare the energy compaction information with a reference value, and to provide the time warp activation signal in dependence on a result of the comparison; wherein the time warp activation signal provider comprises a reference value calculator configured to compute the reference value on the basis of a time warped representation of the input signal, time warped using a standard time warp contour information; and wherein the comparator is configured to form a ratio value using the energy compaction information describing a compaction of energy in a time warped representation of the audio signal and the reference value, and to compare the ratio value with one or more threshold values to acquire the time warp activation signal as the result of the comparison.<br>11) An audio signal encoder for encoding an input audio signal to acquire an encoded representation of the input audio signal, the audio signal encoder comprising: a time warp transformer configured to provide a time warp transformed spectral representation on the basis of the input audio signal using a time warp contour; a time warp activation signal provider for providing a time warp activation signal on the basis of a representation of an audio signal, the time warp activation signal provider comprising:an energy compaction information provider configured to provide an energy compaction information describing a compaction of energy in a time warp transformed spectrum representation of the audio signal, anda comparator configured to compare the energy compaction information with a reference value, and to provide the time warp activation signal in dependence on a result of the comparison wherein the time warp activation signal provider is configured to receive the input audio signal and to provide the time warp activation signal; and a controller configured to selectively provide, in dependence on the time warp activation signal, a newly found time warp contour information, describing a non-constant time warp contour portion, or a standard time warp contour information, describing a constant time warp contour portion, to the time warp transformer to describe the time warp contour used by the time warp transformer.<br>13) A method for providing a time warp activation signal on the basis of an audio signal, the method comprising: providing an energy compaction information describing a compaction of energy in a time warp transformed spectral representation of the audio signal; comparing the energy compaction information with a reference value; and providing the time warp activation signal in dependence on the result of the comparison; wherein a measure of spectral flatness describing the time warp transformed spectrum representation of the audio signal is provided as the energy compaction information.<br>15) A method for encoding an input audio signal to acquire an encoded representation of the input audio signal, the method comprising: providing a time warp activation signal on the basis of an audio signal, the method comprising:providing an energy compaction information describing a compaction of energy in a time warp transformed spectral representation of the audio signal;comparing the energy compaction information with a reference value; andproviding the time warp activation signal in dependence on the result of the comparison, wherein the energy compaction information describes a compaction of energy in a time warp transformed spectrum representation of the input audio signal; and selectively providing, in dependence on the time warp activation signal, a description of the time warp transformed spectral representation of the input audio signal or description of a non-time-warp-transformed spectral representation of the input audio signal for inclusion into the encoded representation of the input audio signal.<br>17) A method for providing a time warp activation signal on the basis of an audio signal, the method comprising: providing an energy compaction information describing a compaction of energy in a time warp transformed spectral representation of the audio signal; comparing the energy compaction information with a reference value; and providing the time warp activation signal in dependence on the result of the comparison; wherein a higher-frequency portion of the time warp transformed spectrum representation is emphasized when compared to a lower frequency portion of the time warp transformed spectrum representation to acquire the energy compaction information.<br>18) A method for providing a time warp activation signal on the basis of an audio signal, the method comprising: providing an energy compaction information describing a compaction of energy in a time warp transformed spectral representation of the audio signal; comparing the energy compaction information with a reference value; and providing the time warp activation signal in dependence on the result of the comparison; wherein a plurality of band-wise measures of spectral flatness is acquired, and wherein an average of the plurality of band-wise measures of spectral flatness is computed to acquire the energy compaction information.<br>19) A method for providing a time warp activation signal on the basis of an audio signal, the method comprising: providing an energy compaction information describing a compaction of energy in a time warp transformed spectral representation of the audio signal; comparing the energy compaction information with a reference value; and providing the time warp activation signal in dependence on the result of the comparison; wherein a measure of perceptual entropy describing the time warp transformed spectrum representation of the audio signal is provided as the energy compaction information.<br>20) A method for providing a time warp activation signal on the basis of an audio signal, the method comprising: providing an energy compaction information describing a compaction of energy in a time warp transformed spectral representation of the audio signal; comparing the energy compaction information with a reference value; and providing the time warp activation signal in dependence on the result of the comparison; wherein an autocorrelation measure describing an autocorrelation of a time warped time domain representation of the audio signal is provided as the energy compaction information.<br>21) A method for providing a time warp activation signal on the basis of an audio signal, the method comprising: providing an energy compaction information describing a compaction of energy in a time warp transformed spectral representation of the audio signal; comparing the energy compaction information with a reference value; and providing the time warp activation signal in dependence on the result of the comparison; wherein the reference value is computed on the basis of an unwarped spectrum representation of the audio signal or on the basis of an unwarped time domain representation of the audio signal; and wherein a ratio value is formed using the energy compaction information describing a compaction of energy in a time warp transformed spectrum representation of the audio signal and the reference value, and wherein the ratio value is compared with one or more threshold values to acquire the time warp activation signal as the result of the comparison.<br>22) A method for providing a time warp activation signal on the basis of an audio signal, the method comprising: providing an energy compaction information describing a compaction of energy in a time warp transformed spectral representation of the audio signal; comparing the energy compaction information with a reference value; and providing the time warp activation signal in dependence on the result of the comparison; wherein the reference value is computed on the basis of a time warped representation of the input signal, time warped using a standard time warp contour information; and wherein a ratio value is formed using the energy compaction information describing a compaction of energy in a time warped representation of the audio signal and the reference value, and wherein the ratio value is compared with one or more threshold values to acquire the time warp activation signal as the result of the comparison.<br>3) A time warp activation signal provider for providing a time warp activation signal on the basis of a representation of an audio signal, the time warp activation signal provider comprising: an energy compaction information provider configured to provide an energy compaction information describing a compaction of energy in a time warp transformed spectrum representation of the audio signal; and a comparator configured to compare the energy compaction information with a reference value, and to provide the time warp activation signal in dependence on a result of the comparison; wherein the energy compaction information provider is configured to emphasize a higher-frequency portion of the time warp transformed spectrum representation when compared to a lower frequency portion of the time warp transformed spectrum representation to acquire the energy compaction information.<br>4) A time warp activation signal provider for providing a time warp activation signal on the basis of a representation of an audio signal, the time warp activation signal provider comprising: an energy compaction information provider configured to provide an energy compaction information describing a compaction of energy in a time warp transformed spectrum representation of the audio signal; and a comparator configured to compare the energy compaction information with a reference value, and to provide the time warp activation signal in dependence on a result of the comparison; wherein the energy compaction information provider is configured to acquire a plurality of band-wise measures of spectral flatness, and to compute an average of the plurality of band-wise measures of spectral flatness to acquire the energy compaction information.<br>5) A time warp activation signal provider for providing a time warp activation signal on the basis of a representation of an audio signal, the time warp activation signal provider comprising: an energy compaction information provider configured to provide an energy compaction information describing a compaction of energy in a time warp transformed spectrum representation of the audio signal; and a comparator configured to compare the energy compaction information with a reference value, and to provide the time warp activation signal in dependence on a result of the comparison; wherein the energy compaction information provider is configured to provide a measure of perceptual entropy describing the time warp transformed spectrum representation of the audio signal as the energy compaction information.<br>7) A time warp activation signal provider for providing a time warp activation signal on the basis of a representation of an audio signal, the time warp activation signal provider comprising: an energy compaction information provider configured to provide an energy compaction information describing a compaction of energy in a time warp transformed spectrum representation of the audio signal; and a comparator configured to compare the energy compaction information with a reference value, and to provide the time warp activation signal in dependence on a result of the comparison; wherein the energy compaction information provider is configured to provide an autocorrelation measure describing an autocorrelation of a time warped time domain representation of the audio signal as the energy compaction information.<br>9) A time warp activation signal provider for providing a time warp activation signal on the basis of a representation of an audio signal, the time warp activation signal provider comprising: an energy compaction information provider configured to provide an energy compaction information describing a compaction of energy in a time warp transformed spectrum representation of the audio signal; and a comparator configured to compare the energy compaction information with a reference value, and to provide the time warp activation signal in dependence on a result of the comparison; wherein the time warp activation signal provider comprises a reference value calculator configured to compute the reference value on the basis of an unwarped spectrum representation of the audio signal or on the basis of an unwarped time domain representation of the audio signal; and wherein the comparator is configured to form a ratio value using the energy compaction information describing a compaction of energy in a time warp transformed spectrum representation of the audio signal and the reference value, and to compare the ratio value with one or more threshold values to acquire the time warp activation signal as the result of the comparison.</p></layer>
<layer id = "layer552"><p><b>US8463412B2:Method and apparatus to facilitate determining signal bounding frequencies</b><br>Disclosed are heat-hardened steel with excellent crashworthiness and a method for manufacturing heat-hardenable parts using the same. The heat-hardened steel according to the invention comprises, based on wt %; C: 0.12-0.8%; Cr: 0.01-2%; Mo: 0.2% or less; B: 0.0005-0.08%; Ca: 0.01 or less; Sb: 1.0% or less; and Ti and/or Nb: 0.2%; and the reminder being Fe and inevitable impurities. In addition, the heat-treatment hardening steel satisfies anyone of following conditions i)-iv), wherein condition i) comprises Si: 0.5-3%; Mn: 1-10% and Al: 0.05-2%; condition ii) comprises Si: 1% or less; Mn: 0.5-5%; Al: 0.1-2.5%; and Ni: 0.01-8%; condition iii) comprises Si: 0.5-3%; Mn: 1-10%; Al: 0.1% or less; and Ni: 0.01-8%; and condition iv) comprises Si: 0.5-3%; Mn: 1-10%; Al: 0.1-2.5%; and Ni: 0.01-8%.<br><b>Independant Claims</b><br>8) A method to facilitate performing bandwidth extension for a signal comprising: at a processor of a signal processing platform: detecting a low-band edge below a highest expected value of the low-band edge to provide a detected low-band edge; adjusting a low-band boost characteristic based on the detected low-band edge to provide an adjusted low-band boost characteristic; applying the adjusted low-band boost characteristic to the signal to obtain a boosted low-band signal.<br>1) A method comprising: at a processor of a signal processing platform: presenting a signal to be processed; identifying signal portions of the signal that exhibit specific characteristics to provide identified signal portions, the specific characteristics comprising energy values; using the identified signal portions to automatically determine at least one bounding frequency for the signal by computing a magnitude spectrum for each of the identified signal portions and using the magnitude spectrum to determine a corresponding measure of flatness within a pass band as pertains to a corresponding normalized signal portion to thereby provide vetted signal portions.</p></layer>
<layer id = "layer553"><p><b>US8326641B2:Apparatus and method for encoding and decoding using bandwidth extension in portable terminal</b><br>A strain wave gear apparatus includes a rigid internal gear, a flexible external gear, and a wave generator. The wave generator includes an input shaft fixing member including eccentric cams, bearings respectively fixed to outer sides of the eccentric cams, and housings respectively fitted to outer peripheral surfaces of the bearings. The eccentric cams are arranged side by side in a direction of an inclined axis inclined with respect to an input rotation axis at an inclination angle (θ) in a manner that respective center axes of the eccentric cams are parallel to the inclined axis and decentered in directions opposite to each other from the inclined axis. The housings are each formed into a tapered shape so that an outer peripheral surface of each of the housings is held in surface contact with an inner peripheral surface of the flexible external gear.<br><b>Independant Claims</b><br>7) A coding method using a band extension, the coding method comprising: extracting second auxiliary information relating to a characteristic of a high band signal using the high band signal and a low band signal; subtracting the second auxiliary information from first auxiliary information acquired from the high band signal; and encoding the subtracted residual high band signal, wherein the extracting of second auxiliary information relating to a characteristic of a high band signal using the high band signal and a low band signal comprises acquiring the second auxiliary information from the low band signal using past pre-coded residual high band signal and the low band signal.<br>1) A coding apparatus using a band extension, the coding apparatus comprising: a bandwidth extender for extracting second auxiliary information relating to a characteristic of a high band signal using the high band signal and a low band signal; and an encoder for encoding a residual high band signal obtained by subtracting the second auxiliary information from first auxiliary information acquired from the high band signal, wherein the bandwidth extender acquires the second auxiliary information from the low band signal using past pre-coded residual high band signal and the low band signal.<br>13) A coding apparatus comprising: a predictor for estimating a high band signal using a pre-decoded high band signal; a bandwidth extender for receiving an encoded low band signal and for estimating a high band signal using the received encoded low band signal; a low band encoder for encoding a received low band signal and for providing the encoded low band signal to the bandwidth extender; and an encoder for providing an encoded high band signal.</p></layer>
<layer id = "layer554"><p><b>US20180350387A1:AUDIO SIGNAL SYNTHESIZER AND AUDIO SIGNAL ENCODER</b><br><b>Independant Claims</b><br>9) An audio signal encoder for generating from an audio signal a data stream comprising components of the audio signal in a first frequency band, control information and spectral band replication parameters, comprising: a frequency selective filter to generate the components of the audio signal in the first frequency band; a generator for generating the spectral band replication parameter from the components of the audio signal in a second frequency band; a control information generator to generate the control information, the control information identifying a patching algorithm from a first or a second different patching algorithm, wherein each patching algorithm generates a raw signal comprising signal components in the second replicated frequency band using the components of the audio signal in the first frequency band.<br>16) A nontransitory digital storage medium having a computer program stored thereon to perform the method for generating a data stream comprising components of an audio signal in a first frequency band, control information and spectral band replication parameters, comprising: frequency selective filtering the audio signal to generate the components of the audio signal in the first frequency band; generating the spectral band replication parameter from the components of the audio signal in a second frequency band; generating the control information identifying a patching algorithm from a first or a second different patching algorithm, wherein each patching algorithm generates a raw signal comprising signal components in the second replicated frequency band using the components of the audio signal in the first frequency band, when said computer program is run by a computer.<br>15) A nontransitory digital storage medium having a computer program stored thereon to perform the method for generating a synthesis audio signal comprising a first frequency band and a second replicated frequency band derived from the first frequency band, comprising: performing at least two different patching algorithms, wherein each patching algorithm generates a raw signal comprising signal components in the second replicated frequency band using an audio signal comprising signal components in the first frequency band, and wherein the patching is performed such that one of the at least two different patching algorithms is selected in response to a control information for a first time portion and the other of the at least two different patching algorithms is selected in response to the control information for a second time portion different from the first time portion to acquire the raw signal for the first and the second time portion; converting the raw signal into a raw signal spectral representation; processing the raw signal spectral representation in response to spectral domain spectral band replication parameters to acquire an adjusted raw signal spectral representation; and combining the audio signal comprising signal components in the first band or a signal derived from the audio signal with the adjusted raw signal spectral representation or with a further signal derived from the adjusted raw signal spectral representation to acquire the synthesis audio signal, when said computer program is run by a computer.<br>14) A method for generating a data stream comprising components of an audio signal in a first frequency band, control information and spectral band replication parameters, comprising: frequency selective filtering the audio signal to generate the components of the audio signal in the first frequency band; generating the spectral band replication parameter from the components of the audio signal in a second frequency band; generating the control information identifying a patching algorithm from a first or a second different patching algorithm, wherein each patching algorithm generates a raw signal comprising signal components in the second replicated frequency band using the components of the audio signal in the first frequency band.<br>13) A method for generating a synthesis audio signal comprising a first frequency band and a second replicated frequency band derived from the first frequency band, comprising: performing at least two different patching algorithms, wherein each patching algorithm generates a raw signal comprising signal components in the second replicated frequency band using an audio signal comprising signal components in the first frequency band, and wherein the patching is performed such that one of the at least two different patching algorithms is selected in response to a control information for a first time portion and the other of the at least two different patching algorithms is selected in response to the control information for a second time portion different from the first time portion to acquire the raw signal for the first and the second time portion; converting the raw signal into a raw signal spectral representation; processing the raw signal spectral representation in response to spectral domain spectral band replication parameters to acquire an adjusted raw signal spectral representation; and combining the audio signal comprising signal components in the first band or a signal derived from the audio signal with the adjusted raw signal spectral representation or with a further signal derived from the adjusted raw signal spectral representation to acquire the synthesis audio signal.<br>12) A data stream for transmission over a transmission line or for storage, the data stream comprising: an encoded audio signal in the first frequency band; control information, the control information identifying a patching algorithm from a first or a second different patching algorithm, wherein each patching algorithm generates a raw signal comprising signal components in a second replicated frequency band using the components of the encoded audio signal in the first frequency band; and spectral band replication parameters.<br>1) An audio signal synthesizer for generating a synthesis audio signal comprising a first frequency band and a second synthesized frequency band derived from the first frequency band, comprising: a patch generator for performing at least two different patching algorithms, wherein each patching algorithm generates a raw signal comprising signal components in the second synthesized frequency band using an audio signal comprising signal components in the first frequency band, and wherein the patch generator is adapted to select one of the at least two different patching algorithms in response to a control information for a first time portion and another of the at least two different patching algorithms in response to the control information for a second time portion different from the first time portion to acquire the raw signal for the first and the second time portion; a spectral converter for converting the raw signal into a raw signal spectral representation; a raw signal processor for processing the raw signal spectral representation in response to spectral domain spectral band replication parameters to acquire an adjusted raw signal spectral representation; and a combiner for combining the audio signal comprising signal components in the first band or a signal derived from the audio signal with the adjusted raw signal spectral representation or with a further signal derived from the adjusted raw signal spectral representation to acquire the synthesis audio signal.</p></layer>
<layer id = "layer555"><p><b>US9299363B2:Time warp contour calculator, audio signal encoder, encoded audio signal representation, methods and computer program</b><br><b>Independant Claims</b><br>1) A time warp contour calculator apparatus for use in an audio signal decoder for providing a decoded audio signal representation on the basis of an encoded audio signal representation, comprising: a warp ratio decoder that includes a mechanism for receiving an input signal including encoded warp ratio information; and a warp node value calculator in communication with the warp ratio decoder; wherein the warp ratio decoder is configured to process the encoded warp ratio information to derive a sequence of warp ratio values, wherein the warp node value calculator is configured to process the sequence of warp ratio values to acquire, starting with a time warp start value, warp contour node values, wherein ratios between the time warp contour node values and the time warp contour starting value associated with a time warp contour start node are determined by the warp ratio values; and wherein the warp node value calculator is configured to compute a time warp contour node value of a given time warp contour node, wherein the given time warp contour node is spaced from the time warp contour starting node with an intermediate time warp contour node in between on the basis of a product-formation, wherein the product-formation comprises as factors a ratio between the time warp contour node value of the intermediate time warp contour node and the time warp contour starting value and a ratio between the time warp contour node value of the given time warp contour node and the time-warp contour node value of the intermediate time warp contour node; wherein the warp node value calculator includes a mechanism for outputting an output signal that includes the warp contour node values.<br>11) A method for providing a decoded audio signal representation on the basis of an encoded audio signal representation, the method comprising: receiving an input signal that includes encoded warp ratio information; processing the encoded warp ratio information to derive a sequence of warp ratio values; and processing the sequence of warp ratio values, to acquire, starting from a time warp contour start value, a plurality of time warp contour node values, wherein ratios between the time warp contour node values and the time warp contour starting value associated with the time warp contour starting node are determined by the warp ratio values; wherein a time warp contour node value of a given time warp contour node, which given time warp contour node is spaced from the time warp contour starting node with an intermediate time warp contour node in between, is computed on the basis of a product- formation, comprising as factors a ratio between the time warp contour node value of the intermediate time warp contour node and the time warp contour starting value, and a ratio between the time warp contour node value of the given time warp contour node and the time warp contour node value of the intermediate time warp contour node; and outputting an output signal that includes the resultant decoded audio signal representation.<br>12) A method for providing an encoded representation of an audio signal, the method comprising: with an input mechanism, receiving the audio signal; receiving a time warp contour information associated with the audio signal; computing ratios between pairs of subsequent node values of a time warp contour; encoding the ratios between subsequent node values of the time warp contour; and acquiring an encoded representation of a spectrum of the audio signal, taking into account a time warp described by the time warp contour information; wherein the encoded representation of the audio signal comprises the encoded ratios and the encoded representation of the spectrum; wherein the node values are sample values of the time warp contour described by the time warp contour information; and with an output mechanism, outputting an output signal that includes the encoded representation of the audio signal.<br>13) A non-transitory computer readable medium comprising a computer program for performing, when executed by a computer, a method for providing a decoded audio signal representation on the basis of an encoded audio signal representation, the method comprising: receiving an input signal, wherein the input signal includes encoded warp ratio information; processing the encoded warp ratio information to derive a sequence of warp ratio values; processing the sequence of warp ratio values, to acquire, starting with a time warp contour start value, a plurality of time warp contour node values, and outputting an output signal that includes the resultant decoded audio signal representation; wherein ratios between the time warp contour node values and the time warp contour starting value associated with the time warp contour starting node are determined by the warp ratio values; wherein a time warp contour node value of a given time warp contour node, which given time warp contour node is spaced from the time warp contour starting node with an intermediate time warp contour node in between, is computed on the basis of a product- formation, comprising as factors a ratio between the time warp contour node value of the intermediate time warp contour node and the time warp contour starting value, and a ratio between the time warp contour node value of the given time warp contour node and the time warp contour node value of the intermediate time warp contour node.<br>14) A non-transitory computer readable medium comprising a computer program for performing, when executed by a computer, a method for providing an encoded representation of an audio signal, the method comprising: receiving the audio signal; receiving a time warp contour information associated with the audio signal; determining, on the basis of the received time warp contour information, ratios between pairs of subsequent node values of a time warp contour; encoding the determined ratios between subsequent node values of the time warp contour; acquiring an encoded representation of a spectrum of the received audio signal, taking into account a time warp described by the received time warp contour information; and outputting an output signal that includes the encoded representation of the received audio signal; wherein the encoded representation of the received audio signal comprises the encoded ratios and the encoded representation of the spectrum; wherein the node values are sample values of the time warp contour described by the time warp contour information.<br>15) An audio signal decoder, wherein the audio signal decoder is configured to provide a decoded audio signal representation on the basis of an encoded audio signal representation, the audio signal decoder comprising: a mechanism for receiving an input signal that includes encoded warp ratio information; a time warp contour calculator that includes a warp ratio decoder and a warp node value calculator; the warp ratio decoder for processing the received encoded warp ratio information to derive a sequence of warp ratio values, and the warp node value calculator for processing the derived sequence of warp ratio values, to acquire, starting from a time warp contour start value, warp contour node values, wherein ratios between the time warp contour node values and the time warp contour starting value associated with a time warp contour start node are determined by the warp ratio values; and wherein the warp node value calculator is configured to compute a time warp contour node value of a given time warp contour node, which given time warp contour node is spaced from the time warp contour starting node with an intermediate time warp contour node in between, on the basis of a product-formation comprising as factors a ratio between the time warp contour node value of the intermediate time warp contour node and the time warp contour starting value, and a ratio between the time warp contour node value of the given time warp contour node and the time-warp contour node value of the intermediate time warp contour node; wherein the audio signal decoder comprises a warp decoder configured to perform a resampling in dependence on the warp contour node values; and a mechanism for outputting an output signal that includes the decoded audio signal representation.<br>9) An audio signal encoder apparatus for providing an encoded representation of an audio signal, the audio signal encoder comprising: an input mechanism for receiving the audio signal; a mechanism for obtaining time warp contour information; a time warp contour encoder in communication with the mechanism for obtaining the time warp contour information, wherein the time warp contour encoder is configured to receive the time warp contour information associated with the received audio signal, compute ratios between pairs of subsequent node values of a time warp contour, and encode the ratios between subsequent node values of the time warp contour; and a time warping signal encoder in communication with the input mechanism, wherein the time warping signal encoder is configured to acquire an encoded representation of a spectrum of the received audio signal, taking into account a time warp described by the time warp contour information; wherein the encoded representation of the received audio signal comprises the encoded ratios and the encoded representation of the spectrum; wherein the node values are sample values of the time warp contour described by the time warp contour information; and an output mechanism in communication with the time warp contour encoder and with the time warping signal encoder, for outputting an output signal that includes the encoded representation of the audio signal.</p></layer>
<layer id = "layer556"><p><b>US8306249B2:Method and acoustic signal processing device for estimating linear predictive coding coefficients</b><br>The present disclosure provides a system and method of generating a transformation specification document describing transformations for transforming a received message conforming to a second interface definition to a message conforming to a first interface definition. The system and method comprise loading the first interface definition into memory; loading the second interface definition into memory; determining all additional elements of the second interface definition loaded into memory not contained in the first interface definition loaded into memory; generating processing logic for removing all of the determined additional elements from the received message; and generating the transformation specification document using the generated processing logic. The present disclosure further relates to a computer program product generating a transformation specification document.<br><b>Independant Claims</b><br>7) An acoustic signal processing device for estimating a set of linear predictive coding coefficients of a microphone signal using minimum mean-square error estimation with a codebook containing several predetermined sets of linear predictive coding coefficients, the acoustic signal processing device comprising: a signal processing unit for determining sums of weighted backward transition probabilities describing transition probabilities between the predetermined sets of linear predictive coding coefficients, the backward transition probabilities being obtained from signal training data by mapping the signal training data to one of the predetermined sets of the codebook and by determining relative frequencies of transitions between two of the predetermined sets of the codebook.<br>1) A method for estimating a set of linear predictive coding coefficients of a microphone signal using minimum mean-square error estimation with a codebook containing several predetermined sets of linear predictive coding coefficients, which comprises the steps of: determining sums of weighted backward transition probabilities describing transition probabilities between the predetermined sets of linear predictive coding coefficients, the backward transition probabilities being obtained from signal training data by mapping the signal training data to one of the predetermined sets of the codebook and by determining relative frequencies of transitions between two of the predetermined sets of the codebook.<br>13) A hearing aid, comprising: an acoustic signal processing device for estimating a set of linear predictive coding coefficients of a microphone signal using minimum mean-square error estimation with a codebook containing several predetermined sets of linear predictive coding coefficients, said acoustic signal processing device having a signal processing unit for determining sums of weighted backward transition probabilities describing transition probabilities between the predetermined sets of linear predictive coding coefficients, the backward transition probabilities being obtained from signal training data by mapping the signal training data to one of the predetermined sets of the codebook and by determining relative frequencies of transitions between two of the predetermined sets of the codebook.</p></layer>
<layer id = "layer557"><p><b>US7636659B1:Computer-implemented methods and systems for modeling and recognition of speech</b><br>An apparatus and method is disclosed for determining polysilicon conductor width for 3-dimensional field effect transistors (FinFETs). Two or more resistors are constructed using a topology in which polysilicon conductors are formed over a plurality of silicon “fins”. A first resistor has a first line width. A second resistor has a second line width. The second line width is slightly different than the first line width. Advantageously, the first line width is equal to the nominal design width used to make FET gates in the particular semiconductor technology. Resistance measurements of the resistors and subsequent calculations using the resistance measurements are used to determine the actual polysilicon conductor width produced by the semiconductor process. A composite test structure not only allows calculation of the polysilicon conductor width, but provides proof that differences in the widths used in the calculations do not introduce objectionable etching characteristics of the polysilicon conductors.<br><b>Independant Claims</b><br>1) A method of extracting speech features from signals for use in performing automatic speech recognition, the method comprising: receiving a signal; performing a time-to-frequency domain transformation on at least a portion of the received signal to generate a frequency domain representation; performing a frequency domain linear prediction on the frequency domain representation to estimate a temporal envelope of the frequency domain representation, the frequency domain linear prediction comprising: selecting a temporal window to apply the frequency domain linear prediction; and determining a pole rate to automatically distribute poles for modeling the temporal envelope, wherein the poles characterize the temporal peaks of the temporal envelope; and generating at least one speech feature based at least in part on the temporal envelope.<br>8) A system for extracting speech features from signals for use in performing automatic speech recognition, the system comprising: means for receiving a signal; means for performing a time-to-frequency domain transformation on at least a portion of the received signal to generate a frequency domain representation; means for performing a frequency domain linear prediction on the frequency domain representation to estimate a temporal envelope of the frequency domain representation, the frequency domain linear prediction comprising: selecting a temporal window to apply the frequency domain linear prediction; and determining a pole rate to automatically distribute poles for modeling the temporal envelope, wherein the poles characterize the temporal peaks of the temporal envelope; and means for generating at least one speech feature based at least in part on the temporal envelope.<br>9) A system for extracting speech features from signals for use in performing automatic speech recognition, the system comprising: a processor at least partially executing a modeling application configured to: receive a signal; perform a time-to-frequency domain transformation on at least a portion of the received signal to generate a frequency domain representation; perform a frequency domain linear prediction on the frequency domain representation to estimate a temporal envelope of the frequency domain representation, the frequency domain linear prediction comprising: selecting a temporal window to apply the frequency domain linear prediction; and determining a pole rate to automatically distribute poles for modeling the temporal envelope, wherein the poles characterize the temporal peaks of the temporal envelope; and generate at least one speech feature based at least in part on the temporal envelope.<br>10) A computer readable medium for storing computer executable instructions for extracting speech features from signals, the executable instructions comprising the steps of: receiving a signal; performing a time-to-frequency domain transformation on at least a portion of the received signal to generate a frequency domain representation; performing a frequency domain linear prediction on the frequency domain representation to estimate a temporal envelope of the frequency domain representation, the frequency domain linear prediction comprising: selecting a temporal window to apply the frequency domain linear prediction; and determining a pole rate to automatically distribute poles for modeling the temporal envelope, wherein the poles characterize the temporal peaks of the temporal envelope; and generating at least one speech feature based at least in part on the temporal envelope.</p></layer>
<layer id = "layer558"><p><b>US9373339B2:Speech intelligibility enhancement system and method</b><br><b>Independant Claims</b><br>1) A method for processing a portion of a speech signal to be played back by an audio device, comprising: estimating a level of the speech signal; estimating a level of background noise; calculating a signal-to-noise ratio (SNR) based on the estimated level of the speech signal and the estimated level of the background noise; and calculating an amount of gain to be applied to the portion of the speech signal based on at least a difference between a predetermined SNR and the calculated SNR, calculating the amount of gain to be applied comprising: calculating a target gain as the difference between the predetermined SNR and the calculated SNR; comparing an actual gain to the target gain, wherein the actual gain represents an amount of gain that was applied to a previously-received portion of the speech signal; calculating the amount of gain to be applied to the portion of the speech signal by adding a fixed amount of gain to the actual gain if the target gain exceeds the actual gain by at least the fixed amount; and calculating the amount of gain to be applied to the portion of the speech signal by subtracting the fixed amount of gain from the actual gain if the target gain is less than the actual gain by at least the fixed amount; applying the amount of gain to the portion of the speech signal; and playing back the portion of the speech signal with the gain applied using the audio device, wherein at least one of the estimating, calculating and applying steps is performed by a processor or an integrated circuit.<br>17) A computer program product comprising a computer-readable storage device having computer program logic recorded thereon for enabling a processor-based system to perform a method for processing a portion of a speech signal to be played back by an audio device, the method comprising: estimating a level of the speech signal; estimating a level of background noise; calculating a signal-to-noise ratio (SNR) based on the estimated level of the speech signal and the estimated level of the background noise; calculating an amount of gain to be applied to the portion of the speech signal based on at least a difference between a predetermined SNR and the calculated SNR, calculating the amount of gain to be applied comprising: calculating a target gain as the difference between the predetermined SNR and the calculated SNR; comparing an actual gain to the target gain, wherein the actual gain represents an amount of gain that was applied to a previously-received portion of the speech signal; calculating the amount of gain to be applied to the portion of the speech signal by adding a fixed amount of gain to the actual gain if the target gain exceeds the actual gain by at least the fixed amount; and calculating the amount of gain to be applied to the portion of the speech signal by subtracting the fixed amount of gain from the actual gain if the target gain is less than the actual gain by at least the fixed amount; applying the amount of gain to the portion of the speech signal; and playing back the portion of the speech signal with the gain applied using the audio device.<br>9) A system for processing a portion of a speech signal be played back by an audio device, comprising: a level estimator configured to estimate a level of the speech signal; a logic block configured to: receive an estimated level of background noise, calculate a signal-to-noise ratio (SNR) based on the estimated level of the speech signal and the estimated level of the background noise, calculate an amount of gain to be applied to the portion of the speech signal based on at least a difference between a predetermined SNR and the calculated SNR, the logic block being configured to calculate the amount of gain to be applied by: calculating a target gain as the difference between the predetermined SNR and the calculated SNR; comparing an actual gain to the target gain, wherein the actual gain represents an amount of gain that was applied to a previously-received portion of the speech signal; calculating the amount of gain to be applied to the portion of the speech signal by adding a fixed amount of gain to the actual gain if the target gain exceeds the actual gain by at least the fixed amount; and calculating the amount of gain to be applied to the portion of the speech signal by subtracting the fixed amount of gain from the actual gain if the target gain is less than the actual gain by at least the fixed amount, apply the amount of gain to the portion of the speech signal; and the audio device configured to playback the portion of the speech signal with the gain applied.</p></layer>
<layer id = "layer559"><p><b>US20120076054A1:TRANSCODERS AND MIXERS FOR VOICE-OVER-IP CONFERENCING</b><br>An end effector for use with a moving device has a frame and a plurality of operational members mounted for movement on the frame. The effector also has an actuation mechanism directly connected to a first operational member and is operable to move the first operational member from a first position to a second position, and from the second position to the first position. A linking apparatus is provided for linking the first operational member to a second operational member. The actuation mechanism moves the first operational member from the first position to the second position, and results in the second operational member being moved by the linking apparatus from a third position to a fourth position. The operational members can be pick up members for picking up items at one pitch and releasing them at a second pitch.<br><b>Independant Claims</b><br>1. A transcoder for converting an input signal to an output signal, the input signal comprising a wideband signal having an upper sub-band and a lower sub-band, and the output signal comprising a narrowband signal, the transcoder comprising: a lower sub-band decoder operable to decode the input signal to provide a decoded lower sub-band signal; and a narrowband encoder operable to encode the decoded lower sub-band signal to produce the output signal.<br>11. A method for converting an input signal to an output signal, the input signal comprising a wideband signal having an upper sub-band and a lower sub-band, and the output signal comprising a narrowband signal, the method comprising: decoding the lower sub-band of the input signal to produce a lower sub-band signal; and encoding the lower sub-band signal to produce the output signal.</p></layer>
<layer id = "layer560"><p><b>US9020813B2:Speech enhancement system and method</b><br><b>Independant Claims</b><br>1) A system, comprising: a speech enhancement processor configured to receive an input signal and output a processed signal; and an encoder device coupled with the speech enhancement processor and configured to receive the processed signal from the speech enhancement processor, where the encoder device is configured to use a codebook to encode the processed signal for transmission over a communication channel; where the speech enhancement processor is configured to modify one or more characteristics of the input signal based on the codebook associated with the encoder device to generate the processed signal.<br>13) A speech enhancement system, comprising: a memory that retains a codebook of spectral shape templates used by an encoder device; a speech enhancement processor coupled with the memory and the encoder device, where the speech enhancement processor is configured to: receive an input signal; modify at least one spectral characteristic of the input signal based on at least one of the spectral shape templates to generate a processed signal; and output the processed signal to the encoder device that uses the codebook to encode the processed signal for transmission over a communication channel.<br>16) A speech enhancement method, comprising: receiving an input signal at a speech enhancement processor; accessing, by the speech enhancement processor, a memory that retains a codebook of spectral shape templates used by an encoder device; modifying, by the speech enhancement processor, at least one spectral characteristic of the input signal based on at least one of the spectral shape templates to generate a processed signal; and outputting the processed signal from the speech enhancement processor to the encoder device that uses the codebook to encode the processed signal for transmission over a communication channel.</p></layer>
<layer id = "layer561"><p><b>US9197181B2:Loudness enhancement system and method</b><br><b>Independant Claims</b><br>1) A method for processing a portion of an audio signal to be played back by an audio device, comprising: determining an overload associated with the portion of the audio signal, wherein the overload comprises an amount by which a level of the audio signal exceeds a maximum desired output level, the maximum desired output level being a level that when exceeded introduces distortion; determining a compression limit associated with the portion of the audio signal as a function of the overload, wherein the compression limit exceeds the maximum desired output level; and compressing the portion of the audio signal to generate a compressed portion of the audio signal having a level that exceeds the maximum desired output level and that does not exceed the compression limit.<br>19) A system for processing a portion of an audio signal to be played back by an audio device, comprising: overload determination logic configured to determine an overload associated with the portion of the audio signal, wherein determining the overload comprises determining an amount by which a level of the audio signal exceeds a maximum desired output level, the maximum desired output level being a level that when exceeded introduces distortion; and compression logic configured to determine a compression limit associated with the portion of the audio signal as a function of the overload, wherein the compression limit is greater than a maximum desired output level, and to compress the portion of the audio signal to generate a compressed portion of the audio signal having a level that exceeds the maximum desired output level and that does not exceed the compression limit.<br>29) A method for processing a portion of an audio signal to be played back by an audio device, comprising: determining a characteristic associated with the audio signal; and applying adaptive soft clipping to the portion of the audio signal to generate an adaptively-soft-clipped portion of the audio signal having a level that does not exceed a maximum desired output level, wherein the adaptive soft clipping is controlled based on at least the characteristic, adaptive soft clipping comprising: combining a weighted version of the soft-clipped portion of the audio signal and a weighted version of a hard-clipped portion of the audio signal.<br>41) A system for processing a portion of an audio signal to be played back by an audio device, comprising: characteristic determination logic configured to determine a characteristic associated with the portion of the audio signal; and adaptive soft clipping logic configured to apply adaptive soft clipping to the compressed portion of the audio signal to generate an adaptively-soft-clipped portion of the audio signal having a level that does not exceed a maximum desired output level, wherein the adaptive soft clipping is controlled based on at least the characteristic, the adaptive soft clipping logic comprising: a combiner configured to combine a weighted version of the soft-clipped portion of the audio signal and a weighted version of a hard-clipped portion of the audio signal.</p></layer>
<layer id = "layer562"><p><b>US8930186B2:Speech enhancement with minimum gating</b><br><b>Independant Claims</b><br>1) A system, comprising: a speech enhancement processor configured to receive an input signal and output a processed signal; and an encoder device coupled with the speech enhancement processor and configured to receive the processed signal from the speech enhancement processor, where the encoder device supports one or more spectral shapes to encode the processed signal for transmission over a communication channel; where the speech enhancement processor is configured to modify a spectral tilt of the input signal, based on a spectral tilt associated with at least one of the one or more spectral shapes supported by the encoder device, to generate the processed signal; and where the speech enhancement processor is configured to modify the spectral tilt of the input signal in response to a determination that an input noise tilt of the input signal surpasses a maximum tilt limitation that is based on one or more spectral shapes available at the encoder device.<br>10) A speech enhancement system, comprising: a noise suppression processor coupled with an encoder device that supports one or more spectral shapes, where the noise suppression processor is configured to: receive an input signal; generate a processed signal from the input signal by modifying a spectral tilt of the input signal based on a spectral tilt associated with at least one of the one or more spectral shapes supported by the encoder device; and output the processed signal to the encoder device that uses at least one of the one or more spectral shapes to encode the processed signal for transmission over a communication channel; where the noise suppression processor is configured to modify the spectral tilt of the input signal in response to a determination that an input noise tilt of the input signal surpasses a maximum tilt limitation that is based on one or more spectral shapes available at the encoder device.<br>11) A speech enhancement system, comprising: a noise suppression processor coupled with an encoder device that supports one or more spectral shapes, where the noise suppression processor is configured to: receive an input signal; generate a processed signal from the input signal by modifying a spectral tilt of the input signal based on a spectral tilt associated with at least one of the one or more spectral shapes supported b the encoder device; and output the processed signal to the encoder device that uses at least one of the one or more spectral shapes to encode the processed signal for transmission over a communication channel; and further comprising the encoder device; where the encoder device is configured to perform a comparison between the processed signal that has a modified spectral tilt and a plurality of spectral shapes that represent comfort noise; and where the encoder device is configured to select, based on the comparison, a spectral shape of the plurality of spectral shapes that represent comfort noise for transmission over the communication channel.<br>12) A speech enhancement system, comprising: a noise suppression processor coupled with an encoder device that supports one or more spectral shapes, where the noise suppression processor is configured to: receive an input signal; generate a processed signal from the input signal by modifying a spectral tilt of the input signal based on a spectral tilt associated with at least one of the one or more spectral shapes supported by the encoder device; and output the processed signal to the encoder device that uses at least one of the one or more spectral shapes to encode the processed signal for transmission over a communication channel; where the noise suppression processor determines an adaptive noise floor with different maximum attenuation levels for frequency ranges below and above a cutoff frequency; where the noise suppression processor comprises a noise suppressor that applies a dynamic noise suppression constrained by the adaptive noise floor to generate a residual noise spectrum; and where the noise suppressor is configured to modify the spectral tilt of the input signal by modifying a spectral tilt of the residual noise spectrum, where the noise suppressor is configured to modify the spectral tilt of the residual noise spectrum by applying more noise suppression in a first frequency range than in a second frequency range when the spectral tilt of the residual noise spectrum surpasses a maximum tilt limitation that is based on the at least one of the one or more spectral shapes supported by the encoder device.<br>13) A speech enhancement method, comprising: receiving an input signal at a speech enhancement processor coupled with an encoder device that supports one or more spectral shapes; modifying a spectral tilt of the input signal by the speech enhancement processor, based on a spectral tilt associated with at least one of the one or more spectral shapes supported by the encoder device, to generate a processed signal; and outputting the processed signal from the speech enhancement processor to the encoder device that uses at least one of the one or more spectral shapes to encode the processed signal for transmission over a communication channel; where the step of modifying the spectral tilt of the input signal comprises modifying the spectral tilt of the input signal in response to a determination that an input noise tilt of the input signal surpasses a maximum tilt limitation that is based on one or more spectral shapes available at the encoder device.<br>14) A speech enhancement method, comprising: receiving an input signal at a speech enhancement processor coupled with an encoder device that supports one or more spectral shapes; modifying a spectral tilt of the input signal by the speech enhancement processor, based on a spectral tilt associated with at least one of the one or more spectral shapes supported by the encoder device, to generate a processed signal; and outputting the processed signal from the speech enhancement processor to the encoder device that uses at least one of the one or more spectral shapes to encode the processed signal for transmission over a communication channel; performing a comparison between the processed signal that has a modified spectral tilt and a plurality of spectral shapes that represent comfort noise; and selecting, based on the comparison, a spectral shape of the plurality of spectral shapes that represent comfort noise for transmission over the communication channel.<br>15) A speech enhancement method, comprising: receiving an input signal at a speech enhancement processor coupled with an encoder device that supports one or more spectral shapes; modifying a spectral tilt of the input signal by the speech enhancement processor, based on a spectral tilt associated with at least one of the one or more spectral shapes supported by the encoder device, to generate a processed signal; and outputting the processed signal from the speech enhancement processor to the encoder device that uses at least one of the one or more spectral shapes to encode the processed signal for transmission over a communication channel; where the step of modifying the spectral tilt of the input signal comprises generating a suppression gain above a gain floor.<br>16) A speech enhancement method, comprising: receiving an input signal at a speech enhancement processor coupled with an encoder device that supports one or more spectral shapes; modifying a spectral tilt of the input signal by the speech enhancement processor, based on a spectral tilt associated with at least one of the one or more spectral shapes supported by the encoder device, to generate a processed signal; and outputting the processed signal from the speech enhancement processor to the encoder device that uses at least one of the one or more spectral shapes to encode the processed signal for transmission over a communication channel; where the step of modifying the spectral tilt of the input signal comprises: determining an adaptive noise floor with different maximum attenuation levels for frequency ranges below and above a cutoff frequency; and applying a dynamic noise suppression constrained by the adaptive noise floor to generate a residual noise spectrum.<br>2) A system, comprising: a speech enhancement processor configured to receive an input signal and output a processed signal; and an encoder device coupled with the speech enhancement processor and configured to receive the processed signal from the speech enhancement processor, where the encoder device supports one or more spectral shapes to encode the processor signal for transmission over a communication channel; where the speech enhancement processor is configured to modify a spectral tilt of the input signal, based on a spectral tilt associated with at least one of the one or more spectral shapes supported by the encoder device, to generate the processed signal; where the encoder device is configured to perform a comparison between the processed signal that has a modified spectral tilt and a plurality of spectral shapes that represent comfort noise; and where the encoder device is configured to select, based on the comparison, a spectral shape of the plurality of spectral shapes that represent comfort noise for transmission over the communication channel.<br>3) A system, comprising: a speech enhancement processor configured to receive an input signal and output a processed signal; and an encoder device coupled with the speech enhancement processor and configured to receive the processed signal from the speech enhancement processor, where the encoder device supports one or more spectral shapes to encode the processed signal for transmission over a communication channel; where the speech enhancement processor is configured to modify a spectral tilt of the input signal, based on a spectral tilt associated with at least one of the one or more spectral shapes supported by the encoder device, to generate the processed signal; and where the speech enhancement processor is configured to modify the spectral tilt of the input signal by maintaining a suppression gain above a predetermined value.<br>4) A system, comprising: a speech enhancement processor configured to receive an input signal and output a processed signal; and an encoder device coupled with the speech enhancement processor and configured to receive the processed signal from the speech enhancement processor, where the encoder device supports one or more spectral shapes to encode the processed signal for transmission over a communication channel; where the speech enhancement processor is configured to modify a spectral tilt of the input signal, based on a spectral tilt associated with at least one of the one or more spectral shapes supported by the encoder device, to generate the processed signal; and where the speech enhancement processor is configured to modify the spectral tilt of the input signal by generating a suppression gain above a gain floor.<br>5) A system, comprising: a speech enhancement processor configured to receive an input signal and output a processed signal; and an encoder device coupled with the speech enhancement processor and configured to receive the processed signal from the speech enhancement processor, where the encoder device supports one or more spectral shapes to encode the processed signal for transmission over a communication channel; where the speech enhancement processor is configured to modify a spectral tilt of the input signal, based on a spectral tilt associated with at least one of the one or more spectral shapes supported by the encoder device, to generate the processed signal; and where the speech enhancement processor is configured to modify the spectral tilt of the input signal by maintaining a suppression gain above a predetermined value, and where the suppression, gain is based on a cutoff frequency that separates a plurality of frequency ranges.<br>6) A system, comprising: a speech enhancement processor configured to receive an input signal and output a processed signal; and an encoder device coupled with the speech enhancement processor and configured to receive the processed signal from the speech enhancement processor, where the encoder device supports one or more spectral shapes to encode the processed signal for transmission over a communication channel; where the speech enhancement processor is configured to modify a spectral tilt of the input signal, based on a spectral tilt associated with at least one of the one or more spectral shapes supported by the encoder device, to generate the processed signal; and where the speech enhancement processor is configured to apply a different maximum attenuation level in a lower aural frequency band than in a higher aural frequency band.<br>7) A system, comprising: a speech enhancement processor configured to receive an input signal and output a processed signal; and an encoder device coin led with the speech enhancement processor and configured to receive the processed signal from the speech enhancement processor, where the encoder device supports one or more spectral shapes to encode the processed signal for transmission over a communication channel; where the speech enhancement processor is configured to modify a spectral tilt of the input signal, based on a spectral tilt associated with at least one of the one or more spectral shapes supported by the encoder device, to generate the processed signal; and where the speech enhancement processor determines an adaptive noise floor with different maximum attenuation levels for frequency ranges below and above a cutoff frequency.</p></layer>
<layer id = "layer563"><p><b>US8831936B2:Systems, methods, apparatus, and computer program products for speech signal processing using spectral contrast enhancement</b><br>An apparatus and method are provided for sensing infrared radiation. The apparatus includes a sensor element that is positioned in a magnetic field during operation to ensure a λ shaped relationship between specific heat and temperature adjacent the Curie temperature of the ferroelectric material comprising the sensor element. The apparatus is operated by inducing a magnetic field on the ferroelectric material to reduce surface charge on the element during its operation.<br><b>Independant Claims</b><br>11) An apparatus comprising: means for performing a spatially selective processing operation on a multichannel sensed audio signal to produce a source signal and a noise reference; and means for performing a first spectral contrast enhancement operation within a first spectral contrast enhancer on a far end speech signal and the noise reference to produce a first processed speech signal.<br>13) The apparatus of 11, wherein the apparatus comprises means for cancelling echoes from the multichannel sensed audio signal, and wherein the means for cancelling echoes is configured and arranged to be trained by the first processed speech signal.<br>1) A method comprising performing each of the following acts within a device that is configured to process audio signals: performing a spatially selective processing operation within a spatially selective processing filter on a multichannel sensed audio signal to produce a source signal and a noise reference; and performing a first spectral contrast enhancement operation within a first spectral contrast enhancer on a far end speech signal and the noise reference to produce a first processed speech signal.<br>20) An apparatus comprising: a spatially selective processing filter configured to perform a spatially selective processing operation on a multichannel sensed audio signal to produce a source signal and a noise reference; and a first spectral contrast enhancer, coupled to the spatially selective processing filter, configured to perform a spectral contrast enhancement operation on a far end speech signal and the noise reference to produce a first processed speech signal.<br>28) A non-transitory computer-readable medium comprising instructions which when executed by at least one processor cause the at least one processor to perform a method comprising: instructions which when executed by a processor cause the processor to perform a spatially selective processing operation on a multichannel sensed audio signal to produce a source signal and a noise reference; and instructions which when executed by a processor cause the processor to perform a first spectral contrast enhancement operation within a first spectral contrast enhancer on a speech signal and the noise reference to produce a first processed speech signal, wherein the speech signal comprises a far end speech signal.<br>32) A non-transitory computer-readable medium comprising instructions which when executed by at least one processor cause the at least one processor to perform the first spectral contrast enhancement operation comprising: instructions which when executed by a processor cause the processor to calculate a first plurality of subband factors based on information from the noise reference; instructions which when executed by a processor cause the processor to calculate a second plurality of subband factors based on information from the far end speech signal; instructions which when executed by a processor cause the processor to generate a contrast enhanced signal by applying the second plurality of subband factors to the far end speech signal subbands; and instructions which when executed by a processor cause the processor to combine the first plurality of subband factors and the first contrast enhanced signal.</p></layer>
<layer id = "layer564"><p><b>US10360921B2:Method and apparatus for determining coding mode</b><br><b>Independant Claims</b><br>3) An encoding method for an audio signal, the method comprising:determining a coding mode of a current frame based on a first plurality of signal characteristics of the current frame, from among a plurality of coding modes including a music coding mode and a speech coding mode;obtaining a second plurality of signal characteristics from a plurality of frames;determining, performed by at least one processing device, whether to change the determined coding mode of the current frame, based on the second plurality of signal characteristics and a parameter to prevent frequent switching among the plurality of coding modes;when the determined coding mode of the current frame is determined to be changed, changing the determined coding mode of the current frame to another mode among the plurality of coding modes;encoding the current frame, according to either the determined coding mode when the determined coding mode of the current frame is determined not to be changed or the changed coding mode when the determined coding mode of the current frame is determined to be changed; andtransmitting a bitstream including a result of the encoding, for reproduction of music or speech,wherein the second plurality of signal characteristics include a signal characteristic determined based on the current frame and a predetermined number of previous frames.<br>1) A coding mode determination method for an audio signal, the method comprising:determining a coding mode of a current frame based on a first plurality of signal characteristics of the current frame, from among a plurality of coding modes including a music coding mode and a speech coding mode;obtaining a second plurality of signal characteristics from a first plurality of frames;determining, performed by at least one processing device, whether to change the determined coding mode of the current frame, based on the second plurality of signal characteristics and a parameter to prevent frequent switching among the plurality of coding modes; andwhen the determined coding mode of the current frame is determined to be changed, changing the determined coding mode of the current frame to another mode among the plurality of coding modes,wherein the second plurality of signal characteristics include a signal characteristic determined based on the current frame and a predetermined number of previous frames.</p></layer>
<layer id = "layer565"><p><b>US8831958B2:Method and an apparatus for a bandwidth extension using different schemes</b><br>Methods for altering levels in plants of one or more phenolic compounds that are intermediates or final products of the plant phenylpropanoid pathway are provided. One method comprises transforming a plant cell with an expression construct comprising a nucleic acid which encodes a transactivator protein comprising the myb domain of the maize \\u201CZmMyb-IF35\\u201D protein and an activation domain. Another method comprises transforming a plant cell with an expression construct comprising a transgene which encodes an antisense ZmMyb-IF35 RNA. The present invention also relates to expression constructs and vectors used in the present methods, transformed plant cells and transgenic plants prepared according to the present methods, and the seeds of such transgenic plants.<br><b>Independant Claims</b><br>1) A method for processing an audio signal, the method comprising: receiving, by an audio processing apparatus, a spectral data of a lower band, coding scheme information, and type information, the coding scheme information indicating an audio coding scheme or a speech coding scheme, the type information indicating a first band extension scheme or a second band extension scheme for a current frame of the audio signal; decoding, by the audio processing apparatus, the spectral data of the lower band using one of the audio coding scheme and the speech coding scheme based on the coding scheme information; when the type information indicates the first band extension scheme for the current frame, generating, by the audio processing apparatus, a spectral data of a higher band in the current frame using the decoded spectral data of the lower band by performing the first band extension scheme; and when the type information indicates the second band extension scheme for the current frame, generating, by the audio processing apparatus, the spectral data of the higher band in the current frame using the decoded spectral data of the lower band by performing the second band extension scheme, wherein the first band extension scheme is based on a first data area of the spectral data of the lower band, and the first data area corresponds to a portion of the spectral data of the lower band, said portion being less than all of the spectral data of the lower band, and wherein the second band extension scheme is based on a second data area of the spectral data of the lower band, and the second data area corresponds to all of the spectral data of the lower band.<br>13) A non-transitory computer-readable medium comprising instructions stored thereon, which, when executed by a processor, causes the processor to perform operations, the instructions comprising: receiving a spectral data of a lower band, coding scheme information, and type information, the coding scheme information indicating an audio coding scheme or a speech coding scheme, the type information indicating a first band extension scheme or a second band extension scheme for a current frame of an audio signal; decoding the spectral data of the lower band using one of the audio coding scheme and the speech coding scheme based on the coding scheme information; when the type information indicates the first band extension scheme for the current frame, generating a spectral data of a higher band in the current frame using the spectral data of the lower band by performing the first band extension scheme; and when the type information indicates the second band extension scheme for the current frame, generating the spectral data of the higher band in the current frame using the spectral data of the lower band by performing the second band extension scheme, wherein the first band extension scheme is based on a first data area of the spectral data of the lower band, and the first data area corresponds to a portion of the spectral data of the lower band, said portion being less than all of the spectral data of the lower band, and wherein the second band extension scheme is based on a second data area of the spectral data of the lower band, and the second data area corresponds to all of the spectral data of the lower band.<br>7) An apparatus for processing an audio signal, the apparatus comprising: a de-multiplexer receiving a spectral data of a lower band, coding scheme information, and type information, the coding scheme information indicating an audio coding scheme or a speech coding scheme, the type information indicating a first band extension scheme or a second band extension scheme; an audio and speech signal decoder decoding the spectral data of the lower band using one of the audio coding scheme and the speech coding scheme based on the coding scheme information; a first band extension decoding unit, when the type information indicates the first band extension scheme for a current frame, generating a spectral data of a higher band in the current frame using the decoded spectral data of the lower band by performing the first band extension scheme; and a second band extension decoding unit, when the type information indicates the second band extension scheme for the current frame, generating the spectral data of the higher band in the current frame using the decoded spectral data of the lower band by performing the second band extension scheme, wherein the first band extension scheme is based on a first data area of the spectral data of the lower band, and the first data area corresponds to a portion of the spectral data of the lower band, said portion being less than all of the spectral data of the lower band, and wherein the second band extension scheme is based on a second data area of the spectral data of the lower band, and the second data area correspond to all of the spectral data of the lower band.</p></layer>
<layer id = "layer566"><p><b>US8532983B2:Adaptive frequency prediction for encoding or decoding an audio signal</b><br>An electrode for a power storage device with good cycle characteristics and high charge/discharge capacity is provided. In addition, a power storage device including the electrode is provided. The electrode for the power storage device includes a conductive layer and an active material layer provided over the conductive layer, the active material layer includes graphene and an active material including a plurality of whiskers, and the graphene is provided to be attached to a surface portion of the active material including a plurality of whiskers and to have holes in part of the active material layer. Further, in the electrode for the power storage device, the graphene is provided to be attached to a surface portion of the active material including a plurality of whiskers and to cover the active material including a plurality of whiskers. Further, the power storage device including the electrode is manufactured.<br><b>Independant Claims</b><br>1) A method of transceiving an audio signal, the method comprising: providing low band spectral information comprising a plurality of spectrum coefficients; predicting a high band extended spectral fine structure from the low band spectral information for at least one subband, the high band extended spectral fine structure comprising a plurality of spectrum coefficients, wherein predicting comprises preparing the spectrum coefficients of the low band spectral information, defining prediction parameters for the high band extended spectral fine structure and index ranges of the prediction parameters, and determining possible best indices of the prediction parameters, determining comprising minimizing a prediction error between a reference subband in high band and a predicted subband that is selected and composed from an available low band, wherein the steps of preparing, defining and determining are performed using a hardware-based audio encoder; and transmitting the possible best indices of the prediction parameters.<br>18) A system for transmitting an audio signal, the system comprising: a transmitter comprising a hardware-based audio coder, the hardware-based audio coder configured to: convert the audio signal to low band spectral information comprising a plurality of spectrum coefficients, predict a high band extended spectral fine structure from the low band spectral information for at least one subband, the high band extended spectral fine structure comprising a plurality of spectrum coefficients, prepare the spectrum coefficients of the low band spectral information, define prediction parameters for the high band extended spectral fine structure and index ranges of the prediction parameters, determine possible best indices of the prediction parameters, wherein a prediction error is minimized between a reference subband in high band and a predicted subband that is selected and composed from an available low band, and produce an encoded audio signal comprising the possible best indices of the prediction parameters; wherein, the transmitter is configured to transmit the encoded audio signal.</p></layer>
<layer id = "layer567"><p><b>US8532998B2:Selective bandwidth extension for encoding/decoding audio/speech signal</b><br>A memory device includes a first metal layer and a first metal oxide layer coupled to the first metal layer. The memory device includes a second metal oxide layer coupled to the first metal oxide layer and a second metal layer coupled to the second metal oxide layer. The formation of the first metal oxide layer has a Gibbs free energy that is lower than the Gibbs free energy for the formation of the second metal oxide layer<br><b>Independant Claims</b><br>23) A system for receiving an encoded audio signal, the system comprising: a receiver configured to receive the encoded audio signal, the receiver comprising a hardware-based audio decoder configured to: measure a periodicity of the audio signal to determine a checked periodicity, and compose at least one extended subband in a frequency domain if the checked periodicity is lower than a threshold by reducing a ratio of copied harmonic components to composed or copied noise components of the least one extended subband, and scaling a magnitude of the at least one extended subband based on a spectral envelope of the audio signal to produce a scaled extended subband.<br>1) A method of receiving an audio signal, the method comprising: measuring a periodicity of the audio signal to determine a checked periodicity; if the checked periodicity of the audio signal is lower than a threshold, composing at least one extended subband in a frequency domain, wherein composing comprises reducing a ratio of copied harmonic components to composed or copied noise components if the checked periodicity is lower than the threshold, and generating an extended fine spectral structure in the frequency domain based on adding the copied harmonic components and the composed or copied noise components of at least one subband; and scaling a magnitude of the at least one extended subband based on a spectral envelope on the audio signal, wherein the steps of measuring, composing, reducing, generating and scaling are performed using a hardware-based audio decoder.<br>15) A method of decoding an encoded audio signal, the method comprising: dividing an available low band of the encoded audio signal into a plurality of available subbands; determining if each available subband comprises adequate harmonic content; selecting available subbands that have adequate harmonic content based on the determining; and composing an extended high band from copying the selected available subbands, wherein composing is performed in a frequency domain and the steps of dividing, determining, selecting and composing are performed using a hardware-based audio decoder.</p></layer>
<layer id = "layer568"><p><b>US8407046B2:Noise-feedback for spectral envelope quantization</b><br>Exemplary embodiments are disclosed of a heating, ventilation and air conditioning (HVAC) system that includes a switched mode power supply. The switched mode power supply is configured to provide standby power to the HVAC system. The standby power may be limited substantially in accordance with power demand by one or more components of the HVAC system.<br><b>Independant Claims</b><br>1) A method of transmitting an input audio signal, the method comprising: quantizing a current spectral magnitude of the input audio signal; feeding back a quantization error of a previous spectral magnitude to influence quantization of the current spectral magnitude, wherein feeding back comprises adaptively modifying a quantization criterion to form a modified quantization criterion; minimizing a current quantization error by using the modified quantization criterion; forming a quantized spectral envelope based on the minimizing, wherein the steps of quantizing, feeding back, minimizing and forming are performed using a hardware-based audio coder; and transmitting the quantized spectral envelope.<br>21) A system for transmitting an input audio signal, the system comprising: a transmitter comprising a hardware-based audio coder, the hardware-based audio coder configured to quantize a current spectral magnitude of the input audio signal; feed back a quantization error of a previous spectral magnitude to influence quantization of the current spectral magnitude, wherein feeding back comprises adaptively modifying a quantization criterion to form a modified quantization criterion; minimize a current quantization error by using the modified quantization criterion; and form a quantized spectral envelope based on minimizing the current quantization error.</p></layer>
<layer id = "layer569"><p><b>US8515747B2:Spectrum harmonic/noise sharpness control</b><br>The present invention relates to the field of high performance computation. Particularly, the invention relates to converting a huge XML document into SDML format which can be processed with high degree of parallelism to achieve high performance. In addition also SDML can be used as a standalone protocol for data representation. SDML deals with one time write and many times read. Further, SDML files can be splitted on number of lines which makes it easier to distribute among multi cores and even distributing across servers.<br><b>Independant Claims</b><br>7) A method of receiving an encoded audio signal, the method comprising: receiving an encoded audio signal bitstream; decoding subbands from the encoded audio signal bitstream; estimating a measured spectral sharpness parameter from the encoded audio signal for each of the decoded subbands, wherein the measured spectral sharpness parameter represents a spectral harmonic/noise sharpness of the decoded subbands, and the measured spectral sharpness parameter is estimated in the decoder by calculating a magnitude ratio between an average magnitude and a maximum magnitude of a decoded spectral subband or an energy level ratio between an average energy level and a maximum energy level of a decoded spectral subband; forming a main sharpness control parameter for each of the decoded subbands, wherein the main sharpness control parameter for each decoded subband is formed by analyzing the measured spectral sharpness parameter from decoded subbands; sharpening ones of the decoded subbands if the corresponding main sharpness control judges that a corresponding subband is not sharp enough based on a result of comparing the main sharpness control parameters of decoded subbands, wherein sharpened subbands are formed by reducing energy of frequency coefficients between harmonic peaks, increasing energy of the harmonic peaks, and/or reducing noise component; flattening ones of the decoded subbands if the corresponding main sharpness control judges that a corresponding subband is not flat enough based on a result of comparing the main sharpness control parameters of decoded subbands, wherein flattened subbands are formed by increasing energy of frequency coefficients between harmonic peaks, reducing energy of the harmonic peaks, and/or increasing noise component; and normalizing an energy level of each sharpened subband and each flattened subband to keep an energy level of each sharpened and/or flattened substantially unchanged.<br>10) A method of transmitting an input audio signal, the method comprising: estimating a spectral sharpness parameter of each subband of the input audio signal, wherein the spectral sharpness parameter represents a spectral harmonic/noise sharpness of each subband of the input audio signal, wherein the spectral sharpness parameter is estimated in an encoder by calculating a magnitude ratio between an average magnitude and a maximum magnitude of an original spectral subband or an energy level ratio between an average energy level and a maximum energy level of an original spectral subband; comparing the estimated spectral sharpness parameters from different subbands; allocating more bits to subbands having a sharper spectrum based on the comparing; allocating less bits to subbands having a flatter spectrum based on the comparing; and transmitting the allocated bits.<br>1) A method of receiving an encoded audio signal comprising audio data and a transmitted spectral sharpness parameter representing a spectral harmonic/noise sharpness of a plurality of spectral subbands, wherein the transmitted spectral sharpness parameter is estimated in an encoder by calculating a magnitude ratio between an average magnitude and a maximum magnitude of an original spectral subband or an energy level ratio between an average energy level and a maximum energy level of an original spectral subband, and the transmitted spectral sharpness parameter is quantized in the encoder and sent to a decoder in which it is used to control spectral sharpness of decoded spectral subbands, the method comprising: receiving the encoded audio signal; decoding subbands from the audio data; estimating a measured spectral sharpness parameter from the received audio data, wherein the measured spectral sharpness parameter is estimated in the decoder by calculating a magnitude ratio between an average magnitude and a maximum magnitude of a decoded spectral subband or an energy level ratio between an average energy level and a maximum energy level of a decoded spectral subband; comparing the transmitted spectral sharpness parameter with the measured spectral sharpness parameter; forming a main sharpness control parameter for each of the decoded subbands, wherein the main sharpness control parameter for each decoded subband is formed by analyzing differences between the corresponding transmitted spectral sharpness parameter and the measured spectral sharpness parameter; analyzing the main sharpness control parameter for each of the decoded subbands; sharpening ones of the decoded subbands if the corresponding main sharpness control judges that a corresponding subband is not sharp enough based on a result of comparing the main sharpness control parameters of decoded subbands, wherein sharpened subbands are formed by reducing energy of frequency coefficients between harmonic peaks, increasing energy of the harmonic peaks, and/or reducing noise component; flattening ones of the decoded subbands if the corresponding main sharpness control judges that a corresponding subband is not flat enough based on a result of comparing the main sharpness control parameters of decoded subbands, wherein flattened subbands are formed by increasing energy of frequency coefficients between harmonic peaks, reducing energy of the harmonic peaks, and/or increasing noise component; and normalizing an energy level of each sharpened subband and each flattened subband to keep an energy level of each sharpened and/or flattened subband substantially unchanged.<br>13) A system for receiving an encoded audio signal, the system comprising: a receiver configured to receive the encoded audio signal, the receiver configured to: decode subbands from the encoded audio signal; estimate a measured spectral sharpness parameter from the encoded audio signal for each of the decoded subbands, wherein the spectral sharpness parameter represents a spectral harmonic/noise sharpness of each decoded subband, wherein the measured spectral sharpness parameter is estimated in the decoder by calculating a magnitude ratio between an average magnitude and a maximum magnitude of a decoded spectral subband or an energy level ratio between an average energy level and a maximum energy level of a decoded spectral subband; form a main sharpness control parameter for each of the decoded subbands, wherein the main sharpness control parameter for each decoded subband is formed by analyzing the measured spectral sharpness parameter from the decoded subbands; sharpen ones of the decoded subbands if the corresponding main sharpness control judges that a corresponding subband is not sharp enough based on a result of comparing the main sharpness control parameters of decoded subbands, wherein sharpened subbands are formed by reducing energy of frequency coefficients between harmonic peaks, increasing energy of the harmonic peaks, and/or reducing noise component; flatten ones of the decoded subbands if the corresponding main sharpness control judges that a corresponding subband is not flat enough based on a result of comparing the main sharpness control parameters of decoded subbands, wherein flattened subbands are formed by increasing energy of frequency coefficients between harmonic peaks, reducing energy of the harmonic peaks, and/or increasing noise component; and normalize an energy level of each sharpened subband and each flattened subband to keep an energy level of each sharpened and/or flattened substantially unchanged.</p></layer>
<layer id = "layer570"><p><b>US9672835B2:Method and apparatus for classifying audio signals into fast signals and slow signals</b><br><b>Independant Claims</b><br>1) A method of classifying an audio signal into a fast signal or a slow signal for audio coding, comprising: determining, by an encoder comprising a processor, a parameter of each of the plurality of frames of the audio signal, wherein the audio signal has a plurality of frames, wherein each of the plurality of frames has at least two spectral sub-bands; comparing, by the encoder, the parameter with a pre-defined threshold as one of determination elements to determine whether each of the plurality of frames should be classified into a fast frame or a slow frame; processing, by the encoder, the fast frame in a fast mode to obtain a processed fast frame suitable for writing into a bitstream for storing or transmitting; or processing, by the encoder, the slow frame in a slow mode to obtain a processed slow frame suitable for writing into a bitstream for storing or transmitting; wherein the parameter is determined according to spectral sharpness, Spec_Sharp, which is defined as follows:Spec_Sharp=Ni·Max⁢{MDCTi⁡(k),k=0,1,2,…⁢⁢Ni-1}∑k⁢⁢MDCTi⁡(k) wherein MDCTi(k), k=0,1, . . . ,Ni−1, are frequency coefficients in a i-th spectral sub-band of a frame of the audio signal, and Ni is the number of spectral coefficients in the i-th spectral sub-band.<br>17) An encoder of classifying an audio signal into a fast signal or a slow signal for audio coding, comprising: a memory for storing processor-executable instructions; and a processor operatively coupled to the memory, the processor being configured to execute the processor-executable instructions to facilitate the following steps: determining, by an encoder comprising a processor, a parameter of each of the plurality of frames of the audio signal, wherein the audio signal has a plurality of frames, wherein each of the plurality of frames has at least two spectral sub-bands; comparing, by the encoder, the parameter with a pre-defined threshold as one of determination elements to determine whether each of the plurality of frames should be classified into a fast frame or a slow frame; processing, by the encoder, the fast frame in a the fast mode to obtain a processed fast frame suitable for writing into a bitstream for storing or transmitting; or processing, by the encoder, the slow frame in a slow mode to obtain a processed slow frame suitable for writing into a bitstream for storing or transmitting; wherein the parameter is determined according to spectral sharpness, Spec_Sharp, which is defined as follows:Spec_Sharp=Ni·Max⁢{MDCTi⁡(k),k=0,1,2,…⁢⁢Ni-1}∑k⁢⁢MDCTi⁡(k) wherein MDCTi(k), k=0,1, . . . , Ni−1, are frequency coefficients in a i-th spectral sub-band of a frame of the audio signal, and Ni is the number of spectral coefficients in the i-th spectral sub-band.<br>9) A method of classifying an audio signal into a fast signal or a slow signal for audio coding, the method comprising: determining, by an encoder comprising a processor, a parameter of each of the plurality of frames of the audio signal, wherein the audio signal has a plurality of frames; and comparing, by the encoder, the parameter with a pre-defined threshold as one of determination elements to determine whether each of the plurality of frames should be classified into the fast signal or the slow signal, processing, by the encoder, the fast signal in a fast signal mode to obtain a processed fast signal suitable for writing into a bitstream for storing or transmitting; or processing, by the encoder, the slow signal in a slow signal mode to obtain a processed slow signal suitable for writing into a bitstream for storing or transmitting; wherein the parameter is or is a function of temporal sharpness which is defined as a ratio between a maximum temporal magnitude and an average temporal magnitude on a temporal sub-frame or a temporal frame; wherein the parameter is or is a function of temporal sharpness, and the temporal sharpness, Temp_Sharp, is defined by a ratio between a peak magnitude at an energy peak point and an average magnitude before the energy peak point in the time domain,Temp_Sharp=Tenv⁡(ip)(1ip)⁢∑i<ip⁢⁢Tenv⁡(i)Tenv⁡(ip)=Max⁢{Tenv⁡(i),i=0,1,…⁢}where {Tenv(i), i=0,1, . . . } is a temporal energy envelope, Tenv(ipis the peak magnitude at the energy peak point ip, and Temp_Sharp is the temporal sharpness expressed in a Linear domain or a Log domain.</p></layer>
<layer id = "layer571"><p><b>US8942988B2:Efficient temporal envelope coding approach by prediction between low band signal and high band signal</b><br><b>Independant Claims</b><br>1) An audio/speech signal decoding method, comprising: receiving a low frequency band signal and an energy ratio between a high frequency band signal and the low frequency band signal from an encoder; estimating a temporal energy envelope shaping of the low frequency band signal from the received low frequency band signal; multiplying the temporal energy envelope shaping of the low frequency band signal with the energy ratio to obtain a predicted temporal energy envelope shaping of the high frequency band signal; obtaining the high frequency band signal according to the predicted temporal energy envelope shaping of the high frequency band signal; and determining, in response to a flag bit indicating that an estimated error of the predicted temporal energy envelope shaping of the high frequency band signal is low enough, that the obtained high frequency band signal is able to be determined at a determined coding bit rate of the low frequency band signal.<br>12) A decoder, comprising: a receiver; and a processor, wherein the receiver is configured to: receive at least one low frequency band signal and at least one energy ratio between at least one high frequency band signal and the at least one low frequency band signal from an encoder; and wherein the processor is configured to: estimate at least one temporal energy shaping of the at least one low frequency band signal from the at least one received low frequency band signal; multiply the at least one temporal energy envelope shaping of the at least one low frequency band signal with the at least one energy ratio to obtain at least one predicted temporal energy envelope shaping of the at least one high frequency band signal; obtain the at least one high frequency band signal according to the at least one predicted temporal energy envelope shaping of the at least one high frequency band signal; and determine, in response to a flag bit indicating that an estimated error of the predicted temporal energy envelope shaping of the high frequency band signal is low enough, that the obtained at least one high frequency band signal is able to be determined at a determined coding bit rate of the at least one low frequency band signal.<br>15) An audio/speech signal decoding method, comprising: receiving a low frequency band signal and an energy ratio between a high frequency band signal and the low frequency band signal from an encoder; estimating a temporal energy envelope shaping of the low frequency band signal from the received low frequency band signal; multiplying the temporal energy envelope shaping of the low frequency band signal with the energy ratio to obtain a predicted temporal energy envelope shaping of the high frequency band signal; obtaining the high frequency band signal according to the predicted temporal energy envelope shaping of the high frequency band signal; and decoding an estimated error of the predicted temporal energy envelope shaping of the high frequency band signal based on an adjusted coding bit rate.<br>16) A decoder, comprising: a receiver; and a processor, wherein the receiver is configured to: receive at least one low frequency band signal and at least one energy ratio between at least one high frequency band signal and the at least one low frequency band signal from an encoder; and wherein the processor is configured to: estimate at least one temporal energy shaping of the at least one low frequency band signal from the at least one received low frequency band signal; multiply the at least one temporal energy envelope shaping of the at least one low frequency band signal with the at least one energy ratio to obtain at least one predicted temporal energy envelope shaping of the at least one high frequency band signal; obtain the at least one high frequency band signal according to the at least one predicted temporal energy envelope shaping of the at least one high frequency band signal; and decode an estimated error of the at least one predicted temporal energy envelope shaping of the at least one high frequency band signal based on an adjusted coding bit.<br>6) An audio/speech signal encoding and decoding method, comprising: predicting a temporal energy envelope shaping of a high frequency band signal from a low frequency band signal; estimating an energy ratio between the high frequency band signal and the low frequency band signal, and quantizing the energy ratio; sending the low frequency band signal and the quantized energy ratio from an encoder to a decoder; and decoding an estimated error of the predicted temporal energy envelope shaping of the high frequency band signal based on an adjusted coding bit rate; wherein predicting a temporal energy envelope shaping of a high frequency band signal from a low frequency band signal comprises multiplying a temporal envelope of the low band signal with the energy ratio.</p></layer>
<layer id = "layer572"><p><b>US8775169B2:Adding second enhancement layer to CELP based core layer</b><br>A data processing system implementing a weak memory model includes a plurality of processing units coupled to an interconnect fabric. In response execution of a multicopy atomic store instruction, an initiating processing unit broadcasts a store request on the interconnect fabric to obtain coherence ownership of a target cache line. The initiating processing unit posts a kill request to at least one of the plurality of processing units to request invalidation of a copy of the target cache line. In response to successful posting of the kill request, the initiating processing unit broadcasts a store complete request on the interconnect fabric to enforce completion of the invalidation of the copy of the target cache line. In response to the store complete request receiving a coherence response indicating success, the initiating processing unit permits an update to the target cache line requested by the multicopy atomic store instruction to be atomically visible.<br><b>Independant Claims</b><br>1) A method of transmitting an input audio signal with a scalable codec by an audio access device comprising a processor, the method comprising: encoding, by the processor, a low frequency band signal having an inner core layer coding; encoding, by the processor, a first coding error of the inner core layer coding having a first enhancement layer on the low frequency band of the low frequency band signal; encoding, by the processor, a second coding error of the first enhancement layer by using a second enhancement layer on the low frequency band of the low frequency band signal after the first enhancement layer, encoding the second coding error comprising coding fine spectrum coefficients of the second coding error to produce coded fine spectrum coefficients, and coding a spectral envelope of the second coding error to produce a coded spectral envelope; and transmitting the coded fine spectrum coefficients and the coded spectral envelope.<br>13) A method of transmitting an input audio signal with a scalable codec by an audio access device comprising a processor, the method comprising: encoding, by the processor, a low frequency band signal having an inner core layer coding; encoding, by the processor, a first coding error of the inner core layer coding having a first modified discrete cosine transform (MDCT) enhancement layer on the low frequency band of the low frequency band signal; determining if a second MDCT enhancement layer is needed on the low frequency band of the low frequency band signal; and if the second MDCT enhancement layer is needed based on the determining, encoding, by the processor, a second coding error by using the second MDCT enhancement layer after the first modified MCDT enhancement layer.<br>19) A system for transmitting an input audio signal with a scalable codec, the system comprising: a transmitter comprising an audio coder, the audio coder comprising an inner core layer coding with a code-excited linear prediction (CELP) codec configured to encode a low frequency band signal, a first modified discrete cosine transform (MDCT) enhancement layer configured to encode a first coding error of the inner core layer coding of CELP on the low frequency band of the low frequency band signal, and a second MDCT enhancement layer configured to encode a second coding error of the first MDCT enhancement layer on the low frequency band of the low frequency band signal, encode fine spectrum coefficients of the second coding error, and encode a spectral envelope of the second coding error.</p></layer>
<layer id = "layer573"><p><b>US8837750B2:Device and method for manipulating an audio signal</b><br>A foldable head restraint assembly includes a mounting subassembly, a structural shell, and a locking plate. The mounting subassembly supports the structural shell and includes a first support post, a second support post, a cross member, and a latch rigidly. The cross member is attached to the first and second support posts and to the latch. The folding motion of the head restraint is initiated by movement of the locking plate which is positionable at a first plate position for engaging the latch and at a second plate position for releasing the latch. The structural shell is pivotable about the mounting subassembly when the latch plate is in the second plate position<br><b>Independant Claims</b><br>1) An apparatus for manipulating an audio signal, comprising: a windower configured for generating a plurality of consecutive blocks of audio samples, the plurality of the consecutive blocks comprising at least one padded block of audio samples, the padded block comprising padded values and audio signal values; a first converter configured for converting the padded block into a spectral representation comprising spectral values; a phase modifier configured for modifying phases of the spectral values to achieve a modified spectral representation; a second converter configured for converting the modified spectral representation into a modified time domain audio signal; and a transient detector configured for detecting a transient event in the audio signal, wherein the first converter is configured for converting the padded block, when the transient detector detects the transient event in a block of the audio signal corresponding to the padded block, wherein the first converter is configured for converting a non-padded block comprising audio signal values only, the non-padded block corresponding to the non-padded block of the audio signal, when the transient detector does not detect the transient event in the non-padded block of the audio signal, and wherein at least one of the windower, the phase modifier, the second converter, and the transient detector comprises a hardware implementation.<br>18) A method for manipulating an audio signal, comprising: generating, by a windower, a plurality of consecutive blocks of audio samples, the plurality of the consecutive blocks of the audio samples comprising at least one padded block of audio samples, the padded block comprising padded values and audio signal values; converting, by a first converter, the padded block into a spectral representation comprising spectral values; modifying, by a phase modifier, phases of the spectral values to achieve a modified spectral representation; and converting, by a second converter, the modified spectral representation into a modified time domain audio signal, determining, by a transient detector, a transient event in the audio signal, wherein the padded block is converted into the spectral representation, when the transient event is detected in a block of the audio signal corresponding to the padded block, and wherein a non-padded block comprising audio signal values only is converted into the spectral representation, the non-padded block corresponding to the block of the audio signal, when the transient event is not detected in the block of the audio signal, and wherein at least one of the windower, the phase modifier, the second converter, and the transient detector comprises a hardware implementation.<br>19) A non-transitory storage medium having stored thereon a computer program comprising a program code for performing a method for manipulating an audio signal when the computer program is executed on a computer, said method comprising: generating a plurality of consecutive blocks of audio samples, the plurality of the consecutive blocks of the audio samples comprising at least one padded block of audio samples, the padded block comprising padded values and audio signal values; converting the padded block into a spectral representation comprising spectral values; modifying phases of the spectral values to achieve a modified spectral representation; converting the modified spectral representation into a modified time domain audio signal; and determining a transient event in the audio signal, wherein the padded block is converted into the spectral representation, when the transient event is detected in a block of the audio signal corresponding to the padded block, and wherein a non-padded block comprising audio signal values only is converted into the spectral representation, the non-padded block corresponding to the block of the audio signal, when the transient event is not detected in the block of the audio signal.</p></layer>
<layer id = "layer574"><p><b>US8463599B2:Bandwidth extension method and apparatus for a modified discrete cosine transform audio coder</b><br>A plunger-style actuator assembly for use in a detent mechanism includes a guide post and an external plunger sleeve supported for sliding movement over the guide post. The external plunger sleeve rides along bearing surfaces that longitudinally extend between the guide post and the external plunger sleeve.<br><b>Independant Claims</b><br>8) A method comprising: defining a transition band for a signal having a spectrum within a first frequency band, said transition band defined as a portion of said first frequency band, said transition band being located near an adjacent frequency band that is adjacent to said first frequency band; analyzing said transition band to obtain a transition band spectral envelope and a transition band excitation spectrum; estimating an adjacent frequency band spectral envelope; generating an adjacent frequency band excitation spectrum by periodic repetition of at least a part of said transition band excitation spectrum with a repetition period determined by a pitch frequency of said signal; and combining said adjacent frequency band spectral envelope and said adjacent frequency band excitation spectrum to obtain an adjacent frequency band signal spectrum.<br>1) A method comprising: defining a transition band for a signal having a spectrum within a first frequency band, said transition band defined as a portion of said first frequency band, said transition band being located near an adjacent frequency band that is adjacent to said first frequency band; analyzing said transition band to obtain transition band spectral data; analyzing said transition band spectral data to obtain a transition band spectral envelope and a transition band excitation spectrum; and generating an adjacent frequency band signal spectrum using said transition band spectral data comprising: estimating an adjacent frequency band spectral envelope; generating an adjacent frequency band excitation spectrum, using said transition band spectral data; and combining said adjacent band spectral envelope and said adjacent frequency band excitation spectrum to generate said adjacent frequency band signal spectrum.<br>14) A device comprising: an input where a signal is provided; a processor coupled to the input wherein the processor is configured to: define a transition band for the signal having a spectrum within a first frequency band, said transition band defined as a portion of said first frequency band, said transition band being located near an adjacent frequency band that is adjacent to said first frequency band; analyze said transition band to obtain a transition band spectral envelope and a transition band excitation spectrum; estimate an adjacent frequency band spectral envelope; generate an adjacent frequency band excitation spectrum by periodic repetition of at least a part of said transition band excitation spectrum with a repetition period determined by a pitch frequency of said signal; and combine said adjacent frequency band spectral envelope and said adjacent frequency band excitation spectrum to obtain an adjacent frequency band signal spectrum.</p></layer>
<layer id = "layer575"><p><b>US8660281B2:Method and system for a multi-microphone noise reduction</b><br>A method, article of manufacture, and apparatus for protecting data. In some embodiments, this includes taking a snapshot of a physical volume with a native snapshot program, determining which blocks have changed since a previous snapshot with a change block tracker, creating a child virtual container, populating the child virtual container with the changed blocks, and linking the child virtual container with a parent virtual container.<br><b>Independant Claims</b><br>1) A method for a multi microphone noise reduction in a complex noisy environment, comprising: estimating a left and a right noise power spectral density for a left and a right noise input frame by a power spectral density estimator; computing a diffuse noise gain from the estimated power spectral density; extracting a target speech power spectral density from the noise input frame by a target speech power spectral density estimator; generating a directional noise gain from the target speech power spectral density and the noise power spectral density; calculating a pre-enhanced side frame from the diffuse noise gain and the directional noise gain; calculating auto regressive coefficients from the side frame for a Kalman filtering method; filtering the noisy input frame by the Kalman filtering method; generating a Kalman based gain from the Kalman filtered noisy frame and the noise power spectral density; and generating a spectral enhancement gain by combining the diffuse noise gain, the directional noise gain, and the Kalman based gain.<br>12) A hearing aid, comprising: a power spectral density estimator for estimating a left and a right noise power spectral density for a left and a right noise input frame; a target speech power spectral density estimator for extracting a target speech power spectral density from the noise input frame; and a processing device for: computing a diffuse noise gain from the estimated power spectral density, generating a directional noise gain from the target speech power spectral density and the noise power spectral density, calculating a pre-enhanced side frame from the diffuse noise gain and the directional noise gain, calculating auto regressive coefficients from the side frame for a Kalman filtering method, filtering the noisy input frame by the Kalman filtering method, generating a Kalman based gain from the Kalman filtered noisy frame and the noise power spectral density, and generating a spectral enhancement gain by combining the diffuse noise gain, the directional noise gain, and the Kalman based gain.</p></layer>
<layer id = "layer576"><p><b>US9123352B2:Ambient noise compensation system robust to high excitation noise</b><br><b>Independant Claims</b><br>1) A noise compensation method, comprising: estimating how loud a background noise resulting from an excitation signal played over a speaker into an acoustic environment would be in a signal captured by a microphone in the acoustic environment; generating an ambient noise estimate associated with the acoustic environment; performing a comparison between the background noise estimate resulting from the excitation signal and a threshold based on the ambient noise estimate; and controlling a gain of the excitation signal based on a result of the comparison; where the estimate of the loudness of the background noise comprises estimating a coupling factor value that represents a ratio of the excitation signal magnitude to an error signal after a filtering stage of an echo canceller.<br>10) A noise compensation system, comprising: a computer memory that stores computer-readable noise compensation instructions; and a processor configured to execute the computer-readable noise compensation instructions, where execution of the computer-readable noise compensation instructions causes the processor to: estimate a level of background noise resulting from an excitation signal played over a speaker into an acoustic environment would be in a signal captured by a microphone in the acoustic environment; generate an ambient noise estimate associated with the acoustic environment; perform a comparison between the background noise estimate resulting from the excitation signal and a threshold based on the ambient noise estimate; and control a gain of the excitation signal based on a result of the comparison; where the estimate of the level of background noise comprises estimating a coupling factor value that represents a ratio of the excitation signal magnitude to an error signal after a filtering stage of an echo canceller.<br>17) A noise compensation system, comprising: a computer memory that stores computer-readable noise compensation instructions; and a processor configured to execute the computer-readable noise compensation instructions, where execution of the computer-readable noise compensation instructions causes the processor to: estimate how loud a background noise resulting from an excitation signal played over a speaker into an acoustic environment would be in a signal captured by a microphone in the acoustic environment; generate an ambient noise estimate associated with the acoustic environment; perform a comparison between the background noise estimate resulting from the excitation signal and a threshold based on the ambient noise estimate; control a gain of the excitation signal based on a result of the comparison; determine that the background noise resulting from the excitation signal noise is too high based on the result of the comparison; set a flag or status marker in response to the determination that the background noise resulting from the excitation signal noise is too high; and control the gain to be applied to the excitation signal while the flag or status marker is set.<br>18) A non-transitory computer-readable medium with instructions stored thereon, where the instructions are executable by a processor to cause the processor to perform the steps of: estimating how loud a background noise resulting from an excitation signal played over a speaker into an acoustic environment would be in a signal captured by a microphone in the acoustic environment; generating an ambient noise estimate associated with the acoustic environment; performing a comparison between the background noise estimate resulting from the excitation signal and a threshold based on the ambient noise estimate; and controlling a gain of the excitation signal based on a result of the comparison; where the estimate of the level of background noise comprises estimating a coupling factor value that represents a ratio of the excitation signal magnitude to the error signal after the filtering stage of an echo canceller.<br>21) A noise compensation method, comprising: estimating how loud a background noise resulting from an excitation signal played over a speaker into an acoustic environment would be in a signal captured by a microphone in the acoustic environment based on a magnitude of the excitation signal and an error signal after a filtering stage; generating an ambient noise estimate associated with the acoustic environment; performing a comparison between the background noise estimate resulting from the excitation signal and a threshold based on the ambient noise estimate; and controlling a gain of the excitation signal based on a result of the comparison; where the estimate of the level of background noise comprises estimating a coupling factor value that represents a ratio of the excitation signal magnitude to the error signal after the filtering stage of an echo canceller.<br>22) A noise compensation method, comprising: estimating how loud a background noise resulting from an excitation signal played over a speaker into an acoustic environment would be in a signal captured by a microphone in the acoustic environment; generating an ambient noise estimate associated with the acoustic environment; performing a comparison between the background noise estimate resulting from the excitation signal and a threshold based on the ambient noise estimate; controlling a gain of the excitation signal based on a result of the comparison by reducing the gain of the excitation signal in response to a determination that an estimate from the excitation signal and a coupling factor is more than the background noise estimate by a second threshold.<br>23) A noise compensation method, comprising: estimating how loud a background noise resulting from an excitation signal played over a speaker into an acoustic environment would be in a signal captured by a microphone in the acoustic environment; generating an ambient noise estimate associated with the acoustic environment; performing a comparison between the background noise estimate resulting from the excitation signal and a threshold based on the ambient noise estimate; controlling a gain of the excitation signal based on a result of the comparison by stopping further increases in the gain of the excitation signal in response to a determination that an estimate from the excitation signal and a coupling factor is more than the background noise estimate by a second threshold.<br>5) A noise compensation method, comprising: estimating how loud a background noise resulting from an excitation signal played over a speaker into an acoustic environment would be in a signal captured by a microphone in the acoustic environment; generating an ambient noise estimate associated with the acoustic environment; performing a comparison between the background noise estimate resulting from the excitation signal and a threshold based on the ambient noise estimate; determining that the background noise estimate associated with the excitation signal is higher than the ambient noise estimate by a predetermined level; and reducing the gain of the excitation signal or stopping further increases in the gain of the excitation signal in response to the determination that the background noise estimate associated with the excitation signal is higher than the ambient noise estimate by a predetermined level.<br>8) A noise compensation method, comprising: estimating how loud a background noise resulting from an excitation signal played over a speaker into an acoustic environment would be in a signal captured by a microphone in the acoustic environment; generating an ambient noise estimate associated with the acoustic environment; performing a comparison between the background noise estimate resulting from the excitation signal and a threshold based on the ambient noise estimate; controlling a gain of the excitation signal based on a result of the comparison; determining that the background noise resulting from the excitation signal noise is too high based on the result of the comparison; setting a flag or status marker in response to the determination that the background noise resulting from the excitation signal noise is too high; and controlling the gain to be applied to the excitation signal while the flag or status marker is set.</p></layer>
<layer id = "layer577"><p><b>US20180166087A1:METHOD AND APPARATUS FOR ENCODING/DECODING SPEECH SIGNAL USING CODING MODE</b><br><b>Independant Claims</b><br>1) (canceled)<br>2) An encoding apparatus comprising: at least one processor configured to: if a bitrate is higher than a predetermined bitrate, encode a frame based on a transform coded excitation (TCX) technology; if a bitrate is lower than the predetermined bitrate, select, an encoding mode of the frame among a plurality of modes including a first encoding mode and a second encoding mode, based on a plurality of parameters including the bitrate and a result of signal classification; if the encoding mode is the first encoding mode, encode the frame by performing a linear prediction based encoding; and if the encoding mode is the second encoding mode, encode the frame by using the transform coded excitation (TCX) technology.</p></layer>
<layer id = "layer578"><p><b>US8209514B2:Media processing system having resource partitioning</b><br>The present invention relates to protein engineering, and concerns especially family G/11 xylanases, and genes encoding said enzymes. In specific, the invention concerns<i>Trichoderma reesei</i>XYNII gene, which codes for endo-1,4-β-xylanase (EC 3.2.1.8). The invention describes how site-directed mutagenesis can be used to improve the properties of an enzyme to match the industrial conditions where it is used. Protein engineering can be used to improve thermoactivity and thermostability of xylanases, as well as to broaden their pH range.<br><b>Independant Claims</b><br>1) A processing system comprising: a processor; memory; one or more media storage devices accessible to the processor, where the one or more media storage devices access media files; process code executable by the processor to spawn a process, where execution of the process includes a request for access to the memory; resource partitioning code executable by the processor to generate at least resource partition object and to assign at least one process to the resource partition object, where the process generates one or more media store objects for storage in the memory, where the media store objects correspond to the one or more media storage devices, and where access by a process to the memory for storage of its media store objects is based on parametric rules of the corresponding resource partition object.<br>10) A system comprising: memory; process code that is executable by a processor to spawn multiple processes, where execution of the multiple processes includes requests for access the memory; resource partitioning code executable by the processor to generate resource partition objects and to assign at least one process to a resource partition object, where the processes generate one or more media store objects for storage in the memory, where the media store objects correspond to one or more media storage devices that are used to access media files, and where access by a process to the memory for storage of its media store objects is based on parametric rules of the corresponding resource partition object.<br>17) A process for managing memory in a media system comprising: spawning multiple processes; executing the multiple processes to provide requests for access a memory; generating resource partition objects; assigning at least one process to a resource partition object; generating, using at least one of the multiple processes, one or more media store objects for storage in the memory, where the media store objects correspond to one or more media storage devices that are used to access media files; and controlling access by a process to the memory for storage of its media store objects based on parametric rules of the corresponding resource partition object.</p></layer>
<layer id = "layer579"><p><b>US8781823B2:Voice band enhancement apparatus and voice band enhancement method that generate wide-band spectrum</b><br>A multi-chip package of power semiconductor includes a lead frame, a first segment group, a second segment group, a first power semiconductor chip and a second power semiconductor chip. The lead frame includes a first segment group having a first gate segment, a first source segment, and a first drain segment that are separated from each other. The second segment group has a second gate segment, a second source segment, and a second drain segment that are separated from each other. The first power semiconductor chip is formed on the first segment group. The second power semiconductor chip is formed on the second segment group. The first source segment is physically connected to the second drain segment.<br><b>Independant Claims</b><br>1) A voice band enhancement tangible hardware apparatus, comprising a computer, the computer performing: a frequency transform procedure to perform frequency transform on an input signal to calculate a spectrum; a mapping function calculating procedure to calculate, by use of the spectrum, a mapping function for generating high-range components from low-range components of the spectrum; a wide-band spectrum generating procedure to generate, in a higher range than a band of the spectrum, a high-range spectrum based on the mapping function and to integrate the generated high-range spectrum and the spectrum calculated by the frequency transform unit, thereby generating a wide-band spectrum wider than the band of the spectrum calculated by the frequency transform procedure; an inverse frequency transform procedure to perform inverse frequency transform on the wide-band spectrum to calculate an output signal; a separation procedure to separate the spectrum calculated by the frequency transform procedure into a sound source signal and a spectrum envelope; and an evaluation value calculating procedure, wherein the mapping function calculating procedure uses separate information separated by the separation procedure, and calculates a mapping function for generating high-range components from low-range components of the separate information, and wherein the wide-band spectrum generating procedure generates, in a higher range than the band of the spectrum, high-range separate information based on the mapping function and to integrate the generated high-range separate information and the separate information separated by the separation procedure, thereby generating the wide-band spectrum based on the integrated separate information, wherein the evaluation value calculating procedure calculates an evaluation value of the mapping function by use of an error between separate information generated based on the mapping function and the separate information separated by the separation procedure, the evaluation value decreasing as the error increases, and wherein the wide-band spectrum generating procedure modifies the high-range separate information by multiplying the high-range separate information by the evaluation value that decreases as the error increases.<br>6) A voice band enhancement method, comprising: performing, via a processor, operations comprising: a frequency transform procedure to perform frequency transform on an input signal to calculate a spectrum; a mapping function calculating procedure to calculate, by use of the spectrum, a mapping function for generating high-range components from low-range components of the spectrum; a wide-band spectrum generating procedure to generate, in a higher range than a band of the spectrum, a high-range spectrum based on the mapping function and to integrate the generated high-range spectrum and the spectrum calculated by the frequency transform procedure, thereby generating a wide-band spectrum wider than the band of the spectrum calculated by the frequency transform procedure; an inverse frequency transform procedure to perform inverse frequency transform on the wide-band spectrum to calculate an output signal; and a separation procedure to separate the spectrum calculated by the frequency transform procedure into a sound source signal and a spectrum envelope; and an evaluation value calculating procedure, wherein the mapping function calculating procedure uses separate information separated by the separation procedure, and calculates a mapping function for generating high-range components from low-range components of the separate information, wherein the wide-band spectrum generating procedure generates, in a higher range than the band of the spectrum, high-range separate information based on the mapping function and to integrate the generated high-range separate information and the separate information separated by the separation procedure, thereby generating the wide-band spectrum based on the integrated separate information, wherein the evaluation value calculating procedure calculates an evaluation value of the mapping function by use of an error between separate information generated based on the mapping function and the separate information separated by the separation procedure, the evaluation value decreasing as the error increases, and wherein the wide-band spectrum generating procedure modifies the high-range separate information by multiplying the high-range separate information by the evaluation value that decreases as the error increases.</p></layer>
<layer id = "layer580"><p><b>US9153245B2:Pitch detection method and apparatus</b><br><b>Independant Claims</b><br>1) A pitch detection method, comprising: performing a pitch detection on an input signal in a signal domain, and obtaining a candidate pitch; performing a linear prediction (LP) on the input signal, and obtaining an LP residual signal; setting a candidate pitch range including the candidate pitch; and performing a pitch detection on the LP residual signal within the candidate pitch range, and obtaining a selected pitch; wherein before performing the pitch detection on the input signal in the signal domain and obtaining the candidate pitch, the method further comprises: pre-processing the input signal and obtaining a pre-processed signal; wherein performing the pitch detection on the input signal in the signal domain and obtaining the candidate pitch comprises: adding a target window around a pulse with a maximum amplitude in a second half-frame of the pre-processed signal; obtaining an initial pitch according to the pre-processed signal in the target window and sliding windows of the target window; and detecting double frequency of the initial pitch, and obtaining a candidate pitch; wherein obtaining the initial pitch according to the pre-processed signals in the target window and sliding windows of the target window comprises: calculating a sum of absolute values of a long-term prediction (LTP) residual signal, according to the pre-processed signals in the target window and sliding windows of the target window, and using the pitch corresponding to a minimum sum of absolute values as the initial pitch.<br>9) A pitch detection apparatus in an audio encoder, the pitch detection apparatus comprising: a signal-domain pitch detecting unit, configured to detect a pitch of an input signal in a signal domain, and obtain a candidate pitch; a linear predicting unit, configured to perform linear prediction (LP) on the input signal, and obtain an LP residual signal; a setting unit, configured to set a candidate pitch range that includes the candidate pitch; a residual-domain refined detecting unit, configured to perform a pitch detection on the LP residual signal within the candidate pitch range, and obtain a selected pitch; wherein at least one of the signal-domain pitch detecting unit, the linear predicting unit, the setting unit or the residual-domain refined detecting unit comprises hardware; wherein the signal domain pitch detecting unit comprises: a windowing module, configured to add a target window around a pulse position with a maximum amplitude in a second half-frame signal of the pre-processed signal; an initial pitch obtaining module, configured to obtain an initial pitch according to the pre-processed signal in the target window and sliding windows of the target window; and a candidate pitch obtaining module, configured to perform double frequency detection on the initial pitch, and obtain a candidate pitch; wherein the initial pitch obtaining module is configured to calculate a sum of absolute values of a long-term prediction (LTP) residual signal according to the pre-processed signal in the target window and sliding windows of the target window, and use a pitch corresponding to a minimum sum of absolute values as the initial pitch.</p></layer>
<layer id = "layer581"><p><b>US20180204586A1:REGENERATION OF WIDEBAND SPEECH</b><br><b>Independant Claims</b><br>1) A method for regeneration of wideband speech, comprising: receiving samples of a narrowband speech signal having a first range of frequencies, wherein a first portion of a range of frequencies in a wideband speech signal is represented in the narrowband speech signal; identifying, based on a characteristic of the narrowband speech signal, frequencies in the first range of frequencies to translate into a target band of a regenerated speech signal, the characteristic being determined from a pitch-dependent spectral translation as approximating a harmonic structure in a second portion of the range of frequencies in the wideband speech signal, wherein the second portion of the range of frequencies is excluded from being represented in the narrowband speech signal; modulating the identified frequencies in the first range of frequencies of the received samples of the narrowband speech signal with a modulation signal, the modulation signal having a modulating frequency adapted to upshift the identified frequencies in the first range of frequencies into the target band; filtering the modulated samples, using a target band filter, to form the regenerated speech signal in the target band; and combining the narrowband speech signal with the regenerated speech signal to produce a new wideband speech signal.<br>14) A computing system, comprising: a memory, operable to host data for a narrowband speech signal, the narrowband speech signal being generated from a wideband speech signal; a processor, operably coupled to the memory, the processor to execute instructions that cause the processor to:receive samples of a narrowband speech signal having a first range of frequencies, wherein a first portion of a range of frequencies in a wideband speech signal is represented in the narrowband speech signal;identify, based on a characteristic of the narrowband speech signal, frequencies in the first range of frequencies to translate into a target band of a regenerated speech signal, the characteristic being determined from a pitch-dependent spectral translation as approximating a harmonic structure in a second portion of the range of frequencies in the wideband speech signal, wherein the second portion of the range of frequencies is excluded from being represented in the narrowband speech signal;modulate the identified frequencies in the first range of frequencies of the received samples of the narrowband speech signal with a modulation signal, the modulation signal having a modulating frequency adapted to upshift the identified frequencies in the first range of frequencies into the target band;filter the modulated samples, using a target band filter, to form the regenerated speech signal in the target band; andcombine the narrowband speech signal with the regenerated speech signal to produce a new wideband speech signal.<br>17) A machinereadable storage device having instructions for execution by a processor of the machine, wherein the instructions, when executed, cause the processor to perform operations comprising: obtaining samples of a narrowband speech signal having a first range of frequencies, wherein a first portion of a range of frequencies in a wideband speech signal is represented in the narrowband speech signal; identifying, based on a characteristic of the narrowband speech signal, frequencies in the first range of frequencies to translate into a target band of a regenerated speech signal, the characteristic being determined from a pitch-dependent spectral translation as approximating a harmonic structure in a second portion of the range of frequencies in the wideband speech signal, wherein the second portion of the range of frequencies is excluded from being represented in the narrowband speech signal, modulating the identified frequencies in the first range of frequencies of the received samples of the narrowband speech signal with a modulation signal, the modulation signal having a modulating frequency adapted to upshift the identified frequencies in the first range of frequencies into the target band; filtering the modulated samples, using a target band filter, to form the regenerated speech signal in the target band; and combining the narrowband speech signal with the regenerated speech signal to produce a new wideband speech signal.</p></layer>
<layer id = "layer582"><p><b>US8355906B2:Method and apparatus for extending the bandwidth of a speech signal</b><br><b>Independant Claims</b><br>18) Apparatus for extending the bandwidth of an audio signal, comprising: a bandpass filter operable to bandpass filter the audio signal to obtain a bandpass signal; a bandwidth extension signal generator operable to pitch-synchronously modulate the bandpass signal about at least one carrier frequency to generate at least one bandwidth extension signal; and a signal combiner operable to combine the audio signal and the at least one bandwidth extension signal.<br>1) A method of extending the bandwidth of an audio signal, comprising: bandpass filtering the audio signal to obtain a bandpass signal; generating at least one bandwidth extension signal by pitch-synchronously modulating the bandpass signal about at least one carrier frequency; and combining the audio signal and the at least one bandwidth extension signal.<br>22) A non-transitory computer-readable storage medium comprising computer-readable instructions which, when interpreted by a computing apparatus, causes the computing apparatus to execute a method of extending the bandwidth of an audio signal, the instructions comprising: instructions executable to bandpass filter the audio signal to obtain a bandpass signal; instructions executable to pitch-synchronously modulate the bandpass signal about at least one carrier frequency to generate at least one bandwidth extension signal; and instructions executable to combine the audio signal and the at least one bandwidth extension signal.</p></layer>
<layer id = "layer583"><p><b>US8682652B2:Audio encoder, audio decoder and audio processor having a dynamically variable warping characteristic</b><br>A circuit for rendering an energy storage device parallelable comprised of an energy storage device connected to a power adapter that converts the potential of the energy storage device into a potential that follows a predetermined function of the state of charge of the energy storage device. When multiple assemblies are paralleled, they may be charged and discharged as a whole with individual storage devices maintaining equal states of charge. The energy storage devices can be batteries with different cell counts, configurations, and energy discharge profiles. In some cases, the power adapters are comprised of DC to DC converters and system controllers that are used to translate each battery's energy discharge profile into a user-determined energy discharge profile that is a predictable function of the battery's state of charge and independent of temperature or other external conditions.<br><b>Independant Claims</b><br>1) Audio encoder for encoding an audio signal, comprising: a pre-filter for generating a pre-filtered audio signal, the pre-filter comprising a variable warping characteristic, the warping characteristic being controllable in response to a time-varying control signal, the control signal indicating a small or no warping characteristic or a comparatively high warping characteristic; a controller for providing the time-varying control signal, the time-varying control signal depending on the audio signal; and a controllable encoding processor for processing the pre-filtered audio signal to acquire an encoded audio signal, wherein the encoding processor is adapted to process the pre-filtered audio signal in accordance with a first coding algorithm adapted to a specific signal pattern, or in accordance with a second different encoding algorithm suitable for encoding a general audio signal, wherein the first coding algorithm is specifically adapted for speech signals and the second coding algorithm is specifically adapted for music signals, and wherein at least one of the pre-filter, the controller, and the controllable encoding processor comprises a hardware implementation.<br>43) Non-transitory digital storage medium having stored thereon an encoded audio signal comprising: a first-time portion of the encoded audio signal being encoded in accordance with a first coding algorithm adapted to a specific signal pattern, a second time portion of the encoded audio signal being encoded in accordance with a different second coding algorithm suitable for encoding a general audio signal, wherein the first coding algorithm is specifically adapted for speech signals and the second coding algorithm is specifically adapted for music signals, and as side information, a warping factor indicating a warping strength underlying the first or the second time portion of the encoded audio signal.<br>25) Audio decoder for decoding an encoded audio signal, the encoded audio signal comprising a first portion encoded in accordance with a first coding algorithm adapted to a specific signal pattern, and comprising a second portion encoded in accordance with a different second coding algorithm suitable for encoding a general audio signal, comprising: a detector for detecting a coding algorithm underlying the first portion or the second portion; a decoding processor for decoding, in response to the detector, the first portion using the first coding algorithm to acquire a first decoded time portion and for decoding the second portion using the second coding algorithm to acquire a second decoded time portion, wherein the first coding algorithm is specifically adapted for speech signals and the second coding algorithm is specifically adapted for music signals; and a post-filter comprising a variable warping characteristic being controllable between a first state comprising a small or no warping characteristic and a second state comprising a comparatively high warping characteristic, wherein at least one of the post-filter, the detector, and the decoding processor comprises a hardware implementation.<br>45) Method of encoding an audio signal, comprising: generating, by a pre-filter, a pre-filtered audio signal, the pre-filter comprising a variable warping characteristic, the warping characteristic being controllable in response to a time-varying control signal, the control signal indicating a small or no warping characteristic or a comparatively high warping characteristic; providing, by a controller, the time-varying control signal, the time-varying control signal depending on the audio signal; and processing, by a controllable encoding processor, the pre-filtered audio signal to acquire an encoded audio signal, in accordance with a first coding algorithm adapted to a specific signal pattern, or in accordance with a second different encoding algorithm suitable for encoding a general audio signal, wherein the first coding algorithm is specifically adapted for speech signals and the second coding algorithm is specifically adapted for music signals, wherein at least one of the pre-filter, the controller, and the controllable encoding processor comprises a hardware implementation.<br>46) Method of decoding an encoded audio signal, the encoded audio signal comprising a first portion encoded in accordance with a first coding algorithm adapted to a specific signal pattern, and comprising a second portion encoded in accordance with a different second coding algorithm suitable for encoding a general audio signal, comprising: detecting, by a detector, a coding algorithm underlying the first portion or the second portion; decoding, by a decoding processor, in response to the step of detecting, the first portion using the first coding algorithm to acquire a first decoded time portion and decoding the second portion using the second coding algorithm to acquire a second decoded time portion, wherein the first coding algorithm is specifically adapted for speech signals and the second coding algorithm is specifically adapted for music signals; and post-filtering, by a post-filter, using a variable warping characteristic being controllable between a first state comprising a small or no warping characteristic and a second state comprising a comparatively high warping characteristic, wherein at least one of the post-filter, the detector, and the decoding processor comprises a hardware implementation.<br>47) Audio processor for processing an audio signal, comprising: a filter for generating a filtered audio signal, the filter comprising a variable warping characteristic, the warping characteristic being controllable in response to a time-varying control signal, the control signal indicating a small or no warping characteristic or a comparatively high warping characteristic; a controller for providing the time-varying control signal, the time-varying control signal depending on the audio signal, and a controllable encoding processor for processing an audio signal pre-filtered by the filter to acquire an encoded audio signal, wherein the encoding processor is adapted to process the pre-filtered audio signal in accordance with a first coding algorithm adapted to a specific signal pattern, or in accordance with a second different encoding algorithm suitable for encoding a general audio signal, or a decoding processor for decoding a first portion of an audio signal using a first coding algorithm to acquire a first decoded time portion and for decoding a second portion of the audio signal using a second coding algorithm to acquire a second decoded time portion, wherein the first decoded time portion and the second decoded time portion are filtered by the filter to obtain the filtered audio signal, wherein the first coding algorithm is specifically adapted for speech signals and the second coding algorithm is specifically adapted for music signals, and wherein at least one of the filter, the controller, the decoding processor, and the controllable encoding processor comprises a hardware implementation.<br>48) Method of processing an audio signal, comprising: generating, by a filter, a filtered audio signal using a filter, the filter comprising a variable warping characteristic, the warping characteristic being controllable in response to a time-varying control signal, the control signal indicating a small or no warping characteristic or a comparatively high warping characteristic; providing, by a controller, the time-varying control signal, the time-varying control signal depending on the audio signal, and processing, by a controllable encoding processor, an audio signal pre-filtered by the filter to acquire an encoded audio signal, wherein the encoding processor is adapted to process the pre-filtered audio signal in accordance with a first coding algorithm adapted to a specific signal pattern, or in accordance with a second different encoding algorithm suitable for encoding a general audio signal, or decoding, by a decoding processor, a first portion of an audio signal using a first coding algorithm to acquire a first decoded time portion and decoding, by the decoding processor, a second portion of the audio signal using a second coding algorithm to acquire a second decoded time portion, wherein the first decoded time portion and the second decoded time portion are filtered by the filter to obtain the filtered audio signal, wherein the first coding algorithm is specifically adapted for speech signals and the second coding algorithm is specifically adapted for music signals, wherein at least one of the filter, the controller, the decoding processor, and the controllable encoding processor comprises a hardware implementation.</p></layer>
<layer id = "layer584"><p><b>US9466308B2:Method for encoding and decoding an audio signal and apparatus for same</b><br><b>Independant Claims</b><br>1) An apparatus for decoding a digital audio or a digital speech signal, the apparatus comprising: a processor that: checks a flag indicating whether decoding of a current frame is possible without referring to information on previous frames, from a bitstream including at least one of the digital audio signal and the digital speech signal; determines whether the current frame is encoded in a linear prediction domain (LPD) or a frequency domain (FD), based on a coding mode of the current frame; decodes the current frame without access to the previous frames in the determined domain, when the decoding of the current frame is possible without referring to information on the previous frames, from the flag; decodes the current frame with access to the previous frames in the determined domain, when the decoding of the current frame requires information on the previous frames, from the flag; and generates a reconstructed audio or speech signal from the digital audio signal or the digital speech signal based on the decoded current frame, for audio or speech reproduction.</p></layer>
<layer id = "layer585"><p><b>US10366696B2:Speech decoder with high-band generation and temporal envelope shaping</b><br><b>Independant Claims</b><br>8) A non-transitory storage medium that stores instructions executable by a processor to decode an encoded speech signal, the storage medium comprising:instructions executable by the processor to decode a bit stream that includes the encoded speech signal to obtain a low frequency component;instructions executable by the processor to transform the low frequency component into a spectral region;instructions executable by the processor to generate a high frequency component by copying the low frequency component transformed into the spectral region from a low frequency band to a high frequency band;instructions executable by the processor to adjust the high frequency component to generate an adjusted high frequency component;instructions executable by the processor to analyze the low frequency component transformed into the spectral region to obtain temporal envelope information by determination of a power value of each QMF subband sample of the low frequency component transformed into the spectral region;instructions executable by the processor to analyze the bit stream, extract from the bit stream an indicator associated with a predetermined parameter, and convert the indicator to the predetermined parameter, the predetermined parameter for adjustment of the temporal envelope information;instructions executable by the processor to adjust the temporal envelope information by adjusting the each QMF subband sample to generate adjusted temporal envelope information using the predetermined parameter; andinstructions executable by the processor to shape a temporal envelope of the adjusted high frequency component using the adjusted temporal envelope information.<br>7) A non-transitory storage medium that stores instructions executable by a processor to decode an encoded speech signal, the storage medium comprising:instructions executable by the processor to separate a bit stream that includes the encoded speech signal into an encoded bit stream and temporal envelope supplementary information, the temporal envelope supplementary information comprising an indicator associated with a predetermined parameter for adjusting the temporal envelope information;instructions executable by the processor to decode the encoded bit stream to obtain a low frequency component;instructions executable by the processor to transform the low frequency component into a spectral region;instructions executable by the processor to generate a high frequency component by copying the low frequency component transformed into the spectral region from a low frequency band to a high frequency band;instructions executable by the processor to adjust the high frequency component to generate an adjusted high frequency component;instructions executable by the processor to analyze the low frequency component transformed into the spectral region to obtain temporal envelope information by determination of a power of each quadrature mirror filter (QMF) subband sample of the low frequency component transformed into the spectral region by the frequency transform means;instructions executable by the processor to convert the indicator included in the temporal envelope supplementary information into the predetermined parameter for adjusting the temporal envelope information;instructions executable by the processor to adjust the temporal envelope information by adjusting the each QMF subband sample to generate adjusted temporal envelope information using the predetermined parameter; andinstructions executable by the processor to shape a temporal envelope of the adjusted high frequency component using the adjusted temporal envelope information.<br>6) A speech decoding method using a speech decoding device for decoding an encoded speech signal, the speech decoding method comprising:a core decoding step in which the speech decoding device decodes a bit stream that includes the encoded speech signal to obtain a low frequency component, the bit stream received from outside the speech decoding device;a frequency transform step in which the speech decoding device transforms the low frequency component obtained in the core decoding step into a spectral region;a high frequency generating step in which the speech decoding device generates a high frequency component by copying the low frequency component transformed into the spectral region in the frequency transform step from a low frequency band to a high frequency band;a high frequency adjusting step in which the speech decoding device adjusts the high frequency component generated in the high frequency generating step to generate an adjusted high frequency component;a low frequency temporal envelope analysis step in which the speech decoding device obtains temporal envelope information by analyzing the low frequency component transformed into the spectral region in the frequency transform step, wherein the temporal envelope information is obtained by obtaining a power value of each quadrature mirror filter (QMF) subband sample of the low frequency component transformed into the spectral region in the frequency transform step;a temporal envelope supplementary information generating step in which the speech decoding device analyzes the bit stream, extracts an indicator associated with a predetermined parameter, and converts the indicator into the predetermined parameter, wherein the predetermined parameter is for adjusting the temporal envelope information;a temporal envelope adjusting step in which the speech decoding device adjusts the temporal envelope information obtained in the low frequency temporal envelope analysis step by adjusting the each QMF subband sample to generate adjusted temporal envelope information, wherein the predetermined parameter is utilized in said adjusting of the temporal envelope information; anda temporal envelope shaping step in which the speech decoding device shapes a temporal envelope of the adjusted high frequency component using the adjusted temporal envelope information.<br>5) A speech decoding method using a speech decoding device for decoding an encoded speech signal, the speech decoding method comprising:a bit stream separating step in which the speech decoding device separates a bit stream that includes the encoded speech signal into an encoded bit stream and temporal envelope supplementary information, the bit stream received from outside the speech decoding device and the temporal envelope supplementary information comprising an indicator associated with a predetermined parameter;a core decoding step in which the speech decoding device obtains a low frequency component by decoding the encoded bit stream separated in the bit stream separating step;a frequency transform step in which the speech decoding device transforms the low frequency component obtained in the core decoding step into a spectral region;a high frequency generating step in which the speech decoding device generates a high frequency component by copying the low frequency component transformed into the spectral region in the frequency transform step from a low frequency band to a high frequency band;a high frequency adjusting step in which the speech decoding device adjusts the high frequency component generated in the high frequency generating step to generate an adjusted high frequency component;a low frequency temporal envelope analysis step in which the speech decoding device obtains temporal envelope information by analyzing the low frequency component transformed into the spectral region in the frequency transform step, wherein the temporal envelope information is obtained by obtaining a power of each quadrature mirror filter (QMF) subband sample of the low frequency component transformed into the spectral region in the frequency transform step;a supplementary information converting step in which the speech decoding device converts the indicator included in the temporal envelope supplementary information into the predetermined parameter, the predetermined parameter for adjusting the temporal envelope information;a temporal envelope adjusting step in which the speech decoding device adjusts the temporal envelope information obtained in the low frequency temporal envelope analysis step by adjusting the each QMF subband sample to generate adjusted temporal envelope information, wherein the predetermined parameter is utilized in said adjusting of the temporal envelope information; anda temporal envelope shaping step in which the speech decoding device shapes a temporal envelope of the adjusted high frequency component using the adjusted temporal envelope information.<br>3) A speech decoding device for decoding an encoded speech signal, the speech decoding device comprising:a processor configured to:decode a bit stream that includes the encoded speech signal to obtain a low frequency component, the bit stream received from outside the speech decoding device;transform the low frequency component into a spectral region;generate a high frequency component by copying the low frequency component, transformed into the spectral region, from a low frequency band to a high frequency band;adjust the high frequency component to generate an adjusted high frequency component;analyze the low frequency component transformed into the spectral region to obtain temporal envelope information;obtain the temporal envelope information by obtaining a power value of each quadrature mirror filter (QMF) subband sample of the low frequency component transformed into the spectral region;analyze the bit stream and extract an indicator included in the bit stream, the indicator associated with a predetermined parameter, the predetermined parameter for adjustment of the temporal envelope information;generate the predetermined parameter for adjustment of the temporal envelope information by conversion of the indicator extracted from the bit stream into the predetermined parameter;adjust the temporal envelope information by adjusting the each QMF subband sample using the predetermined parameter to generate adjusted temporal envelope information;andshape a temporal envelope of the adjusted high frequency component using the adjusted temporal envelope information.<br>1) A speech decoding device for decoding an encoded speech signal, the speech decoding device comprising:a processor configured to:separate a bit stream that includes the encoded speech signal into an encoded bit stream and temporal envelope supplementary information, the bit stream received from outside the speech decoding device and the temporal envelope supplementary information comprising an indicator associated with a predetermined parameter;decode the encoded bit stream to obtain a low frequency component;transform the low frequency component into a spectral region;generate a high frequency component by copying, from a low frequency band to a high frequency band, the low frequency component transformed into the spectral region;adjust the high frequency component generated by the high frequency generating unit to generate an adjusted high frequency component;analyze the low frequency component transformed into the spectral region to obtain temporal envelope information;obtain the temporal envelope information by obtaining power of each quadrature mirror filter (QMF) subband sample of the low frequency component transformed into the spectral region;convert the indicator included in the temporal envelope supplementary information into the predetermined parameter, wherein the predetermined parameter is for adjustment of the temporal envelope information;adjust the temporal envelope information by adjusting the each QMF subband sample using the predetermined parameter to generate adjusted temporal envelope information; andshape a temporal envelope of the adjusted high frequency component using the adjusted temporal envelope information.</p></layer>
<layer id = "layer586"><p><b>US20140140524A1:WIND SUPPRESSION/REPLACEMENT COMPONENT FOR USE WITH ELECTRONIC SYSTEMS</b><br>Provided is a pressure sensor including an elastic thin film including a first surface and a second surface that face each other, the elastic thin film including an elastomer material, a plurality of protruding deformable structures patterned on the first surface; a piezoresistive electrode formed along surfaces of the plurality of protruding deformable structures; and a counter electrode disposed to face the piezoresistive electrode.<br><b>Independant Claims</b><br>1. A method comprising: receiving a first signal at a first detector and a second signal at a second detector; determining a correlation between signals received at the second detector and deriving from the correlation a plurality of wind metrics that characterize wind noise that is acoustic disturbance corresponding to at least one of air flow and air pressure in the second detector; controlling a configuration of the second detector according to the plurality of wind metrics; and generating an output signal for transmission by dynamically mixing the first signal and the second signal according to the plurality of wind metrics.</p></layer>
<layer id = "layer587"><p><b>US8391212B2:System and method for frequency domain audio post-processing based on perceptual masking</b><br>A first data processing request initiated by a first communication terminal is received. The first data processing request includes second communication terminal direction information. A communication code of the second communication terminal is obtained according to the second communication terminal direction information. A request for processing data is sent to the second communication terminal according to the communication code of the second communication terminal A second data processing request initiated by the second communication terminal according to the request for processing data is received and a data processing platform is informed to process data. The present techniques triggers the request for processing data of the server through the first data processing request of the first communication terminal and prompts the second communication terminal to send the second data processing request, thereby forming a reliable online payment on delivery (POD).<br><b>Independant Claims</b><br>1) A method of post-processing of a frequency domain audio signal implemented by an audio post-processor, the method comprising: applying adaptive modification gain factor to each frequency coefficient of the frequency domain audio signal by using the audio post-processor; and determining gain factors based on Local Masking Magnitude and Local Masked Magnitude; wherein the Local Masking Magnitude and Local Masked Magnitude are estimated according to perceptual masking effects, wherein the Local Masking Magnitude is estimated by taking a weighted sum around a specific frequency at i: M0⁡(i)=∑k⁢w0i⁡(k)·F0⁡(i+k), where M0 (i) is the Local Masking Magnitude, w0i (k) is a first frequency dependent weighting window, F0(i) are frequency coefficients of the frequency domain audio signal before the post-processing is applied, and k is an index value, wherein Local Masked Magnitude M1 (i) is estimated by taking a weighted sum the specific frequency at i: M1⁡(i)=∑k⁢w1i⁡(k)·F0⁡(i+k), where M1 (i) is the Local Masked Magnitude, w1i (k) is a second frequency dependent weighting window, and wherein weighting window w1i (k) is flatter and longer in the frequency domain than w0i (k), and wherein an initial gain factor for each frequency is Gain0⁡(i)=M0⁡(i)α·M1⁡(i)+(1-α)·Mav, where i is a frequency index, Mav is an Average Magnitude, and 0≦α≦1.<br>3) A method of post-processing of a frequency domain audio signal implemented by using an audio post-processor, the method comprising: applying adaptive modification gain factor to each frequency coefficient of the frequency domain audio signal by using the audio post-processor; and determining gain factors based on Local Masking Magnitude, Local Masked Magnitude, and Average Magnitude; wherein the Local Masking Magnitude is estimated by taking a weighted sum around a specific frequency at i: M0⁡(i)=∑k⁢w0i⁡(k)·F0⁡(i+k), where M0 (i) is the Local Masking Magnitude, w0i (k) is a first frequency dependent the weighting window, F0(i) are frequency coefficients of the frequency domain audio signal before the post-processing is applied, and k is an index value, wherein Local Masked Magnitude M1 (i) is estimated by taking a weighted sum the specific frequency at i: M1⁡(i)=∑k⁢w1i⁡(k)·F0⁡(i+k), where M1 (i) is the Local Masked Magnitude, w1i (k) is a second frequency dependent weighting window, and wherein weighting window w1i (k) is flatter and longer in the frequency domain than w0i (k), wherein the Average Magnitude is calculated on a whole spectrum band of the frequency domain audio signal, and wherein an initial gain factor for each frequency is Gain0⁡(i)=M0⁡(i)α·M1⁡(i)+(1-α)·Mav, where i is a frequency index, Mav is the Average Magnitude, and 0≦α≦1.<br>14) A system for receiving a frequency domain audio signal, the system comprising a post-processor configured to: apply an adaptive modification gain factor to each frequency coefficient of the frequency domain audio signal; and determine gain factors based on Local Masking Magnitude and Local Masked Magnitude and Average Magnitude, wherein the post-processor estimates the Local Masking Magnitude by taking a weighted sum around a specific frequency at i: M0⁡(i)=∑k⁢w0i⁡(k)·F0⁡(i+k), where M0 (i) is the Local Masking Magnitude, w0i (k) is a first frequency dependent weighting window, F0(i) are frequency coefficients of the frequency domain audio signal before the post-processing is applied, and k is an index value, wherein the post-processor estimates the Local Masked Magnitude M1 (i) by taking a weighted sum the specific frequency at i: M1⁡(i)=∑k⁢w1i⁡(k)·F0⁡(i+k), where M1 (i) is the Local Masked Magnitude, w1i (k) is a second frequency dependent weighting window, and wherein weighting window w1i (k) is flatter and longer in the frequency domain than w0i (k), wherein the post-processor calculates the Average Magnitude on a whole spectrum band of the frequency domain audio signal, and wherein the post-processor calculates an initial gain factor Gain0 (i) for each frequency according to: Gain0⁡(i)=M0⁡(i)α·M1⁡(i)+(1-α)·Mav, where i is a frequency index, Mav (i) is the Average Magnitude, and 0≦α≦1.</p></layer>
<layer id = "layer588"><p><b>US9620132B2:Decoding of multichannel audio encoded bit streams using adaptive hybrid transformation</b><br><b>Independant Claims</b><br>1) A method for decoding a frame of an encoded digital audio signal, wherein: the frame comprises frame metadata, a first audio block and one or more subsequent audio blocks; and each of the first and subsequent audio blocks comprises block metadata and encoded audio data for two or more audio channels, wherein:the encoded audio data comprises scale factors and scaled values representing spectral content of the two or more audio channels, each scaled value being associated with a respective one of the scale factors; andthe block metadata comprises control information describing coding tools used by an encoding process that produced the encoded audio data, wherein the control information indicates that adaptive hybrid transform processing was used by the encoding process and wherein adaptive hybrid transform processing comprises:applying an analysis filter bank implemented by a primary transform to the two or more audio channels to generate primary transform coefficients, andapplying a secondary transform to the primary transform coefficients for at least some of the two or more audio channels to generate hybrid transform coefficients;and wherein the method comprises: (A) receiving the frame of the encoded digital audio signal; and (B) examining the encoded digital audio signal of the frame in a single pass to decode the encoded audio data for each audio block in order by block, wherein the decoding of each respective audio block comprises:(1) if the respective audio block is the first audio block in the frame:(a) obtaining all hybrid transform coefficients of a respective channel for the frame from the encoded audio data in the first audio block, and(b) applying an inverse secondary transform to the hybrid transform coefficients to obtain inverse secondary transform coefficients, and(2) obtaining primary transform coefficients from the inverse secondary transform coefficients for the respective channel in the respective audio block; and (C) applying an inverse primary transform to the primary transform coefficients to generate an output signal representing the respective channel in the respective audio block.<br>11) A non-transitory medium that records a program of instructions executable by a device to perform a method for decoding a frame of an encoded digital audio signal, wherein: the frame comprises frame metadata, a first audio block and one or more subsequent audio blocks; and each of the first and subsequent audio blocks comprises block metadata and encoded audio data for two or more audio channels, wherein:the encoded audio data comprises scale factors and scaled values representing spectral content of the two or more audio channels, each scaled value being associated with a respective one of the scale factors; andthe block metadata comprises control information describing coding tools used by an encoding process that produced the encoded audio data, wherein the control information indicates that adaptive hybrid transform processing was used by the encoding process and wherein adaptive hybrid transform processing comprises:applying an analysis filter bank implemented by a primary transform to the two or more audio channels to generate primary transform coefficients, andapplying a secondary transform to the primary transform coefficients for at least some of the two or more audio channels to generate hybrid transform coefficients;and wherein the method comprises: (A) receiving the frame of the encoded digital audio signal; and (B) examining the encoded digital audio signal of the frame in a single pass to decode the encoded audio data for each audio block in order by block, wherein the decoding of each respective audio block comprises:(1) if the respective audio block is the first audio block in the frame:(a) obtaining all hybrid transform coefficients of a respective channel for the frame from the encoded audio data in the first audio block, and(b) applying an inverse secondary transform to the hybrid transform coefficients to obtain inverse secondary transform coefficients, and(2) obtaining primary transform coefficients from the inverse secondary transform coefficients for the respective channel in the respective audio block; and (C) applying an inverse primary transform to the primary transform coefficients to generate an output signal representing the respective channel in the respective audio block.<br>6) An apparatus for decoding a frame of an encoded digital audio signal, wherein: the frame comprises frame metadata, a first audio block and one or more subsequent audio blocks; and each of the first and subsequent audio blocks comprises block metadata and encoded audio data for two or more audio channels, wherein:the encoded audio data comprises scale factors and scaled values representing spectral content of the two or more audio channels, each scaled value being associated with a respective one of the scale factors; andthe block metadata comprises control information describing coding tools used by an encoding process that produced the encoded audio data, wherein the control information indicates that adaptive hybrid transform processing was used by the encoding process and wherein adaptive hybrid transform processing comprises:applying an analysis filter bank implemented by a primary transform to the two or more audio channels to generate primary transform coefficients, andapplying a secondary transform to the primary transform coefficients for at least some of the two or more audio channels to generate hybrid transform coefficients;and wherein the apparatus comprises: (A) an input terminal for receiving the frame of the encoded digital audio signal; and (B) a processor for:(1) examining the encoded digital audio signal of the frame in a single pass to decode the encoded audio data for each audio block in order by block, wherein the decoding of each respective audio block comprises:(a) if the respective audio block is the first audio block in the frame:(i) obtaining all hybrid transform coefficients of a respective channel for the frame from the encoded audio data in the first audio block, and(ii) applying an inverse secondary transform to the hybrid transform coefficients to obtain inverse secondary transform coefficients, and(b) obtaining primary transform coefficients from the inverse secondary transform coefficients for the respective channel in the respective audio block; and(2) applying an inverse primary transform to the primary transform coefficients to generate an output signal representing the respective channel in the respective audio block.</p></layer>
<layer id = "layer589"><p><b>US8725503B2:Forward time-domain aliasing cancellation with application in weighted or original signal domain</b><br>A plurality of functions to configure a unit of a storage volume is maintained, wherein each of the plurality of functions, in response to being applied to the unit of the storage volume, configures the unit of the storage volume differently. Statistics are computed on growth rate of data and access characteristics of the data stored in the unit of the storage volume. A determination is made as to which of the plurality of functions to apply to the unit of the storage volume, based on the computed statistics.<br><b>Independant Claims</b><br>1) A method for forward cancelling time-domain aliasing in a coded signal received in a bitstream at a decoder, comprising: receiving in the bitstream at the decoder, from a coder, additional information related to correction of the time-domain aliasing in the coded signal, wherein the additional information is representative of a forward aliasing cancellation (FAC) correction signal related to a difference signal based on a difference between a signal to be coded upon transition from a first coding mode to a second coding mode and a synthesis signal obtained using the first coding mode; and in the decoder, cancelling the time-domain aliasing in the coded signal in response to the additional information.<br>10) A method for forward cancelling time-domain aliasing in a coded signal for transmission from a coder to a decoder, comprising: in the coder, calculating additional information related to correction of the time-domain aliasing in the coded signal, wherein calculating the additional information comprises producing a forward aliasing cancellation (FAC) correction signal related to a difference signal based on a difference between a signal to be coded upon transition from a first coding mode to a second coding mode and a synthesis signal obtained using the first coding mode; and sending in a bitstream, from the coder to the decoder, the additional information related to the correction of the time-domain aliasing in the coded signal.<br>18) A device for forward cancelling time-domain aliasing in a coded signal received in a bitstream, comprising: a receiver, from a bitstream from a coder, of additional information related to correction of the time-domain aliasing in the coded signal, wherein the additional information comprises a forward aliasing cancellation (FAC) correction signal related to a difference signal based on a difference between a signal to be coded upon transition from a first coding mode to a second coding mode and a synthesis signal obtained using the first coding mode; and a canceller of the time-domain aliasing in the coded signal in response to the additional information.<br>27) A device for forward time-domain aliasing cancellation in a coded signal for transmission to a decoder, comprising: a calculator of additional information related to correction of the time-domain aliasing in the coded signal, wherein the calculator of the additional information comprises a producer of a forward aliasing cancellation (FAC) correction signal related to a difference signal based on a difference between a signal to be coded upon transition from a first coding mode to a second coding mode and a synthesis signal obtained using the first coding mode; and a transmitter for sending in the bitstream, to a decoder, the additional information related to the correction of the time-domain aliasing in the coded signal.</p></layer>
<layer id = "layer590"><p><b>US8438014B2:Separating speech waveforms into periodic and aperiodic components, using artificial waveform generated from pitch marks</b><br>According to one embodiment, on a substrate, a resist layer is laminated on an upper side of a pattern formation layer on which a desired pattern is formed. A diffraction pattern that diffracts exposure light irradiated on the substrate is formed further on the upper side than the resist layer. Overall exposure is performed from above the diffraction pattern using a deformed light having illumination light source shape determined according to the desired pattern. Diffracted light diffracted on the diffraction pattern by the exposure is irradiated on the resist layer.<br><b>Independant Claims</b><br>9) The speech processing device according to claim wherein the analysis window used for windowing by the extractor is a Hanning window having a window width of 2 to 10 times a fundamental period.<br>1) A speech processing device comprising: an input unit configured to input a speech signal; a marking unit configured to assign a pitch mark representing a representative point in a fundamental period to the speech signal for each fundamental period; an extractor configured to window a part of the speech signal and extract a partial waveform that is a speech waveform of the windowed part; a calculator configured to perform frequency analysis of the partial waveform to calculate a frequency spectrum; an estimator configured to generate an artificial waveform that is a waveform according to an interval between the pitch marks for each harmonic component having a frequency that is a predetermined multiple of a fundamental frequency of the speech signal and configured to estimate harmonic spectral features representing characteristics of the frequency spectrum of the harmonic component from each of the artificial waveforms; and a separator configured to separate the partial waveform into a periodic component produced from periodic vocal-fold vibration as an acoustic source and an aperiodic component produced from aperiodic acoustic sources other than the vocal-fold vibration by using the respective harmonic spectral features and the frequency spectrum of the partial waveform.<br>11) A speech processing method comprising: inputting a speech signal; assigning a pitch mark representing a representative point in a fundamental period to the speech signal for each fundamental period; windowing a part of the speech signal and extract a partial waveform that is a speech waveform of the windowed part; performing frequency analysis of the partial waveform to calculate a frequency spectrum; generating an artificial waveform that is a waveform according to an interval between the pitch marks for each harmonic component having a frequency that is a predetermined multiple of a fundamental frequency of the speech signal; estimating harmonic spectral features representing characteristics of the frequency spectrum of the harmonic component from each of the artificial waveforms; and separating the partial waveform into a periodic component produced from periodic vocal-fold vibration as an acoustic source and an aperiodic component produced from aperiodic acoustic sources other than the vocal-fold vibration by using the respective harmonic spectral features and the frequency spectrum of the partial waveform.<br>12) A computer program product comprising a computer-readable medium having programmed instructions, wherein the instructions, when executed by a computer, cause the computer to execute: inputting a speech signal; assigning a pitch mark representing a representative point in a fundamental period to the speech signal for each fundamental period; windowing a part of the speech signal and extract a partial waveform that is a speech waveform of the windowed part; performing frequency analysis of the partial waveform to calculate a frequency spectrum; generating an artificial waveform that is a waveform according to an interval between the pitch marks for each harmonic component having a frequency that is a predetermined multiple of a fundamental frequency of the speech signal; estimating harmonic spectral features representing characteristics of the frequency spectrum of the harmonic component from each of the artificial waveforms; and separating the partial waveform into a periodic component produced from periodic vocal-fold vibration as an acoustic source and an aperiodic component produced from aperiodic acoustic sources other than the vocal-fold vibration by using the respective harmonic spectral features and the frequency spectrum of the partial waveform.</p></layer>
<layer id = "layer591"><p><b>US7885810B1:Acoustic signal enhancement method and apparatus</b><br>A process of treating a lignocellulosic material includes a pre-extraction step in which hemicellulose is extracted from the lignocellulosic material. In one embodiment, the pre-extraction step involves contacting the lignocellulosic material with an aqueous solution under conditions that release acidic material from the lignocellulosic material into the aqueous solution, and the aqueous solution includes a basic material that at least partly neutralizes the acidic material so that the aqueous solution at the end of the pre-extraction step has a pH within a range of from 4.5 to 11. The process also includes a pulping step, after the pre-extraction step, in which the lignocellulosic material is separated into pulp. The process further includes an adsorption step, after the pulping step, in which hemicellulose is adsorbed on the pulp.<br><b>Independant Claims</b><br>1) An acoustic signal enhancement method comprising the steps of: applying a spectral transformation on a frame derived from an input acoustic signal to generate a spectral representation of the frame; estimating an a posteriori signal-to-noise ratio (SNR) and an a priori SNR of the frame; determining an a priori SNR limit for the frame; limiting the a priori SNR with the a priori SNR limit to generate a final a priori SNR for the frame; determining a spectral gain for the frame according to the a posteriori SNR and the final a priori SNR; and applying the spectral gain on the spectral representation of the frame so as to generate an enhanced spectral representation of the frame; wherein the a priori SNR limit is a function of frequency.<br>17) An acoustic signal enhancement method comprising the steps of: applying a spectral transformation on a frame derived from an input acoustic signal to generate a spectral representation of the frame; estimating an a posteriori signal-to-noise ratio (SNR) and an a priori SNR of the frame; determining a spectral gain for the frame according to the a posteriori SNR and the a priori SNR; determining a spectral gain limit for the frame; limiting the spectral gain with the spectral gain limit to generate a final spectral gain for the frame; and applying the final spectral gain on the spectral representation of the frame to generate an enhanced spectral representation of the frame; wherein the spectral gain limit is a function of frequency.<br>33) An acoustic signal enhancement apparatus comprising: a Fourier transform unit for applying a spectral transformation on a frame derived from an input acoustic signal to generate a spectral representation of the frame; a noise estimation unit coupled to the Fourier transform unit, for estimating a noise spectrum of the frame; an a posteriori signal-to-noise ratio (SNR) estimation unit coupled to the Fourier transform unit and the noise estimation unit, for estimating an a posteriori SNR of the frame; an a priori SNR estimation unit coupled to the noise estimation unit and the a posteriori SNR estimation unit, for estimating an a priori SNR of the frame; an a priori SNR limit determine unit for determining an a priori SNR limit for the frame; a limiter coupled to the a priori SNR estimation unit and the a priori SNR limit determine unit, for limiting the a priori SNR with the a priori SNR limit to generate a final a priori SNR for the frame; a spectral gain calculation module coupled to the a posteriori SNR estimation unit, the a priori SNR estimation unit, and the limiter, for determining a spectral gain for the frame according to the a posteriori SNR and the final a priori SNR; and a multiplication unit coupled to the Fourier transform unit and the spectral gain calculation module, for applying the spectral gain on the spectral representation of the frame so as to generate an enhanced spectral representation of the frame; wherein the a priori SNR limit is a function of frequency.<br>36) An acoustic signal enhancement apparatus comprising: a Fourier transform unit for applying a spectral transformation on a frame derived from an input acoustic signal to generate a spectral representation of the frame; a noise estimation unit coupled to the Fourier transform unit, for estimating a noise spectrum of the frame; an a posteriori signal-to-noise ratio (SNR) estimation unit coupled to the Fourier transform unit and the noise estimation unit, for estimating an a posteriori SNR of the frame; an a priori SNR estimation module coupled to the noise estimation unit and the a posteriori SNR estimation unit, for estimating an a priori SNR of the frame; a spectral gain calculation unit coupled to the a posteriori SNR estimation unit and the a priori SNR estimation module, for determining a preliminary spectral gain for the frame according to the a posteriori SNR and the a priori SNR; a perceptual gain limiter coupled to the Fourier transform unit, the spectral gain calculation unit, and the noise estimation unit, for determining a spectral gain limit for the frame according to the spectral representation and the noise spectrum of the frame, and for limiting the preliminary spectral gain with the spectral gain limit to generate a spectral gain for the frame; and a multiplication unit coupled to the Fourier transform unit and the perceptual gain limiter for applying the spectral gain on the spectral representation of the frame so as to generate an enhanced spectral representation of the frame; wherein the spectral gain limit is a function of frequency.<br>38) An acoustic signal enhancement apparatus comprising: a Fourier transform unit for applying a spectral transformation on a frame derived from an input acoustic signal to generate a spectral representation of the frame; a noise estimation unit coupled to the Fourier transform unit, for estimating a noise spectrum of the frame; an a posteriori signal-to-noise ratio (SNR) estimation unit coupled to the Fourier transform unit and the noise estimation unit, for estimating an a posteriori SNR of the frame; an a priori SNR estimation module coupled to the noise estimation unit and the a posteriori SNR estimation unit, for estimating an a priori SNR of the frame; a spectral gain calculation unit coupled to the a posteriori SNR estimation unit and the a priori SNR estimation module, for determining a preliminary spectral gain for the frame according to the a posteriori SNR and the a priori SNR; and a signal classifier coupled to the Fourier transform unit, for categorizing the frame; and an adaptive gain limiter coupled to the spectral gain calculation unit and the signal classifier, for determining a spectral gain limit for the frame according to a categorization result of the frame, and for limiting the preliminary spectral gain with the spectral gain limit to generate a spectral gain for the frame; and a multiplication unit coupled to the adaptive gain limiter and the Fourier transform unit, for applying the spectral gain on the spectral representation of the frame so as to generate an enhanced spectral representation of the frame; wherein the spectral gain limit is a function of frequency.</p></layer>
<layer id = "layer592"><p><b>US10299040B2:System for increasing perceived loudness of speakers</b><br><b>Independant Claims</b><br>11) A system limiting an audio signal, the system comprising:a limiter that receives an input audio signal and that produces a limited audio signal from the input audio signal; anda distortion control module that uses a hardware processor to:apply a clipping reduction to the limited audio signal to increase signal energy in the limited audio signal compared to the input audio signal, by at least mapping the limited audio signal into a data structure to produce an output signal, the data structure comprising values representing a sum of portions of sine waves; andoutput the output signal to a speaker.<br>1) A method of limiting an audio signal, the method comprising:under control of a hardware processor,receiving an input audio signal;applying a limiter to the input audio signal to produce a limited audio signal; andapplying a clipping reduction to the limited audio signal to increase signal energy in the limited audio signal compared to the input audio signal, the clipping reduction comprising mapping the limited audio signal into a data structure to produce an output signal, the data structure comprising values representing a sum of sine waves; andoutputting the output signal to a speaker.</p></layer>
<layer id = "layer593"><p><b>US8204742B2:System for processing an audio signal to enhance speech intelligibility</b><br>A photosensitive resin composition comprising a dye (A), a dispersant (B), a solvent (C), and a photosensitive binder component (D), the dye (A) being dispersed in the solvent (C) by the dispersant (B), wherein the dye (A) is a dye having a sulfonic acid group; the dispersant (B) is a block polymer that contains a block portion comprising a repeating unit having a tertiary amine; the solvent (C) is a solvent having a solubility of the dye (A) of 0.2 (g/100 g solvent) or less at 23° C.; and a micelle is formed by an acid-base interaction between the tertiary amine of the dispersant (B) and the sulfonic acid group of the dye (A).<br><b>Independant Claims</b><br>1) A system for automatically adjusting a voice intelligibility enhancement applied to an audio signal, the system comprising: an enhancement module configured to receive an input voice signal comprising formants and to apply an audio enhancement to the input voice signal to provide an enhanced voice signal, the audio enhancement configured to emphasize one or more of the formants in the input voice signal; an enhancement controller comprising one or more processors, the enhancement controller configured to adjust an amount of the audio enhancement applied by the enhancement module based at least partly on an amount of detected environmental noise; an output gain controller configured to: adjust an overall gain of the enhanced voice signal based at least partly on the amount of environmental noise and the input voice signal, and apply the overall gain to the enhanced voice signal to produce an amplified voice signal; and a distortion control module configured to reduce clipping in the amplified voice signal by at least mapping one or more samples of the amplified voice signal to one or more values stored in a sum of sines table, the sum of sines table being generated from a sum of lower-order sine harmonics.</p></layer>
<layer id = "layer594"><p><b>US8484020B2:Determining an upperband signal from a narrowband signal</b><br>A system includes a management module transferring sectors between an interface or a memory and ports. The management module transfers a first portion of a first sector to or from a first port while transferring to or from a second port a second portion of the first sector or a first portion of a second sector. A first channel module reads from or writes to a first surface of a disk via a first head by transferring the first portion of the first sector to or from a first amplifier module. A second channel module, while the first channel module transfers the first portion of the first sector to or from the first amplifier module, reads from or writes to a second surface of the disk via a second head by transferring to or from a second amplifier module the second portion or the first portion of the second sector.<br><b>Independant Claims</b><br>27) A computer-program product for determining an upperband speech signal from a narrowband speech signal where the upperband speech spans a higher range of frequencies than the narrowband speech, the computer-program product comprising a non-transitory computer-readable medium having instructions thereon, the instructions comprising: code for determining a list of narrowband line spectral frequencies (LSFs) using Linear Predictive Coding (LPC) analysis based on the narrowband speech signal; code for determining a first pair of adjacent narrowband LSFs that have a lower difference between them than every other pair of adjacent narrowband LSFs in the list; code for determining a first feature that is a mean of the first pair of adjacent narrowband LSFs; and code for determining upperband LSFs based on at least the first feature using codebook mapping.<br>1) A method for determining an upperband speech signal from a narrowband speech signal where the upperband speech spans a higher range of frequencies than the narrowband speech, comprising: determining a list of narrowband line spectral frequencies (LSFs) using Linear Predictive Coding (LPC) analysis based on the narrowband speech signal; determining a first pair of adjacent narrowband LSFs that have a lower difference between them than every other pair of adjacent narrowband LSFs in the list; determining a first feature that is a mean of the first pair of adjacent narrowband LSFs; and determining upperband LSFs based on at least the first feature using codebook mapping.<br>11) An apparatus for determining an upperband speech signal from a narrowband speech signal where the upperband speech spans a higher range of frequencies than the narrowband speech, comprising: a processor; memory in electronic communication with the processor; instructions stored in the memory, the instructions being executable by the processor to: determine a list of narrowband line spectral frequencies (LSFs) using Linear Predictive Coding (LPC) analysis based on the narrowband speech signal; determine a first pair of adjacent narrowband LSFs that have a lower difference between them than every other pair of adjacent narrowband LSFs in the list; determine a first feature that is a mean of the first pair of adjacent narrowband LSFs; and determine upperband LSFs based on at least the first feature using codebook mapping.<br>21) An apparatus for determining an upperband speech signal from a narrowband speech signal where the upperband speech spans a higher range of frequencies than the narrowband speech, comprising: a processor; means for determining a list of narrowband line spectral frequencies (LSFs) using Linear Predictive Coding (LPC) analysis based on the narrowband speech signal; means for determining a first pair of adjacent narrowband LSFs that have a lower difference between them than every other pair of adjacent narrowband LSFs in the list; means for determining a first feature that is a mean of the first pair of adjacent narrowband LSFs; and means for determining upperband LSFs based on at least the first feature using codebook mapping.</p></layer>
<layer id = "layer595"><p><b>US9117458B2:Apparatus for processing an audio signal and method thereof</b><br><b>Independant Claims</b><br>1) A method for decoding an audio signal, the method comprising: receiving, by an audio processing apparatus, spectral data including a current block having a spectral hole, and substitution type information indicating whether to apply a shape prediction scheme to the current block, based on the substitution type information indicating that the shape prediction scheme is applied to the current block, receiving lag information indicating an interval between spectral coefficients of the current block and a predictive shape vector of the shape prediction scheme, and wherein the substitution type information is determined based on a correlation value between spectral coefficients of the current block and the predictive shape vector, the correlation value is estimated by using a candidate lag value (dk), and based on the correlation value being greater than or equal to a predetermined value, the shape prediction scheme is applied to the current block having the spectral hole; obtaining spectral coefficients by substituting for spectral hole included in the current block using the lag information; and decoding the spectral coefficients to output the audio signal.<br>10) An apparatus configured to decode an audio signal, the apparatus comprising: an audio signal processor that includes: a substitution type extracting unit configured to receive spectral data including a current block having a spectral hole, and substitution type information indicating whether to apply a shape prediction scheme to the current block; a lag extracting unit configured to, based on the substitution type information indicating that the shape prediction scheme is applied to the current block, receive lag information indicating an interval between spectral coefficients of the current block and a predictive shape vector of the shape prediction scheme, wherein the substitution type information is determined based on a correlation value between spectral coefficients of the current block and the predictive shape vector, the correlation value is estimated by using a candidate lag value (dk), and based on the correlation value being equal to or greater than a predetermined value, the shape prediction scheme is applied to the current block having the spectral hole; and a shape substitution unit configured to obtain spectral coefficients by substituting for spectral hole included in the current block using lag information; and an audio signal decoder configured to decode the spectral coefficients to output the audio signal.<br>17) An apparatus configured to encode an audio signal, the apparatus comprising: a hole detecting unit configured to receive spectral coefficients of an input audio signal, and to detect spectral hole by de-quantizing the spectral coefficient; a substitution type selecting unit configured to: estimate at least one correlation between at least one candidate shape vector and a current band covering the spectral hole, wherein a correlation value is estimated by using a candidate lag value (dk); and determine substitution type information indicating whether to apply a shape prediction scheme to the current band based on the at least one correlation, wherein based on the estimated correlation value being equal to or greater than a predetermined value, the shape prediction scheme is applied to the current block covering the spectral hole; a shape prediction unit configured to, based on the shape prediction scheme being applied to the current band, determine prediction mode information and lag information, based on the at least one correlation; and a multiplexing unit configured to transmit the substitution type information, the prediction mode information and the lag information, wherein: the prediction mode information indicates whether a prediction mode of the shape prediction scheme is intra-frame mode or inter-frame mode, and the lag information indicates an interval between spectral coefficients of the current block and the predictive shape vector of a current frame or a previous frame.<br>9) A method for encoding an audio signal, the method comprising: receiving, by an audio processing apparatus, spectral coefficients of an input audio signal; detecting spectral hole by de-quantizing the spectral coefficient; estimating at least one correlation between at least one candidate shape vector and a current block covering the spectral hole, wherein a correlation value is estimated by using a candidate lag value (dk); determining substitution type information indicating whether to apply a shape prediction scheme to the current block based on the at least one correlation; wherein based on the estimated correlation value being equal to or greater than a predetermined value, the shape prediction scheme is applied to the current block covering the spectral hole, based on the shape prediction scheme being applied to the current block, determining prediction mode information and lag information, based on the at least one correlation; and, multiplexing, by a multiplexer, the substitution type information, the prediction mode information and the lag information to form a bitstream, wherein: the prediction mode information indicates whether a prediction mode of the shape prediction scheme is intra-frame mode or inter-frame mode, and the lag information indicates an interval between spectral coefficients of the current block and the predictive shape vector of a current frame or a previous frame.</p></layer>
<layer id = "layer596"><p><b>US9324337B2:Method and system for dialog enhancement</b><br><b>Independant Claims</b><br>1) A method for enhancing dialog determined by an audio input signal, said method including the steps of: (a) analyzing the input signal to generate filter control values without use of feedback; and (b) providing at least one of the control values to a peaking filter, filtering a speech channel determined by the input signal in the peaking filter in a manner steered by said at least one of the control values to generate a dialog-enhanced speech channel, and attenuating non-speech channels determined by the input signal in ducking circuitry steered by at least a subset of the control values to generate attenuated non-speech channels, where the control values are distinct from the speech channel, the control values are distinct from the non-speech channels, the peaking filter is distinct from the ducking circuitry, the peaking filter is coupled and configured to filter the speech channel but not the non-speech channels, the ducking circuitry is coupled and configured to attenuate the non-speech channels but not the speech channel, the peaking filter is configured to emphasize frequency components of the speech channel in a frequency range critical to intelligibility of speech, relative to frequency components of the speech channel outside the frequency range, and said frequency range has a center frequency, wherein the step of attenuating the non-speech channels includes reducing gain application to the non-speech channels in response to a change in said at least a subset of the control values indicative of increase of power of the speech channel relative to combined power of the non-speech channels, and the step of filtering the speech channel includes applying more gain to the frequency components of the speech channel at the center frequency in response to a change in said at least one of the control values indicative of an increase in power of the speech channel relative to power of at least one of the non-speech channels.<br>14) A system for enhancing dialog determined by an audio input signal, including: an analysis subsystem coupled and configured to analyze the input signal to generate filter control values without use of feedback; and a filtering subsystem coupled to the analysis subsystem and including a peaking filter and ducking circuitry, wherein the peaking filter is coupled to receive at least one of the control values and configured to filter a speech channel determined by the input signal, while being steered by said at least one of the control values, to generate a dialog-enhanced speech channel, and the ducking circuitry is configured to attenuate non-speech channels determined by the input signal, while being steered by at least a subset of the control values, to generate attenuated non-speech channels, where the control values are distinct from the speech channel, the control values are distinct from the non-speech channels, the peaking filter is distinct from the ducking circuitry, the peaking filter is coupled and configured to filter the speech channel but not the non-speech channels, including by emphasizing frequency components of the speech channel in a frequency range critical to intelligibility of speech relative to frequency components of the speech channel outside the frequency range, where said frequency range has a center frequency, the ducking circuitry is coupled and configured to attenuate the non-speech channels but not the speech channel, including by reducing gain application to the non-speech channels in response to a change in said at least a subset of the control values indicative of an increase, within limits, in power of the speech channel relative to combined power of the non-speech channels, and the peaking filter is configured to apply increased gain to frequency components of the speech channel having the center frequency in response to a change in said at least one of the control values indicating an increase in power of the speech channel relative to power of at least one of the non-speech channels.</p></layer>
<layer id = "layer597"><p><b>US8856011B2:Excitation signal bandwidth extension</b><br>In a method for manufacturing compact keypad, a first molding die with bottom surface of smooth face, matted face or patterned layer is prepared. Colloid is injected into the first molding die and a first carrier covers the surface of the colloid. A rolling wheel presses the first carrier and the colloid evenly into the first molding die. The colloid is cured by UV light to form a keypad layer attached on the first carrier. A background color layer, a functional color layer and a textual color layer are formed on the first carrier. A second carrier is prepared and a reflection layer is printed on the surface of the second carrier. The second carrier and silicon rubber are placed into a second molding die and thermally pressed therein to form a resilient layer. The resilient layer is adhered with the keypad layer to form the keypad panel.<br><b>Independant Claims</b><br>1) A method by an apparatus for generating a high band extension of a low band excitation signal defined by parameters representing a CELP encoded audio signal, the method comprising the steps of: upsampling a low band fixed codebook vector (uFCB) and a low band adaptive codebook vector to a predetermined sampling frequency; determining a modulation frequency from an estimated measure representing a fundamental frequency of the audio signal; modulating the upsampled low band adaptive codebook vector with the determined modulation frequency to form a frequency shifted adaptive codebook vector; estimating a compression factor; attenuating the frequency shifted adaptive codebook vector and the upsampled fixed codebook vector based on the estimated compression factor; and forming a high-pass filtered sum of the attenuated frequency shifted adaptive codebook vector and the attenuated upsampled fixed codebook vector.<br>10) An apparatus for generating a high band extension of a low band excitation signal defined by parameters representing a CELP encoded audio signal, said apparatus comprising: upsamplers configured to upsample a low band fixed codebook vector and a low band adaptive codebook vector to a predetermined sampling frequency; a frequency shift estimator configured to determine a modulation frequency (Ω) from an estimated measure representing a fundamental frequency of the audio signal; a modulator configured to modulate the upsampled low band adaptive codebook vector with the determined modulation frequency to form a frequency shifted adaptive codebook vector; a compression factor estimator configured to estimate a compression factor; a compressor configured to attenuate the frequency shifted adaptive codebook vector and the upsampled fixed codebook vector based on the estimated compression factor; and a combiner configured to form a high-pass filtered sum of the attenuated frequency shifted adaptive codebook vector and the attenuated upsampled fixed codebook vector.</p></layer>
<layer id = "layer598"><p><b>US8929568B2:Bandwidth extension of a low band audio signal</b><br><b>Independant Claims</b><br>1) A method by an apparatus for estimating a high band extension of a low band audio signal, the method comprising: extracting a set of features of the low band audio signal; mapping the extracted set of features of the low band audio signal to at least one high band parameter using generalized additive modeling, wherein the mapping is performed responsive to a sum of sigmoid functions of the extracted set of features of the low band audio signal; frequency shifting a copy of the low band audio signal into the high band; and controlling an envelope of the frequency shifted copy of the low band audio signal in response to the at least one high band parameter.<br>8) An apparatus for estimating a high band extension (ŝHB) of a low band audio signal (ŝLB), the apparatus comprising: a feature extraction block configured to extract a set of features of the low band audio signal; and a mapping block that comprises: a generalized additive model mapper configured to map the extracted set of features of the low band audio signal to at least one high band parameter using generalized additive modeling, wherein the generalized additive model mapper is configured to perform the mapping responsive to a sum of sigmoid functions of the extracted features set of features of the low band audio signal; a frequency shifter configured to frequency shift a copy of the low band audio signal into the high band; and an envelope controller configured to control an envelope of the frequency shifted copy in response to the at least one high band parameter.</p></layer>
<layer id = "layer599"><p><b>US9055374B2:Method and system for determining an auditory pattern of an audio segment</b><br><b>Independant Claims</b><br>1) A computer-implemented method for determining an auditory pattern associated with an audio segment, comprising: receiving, by a processor, a first plurality of frequency components that describe the audio segment in terms of frequency and magnitude, wherein each of the first plurality of frequency components corresponds to one of a plurality of detector locations on an auditory scale; determining an average intensity pattern function at each of a first plurality of detector locations on the auditory scale, wherein the average intensity pattern function is determined using at least one of the first plurality of frequency components; determining a second plurality of frequency components, wherein the second plurality of frequency components is determined based on at least one of the average intensity pattern function and the first plurality of frequency components, wherein locations of the second plurality of frequency components are time-varying; determining a detector location subset based on the average intensity pattern function; and determining an auditory pattern based on at least one of the second plurality of frequency subset components and the detector location subset.<br>16) A computer-implemented method for determining an auditory pattern associated with an audio segment, comprising: receiving, by a processor, a first plurality of frequency components that describe the audio segment in terms of frequency and magnitude, wherein each of the first plurality of frequency components corresponds to one of a plurality of detector locations on an auditory scale; determining an average intensity pattern function at each of a first plurality of detector locations on the auditory scale, wherein the average intensity pattern function is determined using at least one of the first plurality of frequency components determining a second plurality of frequency components, wherein the second plurality of frequency components is determined based on at least one of the average intensity pattern function and the first plurality of frequency components, wherein locations of the second plurality of frequency components are time-varying; determining a plurality of tonal bands in the audio segment, wherein each tonal band comprises a particular range of detector locations of the first plurality of detector locations; for the each of the plurality of tonal bands, selecting a corresponding strongest frequency component from the first plurality of frequency components that corresponds to a location within the particular range of detector locations corresponding to the each of the plurality of tonal bands; determining a plurality of non-tonal bands in the audio segment; for each of the plurality of non-tonal bands, dividing the each of the plurality of non-tonal bands into a plurality of sub-bands, and for each of the plurality of sub-bands determining a corresponding combined frequency component that is representative of a combined sum of intensities of the first plurality of frequency components that are in the corresponding sub-band; and determining an excitation pattern based on the corresponding strongest frequency components and the corresponding combined frequency components.<br>17) A computer program product, comprising a computer-usable medium having a computer-readable program code embodied therein, the computer-readable program code adapted to be executed on a processor to implement a method for determining an excitation pattern associated with an audio segment, the method comprising: receiving, by the processor, a first plurality of frequency components that describe the audio segment in terms of frequency and magnitude, wherein each of the first plurality of frequency components corresponds to one of a plurality of detector locations on an auditory scale; determining, an average intensity pattern function at each of a first plurality of detector locations on the auditory scale, wherein the average intensity pattern function is determined using at least one of the first plurality of frequency components; determining a second plurality of frequency components, wherein the second plurality of frequency components is determined based on at least one of the average intensity pattern function and the first plurality of frequency components, wherein locations of the second plurality of frequency components are time-varying; determining a detector location subset based on the average intensity pattern function; and determining the excitation pattern based on at least one of the second plurality of frequency components and the detector location subset.<br>19) A processing device, comprising: an input port; and a control system comprising a processor coupled to the input port, the control system adapted to: receive a first plurality of frequency components that describe an audio segment in terms of frequency and magnitude, wherein each of the first plurality of frequency components corresponds to one of a plurality of detector locations on an auditory scale determine an average intensity pattern function at each of a first plurality of detector locations on the auditory scale, wherein the average intensity pattern function is determined using at least one of the first plurality of frequency components; determine a second plurality of frequency components, wherein the second plurality of frequency components is determined based on at least one of the average intensity pattern function and the first plurality of frequency components, wherein locations of the second plurality of frequency components are time-varying; determine a detector location subset based on the average intensity pattern function; and determine an excitation pattern based on at least one of the second plurality of frequency components and the detector location subset.</p></layer>
<layer id = "layer600"><p><b>US8595019B2:Audio coder/decoder with predictive coding of synthesis filter and critically-sampled time aliasing of prediction domain frames</b><br>An electronic device includes: a variable resistance element having a first electrode, a variable resistance layer, and a second electrode which are sequentially stacked therein; a spacer formed on the sidewall of the variable resistance element; and a conductive line covering the variable resistance element including the spacer.<br><b>Independant Claims</b><br>20) A method for decoding encoded frames to obtain frames of a sampled audio signal, wherein a frame comprises a number of time domain audio samples, comprising decoding, by a redundancy retrieving decoder, the encoded frames to obtain an information on coefficients for a synthesis filter and prediction domain frame spectra; transforming, by the inverse time-aliasing introducing transformer, the prediction domain frame spectra to the time domain to obtain overlapping prediction domain frames from consecutive prediction domain frame spectra, wherein the transforming comprises: converting prediction domain frame spectra to converted overlapping prediction domain frames, applying a windowing function, by a windowing filter, to the converted overlapping prediction domain frames to obtain the overlapping prediction domain frames, detecting an event, and providing a window sequence information if the event is detected to the windowing filter, wherein the windowing filter is adapted for applying the windowing function according to the window sequence information, and wherein the window sequence information comprises a first zero part, a second bypass part and a third zero part; combining, by an overlap/add combiner, overlapping prediction domain frames to obtain a prediction domain frame in a critically sampled way; and determining, by a predictive analysis stage, the frame based on the coefficients and the prediction domain frame, wherein at least one of the redundancy retrieving decoder, the inverse time-aliasing introducing transformer, the overlap/add combiner, and the predictive analysis stage comprises a hardware implementation.<br>1) An audio encoding apparatus adapted for encoding frames of a sampled audio signal to obtain encoded frames, wherein a frame comprises a number of time domain audio samples, comprising: a predictive coding analysis stage for determining information on coefficients of a synthesis filter and a prediction domain frame based on a frame of audio samples; a time-aliasing introducing transformer for transforming overlapping prediction domain frames to a frequency domain to obtain prediction domain frame spectra, wherein the time-aliasing introducing transformer is adapted for transforming the overlapping prediction domain frames in a critically-sampled way; and a redundancy reducing encoder for encoding the prediction domain frame spectra to obtain the encoded frames based on the coefficients and encoded prediction domain frame spectra, a codebook encoder for encoding the prediction domain frames based on a predetermined codebook to obtain a codebook encoded prediction domain frame; and a decider for deciding whether to use a codebook encoded prediction domain frame or an encoded prediction domain frame to obtain a finally encoded frame based on a coding efficiency measure. wherein at least one of the predictive coding analysis stage, the time-aliasing introducing transformer, the redundancy reducing encoder, the codebook encoder, and the decider comprises a hardware implementation.<br>21) A non-transitory storage medium having stored thereon a computer program product for performing the method for decoding encoded frames to obtain frames of a sampled audio signal, wherein a frame comprises a number of time domain audio samples, the method comprising decoding the encoded frames to obtain an information on coefficients for a synthesis filter and prediction domain frame spectra; transforming the prediction domain frame spectra to the time domain to obtain overlapping prediction domain frames from consecutive prediction domain frame spectra, wherein the transforming comprises converting prediction domain frame spectra to converted overlapping prediction domain frames, applying a windowing function, by a windowing filter, to the converted overlapping prediction domain frames to obtain the overlapping prediction domain frames, detecting an event, and providing a window sequence information if the event is detected to the windowing filter, wherein the windowing filter is adapted for applying the windowing function according to the window sequence information, and wherein the window sequence information comprises a first zero part, a second bypass part and a third zero part; combining overlapping prediction domain frames to obtain a prediction domain frame in a critically sampled way; and determining the frame based on the coefficients and the prediction domain frame, when the computer program runs on a computer or processor.<br>12) A method for encoding frames of a sampled audio signal to obtain encoded frames, wherein a frame comprises a number of time domain audio samples, comprising determining, by a predictive coding analysis stage, information on coefficients for a synthesis filter based on a frame of audio samples and determining a prediction domain frame based on the frame of audio samples; transforming, by a time-aliasing introducing transformer, overlapping prediction domain frames to a frequency domain to obtain prediction domain frame spectra in a critically-sampled way introducing time aliasing; encoding, by a redundancy reducing encoder, the prediction domain frame spectra to obtain the encoded frames based on the coefficients and encoded prediction domain frame spectra; encoding, by a codebook encoder, the prediction domain frames based on a predetermined codebook to obtain a codebook encoded prediction domain frame; and deciding, by a decider, whether to use a codebook encoded prediction domain frame or an encoded prediction domain frame to obtain a finally encoded frame based on a coding efficiency measure wherein at least one of the predictive coding analysis stage, the time-aliasing introducing transformer, the redundancy reducing encoder, the codebook encoder, and the decider comprises a hardware implementation.<br>13) A non-transitory storage medium having stored thereon a computer program comprising a program code for performing the method for encoding frames of a sampled audio signal to obtain encoded frames, wherein a frame comprises a number of time domain audio samples, the method comprising determining information on coefficients for a synthesis filter based on a frame of audio samples; determining a prediction domain frame based on the frame of audio samples; transforming overlapping prediction domain frames to the frequency domain to obtain prediction domain frame spectra in a critically-sampled way introducing time aliasing; and encoding the prediction domain frame spectra to obtain the encoded frames based on the coefficients and the encoded prediction domain frame spectra, encoding the prediction domain frames based on a predetermined codebook to obtain a codebook encoded prediction domain frame; and deciding whether to use a codebook encoded prediction domain frame or an encoded prediction domain frame to obtain a finally encoded frame based on a coding efficiency measure, when the program code runs on a computer or processor.<br>14) An audio decoding apparatus for decoding encoded frames to obtain frames of a sampled audio signal, wherein a frame comprises a number of time domain audio samples, comprising: a redundancy retrieving decoder for decoding the encoded frames to obtain an information on coefficients for a synthesis filter and prediction domain frame spectra; an inverse time-aliasing introducing transformer for transforming the prediction domain frame spectra to the time domain to obtain overlapping prediction domain frames, wherein the inverse time-aliasing introducing transformer is adapted for determining overlapping prediction domain frames from consecutive prediction domain frame spectra, wherein the inverse time-aliasing introducing transformer further comprises a converter for converting prediction domain frame spectra to converted overlapping prediction domain frames and a windowing filter for applying a windowing function to the converted overlapping prediction domain frames to obtain the overlapping prediction domain frames, wherein the inverse time-aliasing introducing transformer comprises a processor for detecting an event and for providing a window sequence information if the event is detected to the windowing filter and wherein the windowing filter is adapted for applying the windowing function according to the window sequence information, and wherein the window sequence information comprises a first zero part, a second bypass part and a third zero part; an overlap/add combiner for combining overlapping prediction domain frames to obtain a prediction domain frame in a critically-sampled way; and a predictive synthesis stage for determining the frames of audio samples based on the coefficients and the prediction domain frame, wherein at least one of the redundancy retrieving decoder, the inverse time-aliasing introducing transformer, the overlap/add combiner, and the predictive analysis stage comprises a hardware implementation.</p></layer>
<layer id = "layer601"><p><b>US20180261234A1:AUDIO SIGNAL CODING AND DECODING METHOD AND DEVICE</b><br><b>Independant Claims</b><br>12) A method, comprising: converting, by a mobile phone, sound into an analog audio signal; converting, by the mobile phone, the analog signal into an digital audio signal; dividing, by the mobile phone, a frequency band of the digital audio signal into a plurality of sub-bands, wherein each sub-band has an index respectively; quantizing, by the mobile phone, the sub-band envelope of each sub-band of the digital audio signal; determining, by the mobile phone, an index of a highest sub-band to be allocated bits according to the quantized sub-band envelope and a ratio factor, wherein the ratio factor is depend on bit rate information, and wherein the ratio factor is greater than 0 and less than 1; allocating, by the mobile phone, at least one bit for a sub-band having an index no greater than the index of the highest sub-band to be allocated bits; encoding, by the mobile phone, a spectrum coefficient of the sub-band having the index no greater than the index of the highest sub-band to be allocated bits with the allocated bits; and transmitting, by the mobile phone, the encoded spectrum coefficient.<br>1) A mobile phone, comprising: at least one microphone, configured to convert sound into an analog audio signal; an analog-digital converter, configured to convert the analog signal into an digital audio signal; a digital signal processor, configured to implement the following operations:dividing a frequency band of the digital audio signal into a plurality of sub-bands, wherein each sub-band has an index respectively;obtaining a sub-band envelope of each sub-band of the digital audio signal;quantizing the sub-band envelope of each sub-band of the digital audio signal;determining an index of a highest sub-band to be allocated bits according to the quantized sub-band envelope and a ratio factor, wherein the ratio factor is depend on bit rate information, and wherein the ratio factor is greater than 0 and less than 1;allocating at least one bit for a sub-band having an index no greater than the index of the highest sub-band to be allocated bits; andencoding a spectrum coefficient of the sub-band having the index no greater than the index of the highest sub-band to be allocated bits with the allocated bits; a transmitter, configured to transmit the encoded spectrum coefficient.</p></layer>
<layer id = "layer602"><p><b>US9084049B2:Automatic equalization using adaptive frequency-domain filtering and dynamic fast convolution</b><br><b>Independant Claims</b><br>1) A method for equalizing an audio signal, wherein the method comprises: receiving the audio signal; applying an adaptive filter to the audio signal to generate a filtered audio signal; driving an acoustic output transducer with the filtered audio signal to generate a sound field; generating a detection audio signal by detecting the sound field after propagating through an acoustic channel with an acoustic input transducer; obtaining a first frequency-domain representation from the detection audio signal that is a composite spectral magnitude response of the acoustic output transducer, the acoustic channel and the acoustic input transducer; applying a delay to the filtered audio signal to obtain a delayed filtered audio signal, wherein the delay includes an approximation of propagation delays of the sound field through the acoustic channel; obtaining a second frequency-domain representation from the delayed filtered audio signal; processing the first frequency-domain representation, the second frequency-domain representation, and a third frequency-domain representation from spectral components of a target spectral magnitude response to generate an estimated spectral magnitude response correction signal; obtaining an equalization-filter control signal from the estimated spectral magnitude response correction signal; and configuring adapting filter characteristics of the adaptive filter in response to the equalization-filter control signal.<br>10) An apparatus for equalizing an audio signal, wherein the apparatus comprises: means for receiving the audio signal; means for applying an adaptive filter to the audio signal to generate a filtered audio signal; means for driving an acoustic output transducer with the filtered audio signal to generate a sound field; means for generating a detection audio signal by detecting the sound field after propagating through an acoustic channel with an acoustic input transducer; means for obtaining a first frequency-domain representation from the detection audio signal that is a composite spectral magnitude response of the acoustic output transducer, the acoustic channel and the acoustic input transducer; means for applying a delay to the filtered audio signal to obtain a delayed filtered audio signal, wherein the delay includes an approximation of propagation delays of the sound field through the acoustic channel; means for obtaining a second frequency-domain representation from the delayed filtered audio signal; means for processing the first frequency-domain representation, the second frequency-domain representation, and a third frequency-domain representation from spectral components of a target spectral magnitude response to generate an estimated spectral magnitude response correction signal; means for obtaining an equalization-filter control signal from the estimated spectral magnitude response correction signal; and means for configuring filter characteristics of the adaptive filter in response to the equalization-filter control signal.<br>15) An apparatus for applying an equalization filter to an audio signal represented by samples, wherein the method comprises: (a) means for appending a segment of zero-valued samples to segments of audio signal samples in a sequence of segments to obtain a sequence of blocks of samples, each block of samples having a first half with audio signal samples and a second half with zero-valued samples; (b) means for configuring the equalization filter to have a first frequency-response characteristic in response to an equalization-filter control signal; (c) means for applying the equalization filter with the first frequency-response characteristic to a first block of samples in the sequence of blocks of samples to obtain a first filtered block of spectral components having a first half and a second half, wherein (1) the first half of the first filtered block represents application of the equalization filter to the first half of the first block of samples and includes convolution products, and (2) the second half of the first filtered block represents application of the equalization filter to the second half of the first block of samples and includes convolution products; (d) means for applying the equalization filter with the first frequency-response characteristic to a second block of samples that follows the first block of samples in the sequence of blocks of samples to obtain a second filtered block of spectral components having a first half and a second half, wherein (1) the first half of the second filtered block represents application of the equalization filter to the first half of the second block of samples and includes convolution products, and (2) the second half of the second filtered block represents application of the equalization filter to the second half of the second block of samples and includes convolution products; (e) means for combining the second half of the first filtered block with the first half of the second filtered block and applying a first half of a window function to obtain a first windowed block, wherein the window function has a first half and a second half and the second half follows the first half; (f) means for configuring the equalization filter to have a second frequency-response characteristic in response to an equalization-filter control signal; (g) means for applying the equalization filter with the second frequency-response characteristic to the first block of samples in the sequence of blocks of samples to obtain a third filtered block of spectral components having a first half and a second half, wherein (1) the first half of the third filtered block represents application of the equalization filter to the first half of the first block of samples and includes convolution products, and (2) the second half of the third filtered block represents application of the equalization filter to the second half of the first block of samples and includes convolution products; (h) means for applying the equalization filter with the second frequency-response characteristic to the second block of samples that follows the first block of samples in the sequence of blocks of samples to obtain a fourth filtered block of spectral components having a first half and a second half, wherein (1) the first half of the fourth filtered block represents application of the equalization filter to the first half of the second block of samples and includes convolution products, and (2) the second half of the fourth filtered block represents application of the equalization filter to the second half of the second block of samples and includes convolution products; (i) means for combining the second half of the third filtered block with the first half of the fourth filtered block and applying the second half of the window function to obtain a second windowed block; and (j) means for combining the first windowed block with the second windowed block to obtain an output block representing a transition in frequency response of filtering applied to the second segment of audio signal samples from the first frequency-response characteristic to the second frequency-response characteristic.<br>16) A non-transitory medium recording a program of instructions that is executed by a device to perform a method for equalizing an audio signal, wherein the method comprises: receiving the audio signal; applying an adaptive filter to the audio signal to generate a filtered audio signal; driving an acoustic output transducer with the filtered audio signal to generate a sound field; generating a detection audio signal by detecting the sound field after propagating through an acoustic channel with an acoustic input transducer; obtaining a first frequency-domain representation from the detection audio signal that is a composite spectral magnitude response of the acoustic output transducer, the acoustic channel and the acoustic input transducer; applying a delay to the filtered audio signal to obtain a delayed filtered audio signal, wherein the delay includes an approximation of propagation delays of the sound field through the acoustic channel; obtaining a second frequency-domain representation from the delayed filtered audio signal; processing the first frequency-domain representation, the second frequency-domain representation, and a third frequency-domain representation from spectral components of a target spectral magnitude response to generate an estimated spectral magnitude response correction signal; obtaining an equalization-filter control signal from the estimated spectral magnitude response correction signal; and configuring filter characteristics of the adaptive filter in response to the equalization-filter control signal.<br>20) A non-transitory medium recording a program of instructions that is executed by a device to perform a method for applying an equalization filter to an audio signal represented by samples, wherein the method comprises: (a) appending a segment of zero-valued samples to segments of audio signal samples in a sequence of segments to obtain a sequence of blocks of samples, each block of samples having a first half with audio signal samples and a second half with zero-valued samples; (b) configuring the equalization filter to have a first frequency-response characteristic in response to an equalization-filter control signal; (c) applying the equalization filter with the first frequency-response characteristic to a first block of samples in the sequence of blocks of samples to obtain a first filtered block of spectral components having a first half and a second half, wherein (1) the first half of the first filtered block represents application of the equalization filter to the first half of the first block of samples and includes convolution products, and (2) the second half of the first filtered block represents application of the equalization filter to the second half of the first block of samples and includes convolution products; (d) applying the equalization filter with the first frequency-response characteristic to a second block of samples that follows the first block of samples in the sequence of blocks of samples to obtain a second filtered block of spectral components having a first half and a second half, wherein (1) the first half of the second filtered block represents application of the equalization filter to the first half of the second block of samples and includes convolution products, and (2) the second half of the second filtered block represents application of the equalization filter to the second half of the second block of samples and includes convolution products; (e) combining the second half of the first filtered block with the first half of the second filtered block and applying a first half of a window function to obtain a first windowed block, wherein the window function has a first half and a second half and the second half follows the first half; (f) configuring the equalization filter to have a second frequency-response characteristic in response to an equalization-filter control signal; (g) applying the equalization filter with the second frequency-response characteristic to the first block of samples in the sequence of blocks of samples to obtain a third filtered block of spectral components having a first half and a second half, wherein (1) the first half of the third filtered block represents application of the equalization filter to the first half of the first block of samples and includes convolution products, and (2) the second half of the third filtered block represents application of the equalization filter to the second half of the first block of samples and includes convolution products; (h) applying the equalization filter with the second frequency-response characteristic to the second block of samples that follows the first block of samples in the sequence of blocks of samples to obtain a fourth filtered block of spectral components having a first half and a second half, wherein (1) the first half of the fourth filtered block represents application of the equalization filter to the first half of the second block of samples and includes convolution products, and (2) the second half of the fourth filtered block represents application of the equalization filter to the second half of the second block of samples and includes convolution products; (i) combining the second half of the third filtered block with the first half of the fourth filtered block and applying the second half of the window function to obtain a second windowed block; and (j) combining the first windowed block with the second windowed block to obtain an output block representing a transition in frequency response of filtering applied to the second segment of audio signal samples from the first frequency-response characteristic to the second frequency-response characteristic.<br>7) A method for applying an equalization filter to an audio signal represented by samples, wherein the method comprises: (a) appending a segment of zero-valued samples to segments of audio signal samples in a sequence of segments to obtain a sequence of blocks of samples, each block of samples having a first half with audio signal samples and a second half with zero-valued samples; (b) configuring the equalization filter to have a first frequency-response characteristic in response to an equalization-filter control signal; (c) applying the equalization filter with the first frequency-response characteristic to a first block of samples in the sequence of blocks of samples to obtain a first filtered block of spectral components having a first half and a second half, wherein (1) the first half of the first filtered block represents application of the equalization filter to the first half of the first block of samples and includes convolution products, and (2) the second half of the first filtered block represents application of the equalization filter to the second half of the first block of samples and includes convolution products; (d) applying the equalization filter with the first frequency-response characteristic to a second block of samples that follows the first block of samples in the sequence of blocks of samples to obtain a second filtered block of spectral components having a first half and a second half, wherein (1) the first half of the second filtered block represents application of the equalization filter to the first half of the second block of samples and includes convolution products, and (2) the second half of the second filtered block represents application of the equalization filter to the second half of the second block of samples and includes convolution products; (e) combining the second half of the first filtered block with the first half of the second filtered block and applying a first half of a window function to obtain a first windowed block, wherein the window function has a first half and a second half and the second half follows the first half; (f) configuring the equalization filter to have a second frequency-response characteristic in response to an equalization-filter control signal; (g) applying the equalization filter with the second frequency-response characteristic to the first block of samples in the sequence of blocks of samples to obtain a third filtered block of spectral components having a first half and a second half, wherein (1) the first half of the third filtered block represents application of the equalization filter to the first half of the first block of samples and includes convolution products, and (2) the second half of the third filtered block represents application of the equalization filter to the second half of the first block of samples and includes convolution products; (h) applying the equalization filter with the second frequency-response characteristic to the second block of samples that follows the first block of samples in the sequence of blocks of samples to obtain a fourth filtered block of spectral components having a first half and a second half, wherein (1) the first half of the fourth filtered block represents application of the equalization filter to the first half of the second block of samples and includes convolution products, and (2) the second half of the fourth filtered block represents application of the equalization filter to the second half of the second block of samples and includes convolution products; (i) combining the second half of the third filtered block with the first half of the fourth filtered block and applying the second half of the window function to obtain a second windowed block; and (j) combining the first windowed block with the second windowed block to obtain an output block representing a transition in frequency response of filtering applied to the second segment of audio signal samples from the first frequency-response characteristic to the second frequency-response characteristic.</p></layer>
<layer id = "layer603"><p><b>US9502048B2:Adaptively reducing noise to limit speech distortion</b><br><b>Independant Claims</b><br>1) A method for reducing noise within an acoustic signal, comprising: separating, via at least one computer hardware processor, an acoustic signal into a plurality of sub-band signals, the acoustic signal representing at least one captured sound; and reducing an energy level of a noise component in a sub-band signal in the plurality of sub-band signals based on an estimated threshold level of speech loss distortion in the sub-band signal, the reducing being in response to determining that speech loss distortion above a threshold would otherwise result if an amount of noise reduction was increased or maintained, the speech loss distortion being excessive when above the threshold.<br>12) A system for reducing noise within an acoustic signal, comprising: a frequency analysis module stored in memory and executed by at least one hardware processor to separate the acoustic signal into a plurality of sub-band signals, the acoustic signal representing at least one captured sound; and a noise reduction module stored in memory and executed by a processor to reduce an energy level of a noise component in a sub-band signal in the plurality of sub-band signals based on an estimated threshold level of speech loss distortion in the sub-band signal, the reducing being in response to determining that speech loss distortion above a threshold would otherwise result if an amount of noise reduction was increased or maintained, the speech loss distortion being excessive when above the threshold.<br>15) A non-transitory computer readable storage medium having embodied thereon a program, the program being executable by a processor to perform a method for reducing noise within an acoustic signal, the method comprising: separating the acoustic signal into a plurality of sub-band signals, the acoustic signal representing at least one captured sound; and reducing an energy level of a noise component in a sub-band signal in the plurality of sub-band signals based on an estimated threshold level of speech loss distortion in the sub-band signal, the reducing being in response to determining that speech loss distortion above a threshold would otherwise result if an amount of noise reduction was increased or maintained, the speech loss distortion being excessive when above the threshold.</p></layer>
<layer id = "layer604"><p><b>US8793126B2:Time/frequency two dimension post-processing</b><br>Print station (1) for a screen printing machine, said print station (1) having a screen frame (14) and a print base (8) for receiving a product (10, 10A) to be screen printed through said screen print frame (14), said print station (1) comprising a screen frame elevation mechanism comprising a first shaft (6) and wherein the screen frame (14) is rotatable about said first shaft (6), wherein said first shaft (6) is movable between a first and a second position, such that the screen frame (14) is translationally moveable relative to the print base (8) when the screen frame (14) is in a printing position relative to the print base (8), further comprising a rotatable circular-section second shaft (5), wherein the first shaft (6) is solidly fixed to the second shaft (5) and the first shaft rotation axis is offset from the second shaft rotation axis. Also, a method of operating the print station (1) for a screen printing machine, comprising: lowering, or raising, the screen frame (14) into, or from, a printing position relative to the print base (8) by simultaneously rotating the screen frame (14) about said first shaft (6) and also moving said first shaft (6) such that the screen frame (14) moves translationally relative to the print base (8).<br><b>Independant Claims</b><br>1) A post-processing method of generating a decoded audio signal, the method comprising: estimating a time-frequency energy array of a decoded audio signal from a time-frequency filter bank; estimating a time direction energy distribution by averaging frequency direction energies; estimating a frequency direction energy distribution by averaging time direction energies; estimating time direction energy modification gains based on the time direction energy distribution; estimating frequency direction energy modification gains based on the frequency direction energy distribution; estimating final two dimension energy modification gains for each T/F point of the time-frequency filter bank; applying the final T/F gains to each corresponding T/F point of the time-frequency filter bank to obtain the modified filter bank coefficients before sent to filter bank synthesis; and outputting final audio signal from the filter bank synthesis.<br>17) A post-processing method of generating a decoded audio signal, the method comprising: receiving a frame comprising a time-frequency (T/F) representation of an input audio signal, the T/F representation having time slots, each time slot having frequency subbands; estimating energy distribution in the time slots and the frequency subbands; estimating post-processing modification gain for each T/F point of time slot and frequency subband according to the T/F energy distribution; making the modification gain smaller at T/F point of lower energy; making the over all energy of after the T/F post-processing equivalent to the one of before the T/F post-processing; applying the final T/F gains to each corresponding T/F point to obtain the modified T/F representation; and outputting final audio signal from the modified T/F representation.</p></layer>
<layer id = "layer605"><p><b>US10217470B2:Bandwidth extension system and approach</b><br><b>Independant Claims</b><br>1) A method, comprising:estimating a bandwidth extension scaling gain by using available filter bank coefficients with extremely low bit rate or without costing any bit, wherein the estimating the bandwidth extension scaling gain comprises:determining Gain_t [ ] to sharpen a time evaluation energy envelope;determining Gain_1[ ] from nearest available high band filter bank coefficients;determining Gain_2[ ] by considering energy ratio between energy at lowest frequency area and lowest energy in all available subbands; andcombining Gain_t [ ], Gain_1[ ], and Gain_2[ ] to estimate the bandwidth extension scaling gain; andgenerating an audio output signal according to the bandwidth extension scaling gain.</p></layer>
<layer id = "layer606"><p><b>US9438992B2:Multi-microphone robust noise suppression</b><br><b>Independant Claims</b><br>1) A system for performing noise reduction in an audio signal, the system comprising: a memory; a frequency analysis module stored in the memory and executed by a processor to generate a plurality of sub-band signals in a frequency domain from time domain acoustic signals; a noise cancellation module stored in the memory and executed by a processor to cancel noise in one or more of the plurality of sub-band signals; a modifier module stored in the memory and executed by a processor to suppress a noise component and an echo component in the one or more noise canceled sub-band signals on a per sub-band basis; and a reconstructor module stored in the memory and executed by a processor to reconstruct a modified time domain signal from the components suppressed sub-band signals provided by the modifier module.<br>10) A method for performing noise reduction in an audio signal, the method comprising: executing a stored frequency analysis module by a processor to generate sub-band signals in a frequency domain from time domain acoustic signals; executing a noise cancellation module by a processor to cancel at least a portion of the sub-band signals; executing a modifier module by a processor to suppress a noise component and an echo component in the noise canceled portion of the sub-band signals on a per sub-band basis; and executing a reconstructor module by a processor to reconstruct a modified time domain signal from the components suppressed sub-band signals provided by the modifier module.<br>18) A non-transitory computer readable storage medium having embodied thereon a program, the program being executable by a processor to perform a method for reducing noise in an audio signal, the method comprising: executing a stored frequency analysis module by a processor to generate a plurality of sub-band signals in a frequency domain from time domain acoustic signals; executing a noise cancellation module by a processor to cancel noise in one or more of the plurality of sub-band signals; executing a modifier module by a processor to suppress a noise component and an echo component in the one or more noise canceled sub-band signals on a per sub-band basis; and executing a reconstructor module by a processor to reconstruct a modified time domain signal from the components suppressed sub-band signals provided by the modifier module.</p></layer>
<layer id = "layer607"><p><b>US20120239409A1:BIT-STREAM PROCESSING/TRANSMITTING AND/OR RECEIVING/PROCESSING METHOD, MEDIUM, AND APPARATUS</b><br>A method for tuning to a radio broadcast frequency in a portable terminal is disclosed. The method includes: determining whether a condition for requiring tuning information is satisfied; computing tuning information using received signal strength indication (RSSI) values of signals received by frequencies if a condition for requiring tuning information is satisfied; and tuning to a radio broadcast frequency corresponding to a radio broadcasting requested by a user, using the computed tuning information, and receiving radio broadcast signals. The tuning information includes: a threshold of RSSI serving as a reference value determine the presence of a radio broadcasting channel; and a Signal-to-Noise Ratio (SNR) value to minimize noise levels.<br><b>Independant Claims</b><br>1. A method of processing/transmitting a bit-stream, the method comprising: coding audio data and at least one extension data for the audio data; truncating selective payloads resulting from the coding; and transmitting the truncated payloads.<br>11. An apparatus processing/transmitting a bit-stream, the apparatus comprising: a coder to code audio data and at least one extension data for the audio data; a truncator to selectively truncate payloads resulting from coding of the coder; and a transmitter to transmit the truncated payloads.<br>12. A method of receiving/processing a bit-stream, the method comprising: receiving payloads having truncated portions; restoring the payloads having the truncated portions to original form restored payloads; and decoding audio data included in the restored payloads and at least one extension data for the audio data.<br>24. An apparatus receiving/processing a bit-stream, the apparatus comprising: a receiver to receive payloads having truncated portions; a restorer to restore the payloads having the truncated portions to original form restored payloads; and a decoder to decode audio data included in the restored payloads and at least one extension data for the audio data.</p></layer>
<layer id = "layer608"><p><b>US9858939B2:Methods and apparatus for post-filtering MDCT domain audio coefficients in a decoder</b><br><b>Independant Claims</b><br>1) A method of operating a decoder comprising: obtaining a vector d(k) comprising quantized Modified Discrete Cosine Transform (MDCT) domain coefficients of a time segment of an audio signal; deriving a processed vector {circumflex over (d)}(k) by applying a post-filter directly on the vector d(k), the post-filter being configured to have a transfer function H(k),H(k)={(abs[d(k)])/(max[abs(d)])}a(k),which is a compressed version of an envelope of the vector d(k), where k goes from 1 to the number of MDCT domain coefficients of the time segment of the audio signal, where max[abs(d)] is a maximum of an absolute value of the vector d(k), and a(k) is an emphasis component configured to control a post-filter aggressiveness over the MDCT spectrum; and deriving a signal waveform by performing an inverse MDCT transform on the processed vector {circumflex over (d)}(k).<br>15) An audio handling entity comprising: memory including computer program modules; and a decoder coupled with the memory, the decoder being configured to execute the computer program modules of the memory to,obtain a vector d(k) comprising quantized Modified Discrete Cosine Transform (MDCT) domain coefficients of a time segment of an audio signal,derive a processed vector {circumflex over (d)}(k) by applying a post-filter directly on the vector d(k), the post-filter being configured to have a transfer function H(k),H(k)={(abs[d(k)])/(max[abs(d)])}a(k),which is a compressed version of an envelope of the vector d(k), where k goes from 1 to the number of MDCT domain coefficients of the time segment of the audio signal, where max[abs(d)] is a maximum of an absolute value of the vector d(k), and a(k) is an emphasis component configured to control a post-filter aggressiveness over the MDCT spectrum, and derive a signal waveform by performing an inverse MDCT transform on the processed vector {circumflex over (d)}(k).<br>8) A decoder comprising: a processor implementing: a filter configured to derive a processed vector {circumflex over (d)}(k) by applying a post-filter directly on a vector d(k), wherein the vector d(k) comprises quantized Modified Discrete Cosine Transform (MDCT) domain coefficients of a time segment of an audio signal, the post-filter being configured to have a transfer function H(k),H(k)={(abs[d(k)])/(max[abs(d)])}a(k),which is a compressed version of an envelope of the vector d(k), where k goes from 1 to the number of MDCT domain coefficients of the time segment of the audio signal, where max[abs(d)] is a maximum of an absolute value of the vector d(k), and a(k) is an emphasis component configured to control a post-filter aggressiveness over the MDCT spectrum, and a converter configured to derive a signal waveform by performing an inverse MDCT transform on the processed vector {circumflex over (d)}(k).</p></layer>
<layer id = "layer609"><p><b>US9294060B2:Bandwidth extender</b><br><b>Independant Claims</b><br>1) A method comprising: generating an excitation signal from an audio signal, wherein in the audio signal comprises a plurality of frequency components; extracting a feature vector from the audio signal, wherein the feature vector comprises at least one frequency domain component feature and at least one time domain component feature; determining at least one spectral shape parameter from the feature vector, wherein the at least one spectral shape parameter corresponds to a sub band signal comprising frequency components which belong to a further plurality of frequency components; and generating the sub band signal by filtering the excitation signal through a filter bank and weighting the filtered excitation signal with the at least one spectral shape parameter, wherein the spectral shape parameter is a sub band energy level value and the sub band energy level value is attenuated when the power of the audio signal approaches an estimate of the level of noise in the audio signal.<br>10) An apparatus comprising at least one processor and at least one memory including computer code, the at least one memory and the computer code configured to with the at least one processor cause the apparatus to at least: generate an excitation signal from an audio signal, wherein in the audio signal comprises a plurality of frequency components; extract a feature vector from the audio signal, wherein the feature vector comprises at least one frequency domain component feature and at least one time domain component feature; determine at least one spectral shape parameter from the feature vector, wherein the at least one spectral shape parameter corresponds to a sub band signal comprising frequency components which belong to a further plurality of frequency components; and generate the sub band signal by filtering the excitation signal through a filter bank and weighting the filtered excitation signal with the at least one spectral shape parameter, wherein the spectral shape parameter is a sub band energy level value and the sub band energy level value is attenuated when the power of the audio signal approaches an estimate of the level of noise in the audio signal.</p></layer>
<layer id = "layer610"><p><b>US9431023B2:Monaural noise suppression based on computational auditory scene analysis</b><br><b>Independant Claims</b><br>1) A method for performing noise reduction, the method comprising: executing a program stored in a memory to transform a time-domain acoustic signal into a plurality of frequency-domain sub-band signals; tracking at least one pitch from a plurality of pitch sources within a frequency-domain sub-band signal in the plurality of frequency-domain sub-band signals, wherein the tracking includes: calculating at least one feature for each of the plurality of pitch sources; and determining, based on the at least one feature, a probability based at least in part on pitch energy level, pitch salience, and pitch stationarity for each pitch source that the pitch source is a desired speech source, the desired speech source being a speech source associated with a desired talker; generating a speech model and one or more noise models based on the tracked at least one pitch, the speech model modeling desired speech and the one or more noise models modeling sources other than the desired speech; and performing the noise reduction on the frequency-domain sub-band signal based on the speech model and the one or more noise models.<br>13) A non-transitory computer readable storage medium having embodied thereon a program, the program being executable by a processor to perform a method for reducing noise in an audio signal, the method comprising: transforming an acoustic signal from a time-domain signal to frequency-domain sub-band signals; tracking at least one pitch from a plurality of pitch sources within the frequency-domain sub-band signals, the tracking including: calculating at least one feature for each of the plurality of pitch sources; and determining, based on the at least one feature, a probability based at least in part on pitch energy level, pitch salience, and pitch stationarity for each pitch source that the pitch source is a desired speech source, the desired speech source being a speech source associated with a desired talker; generating a speech model and one or more noise models based on the tracked at least one pitch, the speech model modeling desired speech and the one or more noise models modeling sources other than the desired speech; and performing noise reduction on the frequency-domain sub-band signals based on the speech model and one or more noise models.<br>9) A system for performing noise reduction in an audio signal, the system comprising: a memory; an analysis module stored in the memory and executed by a processor to transform a time-domain acoustic to frequency-domain sub-band signals; a source inference engine stored in the memory and executed by the processor to track at least one pitch from a plurality of pitch sources within the frequency-domain sub-band signals and to generate a speech model and one or more noise models based on the tracked at least one pitch, the speech model modeling desired speech and the one or more noise models modeling sources other than the desired speech, wherein the tracking includes: calculating at least one feature for each of the plurality of pitch sources; and determining, based on the at least one feature, a probability based at least in part on pitch energy level, pitch salience, and pitch stationarity for each pitch source that the pitch source is a desired speech source, the desired speech source being a speech source associated with a desired talker; and a modifier module stored in the memory and executed by the processor to perform the noise reduction on the frequency-domain sub-band signals based on the speech model and the one or more noise models.</p></layer>
<layer id = "layer611"><p><b>US10339938B2:Spectrum flatness control for bandwidth extension</b><br><b>Independant Claims</b><br>8) A post-processing method of generating a decoded speech/audio signal at a decoder and improving spectrum flatness of a generated high frequency band, the method comprising:generating, by a processor in the decoder, high band coefficients from low band coefficients in a frequency domain using a BandWidth Extension (BWE) high band coefficient generation method;flattening and smoothing, by the processor in the decoder, an energy envelope of the high band coefficients in the frequency domain by multiplying flattening and smoothing gains to the high band coefficients, wherein the flattening and smoothing gains are used to generate an energy of modified high band coefficients being closer to a mean energy value obtained by averaging energies of the high band coefficients, and wherein each of the flattening and smoothing gains is individually calculated by the processor in the decoder based on the mean energy value and a value of a corresponding one of the high band coefficients;shaping and determining, by the processor in the decoder, the energies of the high band coefficients by using a BWE shaping and determining method; andinverse-transforming, by the processor in the decoder, the low band coefficients and the high band coefficients to a time domain to obtain a time domain output speech/audio signal.<br>13) A system for receiving an encoded audio signal, comprising:a memory storage comprising instructions; andone or more processors in communication with the memory, wherein the one or more processors execute the instructions to:transform a low band portion of the encoded audio signal into frequency domain low band coefficients at an output of a low-band block;generate high band coefficients by copying a plurality of the low band coefficients to a high frequency band location;evaluate modification gains through following equation:Gain(k)=(C0+C1·√{square root over (Mean_HB/F_energy_dec[k])}), k=Start_HB, . . . ,End_HB−1,wherein {Gain(k), k=Start_HB, . . . , End_HB−1} are the modification gains, F_energy_dec[k] is an energy distribution at each frequency location index k of a copied high band, Start_HB and End_HB define a high band range, C0 and C1 satisfying C0+C1=1 are pre-determined constants, and Mean_HB is a mean energy value obtained by averaging energies of the high band coefficients;generate shaped high band coefficients by multiplying the modification gains with the high band coefficients in the frequency domain to form processed high band coefficients, wherein the processed high band coefficients have an energy closer to the mean energy value, and apply a received spectral envelope to the high band coefficients, the received spectral envelope being decoded from the encoded audio signal; andproduce a time domain audio output signal.<br>1) A method of decoding an encoded audio bitstream at a decoder, the method comprising:receiving, by a processor in the decoder, the audio bitstream from the network, the audio bitstream comprising a low band bitstream;decoding, by the processor in the decoder, the low band bitstream to get low band coefficients in a frequency domain;copying, by the processor in the decoder, a plurality of the low band coefficients to a high frequency band location to generate high band coefficients;evaluating, by the processor in the decoder, modification gains through following equation:Gain(k)=(C0+C1·√{square root over (Mean_HB/F_energy_dec[k])}), k=Start_HB, . . . ,End_HB−1,wherein {Gain(k), k=Start_HB, . . . , End_HB−1} are the modification gains, F_energy_dec[k] is an energy distribution at each frequency location index k of a copied high band, Start_HB and End_HB define a high band range, C0 and C1 satisfying C0+C1=1 are pre-determined constants, and Mean_HB is a mean energy value obtained by averaging energies of the high band coefficients;modifying, by the processor in the decoder, an energy envelope of the high band coefficients to flatten and smooth the high band coefficients by multiplying modification gains with the high band coefficients in the frequency domain to form processed high band coefficients, wherein the processed high band coefficients have an energy closer to the mean energy value;applying, by the processor in the decoder, a received spectral envelope to the high band coefficients, the received spectral envelope being decoded from the received audio bitstream; andinverse-transforming, by the processor in the decoder, the low band coefficients and the processed high band coefficients to a time domain to obtain a time domain audio output signal.</p></layer>
<layer id = "layer612"><p><b>US8560330B2:Energy envelope perceptual correction for high band coding</b><br>A light emitting element includes: a sapphire substrate having a front surface and a rear surface opposite the front surface; a first conductive type semiconductor layer stacked on the front surface of the sapphire substrate; a light emitting layer stacked on the first conductive type semiconductor layer; a second conductive type semiconductor layer stacked on the light emitting layer; a reflective layer which contains Ag and is disposed on the rear surface of the sapphire substrate, the reflective layer reflecting light from the sapphire substrate toward the front surface of the sapphire substrate; and an adhesive layer which is interposed between the sapphire substrate and the reflective layer and is made of ITO, the adhesive layer being adhered to the reflective layer.<br><b>Independant Claims</b><br>15) A method of encoding an audio bitstream at an encoder, the method comprising: encoding an original low band signal at the encoder by using a closed loop analysis-by-synthesis approach to obtain a coded low band signal; encoding an original high band signal at the encoder by using an open loop energy matching approach to obtain coded high band energy envelopes; comparing an energy of the coded low band signal with an energy of a corresponding original low band signal; generating an indication flag that indicates whether an energy envelope perceptual correction is needed based on comparing the energy; calculating high band energy envelopes of the original high band signal at the encoder; applying energy envelope perceptual correction by reducing amplitudes of the high band energy envelopes if the indication flag is true; encoding the high band energy envelopes after applying the energy envelope perceptual correction at the encoder by using an open loop energy matching to obtain coded high band energy envelopes; and electronically transmitting the coded low band signal, and the coded high band energy envelopes.<br>26) A system for encoding an audio signal, the system comprising: a low band encoder configured to encode an original low band signal using a closed loop analysis-by-synthesis approach to obtain a coded low band signal; a high band encoder configured to encode an original high band signal using an open loop energy matching approach to obtain coded high band energy envelopes; an energy comparison block configured to compare an energy of the coded low band signal with an energy of a corresponding original low band signal for a subframe, and generate an indication flag that indicates whether an energy envelope perceptual correction is needed for the subframe based on comparing the energy; a correction block configured to reduce amplitudes of the high band energy envelopes if the indication flag is true; a high band energy envelope encoder configured to encode the high band energy envelopes after applying the energy envelope perceptual correction at the encoder by using an open loop energy matching to obtain coded high band energy envelopes; and an interface block configured to transmit the coded low band signal, and the coded high band energy envelopes.<br>9) A method of decoding an encoded audio bitstream at a decoder, the method comprising: electronically receiving the encoded audio bitstream, the encoded audio bitstream comprising a coded low band signal, coded high band energy envelopes, and an indication flag; performing an energy envelope perceptual correction by reducing amplitudes of the coded high band energy envelopes if the indication flag is in a true state; generating a high band signal by applying the coded high band energy envelopes after performing the energy envelope perceptual correction; and forming an output speech/audio signal from the coded low band signal and the generated high band signal.<br>30) A system for decoding an encoded audio bitstream, the system comprising: a receiver for receiving an encoded bitstream comprising a coded low band signal, coded high band energy envelopes, and an indication flag; a perceptual correction block configured to reduce amplitudes of the coded high band energy envelopes to form corrected coded high band energy envelopes if the indication flag is in a true state; a high band signal generator coupled to the perceptual correction block, the high band signal generator configured to apply the high band energy envelopes to form a generated high band signal; and a filter bank synthesis block configured to form an output speech/audio signal from the coded low band signal and the generated high band signal.<br>1) A method of encoding an audio bitstream at an encoder, the method comprising: encoding an original low band signal at the encoder by using a closed loop analysis-by-synthesis approach to obtain a coded low band signal; encoding an original high band signal at the encoder by using an open loop energy matching approach to obtain coded high band energy envelopes; comparing an energy of the coded low band signal with an energy of a corresponding original low band signal for a subframe; generating an indication flag that indicates whether an energy envelope perceptual correction is needed for the subframe based on comparing the energy; and electronically transmitting the coded low band signal, the coded high band energy envelopes, and the indication flag.<br>22) A system for encoding an audio signal, the system comprising: a low band encoder configured to encode an original low band signal using a closed loop analysis-by-synthesis approach to obtain a coded low band signal; a high band encoder configured to encode an original high band signal using an open loop energy matching approach to obtain coded high band energy envelopes; an energy comparison block configured to compare an energy of the coded low band signal with an energy of a corresponding original low band signal for a subframe, and generate an indication flag to indicate whether an energy envelope perceptual correction is needed for the subframe based on comparing the energy; and an interface block configured to transmit the coded low band signal, the coded high band energy envelopes, and the indication flag.<br>33) A non-transitory computer readable medium has an executable program stored thereon, wherein the program instructs a processor to perform the steps of: encoding an original low band signal using a closed loop analysis-by-synthesis approach to obtain a coded low band signal; encoding an original high band signal using an open loop energy matching approach to obtain coded high band energy envelopes; comparing an energy of the coded low band signal with an energy of a corresponding original low band signal for a subframe; generating an indication flag that indicates whether an energy envelope perceptual correction is needed for the subframe based on comparing the energy; and transmitting the coded low band signal, the coded high band energy envelopes, and the indication flag.<br>34) A non-transitory computer readable medium has an executable program stored thereon, wherein the program instructs a processor to perform the steps of: encoding an original low band signal using a closed loop analysis-by-synthesis approach to obtain a coded low band signal; encoding an original high band signal using an open loop energy matching approach to obtain coded high band energy envelopes; comparing an energy of the coded low band signal with an energy of a corresponding original low band signal for a subframe; generating an indication flag that indicates whether an energy envelope perceptual correction is needed for the subframe based on comparing the energy; calculating high band energy envelopes of the original high band signal at the encoder; applying energy envelope perceptual correction by reducing amplitudes of the high band energy envelopes if the indication flag is true; encoding the high band energy envelopes after applying the energy envelope perceptual correction at the encoder by using an open loop energy matching to obtain coded high band energy envelopes; and transmitting the coded low band signal, and the coded high band energy envelopes.</p></layer>
<layer id = "layer613"><p><b>US20190164558A1:SIGNAL PROCESSING APPARATUS AND METHOD, AND PROGRAM</b><br><b>Independant Claims</b><br>3) A non-transitory computer-readable storage medium including instructions that, when executed by a processor, perform a method for processing an audio signal, the method comprising:decoding an encoded signal corresponding to the audio signal to produce a decoded signal having an energy spectrum of a shape including an energy depression;performing filter processing on the decoded signal, the filter processing separating the decoded signal into low-frequency range band signals by using a QMF analysis filter;computing an average energy of a plurality of the low-frequency range band signals;computing a ratio for a selected one of the low-frequency range band signals by computing a ratio of the average energy of the plurality of the low-frequency range band signals to an energy for the selected low-frequency range band signal;multiplying the selected low-frequency range band signal by the computed ratio for smoothing the energy depression of the low-frequency range band signals;performing a frequency shift on the smoothed low-frequency range band signals, the frequency shift generating high-frequency range band signals from the low-frequency range band signals;combining the low-frequency range band signals and the high-frequency range band signals to generate an output signal by using a QMF synthesis filter; andoutputting the output signal.<br>2) A device for processing an audio signal, the device comprising:a low-frequency range decoding circuit configured to decode an encoded signal corresponding to the audio signal to produce a decoded signal having an energy spectrum of a shape including an energy depression;a filter processor configured to perform filter processing on the decoded signal, the filter processing separating the decoded signal into low-frequency range band signals by using a QMF analysis filter;a high-frequency range generating circuit configured to:compute an average energy of a plurality of the low-frequency range band signals;compute a ratio for a selected one of the low-frequency range band signals by computing a ratio of the average energy of the plurality of the low-frequency range band signals to an energy for the selected low-frequency range band signal;multiply the selected low-frequency range band signal by the computed ratio for smoothing the energy depression of the low-frequency range band signals; andperform a frequency shift on the smoothed low-frequency range band signals, the frequency shift generating high-frequency range band signals from the low-frequency range band signals; anda combinatorial circuit configured to combine the low-frequency range band signals and the high-frequency range band signals to generate an output signal by using a QMF synthesis filter, and to output the output signal.<br>1) A computer-implemented method for processing an audio signal, the method comprising:decoding an encoded signal corresponding to the audio signal to produce a decoded signal having an energy spectrum of a shape including an energy depression;performing filter processing on the decoded signal, the filter processing separating the decoded signal into low-frequency range band signals by using a QMF analysis filter;computing an average energy of a plurality of the low-frequency range band signals;computing a ratio for a selected one of the low-frequency range band signals by computing a ratio of the average energy of the plurality of the low-frequency range band signals to an energy for the selected low-frequency range band signal;multiplying the selected low-frequency range band signal by the computed ratio for smoothing the energy depression of the low-frequency range band signals;performing a frequency shift on the smoothed low-frequency range band signals, the frequency shift generating high-frequency range band signals from the low-frequency range band signals;combining the low-frequency range band signals and the high-frequency range band signals to generate an output signal by using a QMF synthesis filter; andoutputting the output signal.</p></layer>
<layer id = "layer614"><p><b>US9620129B2:Apparatus and method for coding a portion of an audio signal using a transient detection and a quality result</b><br><b>Independant Claims</b><br>1) An apparatus for coding a portion of an audio signal to acquire an encoded audio signal for the portion of the audio signal, comprising: a transient detector configured for detecting whether a transient signal is located in the portion of the audio signal to achieve a transient detection result for the portion of the audio signal; an encoder stage configured for performing a first encoding algorithm on the portion of the audio signal to obtain a first quality result value for the portion of the audio signal, the first encoding algorithm comprising a first characteristic, and for performing a second encoding algorithm on the same portion of the audio signal from which the first quality result value was derived, to obtain a second quality result value for the portion of the audio signal, the second encoding algorithm comprising a second characteristic being different from the first characteristic; a processor configured for determining which encoding algorithm of the first and second encoding algorithms results in the encoded audio signal for the portion of the audio signal being a better approximation to the portion of the audio signal with respect to the other encoding algorithm of the first and second encoding algorithms to achieve a quality result for the portion of the audio signal, wherein the processor is configured to determine the quality result as a distance between the first quality result value and the second quality result value; a controller configured for determining whether the encoded audio signal for the portion of the audio signal is to be generated using either the first encoding algorithm or the second encoding algorithm based on the transient detection result for the portion of the audio signal and the quality result for the same portion of the audio signal; and an output interface for outputting, for the portion of the audio signal, the encoded signal being either generated using the first encoding algorithm or generated using the second encoding algorithm, wherein the encoder stage is configured for using the first encoding algorithm which is better suited for transient signals than the second encoding algorithm, wherein the controller is configured for determining the second encoding algorithm, although the quality result indicates a better quality for the first encoding algorithm, when the transient detection result indicates a non-transient signal and when the quality result indicates a distance between the encoding algorithms, which is smaller than a threshold distance value, or wherein the controller is configured for determining the first encoding algorithm, although the quality result indicates a better quality for the second encoding algorithm, when the transient detection result indicates a transient signal and when the quality result indicates the distance between the encoding algorithms, which is smaller than the threshold distance value, and wherein at least one of the transient detector, the encoder stage, the processor, the controller, or the output interface comprises a hardware implementation.<br>10) A method of coding a portion of an audio signal to acquire an encoded audio signal for the portion of the audio signal, comprising: detecting, by a transient detector, whether a transient signal is located in the portion of the audio signal to achieve a transient detection result for the portion of the audio signal; performing, by an encoder stage, a first encoding algorithm on the portion of the audio signal to obtain a first quality result value for the portion of the audio signal, the first encoding algorithm comprising a first characteristic, and performing a second encoding algorithm on the same portion of the audio signal from which the first quality result value was derived, to obtain a second quality result value for the portion of the audio signal, the second encoding algorithm comprising a second characteristic being different from the first characteristic; determining, by a processor, which encoding algorithm of the first and second encoding algorithms results in the encoded audio signal being a better approximation to the portion of the audio signal with respect to the other encoding algorithm of the first and second encoding algorithms to achieve a quality result for the portion of the audio signal, wherein the determining comprises determining the quality result as a distance between the first quality result value and the second quality result value; and determining, by a controller, whether the encoded audio signal for the portion of the audio signal is to be generated using either the first encoding algorithm or the second encoding algorithm based on the transient detection result for the same portion of the audio signal and the quality result for the portion of the audio signal; and outputting, by an output interface, for the portion of the audio signal, the encoded signal being either generated using the first encoding algorithm or generated using the second encoding algorithm, wherein the first encoding algorithm is better suited for transient signals than the second encoding algorithm, wherein the determining whether the encoded audio signal for the portion of the audio signal is to be generated using either the first encoding algorithm or the second encoding algorithm comprises determining the second encoding algorithm, although the quality result indicates a better quality for the first encoding algorithm, when the transient detection result indicates a non-transient signal and when the quality result indicates a distance between the encoding algorithms, which is smaller than a threshold distance value, or wherein the determining whether the encoded audio signal for the portion of the audio signal is to be generated using either the first encoding algorithm or the second encoding algorithm comprises determining the first encoding algorithm, although the quality result indicates a better quality for the second encoding algorithm, when the transient detection result indicates a transient signal and when the quality result indicates the distance between the encoding algorithms, which is smaller than the threshold distance value, wherein at least one of the transient detector, the encoder stage, the processor, the controller, or the output interface comprises a hardware implementation.<br>11) A non-transitory storage medium having stored thereon a computer program comprising a program code for performing, when running on a computer, a method of coding a portion of an audio signal to acquire an encoded audio signal for the portion of the audio signal, the method comprising: detecting whether a transient signal is located in the portion of the audio signal to achieve a transient detection result for the portion of the audio signal; performing a first encoding algorithm on the portion of the audio signal to obtain a first quality result value for the portion of the audio signal, the first encoding algorithm comprising a first characteristic, and performing a second encoding algorithm on the same portion of the audio signal from which the first quality result value was derived to obtain a second quality result value for the portion of the audio signal, the second encoding algorithm comprising a second characteristic being different from the first characteristic; determining which encoding algorithm of the first and second encoding algorithms results in the encoded audio signal being a better approximation to the portion of the audio signal with respect to the other encoding algorithm of the first and second encoding algorithms to achieve a quality result for the portion of the audio signal, wherein the determining comprises determining the quality result as a distance between the first quality result value and the second quality result value; determining whether the encoded audio signal for the portion of the audio signal is to be generated using either the first encoding algorithm or the second encoding algorithm based on the transient detection result for the same portion of the audio signal and the quality result for the portion of the audio signal; and outputting, for the portion of the audio signal, the encoded signal being either generated using the first encoding algorithm or generated using the second encoding algorithm, wherein the first encoding algorithm is better suited for transient signals than the second encoding algorithm, wherein the determining whether the encoded audio signal for the portion of the audio signal is to be generated using either the first encoding algorithm or the second encoding algorithm comprises determining the second encoding algorithm, although the quality result indicates a better quality for the first encoding algorithm, when the transient detection result indicates a non-transient signal and when the quality result indicates a distance between the encoding algorithms, which is smaller than a threshold distance value, or wherein the determining whether the encoded audio signal for the portion of the audio signal is to be generated using either the first encoding algorithm or the second encoding algorithm comprises determining the first encoding algorithm, although the quality result indicates a better quality for the second encoding algorithm, when the transient detection result indicates a transient signal and when the quality result indicates the distance between the encoding algorithms, which is smaller than the threshold distance value.</p></layer>
<layer id = "layer615"><p><b>US8311817B2:Systems and methods for enhancing voice quality in mobile device</b><br>A level shifter includes: a first buffer amplifier transferring a preset reference voltage to a first output terminal; a second buffer amplifier connected in parallel to the first buffer amplifier and transferring an input voltage to a second output terminal; a positive feedback amplifier connected in parallel to the first buffer amplifier and the second buffer amplifier, and amplifying the input voltage by a preset gain to transfer the amplified input voltage to a third output terminal; and a level regulation unit regulating levels of output signals of the first buffer amplifier, the second buffer amplifier, and the positive feedback amplifier and providing the regulated output signals to a common output node.<br><b>Independant Claims</b><br>1) A method for improving quality of speech communications, the method comprising: receiving, by a noise suppressor, an input audio signal; suppressing, by the noise suppressor, noise in the input audio signal to generate a processed noise-suppressed input audio signal; classifying, by the noise suppressor, the processed noise-suppressed input audio signal into speech, and speech and noise; based on the classification, creating, by the noise suppressor, speech-noise classification data; and providing, by the noise suppressor, the speech-noise classification data and the processed noise-suppressed input audio signal for use by a speech encoder, the processed noise-suppressed input audio signal generated by the noise suppressor having noise suppressed better than the expected level of noise suppression for which the speech encoder was designed, the speech encoder being configured to encode at least the processed noise-suppressed input audio signal into one or more data rate modes based at least in part on the speech-noise classification data, the speech-noise classification data adapting the speech encoder for the more than expected level of noise suppression.<br>16) A method for improving quality of speech communications, the method comprising: receiving, by a noise suppressor, an audio signal; classifying, by the noise suppressor, the audio signal into speech, and speech and noise; and based on the classification, providing, by the noise suppressor, one or more scaling transition factors for use by a speech encoder, the speech encoder being configured to gradually change a data rate in transitions between one or more encoding modes based at least in part on the one or more scaling transition factors.<br>17) A system for improving quality of speech communications, the system comprising: a communication module of a noise suppressor configured to receive an audio signal the noise suppressor configured to suppress noise in the audio signal to generate a processed noise-suppressed audio signal; and a classification module of the noise suppressor configured to classify the processed noise-suppressed audio signal into speech, and speech and noise, and determine speech-noise classification data based at least in part on the classifying, wherein the speech-noise classification data and processed noise-suppressed audio signal from the noise suppressor are received by a speech encoder, the processed noise-suppressed audio signal generated by the noise suppressor having noise suppressed better than the expected level of noise suppression for which the speech encoder was designed, the speech encoder being configured to encode the processed noise-suppressed audio signal into one or more data rate modes based at least in part on the speech-noise classification data, the speech-noise classification data adapting the speech encoder for the more than expected level of noise suppression.<br>27) A system for improving quality of speech communications, the system comprising: a communication module of a noise suppressor configured to receive an audio signal; and a classification module of the noise suppressor configured to classify the audio signal into one or more speech, and speech and noise signals, and determine one or more scaling transition factors based on the classifying, wherein the noise suppressor is configured to provide the one or more scaling transition factors, the one or more scaling transition factors are received by a speech encoder, and the speech encoder is configured to gradually change a data rate in transitions between one or more encoding modes based at least in part on the one or more scaling transition factors.</p></layer>
<layer id = "layer616"><p><b>US8831937B2:Post-noise suppression processing to improve voice quality</b><br>A cavity wall and stud wherein the stud is characterized by a base exposed to the corridor, and two side flanges which penetrate into the wall and thereafter diverge without closing upon themselves or each other, the ends of the flanges being used to anchor the facing layer of the wall. Resiliency can be introduced into the flanges to reduce sound transmission.<br/><br><b>Independant Claims</b><br>1) A method for improving quality of speech communications, the method comprising: configuring a speech encoder using a first set of parameters associated with a first noise suppressor; receiving a second set of parameters associated with a second noise suppressor; receiving an audio signal; and reconfiguring the speech encoder to encode the audio signal using the second set of parameters.<br>14) A system for improving quality of speech communications, the system comprising: a speech encoder configured to encode an audio signal using a first set of parameters associated with a first noise suppressor; a communications module of a second noise suppressor, stored in a memory and running on a processor, the communications module configured to receive the audio signal; and a suppression module of the second noise suppressor, stored in the memory and running on the processor, the suppression module configured to suppress noise in the audio signal to generate a processed audio signal and to determine a second set of parameters associated with the second noise suppressor for use by the speech encoder, the speech encoder being further configured to receive the processed audio signal and to receive the second set of parameters.<br>21) A method for improving quality of speech communications, the method comprising: configuring a speech encoder using a first set of parameters associated with a first noise suppressor; receiving an audio signal; suppressing noise in the audio signal by a second noise suppressor to generate a processed audio signal; providing the processed audio signal to the speech encoder; determining a second set of parameters associated with the second noise suppressor; and providing the second set of parameters to the speech encoder, the speech encoder being configured to encode the processed audio signal using the second set of parameters.<br>25) A method for improving quality of speech communications, the method comprising: receiving, via a first module stored in a memory and running on a processor, first data and instructions associated with a speech encoder, the speech encoder comprising a first noise suppressor, wherein the first data and instructions comprise a first set; receiving, via a second module stored in the memory and running on the processor, second data associated with a second noise suppressor; receiving, via a third module stored in the memory and running on the processor, an audio signal; and replacing, via a fourth module stored in the memory and running on the processor, at least some of the first data with the second data to create a second set.</p></layer>
<layer id = "layer617"><p><b>US9245524B2:Speech recognition device, speech recognition method, and computer readable medium</b><br><b>Independant Claims</b><br>1) A speech recognition device comprising: a coefficient storage unit which stores a suppression coefficient representing an amount of noise suppression and an adaptation coefficient representing an amount of adaptation which is generated on the basis of a predetermined noise and is synthesized to a clean acoustic model generated on the basis of a voice which does not include noise, in a manner to relate the suppression coefficient with the adaptation coefficient to each other; a noise estimation unit which estimates noise from an input signal; a noise suppression unit which suppresses a portion of the noise specified by a suppression amount specified on the basis of the suppression coefficient, among from the noise estimated by said noise estimation unit, from the input signal; an acoustic model adaptation unit which generates an adapted acoustic model which is noise-adapted, by synthesizing the noise model, which is generated on the basis of the noise estimated by said noise estimation unit in accordance with an amount of adaptation specified on the basis of the adaptation coefficient, to the clean acoustic model; and a search unit which recognizes voice on the basis of the input suppressed noise by said noise suppression unit and the adapted acoustic model generated by said acoustic model adaptation unit.<br>10) A voice recognition method comprising: storing a suppression coefficient representing an amount of noise suppression and an adaptation coefficient representing an amount of adaptation which is generated on the basis of a predetermined noise and is synthesized to a clean acoustic model generated on the basis of a voice which does not include noise, in a manner to relate the suppression coefficient with the adaptation coefficient to each other; estimating noise from an input signal; suppressing a portion of the noise specified by a suppression amount specified on the basis of the suppression coefficient, among from the noise estimated, from the input signal; generating an adapted acoustic model which is noise-adapted, by synthesizing the noise model, which is generated on the basis of the estimated noise in accordance with an amount of adaptation specified on the basis of the adaptation coefficient, to the clean acoustic model; and recognizing voice on the basis of the noise-suppressed input signal and the generated adapted acoustic model.<br>19) A computer readable non-transitory medium embodying a program, said program causing a speech recognition device to perform a method, said method comprising: storing a suppression coefficient representing an amount of noise suppression and an adaptation coefficient representing an amount of adaptation which is generated on the basis of a predetermined noise and is synthesized to a clean acoustic model generated on the basis of a voice which does not include noise, in a manner to relate the suppression coefficient with the adaptation coefficient to each other; estimating noise from an input signal; suppressing a portion of the noise specified by a suppression amount specified on the basis of the suppression coefficient, among from the noise estimated, from the input signal; generating an adapted acoustic model which is noise-adapted, by synthesizing the noise model, which is generated on the basis of the estimated noise in accordance with an amount of adaptation specified on the basis of the adaptation coefficient, to the clean acoustic model; and recognizing voice on the basis of the noise-suppressed input signal and the generated adapted acoustic model.</p></layer>
<layer id = "layer618"><p><b>US8189766B1:System and method for blind subband acoustic echo cancellation postfiltering</b><br>A showerhead electrode includes inner and outer steps at an outer periphery thereof, the outer step cooperating with a clamp ring which mechanically attaches the electrode to a backing plate.<br><b>Independant Claims</b><br>1) A method for blind subband acoustic echo cancellation postfiltering in a communication device, comprising: receiving an acoustic signal via a microphone at a communication device; applying acoustic echo cancellation (AEC) to the acoustic signal to obtain an AEC masked signal; performing blind subband AEC postfiltering on the AEC masked signal to obtain an echo-free acoustic signal; and outputting the echo-free acoustic signal.<br>12) A system for blind subband acoustic echo cancellation postfiltering in a communication device, comprising: an acoustic sensor configured to receive an acoustic signal; an acoustic echo cancellation (AEC) engine configured to reduce echo from the acoustic signal to obtain an AEC masked signal; a blind subband AEC postfiltering (BSAP) system configured to determine a blind subband AEC postfiltering gain for each subband of the AEC masked signal; and a masking module configured to apply the blind subband AEC postfiltering gain to each subband of the AEC masked signal to obtain an echo-free acoustic signal.<br>18) A machine readable medium having embodied thereon a program, the program providing instructions for a method for blind subband acoustic echo cancellation postfiltering in a communication device, comprising: receiving an acoustic signal via a microphone at a communication device; applying acoustic echo cancellation (AEC) to the acoustic signal to obtain an AEC masked signal; performing blind subband AEC postfiltering on the AEC masked signal to obtain an echo-free acoustic signal; and outputting the echo-free acoustic signal.</p></layer>
<layer id = "layer619"><p><b>US8249861B2:High frequency compression integration</b><br>An image processing apparatus includes a first calculating unit configured to add a pixel value and an output of a filter unit, a first quantizing unit configured to quantize an output of the first calculating unit and output a quantized value serving as ΔΣ modulation data, a second calculating unit configured to calculate a difference between the output of the first calculating unit and the quantized value, thereby obtaining the quantization error, a second quantizing unit configured to quantize a portion of the quantization error and output compensating data, a third calculating unit configured to add the ΔΣ modulation data and the compensating data, thereby generating time-integration-effect-using error diffusion data, a fourth calculating unit configured to calculate a difference between the quantization error and the compensating data, the difference serving as a ΔΣ modulation error, and the filter unit configured to perform filtering in space directions.<br><b>Independant Claims</b><br>1) A speech system that improves the intelligibility and quality of a processed speech, comprising: a first spectral compressor that compresses a first pre-selected high frequency band and maps the first compressed high frequency band to a first band limited lower frequency range; an acoustic echo canceller coupled with an output of the first spectral compressor to receive a first sound signal modified by the first spectral compressor, where the acoustic echo canceller dampens repetitive sounds in the first sound signal created by a reflection from a surface; and a second spectral compressor coupled with an output of the acoustic echo canceller to receive a second sound signal modified by the acoustic echo canceller, where the second spectral compressor compresses a second pre-selected high frequency band of the second sound signal and maps the second compressed high frequency band to a second lower band limited frequency range, and where the second spectral compressor comprises circuitry or a computer-readable storage medium that stores instructions executable by a processor.<br>18) A speech system that improves the intelligibility of a processed speech, comprising: a high pass filter that passes frequencies above a first frequency; a low pass filter in communication with the high pass filter that passes frequencies below a second frequency; an acoustic echo canceller in communication with the lowpass filter that dampens repetitive sounds created by a reflection from a surface; a mixer that combines an output of the acoustic echo canceller with an output of the high pass filter; a frequency transformer that converts an output of the mixer into its frequency domain; a spectral compressor coupled to the frequency transformer that compresses a pre-selected high frequency band of a first signal and maps the compressed high frequency band to a lower frequency band; and a gain controller configured to adjust a gain of the compressed high frequency band proportionally to the changing level of an independent and extraneous signal, where the gain controller selects a level for the gain that changes across a frequency range of the compressed high frequency band based on a slope of a noise floor present in an uncompressed frequency band of the first signal and a slope of a noise floor present in the compressed high frequency band of the first signal, and where the gain controller comprises circuitry or a computer-readable storage medium that stores instructions executable by a processor.<br>22) A speech system that improves the intelligibility of a processed speech, comprising: a plurality of devices that detect and convert sound waves into electrical signals; a plurality of frequency transformers that convert an output of one of the plurality of devices into its frequency domain; a plurality of first spectral compressors, each of the first spectral compressors being in communication with one of the plurality of frequency transformers, and each of the first spectral compressors being configured to compress a first pre-selected high frequency band and map the first compressed high frequency band to a first lower frequency band; a plurality of noise detectors each configured to detect and estimate a level of noise present in at least one of the sound waves detected by the respective plurality of devices and compressed by the respective plurality of spectral compressors; a plurality of gain controllers each configured to adjust a gain of at least one of the compressed high frequency bands proportionally to the level of noise present in at least one of the sound waves detected by the respective plurality of devices and compressed by the respective plurality of spectral compressors; a beamformer configured to receive signals processed by the plurality of first spectral compressors and the plurality of gain controllers; an acoustic echo canceller configured to receive an output signal of the beamformer; and a second spectral compressor configured to receive an output signal of the acoustic echo canceller, compress a second pre-selected high frequency band of the output signal of the acoustic echo canceller, and map the second compressed high frequency band to a second lower frequency band.<br>26) A speech system that improves the intelligibility of a processed speech, comprising: a beamformer that passes selected audio signals received from a plurality of receivers; a frequency transformer that converts speech signals from time domain into frequency domain in real time; a spectral compressor coupled to the frequency transformer that compresses a pre-selected high frequency band of a signal and maps the compressed high frequency band to a lower frequency band within a telephone pass band; a noise detector configured to detect and measure a background noise level of speech signals; and a gain controller configured to apply a variable gain to the compressed high frequency band in relation to the level of the background noise, where the gain controller is configured to select a level for the variable gain that substantially aligns a slope of a noise floor present in the compressed high frequency band of the signal with a slope of a noise floor present in an uncompressed frequency band of the signal, where the gain controller comprises circuitry or a computer-readable storage medium that stores instructions executable by a processor.</p></layer>
<layer id = "layer620"><p><b>US8306821B2:Sub-band periodic signal enhancement system</b><br>A mower drive wheel incorporating an edging plate including a number of different blade edge profiles for assisting in edging various types and thicknesses of grass or turf. The drive wheel can be reconfigured so that a one piece edging plate is replaced by a plurality of individually attachable blades. A modified walk behind powered mower is also disclosed and which integrates an adjustment mechanism for modifying a rotary turning speed of the edging drive wheel. A secondary drive wheel disconnect linkage is included and the main blade housing of the mower can also exhibit a widened profile to facilitate vacuum intake of the edging debris.<br><b>Independant Claims</b><br>1) A signal enhancement system, comprising: a delay logic circuit configured to receive an input signal and generate a delayed signal; an adaptive filter circuit coupled with the delay logic circuit and configured to receive the delayed signal and generate an output signal based on the delayed signal and filter coefficients of the adaptive filter circuit, where the adaptive filter circuit is configured to adapt the filter coefficients based on a difference between the output signal and the input signal; and a reinforcement logic circuit coupled to the adaptive filter circuit, where the reinforcement logic circuit is configured to add the input signal and the output signal from the adaptive filter circuit to increase a first periodic signal component in the input signal that is at least partially in-phase with a second periodic signal component in the output signal.<br>21) A machine-readable non-transitory medium having processor-executable instructions to enhance a signal by performing the acts of: delaying an input signal to generate a delayed signal; adaptively filtering the delayed signal to generate an output signal based on the delayed signal and filter coefficients of an adaptive filter; adapting the filter coefficients of the adaptive filter based on a difference between the output signal and the input signal; and reinforcing the input signal with the output signal to generate a reinforced signal, where the act of reinforcing comprises adding the input signal and the output signal from the adaptive filter to increase a first periodic signal component in the input signal that is at least partially in-phase with a second periodic signal component in the output signal.<br>13) A method for enhancing a signal, comprising: delaying an input signal to generate a delayed signal; adaptively filtering the delayed signal, by an adaptive filter implemented in hardware or executed by a processor, to generate an output signal based on the delayed signal and filter coefficients of the adaptive filter; adapting the filter coefficients of the adaptive filter based on a difference between the output signal and the input signal; and reinforcing the input signal with the output signal to generate a reinforced signal, where the act of reinforcing comprises adding the input signal and the output signal from the adaptive filter to increase a first periodic signal component in the input signal that is at least partially in-phase with a second periodic signal component in the output signal.</p></layer>
<layer id = "layer621"><p><b>US8543390B2:Multi-channel periodic signal enhancement system</b><br>A surgical instrument is disclosed. The surgical instrument includes a handle assembly, a drive assembly, an endoscopic portion, a pair of jaw members, a dynamic clamping member, and a tissue stop. The drive assembly is disposed in mechanical cooperation with a movable handle of the handle assembly. The endoscopic portion defines a first longitudinal axis. The jaw members are each longitudinally curved with respect to the longitudinal axis. The dynamic clamping member is disposed in mechanical cooperation with a distal portion of the drive assembly and includes an upper beam, a lower beam, and a vertical beam having a cutting edge on a distal portion thereof. At least a portion of the dynamic clamping member is longitudinally curved with respect to the longitudinal axis. The tissue stop is disposed adjacent a distal portion of the first jaw member and configured to impede tissue from distally escaping the jaw members.<br><b>Independant Claims</b><br>1) A signal enhancement system having an audio source device configured to generate a plurality of input signals from a common source, the system comprising: a plurality of periodic signal enhancement circuits implemented in hardware or executed by a processor, each periodic signal enhancement circuit comprising an adaptive filter and each periodic signal enhancement circuit configured to: receive the respective input signal; add a first periodic signal component in the input signal with a second periodic signal component in an output of the adaptive filter to increase the first periodic signal component in the input signal, the second periodic signal component being at least partially in-phase with the first periodic signal component; and generate an enhanced output signal, the enhanced output signal comprising the increased first periodic signal component; a plurality of alignment circuits, each configured to receive the respective enhanced output signal and a common reference signal; the respective alignment circuit time-aligning each enhanced output signal with the common reference signal to generate a time-aligned output signal; and a summing circuit configured to: add the respective time-aligned output signals and the common reference signal to generate an enhanced time-aligned output signal; and output the enhanced time-aligned output signal.<br>14) A signal enhancement system comprising: an audio source device configured to generate a plurality of input signals from a common source, the input signals having correlated signal components; a plurality of periodic signal enhancement circuits implemented in hardware or executed by a processor, each periodic signal enhancement circuit comprising an adaptive filter and each periodic signal enhancement circuit configured to: receive the respective input signal; add a first periodic signal component in the input signal with a second periodic signal component in an output of the adaptive filter to increase the first periodic signal component in the input signal, the second periodic signal component being at least partially in-phase with the first periodic signal component; and generate an enhanced output signal, the enhanced output signal comprising the increased first periodic signal component; a selection circuit configured to calculate a signal-to-noise ratio for each enhanced output signal and select an enhanced output signal having a highest signal-to-noise ratio as a common reference signal; a plurality of alignment circuits, each configured to receive the respective enhanced output signal and the common reference signal; the respective alignment circuit time-aligning each enhanced output signal with the common reference signal to generate a time-aligned output signal; and a summing circuit configured to: add the respective time-aligned output signals and the common reference signal to generate an enhanced time-aligned output signal; and output the enhanced time-aligned output signal.<br>15) A signal enhancement system having an audio source device configured to generate a plurality of input signals from a common source, the system comprising: a selection circuit configured to calculate a signal-to-noise ratio for each input signal and select an input signal having a highest signal-to-noise ratio as a common reference signal; a periodic signal enhancement circuit implemented in hardware or executed by a processor, the periodic enhancement circuit comprising an adaptive filter and the periodic signal enhancement circuit configured to: receive the common reference signal; add a first periodic signal component in the common reference signal with a second periodic signal component in an output of the adaptive filter to increase the first periodic signal component in the common reference signal, the second periodic signal component being at least partially in-phase with the first periodic signal component; and generate an enhanced common reference signal, the enhanced common reference signal comprising the increased first periodic signal component; a plurality of alignment circuits, each configured to receive the respective input signal and the enhanced common reference signal, the respective alignment circuit time-aligning each input signal with the enhanced common reference signal to generate a time-aligned output signal; and a summing circuit configured to: add the respective time-aligned output signals and the enhanced common reference signal to generate an enhanced time-aligned output signal; and output the enhanced time-aligned output signal.<br>25) A non-transitory computer-readable storage medium comprising processor-executable instructions to enhance a multi-channel signal configured to: receive a plurality of input signals from an audio source device; enhance each of the input signals to generate respective enhanced output signals by adding a first periodic signal component in the input signal with a second periodic signal component in an output of the adaptive filter to increase the first periodic signal component in the input signal, the second periodic signal being at least partially in-phase with the second periodic signal component, each of the enhanced output signals comprising the increased first periodic signal component; align in time each of the enhanced output signals with a common reference signal to generate respective time-aligned output signals, the common reference signal based on an enhanced output signal having a highest signal-to-noise ratio; and sum the respective time-aligned output signals and the common reference signal to generate an enhanced time-aligned output signal.<br>16) A method for enhancing a signal, comprising: receiving a plurality of input signals from an audio source device; enhancing each of the input signals to generate respective enhanced output signals, where for each of the input signals, enhancing the input signal comprises: adding a first periodic signal component in the input signal with a second periodic signal component in an output of the adaptive filter to increase the first periodic signal component in the input signal, the second periodic signal component being at least partially in-phase with the first periodic signal component, the enhanced output signal comprising the increased first periodic signal component; aligning in time each of the enhanced output signals with a common reference signal to generate respective time-aligned output signals, the common reference signal based on an enhanced output signal having a highest signal-to-noise ratio; and summing the respective time-aligned output signals and the common reference signal to generate an enhanced time-aligned output signal.</p></layer>
<layer id = "layer622"><p><b>US5537509A:Comfort noise generation for digital communication systems</b><br>An endless power transmission belt comprising load carrier cord comprising a cord formed from a plurality of strands, wherein the strands comprise fibers of para-aramid and polyvinylpyrrolidone (PVP); and a method for increasing the flexural fatigue resistance and durability of an endless belt, comprising the step of selecting for the belt's load carrier cord a yarn comprising a fiber of para-aramid and PVP.<br><b>Independant Claims</b><br>1. A method of generating background noise during voice inactivity intervals in a communication system having a transmitter with an encoder for encoding and transmitting audio data, and a receiver remote from the transmitter with a decoder for receiving and decoding the transmitted audio data, said method comprising the steps of: encoding audio data in the transmitter and transmitting the encoded audio data to the receiver; detecting in the transmitter voice activity and voice inactivity; continuing transmission of encoded audio data during a predetermined time interval following each detection of voice inactivity; discontinuing transmission of encoded audio data at expiration of each said predetermined time interval; resuming transmission of encoded audio data upon detection in the transmitter of voice activity; decoding in the remote receiver the encoded audio data received from the transmitter; detecting in the remote receiver voice activity and voice inactivity at the transmitter; processing in the receiver the decoded audio data including data received during each said predetermined time interval after the detection of voice inactivity in the transmitter, the step of processing includes deriving a first series of output signals corresponding to an average loudness level of received noise, deriving a second series of output signals having spectral shape attributes corresponding to the received noise, combining the first and second series of derived signals to generate the audible analog audio representing background noise, the step of deriving includes weighting each of the first and second series of signals successively to vary the loudness level and spectral shape during periods of voice inactivity, the step of weighting each of the first and second series of signals includes multiplying each of the first series of signals by a first weighting factor and each of the second series of signals by a second weighting factor, the first and second weighting factors being varied to vary the loudness level and spectral shape, the first weighting factor is defined as a first variable .alpha. and the second weighting factor is defined as a second variable 1-.alpha.; and repeatedly generating audible analog audio representing background noise based upon the audio data processed during each said predetermined time interval until the resumption of transmission of the encoded audio data.<br>4. A system for generating comfort noise for a digital communication system during a period of voice inactivity immediately following a period of voice activity based on received data representing background noise during said period of voice activity, comprising: a synthesis codebook having a first table of values corresponding to long term estimates of background noise; an excitation codebook having a second table of values corresponding to long term estimates of spectrally flattened background noise; means including the received data during each said period of voice inactivity and values from the first table of the synthesis codebook for producing a first series of signals having a loudness level averaged over a plurality of frames of data; means including the received data during each said period of voice inactivity and the second table of values from the excitation codebook for producing a second series of signals having spectral shape attributes corresponding to the received data; means for combining the first and second series of signals to generate the background noise during said period of voice inactivity; means for deriving filter coefficients from the received data, wherein the means for producing the second series of signals includes an infinite impulse response filter for filtering values from the excitation codebook second table in accordance with the derived filter coefficients; means for scaling output signals of the infinite impulse response filter to produce the first series of signals, each having a loudness level corresponding to an average RMS level over a predetermined time period following voice inactivity and to produce the second series of signals each having a spectral shape corresponding to long term spectral shape of background noise with said loudness level; and means for weighting the first series and second series of signals to vary the loudness level and spectral shape periodically, including means for multiplying each of the first series of signals by a first weighting factor and each of the second series of signals by a second weighting factor, the first and second weighting factors being varied to vary the loudness level and spectral shape, wherein the first weighting factor is defined as a first variable .alpha. and the second weighting factor is defined as a second variable 1-.alpha..<br>6. A system for generating comfort noise for a digital communication system during a period of voice inactivity immediately following a period of voice activity based on received data representing background noise during said period of voice activity, comprising: a synthesis codebook having a first table of values corresponding to long term estimates of background noise; an excitation codebook having a second table of values corresponding to long term estimates of spectrally flattened background noise; means including the received data during each said period of voice inactivity and values from the first table of the synthesis codebook for producing a first series of signals having a loudness level averaged over a plurality of frames of data; means including the received data during each said period of voice inactivity and the second table of values from the excitation codebook for producing a second series of signals having spectral shape attributes corresponding to the received data; means for combining the first and second series of signals to generate the background noise during said period of voice inactivity wherein the means for producing the first and second series of signals includes means for weighting each of the signals of the first and second series of signals to vary the spectral shape and loudness level of the background noise, including means for multiplying each of the first series of signals by a first weighting factor and each of the second series of signals by a second weighting factor, the first and second weighting factors being varied to vary the loudness level and spectral shape wherein the first weighting factor is defined as a first variable .alpha. and the second weighting factor is defined as a second variable 1-.alpha..</p></layer>
<layer id = "layer623"><p><b>US5692104A:Method and apparatus for detecting end points of speech activity</b><br>A magnetic recording medium having a magnetic layer on one surface of a non-magnetic base and having as required a backcoat layer on the other surface, having at least one of p-tolyldiiodemethylsulfone, 2,3,3-triiodoallyl alcohol and 2-methoxycarbonylaminobenzimidazole and 2-methoxycarbonylaminobenzimidazolium salt as an anti-fungus agent on or in the magnetic layer and/or the backcoat layer.<br><b>Independant Claims</b><br>1. A method of detecting speech activity in a data input stream comprising the steps of: (a) generating a set of spectral representation vectors to represent the data input stream, wherein each spectral representation vector of the set of spectral representation vectors represents a predetermined portion of the data input stream; (b) generating a steady state spectral representation vector indicative of the state of the data input stream at a first predetermined portion of the data input stream; (c) comparing a spectral representation vector corresponding to the first predetermined portion of the data input stream to the steady state spectral representation vector; (d) determining a first end point of speech activity when the set of spectral representation vectors diverges from the steady state spectral representation vector; and (e) determining a second end point of speech activity when a predetermined number of spectral representation vectors of the set of spectral representation vectors are within a predetermined distance of the steady state spectral representation vector for a continuous predetermined period of time.<br>2. A method of detecting speech activity in a data input stream comprising the steps of: (a) generating a set of autocorrelation vectors to represent the data input stream, wherein each autocorrelation vector of the set of autocorrelation vectors represents a predetermined portion of the data input stream; (b) generating a steady state autocorrelation vector indicative of the state of the data input stream at a first predetermined portion of the data input stream; (c) comparing an autocorrelation vector corresponding to the first predetermined portion of the data input stream to the steady state autocorrelation vector; and (d) determining a first end point of speech activity when the set of autocorrelation vectors diverges from the steady state autocorrelation vector.<br>7. A method of detecting speech activity in a data input stream comprising the steps of: (a) generating a set of Fourier Transform vectors to represent the data input stream, wherein each Fourier Transform vector of the set of Fourier Transform vectors represents a predetermined portion of the data input stream; (b) generating a steady state Fourier Transform vector indicative of the state of the data input stream at a first predetermined portion of the data input stream; (c) comparing a Fourier Transform vector corresponding to the first predetermined portion of the data input stream to the steady state Fourier Transform vector; and (d) determining a first end point of speech activity when the set of Fourier Transform vectors diverges from the steady state Fourier Transform vector.<br>12. An apparatus for detecting speech activity in a data input stream comprising: a memory unit; an input device for receiving the data input stream; and a processor coupled to the memory unit and the input device, wherein the processor generates a set of spectral representation vectors to represent the data input stream and stores the set of spectral representation vectors in the memory unit, wherein each spectral representation vector of the set of spectral representation vectors represents a predetermined portion of the data input stream, wherein the processor also generates a steady state spectral representation vector indicative of the state of the data input stream at a first predetermined portion of the data input stream and compares a spectral representation vector corresponding to the first predetermined portion of the data input stream to the steady state spectral representation vector, determines a first end point of speech activity when the set of spectral representation vectors diverges from the steady state spectral representation vector, and determines a second end point of speech activity when a predetermined number of spectral representation vectors of the set of spectral representation vectors are within a predetermined distance of the steady state spectral representation vector for a continuous predetermined period of time.<br>13. An apparatus for detecting speech activity in a data input stream comprising: a memory unit; an input device for receiving the data input stream; a processor coupled to the memory unit and the input device, wherein the processor generates a set of autocorrelation vectors to represent the data input stream and stores the set of autocorrelation vectors in the memory unit, wherein each autocorrelation vector of the set of autocorrelation vectors represents a predetermined portion of the data input stream, wherein the processor also generates a steady state autocorrelation vector indicative of the state of the data input stream at a first predetermined portion of the data input stream and compares an autocorrelation vector corresponding to the first predetermined portion of the data input stream to the steady state autocorrelation vector, and determines a first end point of speech activity when the set of autocorrelation vectors diverges from the steady state autocorrelation vector.<br>17. An apparatus for detecting speech activity in a data input stream comprising: a memory unit; an input device for receiving the data input stream; a processor coupled to the memory unit and the input device, wherein the processor generates a set of Fourier Transform vectors to represent the data input stream and stores the set of Fourier Transform vectors in the memory unit, wherein each Fourier Transform vector of the set of Fourier Transform vectors represents a predetermined portion of the data input stream, wherein the processor also generates a steady state Fourier Transform vector indicative of the state of the data input stream at a first predetermined portion of the data input stream and compares a Fourier Transform vector corresponding to the first predetermined portion of the data input stream to the steady state Fourier Transform vector, and determines a first end point of speech activity when the set of Fourier Transform vectors diverges from the steady state Fourier Transform vector.<br>21. A method of detecting speech activity in a data input stream comprising the steps of: (a) generating a set of spectral representation vectors to represent a plurality of portions of the data input stream; (b) generating a steady state spectral representation vector indicative of the state of the data input stream at a first portion of the data input stream, wherein the first portion is one of the plurality of portions; (c) comparing a first spectral representation vector representing the first portion of the data input stream to the steady state spectral representation vector; and (d) determining a first end point of speech activity when the set of spectral representation vectors diverges from the steady state spectral representation vector.<br>25. An apparatus for detecting speech activity in a data input stream comprising: a memory unit an input device for receiving the data input stream; and a processor coupled to the memory unit and the input device, wherein the processor generates a set of spectral representation vectors to represent a plurality of portions of the data input stream and stores the set of spectral representation vectors in the memory unit, wherein the processor also generates a steady state spectral representation vector indicative of the state of the data input stream at a first portion of the data input stream, wherein the first portion is one of the plurality of portions, wherein the processor also compares a first spectral representation vector representing the first portion of the data input stream to the steady state spectral representation vector and determines a first end point of speech activity when the set of spectral representation vectors diverges from the steady state spectral representation vector.</p></layer>
<layer id = "layer624"><p><b>US20190156854A1:METHOD AND APPARATUS FOR DETECTING A VOICE ACTIVITY IN AN INPUT AUDIO SIGNAL</b><br><b>Independant Claims</b><br>10) An audio signal processing apparatus, comprising:one or more processors and a memory configured to store program instructions for execution by the processors;wherein the one or more processors, by executing the program instructions, are configured to:obtain a frame of an audio signal, wherein the frame comprises a plurality of sub-bands;determine a long term signal to noise ratio of the audio signal;calculate a sub-band specific parameter (sbsp) of each of N sub-bands using an adaptive function, wherein the sbsp of the ith sub-band sbsp(i) is calculated as follows:sbsp(i)=(ƒ(snr(i))+α)βwhere i is a sub-band index of the ith sub-band, snr(i) is a signal to noise ratio of the ith sub-band, (ƒ(snr(i))+α)β is the adaptive function, a is determined based on the sub-band index i and the long term signal to noise ratio of the audio signal, and β is a configurable variable;obtain a modified segmental signal to noise ratio (mssnr) by summing up the calculated sbsp of each sub-band;compare the mssnr with a threshold value (thr) to provide a voice activity detection decision (VADD), wherein the VADD is used to indicate that a voice activity is present or absent in the frame of the audio signal; andencode the audio signal based on the VADD.<br>1) An audio signal encoding method used by a signal processing apparatus comprising a processor and a memory, the method comprising:obtaining a frame of an audio signal, wherein the frame comprises a plurality of sub-bands;determining a long term signal to noise ratio of the audio signal;calculating a sub-band specific parameter (sbsp) of each sub-band using an adaptive function, wherein the sbsp of the ith sub-band sbsp(i) is calculated as follows:sbsp(i)=(ƒ(snr(i))+α)βwhere i is a sub-band index of the ith sub-band, snr(i) is a signal to noise ratio of the ith sub-band, (ƒ(snr(i))+α)β is the adaptive function, a is determined based on the sub-band index i and the long term signal to noise ratio of the audio signal, and β is a configurable variable;obtaining a modified segmental signal to noise ratio (mssnr) by summing up the calculated sbsp of each sub-band;comparing the mssnr with a threshold value (thr) to provide a voice activity detection decision (VADD), wherein the VADD is used to indicate that a voice activity is present or absent in the frame of the audio signal; andencoding the audio signal based on the VADD.</p></layer>
<layer id = "layer625"><p><b>US8073689B2:Repetitive transient noise removal</b><br>Embodiments of the present invention provide an approach for receiving true and complement clock signals at high or low frequencies into inputs of a divide-by-two quadrature divider, and providing true and complement clock signals, which are one-half the measured frequencies of the clock input signals, at the output of the quadrature divider. A tri-state clock mux coupled with combinatorial reset logic, with pull-up and pull-down devices at the output of the tri-sate clock mux, and/or pull-up and pull-down devices between the quadrature divider latches provide a defined logic state during startup at the input of the quadrature divider. The defined logic state ensures the output of the quadrature divider is metastability-free during high frequency application. Specifically, the quadrature divider has two output clock signals that are true and complement with measured frequencies that are one-half of the measured frequencies of the two clock input signals coming into the quadrature divider.<br><b>Independant Claims</b><br>1) A system for suppressing repetitive transient noises from a signal comprising: a repetitive transient noise detector that comprises a processor adapted to detect the presence of transient noise in a received signal comprising a harmonic spectrum and a noise spectrum, where the repetitive transient noise detector is adapted to analyze one or more frequency spectrum sound event characteristics and one or more temporal sound event characteristics of the transient noise to determine whether the transient noise is repetitive transient noise; and a repetitive transient noise attenuator adapted to dampen the transient noise detected in the received signal in response to the repetitive transient noise detector identifying the transient noise as being repetitive transient noise; where the repetitive transient noise detector is adapted to fit a function to a selected portion of the received signal in a time-frequency domain to evaluate spectro-temporal shape characteristics of a sound event in the received signal and to determine whether the transient noise is repetitive transient noise; and where the repetitive transient noise detector is adapted to identify the sound event as a repetitive transient noise event based on the function, a signal envelope of the sound event, and a correlation threshold that depends on a width and sharpness of the repetitive transient noise.<br>15) A repetitive transient noise detector for detecting the presence of repetitive noise in a signal, the repetitive transient noise detector comprising: an analog to digital converter for converting a received signal into a digital signal; a windowing function generator for dividing the received signal into a plurality of individual analysis windows; a transform module for transforming the individual analysis windows from a time domain spectra to a frequency domain spectra; a modeler that generates and stores attributes of repetitive transient noise in a memory; and a controller adapted to fit a function to a selected portion of the received signal in a time-frequency domain to evaluate spectro-temporal shape characteristics of a transient noise in the received signal and to determine whether the transient noise is repetitive transient noise, where the controller is adapted to identify the transient noise as a repetitive transient noise event based on the function, a signal envelope of the sound event, and a correlation threshold that depends on a width and sharpness of the repetitive transient noise; where the modeler is adapted to identify the transient noise for attenuation in response to the modeler determining that the transient noise is repetitive transient noise.<br>28) A method of attenuating repetitive transient noises from a signal comprising: fitting a function to a received signal in a time-frequency domain to evaluate spectro-temporal shape characteristics of a transient noise in the received signal and to determine whether the transient noise is repetitive transient noise; identifying the transient noise as a repetitive transient noise event based on the function, a signal envelope of the transient noise, and a correlation threshold that depends on a width and sharpness of the repetitive transient noise; and attenuating, by a processor, at least a portion of the transient noise from the received signal in response to identifying the transient noise as the repetitive transient noise event.<br>33) A system for suppressing repetitive transient noises from a signal comprising: a repetitive transient noise detector that comprises a processor adapted to fit a function to a received signal in a time-frequency domain to evaluate spectro-temporal shape characteristics of a transient noise in the received signal and to determine whether the transient noise is repetitive transient noise; and a repetitive transient noise attenuator adapted to dampen the transient noise in the received signal in response to the repetitive transient noise detector identifying the transient noise as being repetitive; where the repetitive transient noise detector is adapted to identify the transient noise as a repetitive transient noise event based on the function, a signal envelope of the transient noise, and a correlation threshold that depends on a width and sharpness of the repetitive transient noise.<br>34) A system for suppressing repetitive transient noises from a signal comprising: a repetitive transient noise detector that comprises a processor adapted to detect the presence of transient noise in a received signal comprising a harmonic spectrum and a noise spectrum, where the repetitive transient noise detector is adapted to fit a function to a selected portion of the received signal in a time-frequency domain to evaluate spectro-temporal shape characteristics of a sound event in the received signal and to determine whether the transient noise is repetitive transient noise, where the repetitive transient noise detector is adapted to identify the sound event as a repetitive transient noise event based on a correlation between the function and a signal envelope of the sound event; and a repetitive transient noise attenuator adapted to dampen the transient noise detected in the received signal in response to the repetitive transient noise detector identifying the transient noise as being repetitive transient noise; where the repetitive transient noise detector is adapted to identify the sound event as the repetitive transient noise event based on the function, the signal envelope of the sound event, and a correlation threshold that depends on a width and sharpness of the repetitive transient noise.</p></layer>
<layer id = "layer626"><p><b>US8612222B2:Signature noise removal</b><br>Disclosed are example methods and systems to determine the quantity of an analyte initially present in a chemical and or biological reaction. Also disclosed are computer implemented methods and systems to automate portions of the analysis comprising mathematical or graphical analysis of an amplification reaction.<br><b>Independant Claims</b><br>1) A noise detection system, comprising: a computer memory that stores a noise model that includes spectral and temporal shape characteristics of a noise; and a processor coupled with the computer memory; where the processor is configured to access the noise model from the computer memory and analyze a signal to determine whether characteristics of the signal correspond to characteristics of the noise model; where the processor is configured to fit the noise model to the signal in a time-frequency domain to evaluate spectral and temporal shape characteristics of a sound event in the signal; where the processor is configured to identify the sound event as a noise event based on a correlation between the noise model and a signal envelope of the sound event; and where the processor is configured to model individual sound events that make up the noise of the noise model, and model a temporal space between the individual sound events.<br>13) A non-transitory computer-readable medium with instructions stored thereon, where the instructions are executable by a processor to cause the processor to perform the steps of: accessing a noise model that includes spectral and temporal shape characteristics of a noise; analyzing a signal to determine whether characteristics of the signal correspond to characteristics of the noise model; fitting the noise model to the signal in a time-frequency domain to evaluate spectral and temporal shape characteristics of a sound event in the signal; identifying the sound event as a noise event based on a correlation between the noise model and a signal envelope of the sound event; modeling individual sound events that make up the noise of the noise model; and modeling a temporal space between the individual sound events.<br>7) A noise detection method, comprising: accessing, by a processor, a computer memory that stores a noise model that includes spectral and temporal shape characteristics of a noise; analyzing a signal to determine whether characteristics of the signal correspond to characteristics of the noise model; fitting, by the processor, the noise model to the signal in a time-frequency domain to evaluate spectral and temporal shape characteristics of a sound event in the signal; identifying, by the processor, the sound event as a noise event based on a correlation between the noise model and a signal envelope of the sound event; and modeling individual sound events that make up the noise of the noise model; and modeling a temporal space between the individual sound events.</p></layer>
<layer id = "layer627"><p><b>US8880410B2:Apparatus and method for generating a bandwidth extended signal</b><br><b>Independant Claims</b><br>1) An apparatus for generating a bandwidth extended signal from an input signal, wherein the input signal is represented, for a first band by a first resolution data, and for a second band by a second resolution data, the second resolution being lower than the first resolution, the apparatus comprising: a patch generator configured to generate a first patch from the first band of the input signal according to a first patching algorithm and configured to generate a second patch from the first band of the input signal according to a second patching algorithm, wherein a spectral density of the second patch generated according to the second patching algorithm is higher than a spectral density of the first patch generated according to the first patching algorithm; and a combiner configured to combine the first patch, the second patch and the first band of the input signal to acquire the bandwidth extended signal, wherein the apparatus for generating a bandwidth extended signal is configured to scale the input signal according to the first patching algorithm and according to the second patching algorithm or to scale the first patch and the second patch, or to scale only one of the first and second patches to obtain a scaled patch, to then combine the scaled patch and a non-scaled patch from the first and second patches to obtain combined patches, and to then scale the combined patches before combining the combined patches with the first band of the input signal, so that the bandwidth extended signal fulfills a spectral envelope criterion.<br>11) An apparatus for providing a bandwidth reduced signal based on an input signal, comprising: a spectral envelope data determiner configured to determine spectral envelope data based on a high-frequency band of the input signal; a patch scaling control data generator configured to generate patch scaling control data for scaling the bandwidth reduced signal at a decoder or for scaling a first patch and a second patch by the decoder, so that a bandwidth extended signal generated by the decoder fulfills a spectral envelope criterion, wherein the spectral envelope criterion is based on the spectral envelope data wherein the first patch is generated from a first band of the bandwidth reduced signal according to a first patching algorithm and the second patch is generated from the first band of the bandwidth reduced signal according to a second patching algorithm, wherein a spectral density of the second patch generated according to the second patching algorithm is higher than a spectral density of the first patch generated according to the first patching algorithm; an output interface configured to combine a low frequency band of the input signal, the spectral envelope data and the patch scaling control data to acquire the bandwidth reduced signal and configured to provide the bandwidth reduced signal for transmission or storage.<br>14) A method for generating a bandwidth extended signal from an input signal, wherein the input signal is represented, for a first band by a first resolution data, and for a second band by a second resolution data, the second resolution being lower than the first resolution, the method comprising: generating a first patch from the first band of the input signal according to a first patching algorithm; generating a second patch from the first band of the input signal according to a second patching algorithm, wherein a spectral density of the second patch generated according to the second patching algorithm is higher than a spectral density of the first patch generated according to the first patching algorithm; scaling the input signal according to the first patching algorithm and according to the second patching algorithm or scaling the first patch and the second patch, so that the bandwidth extended signal fulfills the spectral envelope criterion or scaling only one of the first and second patches to obtain a scaled patch, and then combining the scaled patch and a non-scaled patch from the first and second patches to obtain combined patches, and then scaling the combined patches before combining the combined patches with the first band of the input signal; and combining the first patch, the second patch or the combined patches and the first band of the input signal to acquire the bandwidth extended signal.<br>15) A method for providing a bandwidth reduced signal based on an input signal, comprising: determining a spectral envelope data based on a high frequency band of the input signal; generating patch scaling control data for scaling the bandwidth reduced signal at a decoder or for scaling a first patch and a second patch by the decoder, so that a bandwidth extended signal generated by the decoder fulfills a spectral envelope criterion, wherein the spectral envelope criterion is based on the spectral envelope data, wherein the first patch is generated from a first band of the bandwidth reduced signal according to a first patching algorithm and a second patch is generated from the first band of the bandwidth reduced signal according to a second patching algorithm, wherein a spectral density of the second patch generated according to the second patching algorithm is higher than a spectral density of the first patch generated according to the first patching algorithm; combining a low frequency band of the input signal, the spectral envelope data and the patch scaling control data to acquire the bandwidth reduced signal; providing the bandwidth reduced signal for a transmission or storage.<br>16) A non-transitory storage medium having stored thereon a computer program with a program code for performing the method for generating a bandwidth extended signal from an input signal, wherein the input signal is represented, for a first band by a first resolution data, and for a second band by a second resolution data, the second resolution being lower than the first resolution, the method comprising: generating a first patch from the first band of the input signal according to a first patching algorithm; generating a second patch from the first band of the input signal according to a second patching algorithm, wherein a spectral density of the second patch generated according to the second patching algorithm is higher than a spectral density of the first patch generated according to the first patching algorithm; scaling the input signal according to the first patching algorithm and according to the second patching algorithm or scaling the first patch and the second patch, so that the bandwidth extended signal fulfills the spectral envelope criterion or scaling only one of the first and second patches to obtain a scaled patch, and then combining the scaled patch and a non-scaled patch from the first and second patches to obtain combined patches, and then scaling the combined patches before combining the combined patches with the first band of the input signal; and combining the first patch, the second patch or the combined patches and the first band of the input signal to acquire the bandwidth extended signal, when the computer program runs on a computer or a microcontroller.<br>17) A non-transitory storage medium having stored thereon a computer program with a program code for performing the method for providing a bandwidth reduced signal based on an input signal, the method comprising: determining a spectral envelope data based on a high frequency band of the input signal; generating patch scaling control data for scaling the bandwidth reduced signal at a decoder or for scaling a first patch and a second patch by the decoder, so that a bandwidth extended signal generated by the decoder fulfills a spectral envelope criterion, wherein the spectral envelope criterion is based on the spectral envelope data, wherein the first patch is generated from a first band of the bandwidth reduced signal according to a first patching algorithm and a second patch is generated from the first band of the bandwidth reduced signal according to a second patching algorithm, wherein a spectral density of the second patch generated according to the second patching algorithm is higher than a spectral density of the first patch generated according to the first patching algorithm; combining a low frequency band of the input signal, the spectral envelope data and the patch scaling control data to acquire the bandwidth reduced signal; providing the bandwidth reduced signal for a transmission or storage, when the computer program runs on a computer or a microcontroller.</p></layer>
<layer id = "layer628"><p><b>US8805695B2:Bandwidth expansion method and apparatus</b><br>A droplet ejection head according to the present invention includes a layered body made up of a plurality of metal plates, and an ejection face. The plurality of metal plates in the layered body include n metal plates whose lengthwise directions form the same angle with a rolling direction thereof. The n metal plates include a first stress plate and a second stress plate. The first stress plate has internal stress which forces the metal plate to bend along its lengthwise direction so as to make it protrude toward a ejecting direction. The second stress plate has internal stress which forces the metal plate to bend along its lengthwise direction so as to make it protrude toward a direction opposite to the ejecting direction.<br><b>Independant Claims</b><br>1) A bandwidth expansion method, comprising: estimating a bandwidth of at least one previously decoded frame of a whole-band signal, so as to obtain an estimated bandwidth; wherein the estimated bandwidth is used as the estimated bandwidth of a current frame of a lower-band signal; performing bandwidth expansion for the lower-band signal by using different predictive decoding on the lower-band signal according to an effective bandwidth of the lower-band signal and the estimated bandwidth, comprising: performing first predictive decoding on a part of the lower-band signal in a band above an effective bandwidth of the lower-band signal and below the estimated bandwidth, so as to obtain the part of the lower-band signal above the effective bandwidth of the lower-band signal and below the estimated bandwidth; and performing second predictive decoding on a part of the lower-band signal in a band above the estimated bandwidth, so as to obtain the part of the lower-band signal above the estimated bandwidth.<br>10) A bandwidth expansion apparatus, comprising a processor, an estimation unit coupled to the processor, and a predictive decoding unit coupled to the processor; the estimation unit is configured to estimate a bandwidth of at least one previously decoded frame of a whole-band signal, so as to obtain an estimated bandwidth; wherein the estimated bandwidth is used as the estimated bandwidth of a current frame of a lower-band signal; and the predictive decoding unit is configured to perform bandwidth expansion for the lower-band signal by using different predictive decoding on the lower-band signal according to an effective bandwidth of the lower-band signal and the estimated bandwidth, comprising: a first predictive decoding sub-unit, configured to perform first predictive decoding on a part of the lower-band signal in a band above an effective bandwidth of the lower-band signal and below the estimated bandwidth, so as to obtain the part of the lower-band signal above the effective bandwidth of the lower-band signal and below the estimated bandwidth; and a second predictive decoding sub-unit, configured to perform second predictive decoding on a part of the lower-band signal in a band above the estimated bandwidth, so as to obtain the part of the lower-band signal above the estimated bandwidth.</p></layer>
<layer id = "layer629"><p><b>US9800453B2:Method and apparatus for providing speech coding coefficients using re-sampled coefficients</b><br><b>Independant Claims</b><br>1) A method for providing signal processing coefficients for processing an input signal at a predetermined signal processing sampling rate, wherein the input signal is received at an input signal sampling rate, the method comprising: computing a correlation or covariance function based on the received input signal at the input signal sampling rate to provide first correlation or covariance coefficients at the input signal sampling rate, wherein the input signal comprises an audio signal; re-sampling the computed first correlation or covariance coefficients having the input signal sampling rate to provide second correlation or covariance coefficients at the predetermined signal processing sampling rate; calculating the signal processing coefficients based on the second correlation or covariance coefficients at the predetermined signal processing sampling rate; and coding a re-sampled input signal using the calculated signal processing coefficients, wherein the re-sampled input signal is the input signal re-sampled at a second input signal sampling rate.<br>11) An apparatus for providing signal processing coefficients for processing an input signal at a predetermined signal processing sampling rate, the apparatus comprising: a transducer for receiving the input signal, wherein the input signal comprises an audio signal; a non-transitory computer-readable storage medium including computer-executable instructions for causing the apparatus to perform the method comprising:computing a correlation or covariance function based on the received input signal at an input signal sampling rate to provide first correlation or covariance coefficients at the input signal sampling rate,re-sampling the computed first correlation or covariance coefficients having the input signal sampling rate to provide second correlation or covariance coefficients at the predetermined signal processing sampling rate,calculating the signal processing coefficients based on the second correlation or covariance coefficients at the predetermined signal processing sampling rate, and coding a re-sampled input signal using the calculated signal processing coefficients, wherein the re-sampled input signal is the input signal re-sampled at a second input signal sampling rate.<br>13) A signal processing device comprising: a non-transitory computer-readable storage medium including computer-executable instructions for causing the device to perform the method comprising: computing a correlation or covariance function based on an input signal at an input signal sampling rate to provide first correlation or covariance coefficients at the input signal sampling rate wherein the input signal comprises an audio signal, re-sampling the computed first correlation or covariance coefficients having the input signal sampling rate to provide second correlation or covariance coefficients at the predetermined signal processing sampling rate, calculating the signal processing coefficients based on the second correlation or covariance coefficients at the predetermined signal processing sampling rate, and coding a re-sampled input signal using the calculated signal processing coefficients, wherein the re-sampled input signal is the input signal re-sampled at a second input signal sampling rate.</p></layer>
<layer id = "layer630"><p><b>US9117455B2:Adaptive voice intelligibility processor</b><br><b>Independant Claims</b><br>1) A method of adjusting a voice intelligibility enhancement, the method comprising: receiving an input voice signal; obtaining a spectral representation of the input voice signal with a linear predictive coding (LPC) process, the spectral representation comprising one or more formant frequencies; adjusting the spectral representation of the input voice signal with one or more processors to produce an enhancement filter configured to emphasize the one or more formant frequencies, wherein the adjusting comprises decreasing a distance between line spectral pairs of at least one formant frequency obtained from the LPC process and thereby increasing a gain of a spectral peak associated with the at least one formant frequency; applying an inverse filter to the input voice signal to obtain an excitation signal; applying the enhancement filter to the excitation signal to produce a first modified voice signal with enhanced formant frequencies; applying the enhancement filter to the input voice signal to produce a second modified voice signal; combining at least a portion of the first modified voice signal with at least a portion of the second modified voice signal to produce a combined modified voice signal; detecting an envelope based on the input voice signal; analyzing the detected envelope to determine one or more temporal enhancement parameters; applying the one or more temporal enhancement parameters to the combined modified voice signal to emphasize peaks in one or more time domain envelopes of the combined modified voice signal by increasing a slope of the peaks to produce an output voice signal with emphasized consonant sounds; and output the output voice signal for playback; wherein at least said applying the one or more temporal enhancement parameters is performed by one or more processors.<br>13) A system for adjusting a voice intelligibility enhancement, the system comprising: a linear predictive coding analysis module configured to apply a linear predictive coding (LPC) technique to obtain LPC coefficients that correspond to a spectrum of an input voice signal, the spectrum comprising one or more formant frequencies; a mapping module configured to map the LPC coefficients to line spectral pairs; a formant enhancement module configured to modify the line spectral pairs with one or more processors by at least applying a modulation factor to the line spectral pairs to decrease a distance between the line spectral pairs and thereby produce an enhancement filter configured to emphasize the formant frequency; an inverse filter configured to be applied to the input audio signal to obtain an excitation signal; the enhancement filter configured to be applied to the excitation signal to produce a first modified voice signal, the enhancement filter further configured to be applied to the input voice signal to produce a second modified voice signal; a combiner configured to combine at least a portion of the first modified voice signal with at least a portion of the second modified voice signal to produce a combined modified voice signal; and an output module configured to output an audio signal based on the combined modified voice signal for playback.<br>3) A system for adjusting a voice intelligibility enhancement, the system comprising: an analysis module configured to obtain a spectral representation of at least a portion of an input audio signal, the spectral representation comprising one or more formant frequencies; an inverse filter configured to be applied to the input audio signal to obtain an excitation signal; a formant enhancement module configured to generate an enhancement filter configured to emphasize the one or more formant frequencies, wherein the enhancement filter is configured to decrease a distance between line spectral pairs of at least one formant frequency and thereby increase a gain of a spectral peak associated with the at least one formant frequency; the enhancement filter configured to be applied to the excitation signal with one or more processors to produce a first modified voice signal, the enhancement filter further configured to be applied to the input audio signal with the one or more processors to produce a second modified voice signal; a combiner configured to combine at least a portion of the first modified voice signal with at least a portion of the second modified voice signal to produce a combined modified voice signal; a temporal enveloper shaper configured to apply a temporal enhancement to one or more time domain envelopes of the combined modified voice signal with the one or more processors to produce an output signal, the temporal enhancement configured to emphasize peaks in the one or more time domain envelopes by increasing a slope of the peaks to thereby emphasize one or more consonant sounds in the combined modified voice signal; and an output module configured to output the output signal for playback.</p></layer>
<layer id = "layer631"><p><b>US9009036B2:Methods and systems for bit allocation and partitioning in gain-shape vector quantization for audio coding</b><br><b>Independant Claims</b><br>1) A computer-implemented method of coding an audio signal using gain-shape vector quantization, comprising: organizing coefficients representing audio content into one or more bands; dividing each band into a gain and a shape; determining, in a processor-based device processing the audio content, a number of bits to use for the gain using an approximation method, wherein a size of a codebook dictates a total number of bits to allocate between the gain and the shape; subtracting, in the processor-based device, the number of bits allocated to the gain from the total number of bits to determine a number of bits to allocate to the shape; determining if the number of bits allocated to the shape is less than a defined maximum number of bits used in the codebook; and recursively dividing the band into substantially equal size partitions until the number of bits allocated to the shape in each partition is less than the defined number.<br>10) A computer-implemented method of coding an audio signal using gain-shape vector quantization, comprising: organizing coefficients representing audio content into one or more bands; dividing each band into a gain and a shape; determining, in processor-based device processing the audio content, a number of bits to use for the gain using an approximation method for large factorials that approximates a size of a codebook to use for the gain, wherein the size of the codebook dictates a total number of bits to allocate between the gain and the shape; subtracting, in the processor-based device, the number bits allocated to the gain from the total number of bits to determine a number of bits to allocate to the shape; and quantizing the gain using an A-law quantizer, and quantizing the shape using an optimal spherical quantizer.<br>17) A system for coding an audio signal in an audio codec utilizing gain-shape vector quantization, comprising: a first component organizing coefficients representing audio content into one or more bands and dividing each band into a gain and a shape; a gain shape allocation component determining a number of bits to use for the gain using an approximation method, wherein the size of the codebook dictates a total number of bits to allocate between the gain and the shape, and subtracting, in the processor-based device, the number bits allocated to the gain from the total number of bits to determine a number of bits to allocate to the shape; and a band partitioning and allocation component determining if the number of bits allocated to the shape is less than a defined maximum number of bits used in the codebook, and recursively dividing the band into substantially equal size partitions until the number of bits allocated to the shape in each partition is less than the defined number.</p></layer>
<layer id = "layer632"><p><b>US9620130B2:System and method for processing sound signals implementing a spectral motion transform</b><br><b>Independant Claims</b><br>1) A system configured to process a sound signal, the system comprising: one or more physical computer processors configured by machine-readable instructions to: transform a signal portion of a sound signal into a frequency-chirp domain, wherein the signal portion corresponds to a time window that is larger than a sampling frequency of the signal potion, wherein the frequency-chirp domain representation of the signal portion specifies a transform coefficient as a function of frequency and fractional chirp rate for the signal portion, and wherein the fractional chirp rate is chirp rate divided by frequency; and generate, based on the transformed signal portion, a first sound parameter of an individual harmonic sound represented in the sound signal.<br>10) A method of processing a sound signal, the method comprising: transforming a signal portion of a sound signal into a frequency-chirp domain, wherein the signal portion corresponds to a time window that is larger than a sampling frequency of the signal potion, wherein the frequency-chirp domain representation of a given signal portion specifies a transform coefficient as a function of frequency and fractional chirp rate for the signal portion, and wherein fractional chirp rate is chirp rate divided by frequency; and generating, based on the transformed signal portion, a first sound parameter of an individual harmonic sound represented in the sound signal.<br>19) Non-transitory, machine-readable electronic storage media that stores processor-executable instructions for performing a method of processing a sound signal, the method comprising: transforming a signal portion of a sound signal into a frequency-chirp domain, wherein the signal portion corresponds to a time window that is larger than a sampling frequency of the signal potion, wherein the frequency-chirp domain representation of a given signal portion specifies a transform coefficient as a function of frequency and fractional chirp rate for the signal portion, and wherein fractional chirp rate is chirp rate divided by frequency; and generating, based on the transformed signal portion, a first sound parameter of an individual harmonic sound represented in the sound signal.</p></layer>
<layer id = "layer633"><p><b>US9805738B2:Formant dependent speech signal enhancement</b><br><b>Independant Claims</b><br>1) A computer-implemented method employing at least one hardware implemented computer processor for speech signal processing comprising: receiving an input microphone signal having a speech signal component and a noise component; transforming the microphone signal into a frequency domain set of short term spectra signals; estimating speech formant components within the spectra signals based on detecting regions of high energy density in the spectra signals; applying one or more dynamically adjusted gain factors to the spectra signals to enhance the speech formant components only during voiced speech phonemes and on the speech formant components having signal-to-noise ratio above a threshold; adjusting the gain factors around a center frequency of the speech formant components based upon a presumed reliability of the estimation of the speech formant components, including adjusting the gain factors to boost the speech formant components more for higher reliability formant estimations than lower reliability formant estimations; and requiring a minimum clearance between ones of the speech formant components.<br>13) A speech signal processing system comprising: a speech signal input for receiving a microphone signal having a speech signal component and a noise component; a signal pre-processor for transforming the microphone signal into a frequency domain set of short term spectra signals; a formant estimating module for estimating speech formant components within the spectra signals based on detecting regions of high energy density in the spectra signals; and a formant enhancement module for applying one or more dynamically adjusted gain factors to the spectra signals to enhance the speech formant components only during voiced speech phonemes and on the speech formant components having signal-to-noise ratio above a threshold and for adjusting the gain factors around a center frequency of the speech formant components based upon a presumed reliability of the estimation of the speech formant components, wherein the gain factors are adjusted to boost the speech formant components more for higher reliability formant estimations than lower reliability formant estimations, and wherein there is a minimum clearance between ones of the speech formant components.</p></layer>
<layer id = "layer634"><p><b>US9858934B2:Audio-encoding method and apparatus, audio-decoding method and apparatus, recoding medium thereof, and multimedia device employing same</b><br><b>Independant Claims</b><br>1) An audio decoding method comprising: receiving a bitstream including a coded quantization differential index of an envelope of a sub-band in an audio spectrum; and lossless decoding a coded quantization differential index of a current sub-band, by referring one of a plurality of tables based on a context which is obtained from a decoded quantization differential index of a previous sub-band, wherein the one of the plurality of tables is selected by one among a plurality of groups which are determined by the context.<br>7) An audio decoding apparatus comprising: at least one processor configured to: receive a bitstream including a coded quantization differential index of an envelope of a sub-band in an audio spectrum; and lossless decode a coded quantization differential index of a current sub-band, by referring one of a plurality of tables based on a context which is obtained from a decoded quantization differential index of a previous sub-band, wherein the one of the plurality of tables is selected by one among a plurality of groups which are determined by the context.</p></layer>
<layer id = "layer635"><p><b>US20140046672A1:Signal Classification Method and Device, and Encoding and Decoding Methods and Devices</b><br>Methods of providing a diagnosis using a digital code associated with an image are provided including collecting a multidimensional image, the multidimensional image having at least two dimensions; extracting a two dimensional subset of the multidimensional image; reducing the multidimensional image to a first code that is unique to the multidimensional image based on the extracted two dimensional image; comparing the first unique code associated with the subject to a library of reference codes, each of the reference codes in the library of reference codes being indicative of a class of objects; determining if the subject associated with the first unique code falls into at least one of the classes of objects associated with the reference codes based on a result of the comparison; and formulating a diagnostic decision based on the whether the first unique code associated with the subject falls into at least one of the classes associated with the reference code. Related systems and computer program products are also provided herein.<br><b>Independant Claims</b><br>29. A signal classification device for processing speech/audio signals, comprising: a processor; a division unit controlled by the processor, configured to divide a current frame into a low-frequency band signal and a high-frequency band signal; a judgment unit controlled by the processor, configured to determine, according to a value requirement of a preset encoding/decoding characteristic parameter corresponding to a signal class, whether an encoding/decoding characteristic parameter of the current frame corresponding to the signal class meets the value requirement of the encoding/decoding characteristic parameter; and a determination unit controlled by the processor, configured to determine a signal class of the high-frequency band signal of the current frame according to a determining result.<br>1. An encoding method for processing speech/audio signals, comprising: dividing, by an encoder, a current frame into a low-frequency band signal and a high-frequency band signal, wherein the encoder comprises a processor; attenuating, by the encoder, a one of the group consisting of the high-frequency band signal and a to-be-encoded characteristic parameter of the high-frequency band signal, the attenuating being according to an energy attenuation value of the low-frequency band signal, and wherein the energy attenuation value indicates energy attenuation of the low-frequency band signal caused by encoding of the low-frequency band signal; and encoding, by the encoder, the one of the group consisting of the attenuated high-frequency band signal and the attenuated to-be-encoded characteristic parameter of the high-frequency band signal.<br>11. An encoding device for processing speech/audio signals, comprising: a processor; a division unit controlled by the processor, configured to divide a current frame into a low-frequency band signal and a high-frequency band signal; a correction unit controlled by the processor, configured to attenuate a one of the group consisting of the high-frequency band signal and a to-be-encoded characteristic parameter of the high-frequency band signal according to an energy attenuation value of the low-frequency band signal, wherein the energy attenuation value indicates energy attenuation of the low-frequency band signal caused by encoding of the low-frequency band signal of the current frame; and an encoding unit controlled by the processor, configured to encode the one of the group consisting of the attenuated high-frequency band signal and the attenuated to-be-encoded characteristic parameter of the high-frequency band signal.<br>21. A signal classification method for processing speech/audio signals, comprising: dividing, by an encoder, a current frame into a low-frequency band signal and a high-frequency band signal, wherein the encoder comprises a processor; determining, by the encoder, according to a value requirement of a preset encoding/decoding characteristic parameter corresponding to a signal class, whether an encoding/decoding characteristic parameter of the current frame corresponding to the signal class meets the value requirement of the encoding/decoding characteristic parameter; and determining, by the encoder, a signal class of the high-frequency band signal of the current frame according to a determining result.<br>6. A decoding method for processing speech/audio signals, comprising: decoding, by a decoder, a bit stream to obtain a one of the group consisting of (a) a high-frequency band signal of a current frame and (b) a characteristic parameter of the high-frequency band signal of the current frame, wherein the decoder comprises a processor; and attenuating, by the decoder, the one of the group consisting of (a) the high-frequency band signal and (b) the characteristic parameter of the high-frequency band signal according to an energy attenuation value of a low-frequency band signal of the current frame, wherein the energy attenuation value indicates energy attenuation of the low-frequency band signal caused by encoding of the low-frequency band signal.<br>16. A decoding device for processing speech/audio signals, comprising: a processor; a decoding unit controlled by the processor, configured to decode a bit stream to obtain a one of the group consisting of a high-frequency band signal of a current frame and a characteristic parameter of the high-frequency band signal of the current frame; and a correction unit controlled by the processor, configured to attenuate the one of the group consisting of the high-frequency band signal and the characteristic parameter of the high-frequency band signal according to an energy attenuation value of a low-frequency band signal of the current frame, wherein the energy attenuation value indicates energy attenuation of the low-frequency band signal caused by encoding of the low-frequency band signal of the current frame.</p></layer>
<layer id = "layer636"><p><b>US10083698B2:Packet loss concealment for speech coding</b><br><b>Independant Claims</b><br>8) An apparatus, comprising: an audio signal input interface, configured to receive a sound signal and convert the sound signal into a digital audio signal, wherein the digital audio signal comprises multiple frames, and each frame comprises a plurality of subframes; and a processor for encoding the digital audio signal frame-by-frame, wherein the processor is configured to:for a current frame that is to be encoded, obtain an excitation of the current frame according to a reduced or limited pitch gain value of a first subframe of a previous frame, wherein the current frame is successive to the previous frame, and wherein the reduced or limited pitch gain value of the first subframe of the previous frame is obtained by reducing or limiting an initial pitch gain value of the first subframe of the previous frame; andencode the current frame of the digital audio signal according to the excitation of the current frame; wherein the apparatus further comprises a network interface, configured to output the encoded digital audio signal to a wide area network (WAN), a public switched telephone network (PSTN), or the Internet.<br>1) A method for encoding an audio signal, wherein the audio signal is encoded frame-by-frame by an encoder, and each frame comprises a plurality of subframes, the method comprising: for a current frame that is to be encoded, obtaining an excitation of the current frame according to a reduced or limited pitch gain value of a first subframe of a previous frame, wherein the current frame is successive to the previous frame, and wherein the reduced or limited pitch gain value of the first subframe of the previous frame is obtained by reducing or limiting an initial pitch gain value of the first subframe of the previous frame; and encoding the current frame of the audio signal according to the excitation of the current frame, wherein the encoded audio signal is transmitted to a wide area network (WAN), a public switched telephone network (PSTN), or the Internet.</p></layer>
<layer id = "layer637"><p><b>US9183850B2:System and method for tracking sound pitch across an audio signal</b><br><b>Independant Claims</b><br>1) A method for analyzing an audio signal, the method comprising: obtaining, using a computer processor, a first pitch and a first fractional chirp rate from a first portion of the audio signal; determining, using the computer processor, a predicted pitch corresponding to the first pitch in a second portion of the audio signal, the predicted pitch being determined using the first pitch, the first fractional chirp rate, a first time corresponding to the first portion, and a second time corresponding to the second portion; obtaining, using the computer processor, a pitch likelihood metric in a multi-dimensional representation for the second portion of the audio signal; determining, using the computer processor, a weighting function using the predicted pitch; determining, using the computer processor, a weighted pitch likelihood metric using the pitch likelihood metric and the weighting function; and determining, using the computer processor, a second pitch from the second portion of the audio signal using the weighted pitch likelihood metric.<br>17) A non-transitory computer readable storage medium having data stored therein representing computer program modules executable by a computer, the computer program modules including instructions to track pitch in an audio signal, the storage medium comprising: instructions for obtaining a first pitch and a first fractional chirp rate from a first portion of the audio signal; instructions for determining a predicted pitch corresponding to the first pitch in a second portion of the audio signal, the predicted pitch being determined using the first pitch, the first fractional chirp rate, a first time corresponding to the first portion, and a second time corresponding to the second portion; instructions for obtaining a pitch likelihood metric in a multi-dimensional representation for the second portion of the audio signal; instructions for determining a weighting function using the predicted pitch; instructions for determining a weighted pitch likelihood metric using the pitch likelihood metric and the weighting function; and instructions for determining a second pitch from the second portion of the audio signal using the weighted pitch likelihood metric.<br>9) A system configured to analyze an audio signal, the system comprising: an electronic storage storing computer program modules that include computer program instructions; and one or more processors coupled to the electronic storage and configured to execute the computer program instructions to: obtain a first pitch and a first fractional chirp rate from a first portion of the audio signal; determine a predicted pitch corresponding to the first pitch in a second portion of the audio signal, the predicted pitch being determined using the first pitch, the first fractional chirp rate, a first time corresponding to the first portion, and a second time corresponding to the second portion; obtain a pitch likelihood metric in a multi-dimensional representation for the second portion of the audio signal; determine a weighting using the predicted pitch; determine a weighted pitch likelihood metric using the pitch likelihood metric and the weighting function; and determine a second pitch from the second portion of the audio signal using the weighted pitch likelihood metric.</p></layer>
<layer id = "layer638"><p><b>US9473866B2:System and method for tracking sound pitch across an audio signal using harmonic envelope</b><br><b>Independant Claims</b><br>1) A system configured to track pitch in an audio signal, the system comprising: an electronic storage storing computer program modules; and one or more processors configured to execute the computer program modules, the computer program modules being configured to: receive the audio signal obtained from a user input device; obtain a first transformation of the audio signal in a first time period, wherein the first transformation represents the audio signal as a function of frequency in the first time period; obtain a first pitch corresponding to a first sound in the first time period of the audio signal; determine a first envelope vector of the first time period from the first transformation in a multi-dimensional space, wherein each dimension of the multi-dimensional space corresponds to one of a plurality of harmonics of a pitch and the first envelope vector of the first time period is defined by a first set of coordinates corresponding to intensity coefficients at a plurality of harmonics of the first pitch in the first transformation; obtain a second transformation of the audio signal in a second time period, wherein the second time period is different from the first time period and the second transformation represents the audio signal as a function of frequency in the second time period; obtain a second pitch corresponding to a second sound in the second time period of the audio signal; determine a second envelope vector of the second time period from the second transformation in the multi-dimensional space, wherein the second envelope vector of the second time period is defined by a second set of coordinates corresponding to intensity coefficients at a plurality of harmonics of the second pitch in the second transformation; determine a first correlation between the first envelop vector of the first time period and the second envelope vector of the second time period; obtain a third pitch corresponding to a third sound in the second time period of the audio signal; determine a third envelope vector of the second time period from the second transformation in the multi-dimensional space, wherein the third envelope vector of the second time period is defined by a third set of coordinates corresponding to intensity coefficients at a plurality of harmonics of the third pitch in the second transformation; determine a second correlation between the first envelop vector of the first time period and the third envelope vector of the second time period; and determine, using the first correlation and the second correlation, that the first sound in the first time period of the audio signal and the second sound in the second time period of the audio signal are portions of a same harmonic sound.<br>17) A non-transitory computer readable storage medium having data stored therein representing computer program modules executable by a computer, the computer program modules including instructions to track pitch in an audio signal, the storage medium comprising: instructions for receiving the audio signal obtained from a user input device; instructions for obtaining a first transformation of the audio signal in a first time period, wherein the first transformation represents the first portion of the audio signal as a function of frequency in the first time period; instructions for obtaining a first pitch corresponding to a first sound in the first time period of the audio signal; instructions for determining a first envelope vector of the first time period from the first transformation in a multi-dimensional space, wherein each dimension of the multi-dimensional space corresponds to one of a plurality of harmonics of a pitch and the first envelope vector of the first time period is defined by a first set of coordinates corresponding to intensity coefficients at a plurality of harmonics of the first pitch in the first transformation; instructions for obtaining a second transformation of the audio signal in a second time period, wherein the second time period is different from the first time period and the second transformation represents the second portion of the audio signal as a function of frequency in the second time period; instructions for obtaining a second pitch corresponding to a second sound in the second time period of the audio signal; instructions for determining a second envelope vector of the second time period from the second transformation in the multi-dimensional space, wherein the second envelope vector of the second time period is defined by a second set of coordinates corresponding to intensity coefficients at a plurality of harmonics of the second pitch in the second transformation; instructions for determining a first correlation between the first envelop vector of the first time period and the second envelope vector of the second time period; instructions for obtaining a third pitch corresponding to a third sound in the second time period of the audio signal; instructions for determining a third envelope vector of the second time period from the second transformation in the multi-dimensional space, wherein the third envelope vector of the second time period is defined by a third set of coordinates corresponding to intensity coefficients at a plurality of harmonics of the third pitch in the second transformation; instructions for determining a second correlation between the first envelop vector of the first time period and the third envelope vector of the second time period; and instructions for determining, using the first correlation and the second correlation, that the first sound in the first time period of the audio signal and the second sound in the second time period of the audio signal are portions of a same harmonic sound.<br>9) A method for tracking pitch in an audio signal, the method comprising: receiving the audio signal obtained from a user input device; obtaining a first transformation of the audio signal in a first time period, wherein the first transformation represents the audio signal as a function of frequency in the first time period; obtaining a first pitch corresponding to a first sound in the first time period of the audio signal; determining a first envelope vector of the first time period from the first transformation in a multi-dimensional space, wherein each dimension of the multi-dimensional space corresponds to one of a plurality of harmonics of a pitch and the first envelope vector of the first time period is defined by a first set of coordinates corresponding to intensity coefficients at a plurality of harmonics of the first pitch in the first transformation; obtaining a second transformation of the audio signal in a second time period, wherein the second time period is different from the first time period and the second transformation represents the audio signal as a function of frequency in the second time period; obtaining a second pitch corresponding to a second sound in the second time period of the audio signal; determining a second envelope vector of the second time period from the second transformation in the multi-dimensional space, wherein the second envelope vector of the second time period is defined by a second set of coordinates corresponding to intensity coefficients at a plurality of harmonics of the second pitch in the second transformation; determining a first correlation between the first envelop vector of the first time period and the second envelope vector of the second time period; obtaining a third pitch corresponding to a third sound in the second time period of the audio signal; determining a third envelope vector of the second time period from the second transformation in the multi-dimensional space, wherein the third envelope vector of the second time period is defined by a third set of coordinates corresponding to intensity coefficients at a plurality of harmonics of the third pitch in the second transformation; determining a second correlation between the first envelop vector of the first time period and the third envelope vector of the second time period; and determining, using the first correlation and the second correlation, that the first sound in the first time period of the audio signal and the second sound in the second time period of the audio signal are portions of a same harmonic sound.</p></layer>
<layer id = "layer639"><p><b>US9485597B2:System and method of processing a sound signal including transforming the sound signal into a frequency-chirp domain</b><br><b>Independant Claims</b><br>1) A method of processing a sound signal comprising a harmonic sound having multiple harmonics, the method comprising: obtaining, by a computer processor, a first portion of the sound signal; transforming the first portion of the sound signal from time domain using a set of filters to generate a set of transform coefficients, each filter being specified by a chirp rate and a frequency, the set of filters comprising different chirp rate and frequency values; generating a multi-dimensional representation using the computer processor, wherein: a first domain corresponds to frequency, a second domain corresponds to fractional chirp rate, each transform coefficient of the multi-dimensional representation corresponds to a fractional chirp rate in the second domain and a frequency in the first domain, the fractional chirp rate in the second domain is determined by dividing a chirp rate of a corresponding filter by a frequency of the corresponding filter; determining a first common fractional chirp rate corresponding to the multiple harmonics of the harmonic sound in the first portion of the sound signal using the multi-dimensional representation, wherein a chirp rate of a nth (n being a positive integer) harmonic of the multiple harmonics divided by a frequency of the nth harmonic of the multiple harmonics is equal to the first common fractional chirp rate; determining a pitch corresponding to the multiple harmonics in the first portion of the sound signal using the first common fractional chirp rate; generating multiple synthesized harmonics using an oscillator and the pitch for each harmonic of the multiple harmonics; and summing the multiple synthesized harmonics to obtain an audio signal.<br>13) A non-transitory computer-readable storage media encoded with software comprising computer executable instructions and when the software is executed operable to: obtain a first portion of the sound signal comprising a harmonic sound having multiple harmonics; transform the first portion of the sound signal from time domain using a set of filters to generate a set of transform coefficients, each filter being specified by a chirp rate and a frequency, the set of filters comprising chirp rate and frequency values; generate a multi-dimensional representation, wherein: a first domain corresponds to frequency, a second domain corresponds to fractional chirp rate, each transform coefficient of the multi-dimensional representation corresponds to a fractional chirp rate in the second domain and a frequency in the first domain, the fractional chirp rate in the second domain is determined by dividing a chirp rate of a corresponding filter by a frequency of the corresponding filter; determine a first common fractional chirp rate corresponding to the multiple harmonics of the harmonic sound in the first portion of the sound signal using the multi-dimensional representation, wherein a chirp rate of a nth (n being a positive integer) harmonic of the multiple harmonics divided by a frequency of the nth harmonic of the multiple harmonics is equal to the first common fractional chirp rate; determine a pitch corresponding to the multiple harmonics in the first portion of the sound signal using the first common fractional chirp rate; generate multiple synthesized harmonics using an oscillator and the pitch for each harmonic of the multiple harmonics; and sum the multiple synthesized harmonics to obtain an audio signal.<br>7) A system configured to process a sound signal comprising a harmonic sound having multiple harmonics, the system comprising: a memory containing computer executable instructions; and a processor coupled to the memory, wherein the processor is configured execute the computer executable instructions to: obtain a first portion of the sound signal; transform the first portion of the sound signal from time domain using a set of filters to generate a set of transform coefficients, each filter being specified by a chirp rate and a frequency, the set of filters comprising different chirp rate and frequency values; generate a multi-dimensional representation wherein: a first domain corresponds to frequency, a second domain corresponds to fractional chirp rate, each of the multi-dimensional representation corresponds to a fractional chirp rate in the second domain and a frequency in the first domain, the fractional chirp rate in the second domain is determined by dividing a chirp rate of a corresponding filter by a frequency of the corresponding filter; determine a first common fractional chirp rate corresponding to the multiple harmonics of the harmonic sound in the first portion of the sound signal using the multi-dimensional representation, wherein a chirp rate of a nth (n being a positive integer) harmonic of the multiple harmonics divided by a frequency of the nth harmonic of the multiple harmonics is equal to the first common fractional chirp rate; determine a pitch corresponding to the multiple harmonics in the first portion of the sound signal using the first common fractional chirp rate; generate multiple synthesized harmonics using an oscillator and the pitch for each harmonic of the multiple harmonics; and sum the multiple synthesized individual harmonics to obtain an audio signal.</p></layer>
<layer id = "layer640"><p><b>US9252728B2:Non-speech content for low rate CELP decoder</b><br><b>Independant Claims</b><br>1) A device for modifying a synthesis of a time-domain code-excited linear prediction (CELP) excitation decoded by a time-domain CELP decoder, comprising: at least one processor; and a memory coupled to the processor and comprising non-transitory instructions that when executed cause the processor to implement: a classifier of the synthesis of the decoded time-domain CELP excitation into one of a number of categories; a first converter of the decoded time-domain CELP excitation into a frequency-domain excitation; a modifier of the frequency-domain excitation as a function of the category in which the synthesis of the decoded time-domain CELP excitation is classified by the classifier; a second converter of the modified frequency-domain excitation into a modified time-domain CELP excitation; and a first linear prediction synthesis filter supplied with the modified time-domain CELP excitation to produce a modified synthesis of the decoded time-domain CELP excitation.<br>17) A method for modifying a synthesis of a time-domain code-excited linear prediction (CELP) excitation decoded by a time-domain CELP decoder, comprising: classifying the synthesis of the decoded time-domain CELP excitation into one of a number of categories; converting the decoded time-domain CELP excitation into a frequency-domain excitation; modifying the frequency-domain excitation as a function of the category in which the synthesis of the decoded time-domain CELP excitation is classified; converting the modified frequency-domain excitation into a modified time-domain CELP excitation; synthesizing, using a linear prediction synthesis filter, the modified time-domain CELP excitation to produce a modified synthesis of the decoded time-domain CELP excitation.</p></layer>
<layer id = "layer641"><p><b>US9390718B2:Audio signal restoration device and audio signal restoration method</b><br><b>Independant Claims</b><br>1) An audio signal restoration device comprising: a sound generator that receives an audio signal of a first frequency band and generates, from the received audio signal of the first frequency, a sound source signal of a second frequency band including the first frequency band and being wider than the first frequency band; a noise suppressor that receives the audio signal of the first frequency band and generates a noise suppressed audio signal in which a noise component included in the audio signal of the first frequency band is suppressed; a spectral envelope estimator that estimates a spectral envelope of the second frequency band from the noise suppressed audio signal generated by the noise suppressor; and a signal synthesizer that generates an audio signal of the second frequency band by combining the sound source signal of the second frequency band the sound generator generates and the spectral envelope of the second frequency band the spectral envelope estimator estimates.<br>8) An audio signal restoration method comprising: receiving an audio signal of a first frequency band; generating, from the received audio signal of the first frequency band, a sound source signal of a second frequency band including the first frequency band and being wider than the first frequency band; suppressing a noise component included in the audio signal of the first frequency band and generating a noise suppressed audio signal; estimating a spectral envelope of the second frequency band from the noise suppressed audio signal; and synthesizing an audio signal of the second frequency band by combining the sound source signal of the second frequency band generated by the generating and the estimated spectral envelope of the second frequency band estimated by the estimating.</p></layer>
<layer id = "layer642"><p><b>US9111531B2:Multiple coding mode signal classification</b><br><b>Independant Claims</b><br>1) A method comprising: receiving a portion of an audio signal at a first classifier in a digital audio device; classifying, by the digital audio device, the portion of the audio signal at the first classifier as speech or as music; and processing the portion of the audio signal, wherein processing the portion of the audio signal comprises: if the portion is classified by the first classifier as speech, then encoding, by the digital audio device, the speech using a first coding mode; or if the portion is classified by the first classifier as music, then: providing the portion to a second classifier in the digital audio device; classifying, by the digital audio device, the portion at the second classifier as speech or as music; and encoding the portion of the audio signal, wherein encoding the portion of the audio signal comprises: if the portion is classified at the second classifier as speech, then encoding, by the digital audio device, the portion using a second coding mode; or if the portion is classified at the second classifier as music, then encoding, by the digital audio device, the portion using a third coding mode.<br>11) An apparatus comprising: means for receiving a portion of an audio signal at a first classifier in a digital audio device; means for classifying, by the digital audio device, the portion of the audio signal at the first classifier as speech or as music; means for encoding, by the digital audio device, the speech using a first coding mode if the portion is classified by the first classifier as speech, or classifying, by the digital audio device, the portion at the second classifier as speech or as music when the portion is classified by the first classifier as music; and means for encoding, by the digital audio device, the portion using a second coding mode when the portion is classified at the second classifier as speech, or encoding, by the digital audio device, the portion using a third coding mode when the portion is classified at the second classifier as music.<br>21) A non-transitory computer-readable medium comprising computer-readable instructions for causing a processor to: receive a portion of an audio signal at a first classifier in a digital audio device; classify, by the digital audio device, the portion of the audio signal at the first classifier as speech or as music; and process the portion of the audio signal, wherein processing the portion of the audio signal comprises: if the portion is classified by the first classifier as speech, then encode, by the digital audio device, the speech using a first coding mode; or if the portion is classified by the first classifier as music, then: provide the portion to a second classifier in the digital audio device; classify, by the digital audio device, the portion at the second classifier as speech or as music; and encode the portion of the audio signal, wherein encoding the portion of the audio signal comprises: if the portion is classified at the second classifier as speech, then encode, by the digital audio device, the portion using a second coding mode; or if the portion is classified at the second classifier as music, then encode, by the digital audio device, the portion using a third coding mode.<br>31) An apparatus comprising: a processor; memory in electronic communication with the processor; and instructions stored in the memory, the instructions being executable by the processor to: receive a portion of an audio signal at a first classifier in a digital audio device; classify, by the digital audio device, the portion of the audio signal at the first classifier as speech or as music; and process the portion of the audio signal, wherein processing the portion of the audio signal comprises: if the portion is classified by the first classifier as speech, then encode, by the digital audio device, the speech using a first coding mode; or if the portion is classified by the first classifier as music, then: provide the portion to a second classifier in the digital audio device; classify, by the digital audio device, the portion at the second classifier as speech or as music; and encode the portion of the audio signal, wherein encoding the portion of the audio signal comprises: if the portion is classified at the second classifier as speech, then encode, by the digital audio device, the portion using a second coding mode; or if the portion is classified at the second classifier as music, then encode, by the digital audio device, the portion using a third coding mode.</p></layer>
<layer id = "layer643"><p><b>US9437213B2:Voice signal enhancement</b><br><b>Independant Claims</b><br>1) A method of discriminating relative to a voice signal, the method comprising: receiving, via one or more audible sensors, an audible signal including a target voice signal; converting the audible signal into a corresponding plurality of wideband time-frequency units, wherein the time dimension of each time-frequency unit includes at least one of a plurality of sequential intervals, and wherein the frequency dimension of each time-frequency unit includes at least one of a plurality of wide sub-bands; calculating one or more characterizing metrics from the plurality of wideband time-frequency units; calculating a gain function from one or more characterizing metrics calculated from the plurality of wideband time-frequency units; converting the audible signal into a corresponding plurality of narrowband time-frequency units; applying the gain function, calculated from the plurality of wideband time-frequency units, to the plurality of narrowband time-frequency units to produce a corresponding plurality of narrowband gain-corrected time-frequency units; converting the plurality of narrowband gain-corrected time-frequency units into a corrected audible signal, wherein the corrected audible signal includes an improved target voice signal relative to the received audible signal; and outputting the corrected audible signal through an output device.<br>11) A method of discriminating against far field audible components, the method comprising: receiving, via one or more audible sensors, an audible signal including a target voice signal; converting the audible signal into a corresponding plurality of time-frequency units, wherein the time dimension of each time-frequency unit includes at least one of a plurality of sequential intervals, and wherein the frequency dimension of each time-frequency unit includes at least one of a plurality of sub-bands; calculating one or more characterizing metrics from the plurality of time-frequency units associated with near field audible components; calculating a discriminating function from one or more characterizing metrics calculated from the plurality of wideband time-frequency units; applying the discriminating function, calculated from the plurality of wideband time-frequency units, to the plurality of time-frequency units to produce a corresponding plurality of corrected time-frequency units; converting the plurality of corrected time-frequency units into a corrected audible signal, wherein the corrected audible signal includes an improved target voice signal relative to the received audible signal; and outputting the corrected audible signal through an output device.<br>12) A voice signal enhancement device to discriminate relative to a voice signal, the device comprising: one or more audio sensors configured to receive and audible signal including a target voice signal; a first conversion module configured to convert the audible signal into a corresponding plurality of wideband time-frequency units, wherein the time dimension of each time-frequency unit includes at least one of a plurality of sequential intervals, and wherein the frequency dimension of each time-frequency unit includes at least one of a plurality of wide sub-bands; a second conversion module configured to convert the audible signal into a corresponding plurality of narrowband time-frequency units; a metric calculator configured to calculate one or more characterizing metrics from the plurality of wideband time-frequency units; a gain calculator configured to calculate a gain function from one or more characterizing metrics calculated from the plurality of wideband time-frequency units; a filtering module configured to apply the gain function, calculated from the plurality of wideband time-frequency units, to the plurality of narrowband time-frequency units to produce a corresponding plurality of narrowband gain-corrected time-frequency units; a third conversion module configured to convert the plurality of narrowband gain-corrected time-frequency units into a corrected audible signal, wherein the corrected audible signal includes an improved target voice signal relative to the received audible signal; and an output device configured to output the corrected audible signal.<br>19) A voice signal enhancement device to discriminate relative to a voice signal, the device comprising: means for receiving an audible signal including a target voice signal; means for converting the audible signal into a corresponding plurality of wideband time-frequency units, wherein the time dimension of each time-frequency unit includes at least one of a plurality of sequential intervals, and wherein the frequency dimension of each time-frequency unit includes at least one of a plurality of wide sub-bands; means for converting the audible signal into a corresponding plurality of narrowband time-frequency units; means for calculating one or more characterizing metrics from the plurality of wideband time-frequency units; means for calculating gain function from one or more characterizing metrics calculated from the plurality of wideband time-frequency units; means for applying the gain function, calculated from the plurality of wideband time-frequency units, to the plurality of narrowband time-frequency units to produce a corresponding plurality of narrowband gain-corrected time-frequency units; means for converting the plurality of narrowband gain-corrected time-frequency units into a corrected audible signal, wherein the corrected audible signal includes an improved target voice signal relative to the received audible signal; and means for outputting the corrected audible signal.<br>20) A voice signal enhancement device to discriminate relative to a voice signal, the device comprising: one or more audio sensors configured to receive and audible signal including a target voice signal; a processor; a memory including instructions, that when executed by the processor cause the device to: convert an audible signal into a corresponding plurality of wideband time-frequency units, wherein the time dimension of each time-frequency unit includes at least one of a plurality of sequential intervals, and wherein the frequency dimension of each time-frequency unit includes at least one of a plurality of wide sub-bands; convert the audible signal into a corresponding plurality of narrowband time-frequency units; calculate one or more characterizing metrics from the plurality of wideband time-frequency units; calculate gain function from one or more characterizing metrics calculated from the plurality of wideband time-frequency units; apply the gain function, calculated from the plurality of wideband time-frequency units, to the plurality of narrowband time-frequency units to produce a corresponding plurality of narrowband gain-corrected time-frequency units; convert the plurality of narrowband gain-corrected time-frequency units into a corrected audible signal, wherein the corrected audible signal includes an improved target voice signal relative to the received audible signal; and output the corrected audible signal through an output device.</p></layer>
<layer id = "layer644"><p><b>US9240190B2:Formant based speech reconstruction from noisy signals</b><br><b>Independant Claims</b><br>1) A method of formant-based speech reconstruction, the method comprising: at a formant-based auditory processing system configured to synthesize a speech signal based on formant information determined from an audible signal, the auditory processing system including one or more audio sensors: selecting one or more tuples from a non-transitory memory based at least on the one or more formants within an audible signal, wherein each tuple includes a respective formant spectrum value and a respective one or more formant amplitude values; and interpolating the spectrum between the corresponding one or more formants associated with the one or more selected tuples to generate a reconstructed speech signal, wherein the interpolation of the spectrum between the corresponding one or more formants associated with the one or more selected tuples comprises synthesizing one or more voice sections one glottal pulse at a time.<br>19) A formant-based voice reconstruction device, the device comprising: means for detecting one or more formants in an audible signal; means for selecting one or more tuples from a non-transitory memory base at least on the one or more detected formants, wherein each tuple includes a respective formant spectrum value and a respective one or more formant amplitude values; and means for interpolating the spectrum between the corresponding one or more formants associated with the one or more selected tuples to generate a reconstructed speech signal, wherein the interpolation of the spectrum between the corresponding one or more formants associated with the one or more selected tuples comprises synthesizing one or more voice sections one glottal pulse at a time.<br>20) A formant-based voice reconstruction device, the device comprising: a processor; and a non-transitory memory including instructions, that when executed by the processor causes the device to: detect one or more formants in an audible signal; select one or more tuples from the non-transitory memory based at least on the one or more detected formants, wherein each tuple includes a respective formant spectrum value and a respective one or more formant amplitude values; and interpolate the spectrum between the corresponding one or more formants associated with the one or more selected tuples to generate a reconstructed speech signal, wherein the interpolation of the spectrum between the corresponding one or more formants associated with the one or more selected tuples comprises synthesizing one or more voice sections one glottal pulse at a time.</p></layer>
<layer id = "layer645"><p><b>US9911432B2:Frequency band extension in an audio signal decoder</b><br><b>Independant Claims</b><br>1) A frequency band extending method applied to an audio frequency signal in a decoding process comprising an act of decoding or an enhancement process comprising an act of extraction, in a first frequency band called low band, of an excitation signal and coefficients of a linear prediction filter, wherein the method comprises: obtaining of an extended signal from an oversampled and extended excitation signal in at least one second frequency band higher than the first frequency band generated according to the following equation:UHB⁢⁢1⁡(k)={0k=0,⋯⁢,199U⁡(k)k=200,⋯⁢,239U⁡(k+start_band-240)k=240,⋯⁢,319with k being an index of a signal sample, UHB1 (k) being a spectrum of the extended excitation signal, U(k) being a spectrum of the excitation signal obtained after a time-frequency transform act and start_band being a predefined variable; scaling of the extended signal by a gain defined per sub-frame using a calculation based on a comparison between the extended signal and the low-band signal of a ratio of energy per sub-frame and energy per frame so that the extended signal has the same ratio of energy between a sub-frame and a frame as in the low-band signal; filtering of said scaled extended signal by a linear prediction filter whose coefficients are derived from decoded or extracted coefficients of a linear prediction filter in the low-band.<br>10) An audio frequency signal decoder, comprising a frequency band extension device for extending the frequency band of an audio frequency signal comprising a decoding module for decoding or an extraction module for extracting, in a first frequency band called low band, an excitation signal and coefficients of a linear prediction filter, wherein the device comprises: a module for obtaining an extended signal from an oversampled and extended excitation signal in at least one second frequency band higher than the first frequency band generated according to the following equation:UHB⁢⁢1⁡(k)={0k=0,⋯⁢,199U⁡(k)k=200,⋯⁢,239U⁡(k+start_band-240)k=240,⋯⁢,319with k being an index of a signal sample, UHB1 (k) being a spectrum of the extended excitation signal, U(k) being a spectrum of the excitation signal obtained after a time-frequency transform act and start_band being a predefined variable; a module for scaling the extended signal by a gain defined per sub-frame using a calculation based on a comparison between the extended signal and the low-band signal of a ratio of energy per sub-frame and energy per frame so that the extended signal has the same ratio of energy between a sub-frame and a frame as in the low-band signal; a module for filtering said scaled extended signal by a linear prediction filter whose coefficients are derived from decoded or extracted coefficients of a linear prediction filter in the low-band.<br>11) A non-transitory storage medium that can be read by a frequency band extending device for extending the frequency band of an audio frequency signal on which is stored a computer program comprising code instructions for execution of a frequency band extending method, the method for extending the frequency band applied to an audio frequency signal in a decoding process comprising an act of decoding or an enhancement process comprising an act of extraction, in a first frequency band called low band, of an excitation signal and coefficients of a linear prediction filter, wherein the method comprises: obtaining of an extended signal from an oversampled and extended excitation signal in the at least one second frequency band higher than the first frequency band generated according to the following equation:UHB⁢⁢1⁡(k)={0k=0,⋯⁢,199U⁡(k)k=200,⋯⁢,239U⁡(k+start_band-240)k=240,⋯⁢,319with k being an index of a signal sample, UHB1 (k) being a spectrum of the extended excitation signal, U(k) being a spectrum of the excitation signal obtained after a time-frequency transform act and start_band being a predefined variable; scaling of the extended signal by a gain defined per sub-frame using a calculation based on a comparison between the extended signal and the low-band signal of a ratio of energy per sub-frame and energy per frame so that the extended signal has the same ratio of energy between a sub-frame and a frame as in the low-band signal; filtering of said scaled extended signal by a linear prediction filter whose coefficients are derived from decoded or extracted coefficients of a linear prediction filter in the low-band.<br>9) A frequency band extending device for extending the frequency band of an audio frequency signal comprising a decoding module for decoding or an extraction module for extracting, in a first frequency band called low band, an excitation signal and coefficients of a linear prediction filter, wherein the device comprises: a module for obtaining an extended signal from an oversampled and extended excitation signal in at least one second frequency band higher than the first frequency band generated according to the following equation:UHB⁢⁢1⁡(k)={0k=0,⋯⁢,199U⁡(k)k=200,⋯⁢,239U⁡(k+start_band-240)k=240,⋯⁢,319with k being an index of a signal sample, UHB1 (k) being a spectrum of the extended excitation signal, U(k) being a spectrum of the excitation signal obtained after a time-frequency transform act and start_band being a predefined variable; a module for scaling the extended signal by a gain defined per sub-frame using a calculation based on a comparison between the extended signal and the low-band signal of a ratio of energy per sub-frame and energy per frame so that the extended signal has the same ratio of energy between a sub-frame and a frame as in the low-band signal; a module for filtering said scaled extended signal by a linear prediction filter whose coefficients are derived from decoded or extracted coefficients of a linear prediction filter in the low-band.</p></layer>
<layer id = "layer646"><p><b>US9858936B2:Methods and systems for selecting layers of encoded audio signals for teleconferencing</b><br><b>Independant Claims</b><br>1) A teleconferencing method in which nodes perform audio coding to generate spatially layered encoded audio, the nodes include endpoints, and at least some of the spatially layered encoded audio is transmitted from one of the nodes to at least another one of the nodes, wherein the nodes include a first node which is configured to generate spatially layered encoded audio in response to soundfield audio data, said encoded audio including any of a number of different subsets of a set of layers, said set of layers including at least one monophonic layer and at least one soundfield layer, said method including steps of: (a) in the first node, determining a first subset of the set of layers by performing at least one of perceptually-driven layer selection or endpoint-driven layer selection, said first subset including at least one of said monophonic layer or said soundfield layer, wherein said endpoint-driven layer selection includes at least one independent decision by at least one of the endpoints based on at least one analyzed characteristic of said at least one of the endpoints or of audio content captured by said at least one of the endpoints, and wherein said perceptually-driven layer selection is not based on any downstream capability consideration; and (b) in said first node, generating first spatially layered encoded audio, wherein the first spatially layered encoded audio includes the first subset of the set of layers determined in step (a), and wherein the first spatially layered encoded audio does not include any layer of said set of layers which is not included in said first subset of the set of layers determined in step (a).<br>8) A teleconferencing system, including: nodes configured to perform audio coding to generate spatially layered encoded audio, wherein the nodes include endpoints, and each of the nodes is coupled to at least one other one of the nodes and configured to transmit at least some of the spatially layered encoded audio to said at least one other one of the nodes, and wherein the nodes include a first node configured to generate spatially layered encoded audio in response to soundfield audio data, said encoded audio including any of a number of different subsets of a set of layers, said set of layers including at least one monophonic layer and at least one soundfield layer, and wherein the first node is configured to determine a first subset of the set of layers by performing at least one of perceptually-driven layer selection or endpoint-driven layer selection, said first subset including at least one of said monophonic layer or said soundfield layer, wherein said endpoint-driven layer selection includes at least one independent decision by at least one of the endpoints based on at least one analyzed characteristic of said at least one of the endpoints or of audio content captured by said at least one of the endpoints, and wherein said perceptually-driven layer selection is not based on any downstream capability consideration, and wherein said first node is configured to generate first spatially layered encoded audio, wherein the first spatially layered encoded audio includes the first subset of the set of layers determined by said first node, and wherein the first spatially layered encoded audio does not include any layer of said set of layers which is not included in said first subset of the set of layers determined by said first node.</p></layer>
<layer id = "layer647"><p><b>US10339948B2:Method and apparatus for encoding and decoding high frequency for bandwidth extension</b><br><b>Independant Claims</b><br>3) A decoding method, performed by a decoding apparatus comprising a processor, comprising:receiving a bitstream including one of first excitation class information, second excitation class information and third excitation class information as an excitation class of a current frame;decoding a low frequency spectrum of the current frame from the bitstream;obtaining a high frequency excitation spectrum of the current frame by copying the low frequency spectrum, based on the excitation class of the current frame;generating a high frequency spectrum based on the high frequency excitation spectrum; andcombining the low frequency spectrum and the high frequency spectrum,wherein the first excitation class information for the current frame indicates that the excitation class of the current frame corresponds to a speech class, when the current frame has a speech characteristic,wherein the second excitation class information for the current frame indicates that the excitation class of the current frame corresponds to a first non-speech class, when the current frame does not have the speech characteristic,wherein the third excitation class information for the current frame indicates that the excitation class of the current frame corresponds to a second non-speech class, when the current frame does not have the speech characteristic, andwherein whether the excitation class of the current frame corresponds to the first non-speech class or the second non-speech class is determined based on a tonal characteristic of the current frame.<br>1) A decoding apparatus for generating a high frequency spectrum, the decoding apparatus comprising:a receiving unit configured to receive a bitstream including one of first excitation class information, second excitation class information and third excitation class information as an excitation class of a current frame; anda processor configured to:decode a low frequency spectrum of the current frame from the bitstream;obtain a high frequency excitation spectrum of the current frame by copying the low frequency spectrum, based on the excitation class of the current frame;generate a high frequency spectrum based on the high frequency excitation spectrum; andcombine the low frequency spectrum and the high frequency spectrum,wherein the first excitation class information for the current frame indicates that the excitation class of the current frame corresponds to a speech class, if the current frame has a speech characteristic,wherein the second excitation class information for the current frame indicates that the excitation class of the current frame corresponds to a first non-speech class, if the current frame does not have the speech characteristic,wherein the third excitation class information for the current frame indicates that the excitation class of the current frame corresponds to a second non-speech class, if the current frame does not have the speech characteristic, andwherein whether the excitation class of the current frame corresponds to the first non-speech class or the second non-speech class is determined based on a tonal characteristic of the current frame.</p></layer>
<layer id = "layer648"><p><b>US9280978B2:Packet loss concealment for bandwidth extension of speech signals</b><br><b>Independant Claims</b><br>1) A speech receiving apparatus comprising: a low-band packet loss concealment (PLC) module and a synthesis filter reconstructing a low-band speech signal of a lost frame from a previous good frame; a high-band PLC module reconstructing a high-band speech signal of the lost frame from the previous good frame; a transforming part transforming the low-band speech signal to a frequency domain; a bandwidth extending part generating at least an extended modified discrete cosine transform (MDCT) coefficient as information for the high-band speech signal from the low-band speech signal transformed by the transforming part; a smoothing part smoothing the extended MDCT coefficient; an inverse transforming part inversely transforming the extended MDCT coefficient smoothed by the smoothing part to a time domain; and a synthesizing part synthesizing the low-band speech signal, and the high-band speech signal that is inverse-transformed by the inverse transforming part and reconstructed, to output a wideband speech signal; wherein the bandwidth extending part performs spectral folding of low-band MDCT coefficients to generate at least a part of the extended MDCT coefficients.<br>11) A speech receiving method comprising: reconstructing a low-band speech signal of a lost frame from a previous good frame; transforming the reconstructed low-band speech signal to a frequency domain to provide a low-band modified discrete cosine transform (MDCT) coefficient; processing the low-band MDCT coefficient by different methods according to the frequency ranges of the high band, which are classified into at least two cases, to provide an extended MDCT coefficient of a high-band speech signal; inversely transforming the extended MDCT coefficient to a time domain to reconstruct the high-band speech signal; and synthesizing the reconstructed high-band speech signal and the low-band speech signal; wherein a second frequency range that is a part of the extended MDCT coefficients is obtained by folding the low-band MDCT coefficient.</p></layer>
<layer id = "layer649"><p><b>US9559656B2:System for adjusting loudness of audio signals in real time</b><br><b>Independant Claims</b><br>1) A method of adjusting loudness of an audio signal, the method comprising: receiving an audio signal; dividing the audio signal into a plurality of frames; for a current frame of the plurality of frames, by one or more processors: measuring initial loudness values for blocks of samples in the current frame to determine a plurality of initial loudness values, comparing the plurality of initial loudness values to a loudness threshold and selectively discarding at least some of the initial loudness values that do not satisfy the loudness threshold to avoid or reduce subsequent loudness adiustment of first portions of the audio signal containing silence or noise instead of information, computing an adjusted adaptive loudness threshold based at least partly on a deviation between a representation of the initial loudness values that have not been discarded and a representation of a previous adaptive loudness threshold computed for a previous frame, the adjusted adaptive loudness threshold computed for the current frame being different from the previous adaptive loudness threshold computed for the previous frame, wherein the adaptive loudness threshold is responsive to transient loudness spikes in the audio signal so that the subsequent loudness adiustment compensates for the transient loudness spikes more than a mean loudness smoothing would compensate for the transient loudness spikes, and in response to comparing initial loudness values that have not been discarded to the adjusted adaptive loudness threshold, selectively discarding at least some of the initial loudness values that do not satisfy the adjusted adaptive loudness threshold, wherein selectively discarding the at least some of the initial loudness values includes discarding at least one block of samples corresponding to the at least some of the initial loudness values, and wherein the at least one discarded block of samples is excluded from further processing; adjusting loudness of the audio signal based at least partly on the initial loudness values that have not been discarded, wherein said adiusting comprises applying larger adjustment to second portions of the audio signal due to the transient loudness spikes than to third portions of the audio signal having lower amplitude loudness changes than the transient loudness spikes, and wherein said adjusting comprises applying reduced or no adjustment to the first portions of the audio signal containing silence or noise; and providing the adjusted audio signal for playback.<br>10) A system for adjusting loudness of an audio signal, the system comprising: a loudness analysis module comprising one or more processors, the loudness analysis module configured to: access a current frame of an audio signal, the frame comprising a plurality of samples of the audio signal, measure initial loudness values for blocks of the samples in the current frame to calculate a plurality of initial loudness values, compare the plurality of initial loudness values to a loudness threshold and selectively discard at least some of the initial loudness values that do not satisfy the loudness threshold, compute an adjusted loudness threshold based at least partly on a deviation between a representation of the initial loudness values that have not been discarded and a representation of a previous adaptive loudness threshold computed for previous frame, the adjusted adaptive loudness threshold computed for the current frame being different from the previous adaptive loudness threshold computed for the previous frame, wherein the adaptive loudness threshold is responsive to transient loudness spikes in the audio signal so that the subsequent loudness adjustment substantially compensates for the transient loudness spikes, and in response to comparing initial loudness values that have not been discarded to the adjusted adaptive loudness threshold, selectively discard at least some of the initial loudness values that do not satisfy the adjusted adaptive loudness threshold, wherein selectively discarding the at least some of the initial loudness values includes discarding at least one block of samples corresponding to the at least some of the initial loudness values, and wherein the at least one discarded block of samples is excluded from further processing; a dynamics control module configured to adjust loudness of the audio signal based at least partly on the initial loudness values that have not been discarded, wherein said adiusting comprises applying larger adjustment to second portions of the audio signal due to the transient loudness spikes than to third portions of the audio signal having lower amplitude loudness changes than the transient loudness spikes; and an output module configured to provide the adjusted audio signal for playback.</p></layer>
<layer id = "layer650"><p><b>US9305567B2:Systems and methods for audio signal processing</b><br><b>Independant Claims</b><br>1) A method for signal level matching of one or more audio signals by an electronic audio device, comprising: segmenting an input spectrum into one or more bands; measuring a signal-to-noise ratio for each band; determining if the signal-to-noise ratios are less than a signal-to-noise ratio threshold; assembling a target spectrum, wherein assembling a target spectrum comprises replacing a portion of a speech reference spectrum with a portion of a speech template spectrum that corresponds to one or more bands of the audio signals with signal-to-noise ratios that are less than the signal-to-noise ratio threshold; and adjusting a gain of one or more bands in a noise-suppressed signal such that the one or more bands approximately match the target spectrum.<br>14) An electronic audio device for signal level matching of one or more audio signals, comprising: inter-microphone subtraction circuitry configured to segment an input spectrum into one or more bands; peak sufficiency determination circuitry coupled to the inter-microphone subtraction circuitry, wherein the peak sufficiency determination circuitry is configured to measure a signal-to-noise ratio for each band and to determine if the signal-to-noise ratios are less than a signal-to-noise ratio threshold; assemble spectrum circuitry coupled to the peak sufficiency determination circuitry, wherein the assemble spectrum circuitry is configured to assemble a target spectrum by replacing a portion of a speech reference spectrum with a portion of a speech template spectrum that corresponds to one or more bands of the audio signals with signal-to-noise ratios that are less than the signal-to-noise ratio threshold; and a gain adjuster coupled to the assemble spectrum circuitry, wherein the gain adjuster is configured to adjust a gain of one or more bands in the noise-suppressed signal such that the one or more bands approximately match the target spectrum.<br>25) A computer-program product for signal level matching of one or more audio signals, comprising a non-transitory tangible computer-readable medium having instructions thereon, the instructions comprising: code for causing the electronic audio device to segment an input spectrum into one or more bands; code for causing the electronic audio device to measure a signal-to-noise ratio for each band; code for causing the electronic audio device to determine if the signal-to-noise ratios are less than a signal-to-noise ratio threshold; code for causing the electronic audio device to assemble a target spectrum, wherein assembling a target spectrum comprises replacing a portion of a speech reference spectrum with a portion of a speech template spectrum that corresponds to one or more bands of the audio signals with signal-to-noise ratios that are less than the signal-to-noise ratio threshold; and code for causing the electronic audio device to adjust a gain of one or more bands in a noise-suppressed signal such that the one or more bands approximately match the target spectrum.<br>35) An electronic audio device for signal level matching of one or more audio signals, comprising: means for segmenting an input spectrum into one or more bands; means for measuring a signal-to-noise ratio for each band; means for determining if the signal-to-noise ratios are less than a signal-to-noise ratio threshold; means for assembling a target spectrum, wherein the means for assembling a target spectrum comprises means for replacing a portion of a speech reference spectrum with a portion of a speech template spectrum that corresponds to one or more bands of the audio signals with signal-to-noise ratios that are less than the signal-to-noise ratio threshold; and means for adjusting a gain of one or more bands in the noise-suppressed signal such that the one or more bands approximately match the target spectrum.</p></layer>
<layer id = "layer651"><p><b>US20180336909A1:AUDIO DECODING DEVICE, AUDIO CODING DEVICE, AUDIO DECODING METHOD, AUDIO CODING METHOD, AUDIO DECODING PROGRAM, AND AUDIO CODING PROGRAM</b><br><b>Independant Claims</b><br>5) A speech decoding device that decodes an encoded speech signal and outputs a speech signal, the speech decoding device comprising: a low frequency decoder that receives and decodes a code sequence including encoded information of a low frequency signal to obtain the low frequency signal; a high frequency decoder that receives first information from the low frequency decoder and generates a high frequency signal based on the first information; a high frequency temporal envelope shape determiner that determines a temporal envelope shape of the generated high frequency signal based on second information sent from an encoding device; a high frequency temporal envelope modifier that modifies the temporal envelope shape of the generated high frequency signal based on the temporal envelope shape determined by the high frequency temporal envelope shape determiner and outputs the modified high frequency signal; and a low frequency/high frequency signal combiner that receives the low frequency signal from the low frequency decoder, receives the high frequency signal, whose temporal envelope shape is modified, from the high frequency temporal envelope modifier and combines the low frequency signal and the high frequency signal, whose temporal envelope shape is modified, to obtain a speech signal to be output, wherein the high frequency temporal envelope modifier modifies the temporal envelope shape of the generated high frequency signal using a high frequency signal generated in a time segment identical to that of the generated high frequency signal and outputs the modified high frequency signal, when the high frequency temporal envelope shape determiner determines the temporal envelope shape to be flat, and utilizes time envelope information of a high frequency signal determined by power of the high frequency signal generated by the high frequency decoder, during decoding of an encoded speech signal and obtaining of a speech signal.<br>4) .-(canceled)<br>3) .-(canceled)<br>2) .-(canceled)<br>1) .-(canceled)</p></layer>
<layer id = "layer652"><p><b>US20190180766A1:Method and Apparatus for Detecting Correctness of Pitch Period</b><br><b>Independant Claims</b><br>14) An apparatus for detecting correctness of a pitch period, comprising:a memory comprising instructions; andone or more processors in communication with the memory, wherein the instructions cause the one or more processors to be configured to:receive an input signal, wherein the input signal comprises a speech signal or an audio signal in a time domain;perform an open-loop detection on the input signal to obtain an initial pitch period;determine, according to the initial pitch period of the input signal, a pitch frequency bin of the input signal;transform the input signal in the time domain to a frequency domain;determine, based on an amplitude spectrum of the input signal in the frequency domain, a pitch period correctness decision parameter of the input signal associated with the pitch frequency bin; anddetermine correctness of the initial pitch period according to the pitch period correctness decision parameter, wherein the pitch period correctness decision parameter comprises a difference-to-amplitude ratio parameter, and wherein the difference-to-amplitude ratio parameter is a ratio of a sum of spectral differences of a predetermined quantity of frequency bins on two sides of the pitch frequency bin to an average of the spectral amplitudes of the predetermined quantity of the frequency bins on the two sides of the pitch frequency bin.<br>1) A method for detecting correctness of a pitch period, comprising:receiving an input signal, wherein the input signal comprises a speech signal or an audio signal in a time domain;performing an open-loop detection on the input signal to obtain an initial pitch period;determining, according to the initial pitch period of the input signal, a pitch frequency bin of the input signal;transforming the input signal in the time domain to a frequency domain;determining, based on an amplitude spectrum of the input signal in the frequency domain, a pitch period correctness decision parameter of the input signal associated with the pitch frequency bin; anddetermining correctness of the initial pitch period according to the pitch period correctness decision parameter, wherein the pitch period correctness decision parameter comprises a difference-to-amplitude ratio parameter, and wherein the difference-to-amplitude ratio parameter is a ratio of a sum of spectral differences of a predetermined quantity of frequency bins on two sides of the pitch frequency bin to an average of spectral amplitudes of the predetermined quantity of the frequency bins on the two sides of the pitch frequency bin.</p></layer>
<layer id = "layer653"><p><b>US8712076B2:Post-processing including median filtering of noise suppression gains</b><br>This patent is provided a method for producing a porous polymer film using vanadium oxide nanowires, and a porous polymer film obtained from the method. The method allows control of a uniform pore size and density through a simple process including the steps of: adding an ion exchanger to deionized water to perform acidification and adding a vanadate compound thereto to grow vanadium oxide nanowires by a sol-gel process; mixing the resultant solution of grown nanowires with a polymer solution to provide a mixed solution of nanowires; pouring the mixed solution of nanowires to a mold, followed by drying and curing, to form a film; and etching the resultant film with an etching solution to remove the vanadium oxide nanowires.<br><b>Independant Claims</b><br>1) A method of operating one or more processors, the method comprising: post-processing raw banded gains to generate banded post-processed gains to apply to one or more audio signals, the raw banded gains determined by input processing the one or more input audio signals to generate the raw banded gains at a plurality of frequency bands, some of the bands comprising more than one frequency bin, the raw banded gains being in order to carry out one or more of reducing noise, reducing out-of-location signals, reducing echoes, perceptual domain-based leveling, perceptual domain-based dynamic range control, and perceptual domain-based dynamic equalization, wherein the generating of a particular post-processed gain for a particular frequency band includes at least median filtering using raw gain values for frequency bands adjacent to the particular frequency band, thereby yielding median filtered gains, wherein the post-processing is according to one or more properties, including an end condition and a width for the median filtering, and wherein at least one of the end condition of the median filtering and the width of the median filtering depends on signal classification of the one or more input audio signals.<br>14) A non-transitory computer-readable medium comprising instructions that when executed by at least one processor of a processing system, cause carrying out a method comprising: post-processing raw banded gains to generate banded post-processed gains to apply to one or more audio signals, the raw banded gains determined by input processing the one or more input audio signals to generate the raw banded gains at a plurality of frequency bands, some of the bands comprising more than one frequency bin, the raw banded gains being in order to carry out one or more of reducing noise, reducing out-of-location signals, reducing echoes, perceptual domain-based leveling, perceptual domain-based dynamic range control, and perceptual domain-based dynamic equalization, wherein the generating of a particular post-processed gain for a particular frequency band includes at least median filtering using raw gain values for frequency bands adjacent to the particular frequency band, thereby yielding median filtered gains, wherein the post-processing is according to one or more properties, including an end condition and a width for the median filtering, and wherein at least one of the end condition of the median filtering and the width of the median filtering depends on signal classification of the one or more input audio signals.<br>27) An apparatus comprising: one or more processors; and a storage medium coupled to the one or more processors, wherein the medium comprises instructions that when executed by at least one processor of the one or more processors, cause carrying out a method comprising: post-processing raw banded gains to generate banded post-processed gains to apply to one or more audio signals, the raw banded gains determined by input processing the one or more input audio signals to generate the raw banded gains at a plurality of frequency bands, some of the bands comprising more than one frequency bin, the raw banded gains being in order to carry out one or more of reducing noise, reducing out-of-location signals, reducing echoes, perceptual domain-based leveling, perceptual domain-based dynamic range control, and perceptual domain-based dynamic equalization, wherein the generating of a particular post-processed gain for a particular frequency band includes at least median filtering using raw gain values for frequency bands adjacent to the particular frequency band, thereby yielding median filtered gains, wherein the post-processing is according to one or more properties, including an end condition and a width for the median filtering, and wherein at least one of the end condition of the median filtering and the width of the median filtering depends on signal classification of the one or more input audio signals.<br>29) An apparatus comprising: a post-processor operative to accept raw banded gains determined by input processing one or more input audio signals by an input processor, the post-processor operative to apply post-processing to the raw banded gains to generate banded post-processed gains to apply to the one or more input audio signals, the input processing operative to generate the raw banded gains at a plurality of frequency bands, some of which comprise more than one frequency bin, the raw banded gains being in order to carry out one or more of reducing noise, reducing out-of-location signals, reducing echoes, perceptual domain-based leveling, perceptual domain-based dynamic range control, and perceptual domain-based dynamic equalization, wherein the banded post-processed gains are for applying to the one or more input audio signals, wherein the post-processor includes a median filter operative to carry out median filtering of the raw banded gains, thereby yielding median filtered gains, wherein the generating by the post-processor of a particular post-processed gain for a particular frequency band includes the median filtering using raw gain values for frequency bands adjacent to the particular frequency band, wherein the post-processing is according to one or more properties, including an end condition and a width for the median filtering, and wherein at least one of the end condition of the median filtering and the width of the median filtering depends on signal classification of the one or more input audio signals.</p></layer>
<layer id = "layer654"><p><b>US20180336910A1:SPEECH/AUDIO SIGNAL PROCESSING METHOD AND CODING APPARATUS</b><br><b>Independant Claims</b><br>11) A coding apparatus, comprising: a non-transitory memory storage comprising instructions; and a processor in communication with the memory, wherein the processor executes the instructions to: determine if a first wideband speech/audio signal is a harmonic signal; when the first wideband speech/audio signal is a harmonic signal, adjust a determining condition to generate a broader determining condition, with the broader determining condition being generated to increase a probability of determining that a second wideband speech/audio signal is a harmonic signal, wherein the first wideband speech/audio signal bandwidth is different from the second wideband speech/audio signal bandwidth; and determine whether the second wideband speech/audio signal is a harmonic signal, using the broader determining condition.<br>1) A speech/audio signal processing method performed by an encoder configured on a processor, the method comprising: the encoder configured on the processor determining if a first wideband speech/audio signal is a harmonic signal; when the first wideband speech/audio signal is a harmonic signal, the encoder configured on the processor adjusting a determining condition to generate a broader determining condition, with the broader determining condition being generated to increase a probability of determining that a second wideband speech/audio signal is a harmonic signal, wherein the first wideband speech/audio signal bandwidth is different from the second wideband speech/audio signal bandwidth; and the encoder configured on the processor determining whether the second wideband speech/audio signal is a harmonic signal, using the broader determining condition.</p></layer>
<layer id = "layer655"><p><b>US10339941B2:Comfort noise addition for modeling background noise at low bit-rates</b><br><b>Independant Claims</b><br>29) A method of decoding an audio bitstream, wherein the method comprises:deriving a decoded audio signal from the bitstream, wherein the decoded audio signal comprises at least one decoded frame;producing a noise estimation signal comprising an estimation of a level and/or a spectral shape of a noise in the decoded audio signal by using a noise estimation device;deriving a comfort noise signal from the noise estimation signal; andcombining the decoded frame of the decoded audio signal and the comfort noise by using a combiner in order to acquire an audio output signal, in such way that the decoded frame in the audio output signal comprises artificial noise;wherein a decoder comprising a bitstream decoder and a further bitstream decoder is used for deriving the decoded audio signal from the bitstream, wherein the bitstream decoder and the further bitstream decoder are of different types, wherein the decoded signal is provided either by the bitstream decoder or by the further bitstream decoder, wherein either the decoded signal from the bitstream decoder or the decoded bitstream from the further bitstream is fed to the noise estimation device and to the combiner.<br>25) A method of audio signal encoding for producing an audio bitstream, wherein the method comprises:determining a signal-to-noise ratio of an audio input signal based on a determined energy of a wanted signal of the audio input signal and a determined energy of a noise of the audio input signal;producing a noise reduced audio signal;producing an encoded audio signal corresponding to the audio input signal, wherein, depending on the determined signal-to-noise ratio of the audio input signal, either the audio input signal or the noise reduced audio signal is encoded;deriving the bitstream from the encoded audio signal; andtransmitting a side information, which indicates whether the audio input signal or the noise reduced audio signal is encoded, within the bitstream.<br>24) A method of decoding an audio bitstream, wherein the method comprises:deriving a decoded audio signal from the bitstream, wherein the decoded audio signal comprises at least one decoded frame;producing a noise estimation signal comprising an estimation of a level and/or a spectral shape of a noise in the decoded audio signal;deriving a comfort noise signal from the noise estimation signal; andcombining the decoded frame of the decoded audio signal and the comfort noise signal in order to acquire an audio output signal, in such way that the decoded frame in the audio output signal comprises artificial noise;wherein alternatively a first mode of operation or a second mode of operation is used, wherein in the first mode of operation the comfort noise signal is combined with the decoded frame of the decoded audio signal, whereas the comfort noise signal is not combined with the decoded frame of the decoded audio signal in the second mode of operation; andwherein the first mode of operation or the second mode of operation is used depending on a signal-to-noise ratio of the decoded audio signal, wherein under low-signal-to-noise-ratio-conditions the first mode of operation is used, and wherein under high-signal-to-noise-ratio-conditions the second mode of operation is used.<br>22) An encoder being configured for producing an audio bitstream, wherein the encoder comprises:a bitstream encoder configured to produce an encoded audio signal corresponding to an audio input signal and to derive the bitstream from the encoded audio signal;a signal analyzer comprising a signal-to-noise ratio estimator configured to determine the signal-to-noise ratio of the audio input signal based on an energy of a wanted signal of the audio input signal determined by a wanted signal energy estimator and based on an energy of a noise of the audio input signal determined by noise energy estimator;a noise reduction device configured to produce a noise reduced audio signal; anda switch device configured to feed, depending on the determined signal-to-noise ratio of the audio input signal, either the audio input signal or the noise reduced audio signal to the bitstream encoder for encoding the respective signal, wherein the bitstream encoder is configured to transmit a side information, which indicates whether the audio input signal or the noise reduced audio signal is encoded, within in the bitstream.<br>14) A decoder being configured for processing an encoded audio bitstream, wherein the decoder comprises:a bitstream decoder configured to derive a decoded audio signal from the bitstream, wherein the decoded audio signal comprises at least one decoded frame;a noise estimation device configured to produce a noise estimation signal comprising an estimation of a level and/or a spectral shape of a noise in the decoded audio signal;a comfort noise generating device configured to derive a comfort noise signal from the noise estimation signal; anda combiner configured to combine the decoded frame of the decoded audio signal and the comfort noise signal in order to acquire an audio output signal, in such way that the decoded frame in the audio output signal comprises artificial noise;wherein the decoder comprises a further bitstream decoder, wherein the bitstream decoder and the further bitstream decoder are of different types, wherein the decoder comprises a switch configured to feed either the decoded signal from the bitstream decoder or the decoded signal from the further bitstream decoder to the noise estimation device and to the combiner.<br>1) A decoder being configured for processing an encoded audio bitstream, wherein the decoder comprises:a bitstream decoder configured to derive a decoded audio signal from the bitstream, wherein the decoded audio signal comprises at least one decoded frame;a noise estimation device configured to produce a noise estimation signal comprising an estimation of a level and/or a spectral shape of a noise in the decoded audio signal;a comfort noise generating device configured to derive a comfort noise signal from the noise estimation signal; anda combiner configured to combine the decoded frame of the decoded audio signal and the comfort noise signal in order to acquire an audio output signal, in such way that the decoded frame in the audio output signal comprises artificial noise;wherein the decoder comprises a switch device configured to switch the decoder alternatively to a first mode of operation or to a second mode of operation, wherein in the first mode of operation the comfort noise signal is fed to the combiner, whereas the comfort noise signal is not fed to the combiner in the second mode of operation; andwherein the decoder comprises a control device configured to control the switch device automatically, wherein the control device comprises a noise detector and configured to control the switch device depending on a signal-to-noise ratio of the decoded audio signal, wherein under low-signal-to-noise-ratio-conditions the decoder is switched to the first mode of operation and under high-signal-to-noise-ratio-conditions to the second mode of operation.</p></layer>
<layer id = "layer656"><p><b>US9583114B2:Generation of a comfort noise with high spectro-temporal resolution in discontinuous transmission of audio signals</b><br><b>Independant Claims</b><br>1) Audio decoder for decoding a bitstream so as to produce therefrom an audio output signal, the bitstream comprising at least an active phase followed by at least an inactive phase, wherein the bitstream has encoded therein at least a silence insertion descriptor frame which describes a spectrum of a background noise, the audio decoder comprising: a silence insertion descriptor decoder configured to decode the silence insertion descriptor frame so as to reconstruct the spectrum of the background noise; a decoding device configured to reconstruct the audio output signal from the bitstream during the active phase; a spectral converter configured to determine a spectrum of the audio output signal; a noise estimator device configured to determine a first spectrum of noise of the audio output signal based on the spectrum of the audio output signal provided by the spectral converter, wherein the first spectrum of the noise of the audio output signal comprises a higher spectral resolution than the spectrum of the background noise; a resolution converter configured to establish a second spectrum of the noise of the audio output signal based on the first spectrum of the noise of the audio output signal, wherein the second spectrum of the noise of the audio output signal comprises a same spectral resolution as the spectrum of the background noise; a comfort noise spectrum estimation device comprising a scaling factor computing device configured to compute scaling factors for a spectrum for a comfort noise based on the spectrum of the background noise as provided by the silence insertion descriptor decoder and based on the second spectrum of the noise of the audio output signal as provided by the resolution converter and comprising a comfort noise spectrum generator configured to compute the spectrum for a comfort noise based on the scaling factors; and a comfort noise generator configured to produce the comfort noise during the inactive phase based on the spectrum for the comfort noise.<br>18) A method of decoding an audio bitstream so as to produce therefrom an audio output signal, the bitstream comprising at least an active phase followed by at least an inactive phase, wherein the bitstream has encoded therein at least a silence insertion descriptor frame which describes a spectrum of a background noise, the method comprising: decoding the silence insertion descriptor frame so as to reconstruct the spectrum of the background noise; reconstructing the audio output signal from the bitstream during the active phase; determining a spectrum of the audio output signal; determining a first spectrum of noise of the audio output signal based on the spectrum of the audio output signal, wherein the first spectrum of the noise of the audio output signal comprises a higher spectral resolution than the spectrum of the background noise; establishing a second spectrum of the noise of the audio output signal based on the first spectrum of the noise of the audio output signal, wherein the second spectrum of the noise of the audio output signal comprises a same spectral resolution as the spectrum of the background noise; computing scaling factors for a spectrum for a comfort noise based on the spectrum of the background noise and based on the second spectrum of the noise of the audio output signal; computing the spectrum for the comfort noise based on the scaling factors; and producing the comfort noise during the inactive phase based on the spectrum for the comfort noise.</p></layer>
<layer id = "layer657"><p><b>US9640190B2:Decoding method, decoding apparatus, program, and recording medium therefor</b><br><b>Independant Claims</b><br>1) A decoding method, comprising: a speech decoding step of obtaining a current frame of a decoded speech signal from an input code; a noise generating step of generating a noise signal that is a random signal; and a noise adding step of outputting a noise-added signal, the noise-added signal being obtained by summing said decoded speech signal and a signal obtained by performing, on said noise signal, a signal processing that is based on a spectrum envelope corresponding to the decoded speech signal for the current frame, wherein the spectrum envelope corresponding to the decoded speech signal for said current frame is a spectrum envelope obtained by dulling a spectrum envelope corresponding to a linear predictive coefficient for the current frame provided in said speech decoding step, wherein the dulling operation is an operation which operates a predetermined constant to the linear predictive coefficient for the current frame.<br>5) A decoding apparatus, comprising: processing circuitry configured toobtain a current frame of a decoded speech signal from an input code;generate a noise signal that is a random signal; andoutput a noise-added signal, the noise-added signal being obtained by summing said decoded speech signal and a signal obtained by performing, on said noise signal, a signal processing that is based on a spectrum envelope corresponding to the decoded speech signal for the current frame, wherein the spectrum envelope corresponding to the decoded speech signal for said current frame is a spectrum envelope obtained by dulling a spectrum envelope corresponding to a linear predictive coefficient for the obtained current frame, wherein the dulling operation is an operation which operates a predetermined constant to the linear predictive coefficient for the current frame.<br>9) A non-transitory computer-readable recording medium that stores a program that makes a decoding apparatus perform a decoding method, comprising: a speech decoding step of obtaining a current frame of a decoded speech signal from an input code; a noise generating step of generating a noise signal that is a random signal; and a noise adding step of outputting a noise-added signal, the noise-added signal being obtained by summing said decoded speech signal and a signal obtained by performing, on said noise signal, a signal processing that is based on a spectrum envelope corresponding to the decoded speech signal for the current frame, wherein the spectrum envelope corresponding to the decoded speech signal for said current frame is a spectrum envelope obtained by dulling a spectrum envelope corresponding to a linear predictive coefficient for the current frame provided in said speech decoding step, wherein the dulling operation is an operation which operates a predetermined constant to the linear predictive coefficient for the current frame.</p></layer>
<layer id = "layer658"><p><b>US20180322886A1:AUDIO ENCODER AND DECODER</b><br><b>Independant Claims</b><br>1) A method for decoding an encoded audio signal in a bitstream, the method comprising: determining prediction coefficients based on coefficient data comprised within the bitstream to determine quantized prediction coefficients; inversely quantizing the quantized prediction coefficients to determine dequantized prediction coefficients; and determining a plurality of spectral energy values for a corresponding plurality of frequency bands based on the dequantized prediction coefficients.</p></layer>
<layer id = "layer659"><p><b>US9847095B2:Method and apparatus for adaptively encoding and decoding high frequency band</b><br><b>Independant Claims</b><br>1) A method of reconstructing a high frequency band audio signal, the method comprising: if determined that a frequency band is encoded in a time domain, reconstructing, performed by using at least one processor, the high frequency band audio signal based on a decoded excitation signal of a low frequency band , wherein the frequency band corresponds to a higher frequency band than the low frequency band; and if determined that the frequency band is encoded in a frequency domain, reconstructing the high frequency band audio signal based on an envelope obtained from a received bitstream.<br>4) A non-transitory computer readable medium comprising instructions executable by a computer to cause the computer to perform: if determined that a frequency band is encoded in a time domain, reconstructing a high frequency band audio signal based on a decoded excitation signal of a low frequency band, wherein the frequency band corresponds to a higher frequency band than the low frequency band; and if determined that the frequency band is encoded in a frequency domain, reconstructing the high frequency band audio signal based on an envelope obtained from a received bitstream.</p></layer>
<layer id = "layer660"><p><b>US20180308495A1:APPARATUS AND METHOD FOR GENERATING AN ADAPTIVE SPECTRAL SHAPE OF COMFORT NOISE</b><br><b>Independant Claims</b><br>13) A nontransitory digital storage medium having a computer program stored thereon to perform the method for decoding an encoded audio signal to acquire a reconstructed audio signal, wherein the method comprises: receiving one or more frames, determining, if a current frame of the one or more frames is received and if the current frame being received is not corrupted, one or more first audio signal coefficients, being comprised by the current frame, wherein said one or more first audio signal coefficients indicate a characteristic of the encoded audio signal, and one or more noise coefficients indicating a background noise of the encoded audio signal, generating one or more second audio signal coefficients, depending on the one or more first audio signal coefficients and depending on the one or more noise coefficients, if the current frame is not received or if the current frame being received is corrupted, reconstructing a first portion of the reconstructed audio signal depending on the one or more first audio signal coefficients, if the current frame is received and if the current frame being received is not corrupted, and reconstructing a second portion of the reconstructed audio signal depending on the one or more second audio signal coefficients, if the current frame is not received or if the current frame being received is corrupted, when said computer program is run by a computer.<br>12) A method for decoding an encoded audio signal to acquire a reconstructed audio signal, wherein the method comprises: receiving one or more frames, determining, if a current frame of the one or more frames is received and if the current frame being received is not corrupted, one or more first audio signal coefficients, being comprised by the current frame, wherein said one or more first audio signal coefficients indicate a characteristic of the encoded audio signal, and one or more noise coefficients indicating a background noise of the encoded audio signal, generating one or more second audio signal coefficients, depending on the one or more first audio signal coefficients and depending on the one or more noise coefficients, if the current frame is not received or if the current frame being received is corrupted, reconstructing a first portion of the reconstructed audio signal depending on the one or more first audio signal coefficients, if the current frame is received and if the current frame being received is not corrupted, and reconstructing a second portion of the reconstructed audio signal depending on the one or more second audio signal coefficients, if the current frame is not received or if the current frame being received is corrupted.<br>1) An apparatus for decoding an encoded audio signal to acquire a reconstructed audio signal, wherein the apparatus comprises: a receiving interface for receiving one or more frames, a coefficient generator, and a signal reconstructor, wherein the coefficient generator is configured to determine, if a current frame of the one or more frames is received by the receiving interface and if the current frame being received by the receiving interface is not corrupted, one or more first audio signal coefficients, being comprised by the current frame, wherein said one or more first audio signal coefficients indicate a characteristic of the encoded audio signal, and one or more noise coefficients indicating a background noise of the encoded audio signal, wherein the coefficient generator is configured to generate one or more second audio signal coefficients, depending on the one or more first audio signal coefficients and depending on the one or more noise coefficients, if the current frame is not received by the receiving interface or if the current frame being received by the receiving interface is corrupted, wherein the audio signal reconstructor is configured to reconstruct a first portion of the reconstructed audio signal depending on the one or more first audio signal coefficients, if the current frame is received by the receiving interface and if the current frame being received by the receiving interface is not corrupted, and wherein the audio signal reconstructor is configured to reconstruct a second portion of the reconstructed audio signal depending on the one or more second audio signal coefficients, if the current frame is not received by the receiving interface or if the current frame being received by the receiving interface is corrupted.</p></layer>
<layer id = "layer661"><p><b>US9343056B1:Wind noise detection and suppression</b><br><b>Independant Claims</b><br>1) A method for performing noise reduction, comprising: transforming an acoustic signal from time domain to frequency domain sub-band signals, the acoustic signal representing at least one captured sound; extracting, using at least one hardware processor, a feature from a sub-band of the transformed acoustic signal; detecting the presence of wind noise based on the feature; generating a modification to suppress the wind noise based on the feature; and before reducing other noise within the transformed acoustic signal, applying the modification to suppress the wind noise.<br>12) A system for reducing noise in an acoustic signal, the system comprising: a wind noise characterization engine executable, using at least one hardware processor, to provide a wind noise characterization of a first acoustic signal, the first acoustic signal representing at least one captured sound; a mask generator executable to generate a modification to suppress wind noise; and a modifier module configured to apply the modification to suppress the wind noise based on the wind noise characterization, before environmental noise is reduced within the first acoustic signal.<br>18) A non-transitory computer readable storage medium having embodied thereon a program, the program being executable by a processor to perform a method for reducing noise in an audio signal, the method comprising: transforming an acoustic signal from time domain to frequency domain sub-band signals, the acoustic signal representing at least one captured sound; extracting, using at least one hardware processor, a feature from a sub-band of the transformed acoustic signal; detecting the presence of wind noise based on the feature; generating a modification to suppress the wind noise based on the feature; and before reducing environmental noise within the transformed acoustic signal, applying the modification to suppress the wind noise.</p></layer>
<layer id = "layer662"><p><b>US20180336914A1:Method And Device For Spectral Expansion For An Audio Signal</b><br><b>Independant Claims</b><br>19) A system, comprising: a memory that stores instructions; and a process that executes the instructions to perform operations, the operations comprising:generating a mapping matrix, comprising:receiving a sentence recorded by an ambient microphone and by an ear canal microphone, wherein the ambient microphone captures a reference wideband signal and the ear canal microphone captures a reference narrowband signal;performing, via the processor, a frequency transform on the reference wideband signal;performing, via the processor, another frequency transform on the reference narrowband signal;wherein the mapping matrix is based on an analysis of the frequency transform on the wideband signal and the frequency transform on the narrowband signal;generating an energy envelope analysis of an input narrowband audio signal;generating a resynthesized noise signal by processing a noise signal with the mapping matrix and the envelope analysis to provide the resynthesized noise signal;high-pass filtering the resynthesized noise signal to provide a high-pass filtered resynthesized noise signal; andsumming the high-pass filtered resynthesized noise signal with the input narrowband audio signal.<br>12) A system, comprising: a memory that stores instructions; and a process that executes the instructions to perform operations, the operations comprising:generating a mapping matrix, comprising:receiving a wideband speech signal from an ambient microphone;receiving a narrow band signal from a non-microphone source;performing, via the processor, a frequency transform on the wideband signal;performing, via the processor, another frequency transform on the narrowband signal;wherein the mapping matrix is based on an analysis of the frequency transform on the wideband signal and the frequency transform on the narrowband signal;generating an energy envelope analysis of an input narrowband audio signal;generating a resynthesized noise signal by processing a noise signal with the mapping matrix and the envelope analysis to provide the resynthesized noise signal;high-pass filtering the resynthesized noise signal to provide a high-pass filtered resynthesized noise signal; andsumming the high-pass filtered resynthesized noise signal with the input narrowband audio signal.<br>1) A system, comprising: a wearable communications device, comprising: an ambient microphone and an ear canal microphone; a memory that stores instructions; and a process that executes the instructions to perform operations, the operations comprising:generating a mapping matrix, comprising:simultaneously recording a sentence by the ambient microphone and by the ear canal microphone, wherein the ambient microphone captures a wideband signal and the ear canal microphone captures a narrowband signal;performing, via the processor, a frequency transform on the wideband signal;performing, via the processor, another frequency transform on the narrowband signal;wherein the mapping matrix is based on an analysis of the frequency transform on the wideband signal and the frequency transform on the narrowband signal;generating an energy envelope analysis of an input narrowband audio signal;generating a resynthesized noise signal by processing a noise signal with the mapping matrix and the envelope analysis to provide the resynthesized noise signal;high-pass filtering the resynthesized noise signal to provide a high-pass filtered resynthesized noise signal; andsumming the high-pass filtered resynthesized noise signal with the input narrowband audio signal.</p></layer>
<layer id = "layer663"><p><b>US9263030B2:Adaptive online feature normalization for speech recognition</b><br><b>Independant Claims</b><br>1) A computer-implemented method, performed by a processor, for reducing speaker variability in speech recognition, the computer-implemented method comprising: receiving a first portion of an utterance received from a speaker; based on the first potion of the utterance, placing the speaker into a group, wherein the group is one of a plurality of groups each defined by a range of warping factor values; based on the grouping of the speaker, estimating a warping factor; receiving additional portions of speech from the speaker; adaptively adjusting the estimated warping factor based on the additional portions of speech; and based on the adjusted estimated warping factor, adjust the speech recognition for speaker variability associated with the speaker.<br>10) A computer-readable storage device storing computer-executable instructions for reducing speaker variability in speech recognition, comprising: receiving a window of speech that is sized between 50 ms and 150 ms comprising a portion of an utterance received from a speaker; estimating a warping factor using the window of speech; receiving additional windows of speech; using the additional portions when adaptively estimating the warping factor; and using the warping factor when applying Vocal Tract Length Normalization (VTLN) using the estimated warping factor to adjust for speaker variability that is associated with the speaker.<br>16) A system for adapting for reducing speaker variability in speech recognition, comprising: a processor and memory; an operating environment executing using the processor; and a warping manager that is configured to perform actions comprising: receiving a window of speech that is sized between 50 ms and 150 ms comprising a portion of an utterance received from a speaker; estimating a warping factor using the window of speech; receiving additional windows of speech; using the additional portions when adaptively estimating the warping factor until a value of the warping factor converges; and using the warping factor when applying Vocal Tract Length Normalization (VTLN) using the estimated warping factor to adjust for speaker variability that is associated with the speaker.</p></layer>
<layer id = "layer664"><p><b>US9842594B2:Frequency band table design for high frequency reconstruction algorithms</b><br><b>Independant Claims</b><br>1) A system configured to determine a master scale factor band table of a highband signal of an audio signal, wherein the master scale factor band table is indicative of a frequency resolution of a spectral envelope of the highband signal; wherein the system is configured to: receive a set of parameters transmitted from an audio encoder along with an audio bitstream being indicative of a lowband signal of the audio signal, the set of parameters including a selection parameter and one or more index parameters; store a plurality of pre-determined scale factor band tables in a memory of the system independently from the audio encoder; wherein at least one scale factor band of the pre-determined scale factor band tables comprises a plurality of frequency bands; determine the master scale factor band table by selecting a particular one of the pre-determined scale factor band tables based on the selection parameter of the received set of parameters and by selecting some or all of the scale factor bands of the selected pre-determined scale factor band table using the one or more index parameters of the received set of parameters, the one or more index parameters representing indexes into the selected pre-determined scale factor band table; and reconstruct the highband signal from the lowband signal using the master scale factor band table.<br>29) A method for determining a master scale factor band table for a highband signal of an audio signal, wherein the master scale factor band table is indicative of a frequency resolution of a spectral envelope of the highband signal; wherein the method comprises: receiving a set of parameters transmitted from an audio encoder along with an audio bitstream being indicative of the lowband signal of the audio signal, the set of parameters including a selection parameter and one or more index parameters; storing a plurality of pre-determined scale factor band tables in a memory independently from the audio encoder; wherein at least one scale factor band of the pre-determined scale factor band tables comprises a plurality of frequency bands; determining the master scale factor band table by selecting a particular one of the pre-determined scale factor band tables based on the selection parameter of the received set of parameters and by selecting some or all of the scale factor bands of the selected pre-determined scale factor band table using the one or more index parameters of the set of parameters, the one or more index parameters representing indexes into the selected pre-determined scale factor band table; and reconstructing the highband signal from the lowband signal using the master scale factor band table.</p></layer>
<layer id = "layer665"><p><b>US20190057713A1:METHODS AND APPARATUS FOR DECODING BASED ON SPEECH ENHANCEMENT METADATA</b><br><b>Independant Claims</b><br>9) An apparatus, comprising:a receiver configured to receive mixed audio content, wherein the mixed audio content includes at least a mid-channel mixed content signal and a side-channel mixed content signal, wherein the mid-channel signal represents a weighted or non-weighted sum of two channels of a reference audio channel representation, and wherein the side-channel signal represents a weighted or non-weighted difference of two channels of the reference audio channel representation;a decoder configured to decode the mid-channel signal and the side-channel signal into a left channel signal and a right channel signal, wherein the decoding includes decoding based on speech enhancement metadata, wherein the speech enhancement metadata includes a preference flag which indicates at least a type of speech enhancement operation to be performed on the mid-channel signal and the side-channel signal during decoding, and wherein the speech enhancement metadata further indicates a first type of speech enhancement for the mid-channel signal and a second type of speech enhancement of the mid-channel signal; anda processor configured to generate an audio signal that comprises the left channel signal and the right channel signal for the one or more portions of the decoded mid channel signal and side-channel signal of the mixed audio content.<br>1) A method, comprising:receiving mixed audio content, wherein the mixed audio content includes at least a mid-channel mixed content signal and a side-channel mixed content signal, wherein the mid-channel signal represents a weighted or non-weighted sum of two channels of a reference audio channel representation, and wherein the side-channel signal represents a weighted or non-weighted difference of two channels of the reference audio channel representation;decoding, by an audio decoder, the mid-channel signal and the side-channel signal into a left channel signal and a right channel signal, wherein the decoding includes decoding based on speech enhancement metadata, wherein the speech enhancement metadata includes a preference flag which indicates at least a type of speech enhancement operation to be performed on the mid-channel signal and the side-channel signal during decoding, and wherein the speech enhancement metadata further indicates a first type of speech enhancement for the mid-channel signal and a second type of speech enhancement of the mid-channel signal; andgenerating an audio signal that comprises the left channel signal and the right channel signal for the one or more portions of the decoded mid channel signal and side-channel signal of the mixed audio content,wherein the method is performed by one or more computing devices.</p></layer>
<layer id = "layer666"><p><b>US20190164562A1:Audio Coding Method and Related Apparatus</b><br><b>Independant Claims</b><br>8) An audio signal encoder, comprising:a memory storing program instructions; andat least one processor coupled to the memory, wherein the program instructions cause the at least one processor to be configured to:obtain an audio signal, wherein the audio signal comprises a current frame, and wherein the current frame comprises a subband i, a subband j, a subband x, and a subband y;obtain an average energy of the subband i, an average energy of the subband j, a spectral peak of the subband x, a spectral average of the subband x, a spectral peak of the subband y, and a spectral average of the subband y; andencode the current frame using a high quality transform coding (HQ) algorithm when the average energy of the subband j is greater than a product of the average energy of the subband i multiplied by a first constant (T4), a product of the spectral peak of the subband x multiplied by the spectral average of the subband y is greater than a product of the spectral peak of the subband y multiplied by the spectral average of the subband x and multiplied by a lowest value of a first interval (R1), and the product of the spectral peak of the subband x multiplied by the spectral average of the subband y is less than a product of the spectral peak of the subband y multiplied by the spectral average of the subband x and multiplied by a highest value of the R1.<br>5) An audio signal encoding method, comprising:obtaining, by an audio signal encoder, an audio signal, wherein the audio signal comprises a current frame, and wherein the current frame comprises a subband x and a subband y;obtaining, by the audio signal encoder, a spectral peak of the subband x, a spectral average of the subband x, a spectral peak of the subband y, and a spectral average of the subband y;encoding, by the audio signal encoder, the current frame using a high quality transform coding (HQ) algorithm when a product of the spectral peak of the subband x multiplied by the spectral average of the subband y is less than a product of the spectral peak of the subband y multiplied by the spectral average of the subband x multiplied by a first constant (T44), and the spectral peak of the subband y is greater than a product of the spectral average of the subband y multiplied by a second constant (T45); andencoding, by the audio signal encoder, the current frame using the HQ algorithm when the product of the spectral peak of the subband x multiplied by the spectral average of the subband y is greater than a product of the spectral peak of the subband y multiplied by the spectral average of the subband x multiplied by a third constant (T46), and the spectral peak of the subband y is less than a product of the spectral average of the subband y multiplied by the T45.<br>19) An audio signal encoder, comprising:a circuit configured to obtain an audio signal, wherein the audio signal comprises a current frame, and wherein the current frame comprises a subband x and a subband y; anda circuit configured to obtain a spectral peak of the subband x, a spectral average of the subband x, a spectral peak of the subband y, and a spectral average of the subband y; anda circuit configured to:encode the current frame using a high quality transform coding (HQ) algorithm when a product of the spectral peak of the subband x multiplied by the spectral average of the subband y is less than a product of the spectral peak of the subband y multiplied by the spectral average of the subband x multiplied by a first constant (T44), and the spectral peak of the subband y is greater than a product of the spectral average of the subband y multiplied by a second constant (T45); andencode the current frame using the HQ algorithm when the product of the spectral peak of the subband x multiplied by the spectral average of the subband y is greater than a product of the spectral peak of the subband y multiplied by the spectral average of the subband x multiplied by a third constant (T46), and the spectral peak of the subband y is less than a product of the spectral average of the subband y multiplied by the T47.<br>15) An audio signal encoder, comprising:a circuit configured to obtain an audio signal, wherein the audio signal comprises a current frame, and wherein the current frame comprises a subband i, a subband j, a subband x, and a subband y;a circuit configured to obtain an average energy of the subband i, an average energy of the subband j, a spectral peak of the subband x, a spectral average of the subband x, a spectral peak of the subband y, and a spectral average of the subband y; anda circuit configured to encode the current frame using a high quality transform coding (HQ) algorithm when the average energy of the subband j is greater than a product of the average energy of the subband i multiplied by a first constant (T4), a product of the spectral peak of the subband x multiplied by the spectral average of the subband y is greater than a product of the spectral peak of the subband y multiplied by the spectral average of the subband x and multiplied by a lowest value of a first interval (R1), and the product of the spectral peak of the subband x multiplied by the spectral average of the subband y is less than a product of the spectral peak of the subband y multiplied by the spectral average of the subband x and multiplied by a highest value of the R1.<br>12) An audio signal encoder, comprising:a memory storing program instructions; andat least one processor coupled to the memory, wherein the program instructions cause the at least one processor to be configured to:obtain an audio signal, wherein the audio signal comprises a current frame, and wherein the current frame comprises a subband x and a subband y;obtain a spectral peak of the subband x, a spectral average of the subband x, a spectral peak of the subband y, and a spectral average of the subband y;encode the current frame using a high quality transform coding (HQ) algorithm when a product of the spectral peak of the subband x multiplied by the spectral average of the subband y is less than a product of the spectral peak of the subband y multiplied by the spectral average of the subband x multiplied by a first constant (T44), and the spectral peak of the subband y is greater than a product of the spectral average of the subband y multiplied by a second constant (T45); andencode the current frame using the HQ algorithm when the product of the spectral peak of the subband x multiplied by the spectral average of the subband y is greater than a product of the spectral peak of the subband y multiplied by the spectral average of the subband x multiplied by a third constant (T46), and the spectral peak of the subband y is less than a product of the spectral average of the subband y multiplied by the T47.<br>1) An audio signal encoding method, comprising:obtaining, by an audio signal encoder, an audio signal, wherein the audio signal comprises a current frame, and wherein the current frame comprises a subband i, a subband j, a subband x, and a subband y;obtaining, by the audio signal encoder, an average energy of the subband i, an average energy of the subband j, a spectral peak of the subband x, a spectral average of the subband x, a spectral peak of the subband y, and a spectral average of the subband y; andencoding, by the audio signal encoder, the current frame using a high quality transform coding (HQ) algorithm when the average energy of the subband j is greater than a product of the average energy of the subband i multiplied by a first constant (T4), a product of the spectral peak of the subband x multiplied by the spectral average of the subband y is greater than a product of the spectral peak of the subband y multiplied by the spectral average of the subband x andmultiplied by a lowest value of a first interval (R1), and the product of the spectral peak of the subband x multiplied by the spectral average of the subband y is less than a product of the spectral peak of the subband y multiplied by the spectral average of the subband x and multiplied by a highest value of the R1.</p></layer>
<layer id = "layer667"><p><b>US20180166085A1:Bandwidth Extension Audio Decoding Method and Device for Predicting Spectral Envelope</b><br><b>Independant Claims</b><br>1) A signal encoding method, comprising: performing core layer encoding on at least one of a voice signal or an audio signal and obtaining a core layer bit stream of the at least one of the voice or the audio signal from the core layer encoding; performing extension layer processing on the at least one of the voice or the audio signal and determining a first envelope of an extension band according to the extension layer processing; determining a second envelope of the extension band according to a signal-to-noise ratio of the at least one of the voice or the audio signal, a pitch period of the at least one of the voice or the audio signal, and the first envelope of the extension band; encoding the second envelope and obtaining an extension layer bit stream according to the encoding of the second envelope; and sending the core layer bit stream and the extension layer bit stream to a decoder end.<br>2) A signal decoding method, comprising: receiving, from an encoder end, a core layer bit stream and an extension layer bit stream of at least one of a voice or audio signal; decoding the extension layer bit stream and determining a second envelope of an extension band according to the decoding the extensions layer bitstream, wherein the second envelope is determined by the encoder end according to a signal-to-noise ratio of the at least one of the voice or the audio signal, a pitch period of the at least one of the voice or the audio signal, and a first envelope of the extension band; decoding the core layer bit stream and obtaining a core layer signal of the at least one of the voice or the audio signal according to the decoding the core layer bit stream; predicting an excitation signal of the extension band according to the core layer signal; and predicting a signal of the extension band according to the excitation signal of the extension band and the second envelope of the extension band.<br>3) A signal encoding device, comprising: a processor; and a non-transitory computer-readable storage medium storing a program to be executed by the processor, the program including instructions for:performing core layer encoding on at least one of a voice signal or an audio signal and obtaining a core layer bit stream of the at least one of the voice or the audio signal from the core layer encoding; performing extension layer processing on the at least one of the voice or the audio signal and determining a first envelope of an extension band according to the extension layer processing; determining a second envelope of the extension band according to a signal-to-noise ratio of the at least one of the voice or the audio signal, a pitch period of the at least one of the voice or the audio signal, and the first envelope of the extension band; encoding the second envelope and obtaining an extension layer bit stream according to the encoding of the second envelope; and sending the core layer bit stream and the extension layer bit stream to a decoder end.<br>4) A signal decoding device, comprising: a processor; and a non-transitory computer-readable storage medium storing a program to be executed by the processor, the program including instructions for:receiving, from an encoder end, a core layer bit stream and an extension layer bit stream of at least one of a voice or audio signal; decoding the extension layer bit stream and determining a second envelope of an extension band according to the decoding the extensions layer bitstream, wherein the second envelope is determined by the encoder end according to a signal-to-noise ratio of the at least one of the voice or the audio signal, a pitch period of the at least one of the voice or the audio signal, and a first envelope of the extension band; decoding the core layer bit stream and obtaining a core layer signal of the at least one of the voice or the audio signal according to the decoding the core layer bit stream; predicting an excitation signal of the extension band according to the core layer signal; and predicting a signal of the extension band according to the excitation signal of the extension band and the second envelope of the extension band.</p></layer>
<layer id = "layer668"><p><b>US10147434B2:Signal processing device and signal processing method</b><br><b>Independant Claims</b><br>9) A signal processing method, comprising: detecting a frequency band which satisfies a predetermined condition from an audio signal; generating a reference signal in accordance with the detected frequency band; correcting the generated reference signal on a basis of a frequency characteristic of the generated reference signal; extending the corrected reference signal up to a frequency band higher than the detected frequency band; generating an interpolation signal by weighting each frequency component within the extended frequency band in accordance with a frequency characteristic of the audio signal; and synthesizing the generated interpolation signal with the audio signal, wherein in the generating interpolation signal: (i) a first regression analysis is performed on at least a portion of the audio signal; (ii) an interpolation signal weighting value is calculated for each frequency component within the extended frequency band on a basis of a slope of at least a portion of the audio signal obtained by the first regression analysis; and (iii) the interpolation signal is generated by multiplying the calculated interpolation signal weighting value for each frequency component and each frequency component within the extended frequency band together; wherein the slope of at least the portion of the audio signal obtained by the first regression analysis includes a rate of change of the frequency components within the extended frequency band, and wherein in the generating the interpolation signal, the interpolation signal weighting value is increased as the rate of change gets greater in a minus direction.<br>18) A signal processing method, comprising: detecting a frequency band which satisfies a predetermined condition from an audio signal; generating a reference signal in accordance with the detected frequency band; correcting the generated reference signal on a basis of a frequency characteristic of the generated reference signal; extending the corrected reference signal up to a frequency band higher than the detected frequency band; generating an interpolation signal by weighting each frequency component within the extended frequency band in accordance with a frequency characteristic of the audio signal; and synthesizing the generated interpolation signal with the audio signal; wherein in the generating interpolation signal: (i) a first regression analysis is performed on at least a portion of the audio signal; (ii) an interpolation signal weighting value is calculated for each frequency component within the extended frequency band on a basis of a slope of at least a portion of the audio signal obtained by the first regression analysis; and (iii) the interpolation signal is generated by multiplying the calculated interpolation signal weighting value for each frequency component and each frequency component within the extended frequency band together; and wherein in the generating the interpolation signal, the interpolation signal weighting value is decreased as an upper frequency limit of a range for the first regression analysis gets higher.<br>17) A signal processing device, comprising: a band detecting unit configured to detect a frequency band which satisfies a predetermined condition from an audio signal; an extracting unit configured to generate a reference signal in accordance with the detected frequency band by the band detecting unit; a reference signal correcting unit configured to correct the generated reference signal on a basis of a frequency characteristic of the generated reference signal; a frequency band extending unit configured to extend the corrected reference signal up to a frequency band higher than the detected frequency band; an interpolation signal generating unit configured to generate an interpolation signal by weighting each frequency component within the extended frequency band in accordance with a frequency characteristic of the audio signal; an adder unit configured to synthesize the generated interpolation signal with the audio signal; wherein the interpolation signal generating unit: (i) performs a first regression analysis on at least a portion of the audio signal; (ii) calculates an interpolation signal weighting value for each frequency component within the extended frequency band on a basis of a slope of at least a portion of the audio signal obtained by the first regression analysis; and (iii) generates the interpolation signal by multiplying the calculated interpolation signal weighting value for each frequency component and each frequency component within the extended frequency band together; and wherein the interpolation signal generating unit decreases the interpolation signal weighting value as an upper frequency limit of a range for the first regression analysis gets higher.<br>1) A signal processing device, comprising: a band detecting unit configured to detect a frequency band which satisfies a predetermined condition from an audio signal; an extracting unit configured to generate a reference signal in accordance with the detected frequency band by the band detecting unit; a reference signal correcting unit configured to correct the generated reference signal on a basis of a frequency characteristic of the generated reference signal; a frequency band extending unit configured to extend the corrected reference signal up to a frequency band higher than the detected frequency band; an interpolation signal generating unit configured to generate an interpolation signal by weighting each frequency component within the extended frequency band in accordance with a frequency characteristic of the audio signal; an adder unit configured to synthesize the generated interpolation signal with the audio signal, wherein the interpolation signal generating unit: (i) performs a first regression analysis on at least a portion of the audio signal; (ii) calculates an interpolation signal weighting value for each frequency component within the extended frequency band on a basis of a slope of at least a portion of the audio signal obtained by the first regression analysis; and (iii) generates the interpolation signal by multiplying the calculated interpolation signal weighting value for each frequency component and each frequency component within the extended frequency band together; and wherein the slope of at least the portion of the audio signal obtained by the first regression analysis includes a rate of change of the frequency components within the extended frequency band; and wherein the interpolation signal generating unit increases the interpolation signal weighting value as the rate of change gets greater in a minus direction.</p></layer>
<layer id = "layer669"><p><b>US9536540B2:Speech signal separation and synthesis based on auditory scene analysis and speech modeling</b><br><b>Independant Claims</b><br>1) A method for generating clean speech from a mixture of noise and speech, the method comprising: deriving speech parameters, based on the mixture of noise and speech and a model of speech, the deriving using at least one hardware processor, wherein the deriving speech parameters comprises: performing one or more spectral analyses on the mixture of noise and speech to generate one or more spectral representations; deriving, based on the one or more spectral representations, feature data; grouping target speech features in the feature data according to the model of speech; separating the target speech features from the feature data; and generating, based at least partially on the target speech features, the speech parameters; and synthesizing, based at least partially on the speech parameters, clean speech.<br>11) A system for generating clean speech from a mixture of noise and speech, the system comprising: one or more processors; and a memory communicatively coupled with the processor, the memory storing instructions which if executed by the one or more processors perform a method comprising: deriving speech parameters, based on the mixture of noise and speech and a model of speech, wherein the deriving speech parameters comprises: performing one or more spectral analyses on the mixture of noise and speech to generate one or more spectral representations; deriving, based on the one or more spectral representations, feature data; grouping target speech features in the feature data according to the model of speech; separating the target speech features from the feature data; and generating, based at least partially on the target speech features, the speech parameters; and synthesizing, based at least partially on the speech parameters, clean speech.<br>20) A non-transitory computer-readable storage medium having embodied thereon a program, the program being executable by a processor to perform a method for generating clean speech from a mixture of noise and speech, the method comprising: deriving speech parameters, based on the mixture of noise and speech and a model of speech, via instructions stored in the memory and executed by the one or more processors, wherein the deriving speech parameters comprises: performing one or more spectral analyses on the mixture of noise and speech to generate one or more spectral representations; deriving, based on the one or more spectral representations, feature data; grouping target speech features in the feature data according to the model of speech; separating the target speech features from the feature data; and generating, based at least partially on the target speech features, the speech parameters; and synthesizing, based at least partially on the speech parameters, via instructions stored in the memory and executed by the one or more processors, clean speech.</p></layer>
<layer id = "layer670"><p><b>US10249313B2:Adaptive bandwidth extension and apparatus for the same</b><br><b>Independant Claims</b><br>9) An apparatus for decoding an encoded audio bitstream, comprising:at least one processor; andat least one memory storing instructions which, when executed by the processor, cause the processor to:decode the audio bitstream to produce a decoded low band audio signal and generate a low band excitation spectrum corresponding to a low frequency band;determine a sub-band area from the low frequency band using at least one parameter which indicates energy distribution information of a spectral envelope of the decoded low band audio signal; wherein a starting point of the sub-band area is corresponding to the highest spectral formant energy within a searching range, and wherein the searching range is a frequency region within the low frequency band;generate a high band excitation spectrum for a high frequency band by copying a sub-band excitation spectrum from the determined sub-band area to the high frequency band;generate an extended high band audio signal using the generated high band excitation spectrum; andsynthesize an audio output signal having an extended frequency bandwidth according to the extended high band audio signal and the decoded low band audio signal.<br>16) A non-transitory storage medium storing instructions which, when executed by at least one processor, cause the processor to perform operations comprising:decoding the audio bitstream to produce a decoded low band audio signal and generate a low band excitation spectrum corresponding to a low frequency band;determining a sub-band area from the low frequency band using at least one parameter which indicates energy distribution information of a spectral envelope of the decoded low band audio signal; wherein a starting point of the sub-band area is corresponding to the highest spectral formant energy within a searching range, and wherein the searching range is a frequency region within the low frequency band;generating a high band excitation spectrum for a high frequency band by copying a sub-band excitation spectrum from the determined sub-band area to the high frequency band;generating an extended high band audio signal using the generated high band excitation spectrum; andsynthesizing an audio output signal having an extended frequency bandwidth according to the extended high band audio signal and the decoded low band audio signal.<br>1) A method of decoding an encoded audio bitstream at a decoder, comprising:decoding the audio bitstream to produce a decoded low band audio signal and generate a low band excitation spectrum corresponding to a low frequency band;determining a sub-band area from the low frequency band using at least one parameter which indicates energy distribution information of a spectral envelope of the decoded low band audio signal; wherein a starting point of the sub-band area is corresponding to the highest spectral formant energy within a searching range, and wherein the searching range is a frequency region within the low frequency band;generating a high band excitation spectrum for a high frequency band by copying a sub-band excitation spectrum from the determined sub-band area to the high frequency band;generating an extended high band audio signal using the generated high band excitation spectrum; andsynthesizing an audio output signal having an extended frequency bandwidth according to the extended high band audio signal and the decoded low band audio signal.</p></layer>
<layer id = "layer671"><p><b>US10083708B2:Estimation of mixing factors to generate high-band excitation signal</b><br><b>Independant Claims</b><br>7) An apparatus for adjusting a mixing parameter to reduce artifacts associated with a high-band estimate, the apparatus comprising: a linear prediction analysis filter configured to generate a high-band residual signal based on a high-band portion of an audio signal; a non-linear transformation generator configured to generate a harmonically extended signal at least partially based on a low-band portion of the audio signal; a high-band adjustment factor calculator configured to estimate a high-band adjustment factor using a closed-loop analysis, the high-band adjustment factor estimated based on the high-band residual signal, the harmonically extended signal, and modulated noise, wherein the modulated noise is at least partially based on the harmonically extended signal and white noise; a mixing factor calculator configured to estimate a mixing factor based on the high-band adjustment factor and a voicing factor; a high-band excitation generator configured to:scale the harmonically extended signal based on the mixing factor to generate a first scaled signal;scale the modulated noise based on the mixing factor to generate a second scaled signal; andcombine the first scaled signal and the second scaled signal to generate a high-band excitation signal; encoding circuitry configured to generate an encoded bit-stream corresponding to an encoded version of the audio signal, the encoded bit-stream including data representing the high-band adjustment factor; and a transmitter configured to transmit the encoded bit-stream to a receiver, the encoded bit-stream usable by the receiver to reconstruct the audio signal.<br>16) An apparatus for adjusting a mixing parameter to reduce artifacts associated with a high-band estimate, the apparatus comprising: means for generating a high-band residual signal based on a high-band portion of an audio signal; means for generating a harmonically extended signal at least partially based on a low-band portion of the audio signal; means for estimating a high-band adjustment factor using a closed-loop analysis, the high-band adjustment factor estimated based on the high-band residual signal, the harmonically extended signal, and modulated noise, wherein the modulated noise is at least partially based on the harmonically extended signal and white noise; means for estimating a mixing factor based on the high-band adjustment factor and a voicing factor; means for generating a high-band excitation signal, the means for generating the high-band excitation signal comprising:means for scaling the harmonically extended signal based on the mixing factor to generate a first scaled signal;means for scaling the modulated noise based on the mixing factor to generate a second scaled signal; andmean for combining the first scaled signal and the second scaled signal to generate the high-band excitation signal; means for generating an encoded bit-stream corresponding to an encoded version of the audio signal, the encoded bit-stream including data representing the high-band adjustment factor; and means for transmitting the encoded bit-stream to a receiver, the encoded bit-stream usable by the receiver to reconstruct the audio signal.<br>13) A non-transitory computer readable medium comprising instructions for adjusting a mixing parameter to reduce artifacts associated with a high-band estimate, the instructions, when executed by a processor at a speech encoder, cause the processor to perform operations comprising: generating a high-band residual signal based on a high-band portion of an audio signal; generating a harmonically extended signal at least partially based on a low-band portion of the audio signal; estimating a high-band adjustment factor using a closed-loop analysis, the high-band adjustment factor estimated based on the high-band residual signal, the harmonically extended signal, and modulated noise, wherein the modulated noise is at least partially based on the harmonically extended signal and white noise; estimating a mixing factor based on the high-band adjustment factor and a voicing factor; scaling the harmonically extended signal based on the mixing factor to generate a first scaled signal; scaling the modulated noise based on the mixing factor to generate a second scaled signal; combining the first scaled signal and the second scaled signal to generate the high-band excitation signal; generating an encoded bit-stream corresponding to an encoded version of the audio signal, the encoded bit-stream including data representing the high-band adjustment factor; and initiating transmission of the encoded bit-stream to a receiver, the encoded bit-stream usable by the receiver to reconstruct the audio signal.<br>1) A method of adjusting a mixing parameter to reduce artifacts associated with a high-band estimate, the method comprising: generating, at a speech encoder, a high-band residual signal based on a high-band portion of an audio signal; generating a harmonically extended signal at least partially based on a low-band portion of the audio signal; estimating a high-band adjustment factor using a closed-loop analysis, the high-band adjustment factor estimated based on the high-band residual signal, the harmonically extended signal, and modulated noise, wherein the modulated noise is at least partially based on the harmonically extended signal and white noise; estimating a mixing factor based on the high-band adjustment factor and a voicing factor; scaling the harmonically extended signal based on the mixing factor to generate a first scaled signal; scaling the modulated noise based on the mixing factor to generate a second scaled signal; combining the first scaled signal and the second scaled signal to generate a high-band excitation signal; generating an encoded bit-stream corresponding to an encoded version of the audio signal, the encoded bit-stream including data representing the high-band adjustment factor; and transmitting the encoded bit-stream to a receiver, the encoded bit-stream usable by the receiver to reconstruct the audio signal.</p></layer>
<layer id = "layer672"><p><b>US9620134B2:Gain shape estimation for improved tracking of high-band temporal characteristics</b><br><b>Independant Claims</b><br>1) A method comprising: performing a first determination, at a speech encoder, of first gain shape parameters based at least in part on energy levels of a first plurality of sub-frames of a harmonically extended signal, based at least in part on energy levels of a second plurality of sub-frames of a high-band residual signal associated with a high-band portion of an audio signal, or any combination thereof; generating a high-band excitation signal based at least in part on the first gain shape parameters; generating a synthesized high-band signal based on the high-band excitation signal; performing a second determination of second gain shape parameters based on the synthesized high-band signal and based on the high-band portion of the audio signal; and inserting the first gain shape parameters and the second gain shape parameters into an encoded version of the audio signal.<br>12) An apparatus comprising: a first gain shape estimator configured to determine first gain shape parameters at least in part based on energy levels of a first plurality of sub-frames of a harmonically extended signal, based at least in part on energy levels of a second plurality of sub-frames of a high-band residual signal associated with a high-band portion of an audio signal, or any combination thereof; a high-band excitation generator configured to generate a high-band excitation signal based at least in part on the first gain shape parameters; a linear prediction synthesizer configured to perform a linear prediction synthesis operation on the high-band excitation signal to generate a synthesized high-band signal; a second gain shape estimator configured to determine second gain shape parameters based on the synthesized high-band signal and based on the high-band portion of the audio signal; and circuitry configured to insert the first gain shape parameters and the second gain shape parameters into an encoded version of the audio signal.<br>21) The apparatus of claim. , further comprising: a first gain shape adjuster configured to adjust the harmonically extended signal based on a low-band frame of the harmonically extended signal; and a second gain shape adjuster configured to adjust the synthesized high-band signal based on the second gain shape parameters.<br>22) A method comprising: receiving, at a speech decoder, an encoded audio signal from a speech encoder, wherein the encoded audio signal comprises:first gain shape parameters based on a first determination, the first determination based at least in part on energy levels of a first plurality of sub-frames of a first harmonically extended signal generated at the speech encoder, based at least in part on energy levels of a second plurality of sub-frames of a high-band residual signal generated at the speech encoder, or any combination thereof; andsecond gain shape parameters based on a second determination, the second determination based on a first synthesized high-band signal generated at the speech encoder and based on a high-band portion of an audio signal, wherein the synthesized high-band signal is based on a first high-band excitation signal that is based at least in part on the first gain shape parameters; and reproducing the audio signal from the encoded audio signal based on the first gain shape parameters and based on the second gain shape parameters.<br>26) A system including a speech decoder, the speech decoder configured to: receive an encoded audio signal from a speech encoder, wherein the encoded audio signal comprises:first gain shape parameters based on a first determination, the first determination based at least in part on energy levels of a first plurality of sub-frames of a first harmonically extended signal generated at the speech encoder, based at least in part on energy levels of a second plurality of sub-frames of a high-band residual signal generated at the speech encoder, or any combination thereof; andsecond gain shape parameters based on a second determination, the second determination based on a first synthesized high-band signal generated at the speech encoder and based on a high-band portion of an audio signal, wherein the first synthesized high-band signal is based on a first high-band excitation signal that is based at least in part on the first gain shape parameters; and reproduce the audio signal from the encoded audio signal based on the first gain shape parameters and based on the second gain shape parameters.</p></layer>
<layer id = "layer673"><p><b>US9384746B2:Systems and methods of energy-scaled signal processing</b><br><b>Independant Claims</b><br>1) A method comprising: determining a first modeled high-band signal based on a low-band excitation signal of an audio signal, the audio signal including a high-band portion and a low-band portion; determining a first set of one or more scaling factors based on energy of sub-frames of the first modeled high-band signal and energy of corresponding sub-frames of the high-band portion of the audio signal; applying a second set of one or more scaling factors based on at least one among the first set of one or more scaling factors to a modeled high-band excitation signal to determine a scaled high-band excitation signal; determining a second modeled high-band signal based on the scaled high-band excitation signal; determining gain parameters based on the second modeled high-band signal and the high-band portion of the audio signal; and outputting a data stream based on the determined gain parameters.<br>16) An apparatus comprising: a first synthesis filter configured to determine a first modeled high-band signal based on a low-band excitation signal of an audio signal, the audio signal including a high-band portion and a low-band portion; a scaling module configured to determine scaling factors based on energy of sub-frames of the first modeled high-band signal and energy of corresponding sub-frames of the high-band portion of the audio signal and to apply the scaling factors to a modeled high-band excitation signal to determine a scaled high-band excitation signal; a second synthesis filter configured to determine a second modeled high-band signal based on the scaled high-band excitation signal; a gain estimator configured to determine gain parameters based on the second modeled high-band signal and the high-band portion of the audio signal; and a multiplexer configured to output a data stream based on the determined gain parameters.<br>27) A device comprising: means for determining a first modeled high-band signal based on a low-band excitation signal of an audio signal, the audio signal including a high-band portion and a low-band portion; means for determining scaling factors based on energy of sub-frames of the first modeled high-band signal and energy of corresponding sub-frames of the high-band portion of the audio signal; means for applying the scaling factors to a modeled high-band excitation signal to determine a scaled high-band excitation signal; means for determining a second modeled high-band signal based on the scaled high-band excitation signal; means for determining gain parameters based on the second modeled high-band signal and the high-band portion of the audio signal; and means for outputting a data stream responsive to the means for determining gain parameters.<br>30) A non-transitory computer-readable medium storing instructions that are executable by a processor to cause the processor to perform operations comprising: determining a first modeled high-band signal based on a low-band excitation signal of an audio signal, the audio signal including a high-band portion and a low-band portion; determining scaling factors based on energy of sub-frames of the first modeled high-band signal and energy of corresponding sub-frames of the high-band portion of the audio signal; applying the scaling factors to a modeled high-band excitation signal to determine a scaled high-band excitation signal; determining a second modeled high-band signal based on the scaled high-band excitation signal; determining gain parameters based on the second modeled high-band signal and the high-band portion of the audio signal; and outputting a data stream based on the determined gain parameters.</p></layer>
<layer id = "layer674"><p><b>US10297263B2:High band excitation signal generation</b><br><b>Independant Claims</b><br>27) An apparatus comprising:means for extracting a voicing classification parameter of an audio signal;means for determining a filter coefficient of a low pass filter based on the voicing classification parameter, the filter coefficient having:a first value if the voicing classification parameter indicates that the audio signal is a strongly voiced signal;a second value if the voicing classification parameter indicates that the audio signal is a weakly voiced signal, the second value lower than the first value;a third value if the voicing classification parameter indicates that the audio signal is a weakly unvoiced signal, the third value lower than the second value; ora fourth value if the voicing classification parameter indicates that the audio signal is a strongly unvoiced signal, the fourth value lower than the third value;means for filtering a low-band portion of the audio signal to generate a low-band audio signal;means for controlling an amplitude of a temporal envelope of the low-band audio signal based on the filter coefficient of the low pass filter;means for modulating a white noise signal based on the amplitude of the temporal envelope to generate a modulated white noise signal;means for scaling the modulated white noise signal based on a noise gain to generate a scaled modulated white noise signal;means for mixing a scaled version of the low-band audio signal with the scaled modulated white noise signal to generate a high-band excitation signal; andmeans for generating a decoded version of the audio signal based on the high-band excitation signal and for providing the decoded version of the audio signal to a device that includes a sneaker.<br>20) A non-transitory computer-readable medium comprising instructions that, when executed by a processor within a decoder, cause the processor to perform operations comprising:extracting a voicing classification parameter of an audio signal;determining a filter coefficient of a low pass filter based on the voicing classification parameter, the filter coefficient having:a first value if the voicing classification parameter indicates that the audio signal is a strongly voiced signal;a second value if the voicing classification parameter indicates that the audio signal is a weakly voiced signal, the second value lower than the first value;a third value if the voicing classification parameter indicates that the audio signal is a weakly unvoiced signal, the third value lower than the second value; ora fourth value if the voicing classification parameter indicates that the audio signal is a strongly unvoiced signal, the fourth value lower than the third value;filtering a low-band portion of the audio signal to generate a low-band audio signal;controlling an amplitude of a temporal envelope of the low-band audio signal based on the filter coefficient of the low pass filter;modulating a white noise signal based on the amplitude of the temporal envelope to generate a modulated white noise signal;scaling the modulated white noise signal based on a noise gain to generate a scaled modulated white noise signal;mixing a scaled version of the low-band audio signal with the scaled modulated white noise signal to generate a high-band excitation signal;generating a decoded version of the audio signal based on the high-band excitation signal; andproviding the decoded version of the audio signal to a device that includes a speaker.<br>11) An apparatus comprising:a voicing classifier configured to extract a voicing classification parameter of an audio signal;an envelope adjuster configured to:determine a filter coefficient of a low pass filter based on the voicing classification parameter, the filter coefficient having:a first value if the voicing classification parameter indicates that the audio signal is a strongly voiced signal;a second value if the voicing classification parameter indicates that the audio signal is a weakly voiced signal, the second value lower than the first value;a third value if the voicing classification parameter indicates that the audio signal is a weakly unvoiced signal, the third value lower than the second value; ora fourth value if the voicing classification parameter indicates that the audio signal is a strongly unvoiced signal, the fourth value lower than the third value; andcontrol an amplitude of a temporal envelope of a low-band audio signal based on the filter coefficient of the low pass filter, wherein a low-band portion of the audio signal is filtered to generate the low-band audio signal;a modulator configured to modulate a white noise signal based on the amplitude of the temporal envelope to generate a modulated white noise signal;a multiplier configured to scale the modulated white noise signal based on a noise gain to generate a scaled modulated white noise signal;an adder configured to mix a scaled version of the low-band audio signal with the scaled modulated white noise signal to generate a high-band excitation signal; andcircuitry configured to generate a decoded version of the audio signal based on the high-band excitation signal and further configured to provide the decoded version of the audio signal to a device that includes a speaker.<br>1) A method comprising:extracting, at a decoder, a voicing classification parameter of an audio signal;determining a filter coefficient of a low pass filter based on the voicing classification parameter, the filter coefficient having:a first value if the voicing classification parameter indicates that the audio signal is a strongly voiced signal;a second value if the voicing classification parameter indicates that the audio signal is a weakly voiced signal, the second value lower than the first value;a third value if the voicing classification parameter indicates that the audio signal is a weakly unvoiced signal, the third value lower than the second value; ora fourth value if the voicing classification parameter indicates that the audio signal is a strongly unvoiced signal, the fourth value lower than the third value;filtering a low-band portion of the audio signal to generate a low-band audio signal;controlling an amplitude of a temporal envelope of the low-band audio signal based on the filter coefficient of the low pass filter;modulating a white noise signal based on the amplitude of the temporal envelope to generate a modulated white noise signal;scaling the modulated white noise signal based on a noise gain to generate a scaled modulated white noise signal;mixing a scaled version of the low-band audio signal with the scaled modulated white noise signal to generate a high-band excitation signal;generating a decoded version of the audio signal based on the high-band excitation signal; andproviding the decoded version of the audio signal to a device that includes a speaker.</p></layer>
<layer id = "layer675"><p><b>US9721580B2:Situation dependent transient suppression</b><br><b>Independant Claims</b><br>1) A method performed by a teleconference computing device for suppressing transient noise in an audio signal, the method comprising: estimating a voice probability for a segment of the audio signal containing transient noise, the estimated voice probability being a probability that the segment contains voice data; responsive to determining that the estimated voice probability for the segment is greater than a threshold probability, suppressing the transient noise contained in the segment of the audio signal while reducing distortion of the voice data, including:calculating a spectral mean for the audio segment over a plurality of frequency bins of the audio segment, andfor each frequency bin of the plurality of frequency bins of the audio segment, if a comparison of a current value of the magnitude of the frequency bin to the spectral mean and to a calculated factor of the spectral mean indicates that transient noise is present, suppressing the transient noise in the frequency bin, wherein the calculated factor of the spectral mean is a fixed spectral weighting that is configured to de-emphasize frequency bins of the plurality of frequency bins corresponding to frequencies at which the voice data is transmitted, wherein suppressing the transient noise includes adjusting the magnitude of the frequency bin to a new value between the spectral mean and the current value of the magnitude of the frequency bin; and responsive to determining that the estimated voice probability for the segment is less than the threshold probability, suppressing the transient noise contained in the segment of the audio signal while not reducing distortion of the voice data, including:calculating a spectral mean for the audio segment over the plurality of frequency bins of the audio segment, andfor each frequency bin of the plurality of frequency bins of the audio segment, if a comparison of a magnitude of the frequency bin to the spectral mean indicates that transient noise is present, suppressing the transient noise in the frequency bin, wherein suppressing the transient noise includes adjusting the magnitude of the frequency bin to a new value between the spectral mean and the current value of the magnitude of the frequency bin, wherein the transient noise is at least one of feedback noise, fan noise, and button-clicking noise due to mechanical connection between an audio capture device and a keyboard or trackpad of the teleconferencing computing device.<br>16) A method performed by a teleconference computing device for suppressing transient noise in an audio signal, the method comprising: estimating a voice probability for a segment of the audio signal containing transient noise, the estimated voice probability being a probability that the segment contains voice data; responsive to determining that the estimated voice probability for the segment is greater than a threshold probability, suppressing the transient noise contained in the segment of the audio signal while reducing distortion of the voice data, including:calculating a spectral mean for the audio segment over a plurality of frequency bins of the audio segment, andfor each frequency bin of the plurality of frequency bins of the audio segment, if a comparison of a current value of the magnitude of the frequency bin to the spectral mean and to a calculated factor of the spectral mean indicates that transient noise is present, suppressing the transient noise in the frequency bin, wherein the calculated factor of the spectral mean is a fixed spectral weighting that is configured to de-emphasize frequency bins of the plurality of frequency bins corresponding to frequencies at which the voice data is transmitted, wherein suppressing the transient noise includes adjusting the magnitude of the frequency bin to a new value between the spectral mean and the current value of the magnitude of the frequency bin; and responsive to determining that the estimated voice probability for the segment is less than the threshold probability, suppressing the transient noise contained in the segment of the audio signal while not reducing distortion of the voice data, including:calculating a spectral mean for the audio segment over the plurality of frequency bins of the audio segment, andfor each frequency bin of the plurality of frequency bins of the audio segment, if a comparison of a magnitude of the frequency bin to the spectral mean indicates that transient noise is present, suppressing the transient noise in the frequency bin, wherein suppressing the transient noise includes adjusting the magnitude of the frequency bin to a new value between the spectral mean and the current value of the magnitude of the frequency bin, wherein the transient noise is at least one of feedback noise, fan noise, and button-clicking noise due to mechanical connection between an audio capture device and a keyboard or trackpad of the teleconferencing computing device.<br>9) A teleconferencing computing system for suppressing transient noise in an audio signal, the system comprising: at least one processor; and a non-transitory computer-readable medium coupled to the at least one processor having instructions stored thereon which, when executed by the at least one processor, causes the at least one processor to:estimate a voice probability for a segment of the audio signal containing transient noise, the estimated voice probability being a probability that the segment contains voice data;responsive to determining that the estimated voice probability for the segment is greater than a threshold probability, suppress the transient noise contained in the segment of the audio signal while reducing distortion of the voice data, including:calculating a spectral mean for the audio segment over a plurality of frequency bins of the audio segment, andfor each frequency bin of the plurality of frequency bins of the audio segment, if a comparison of a current value of the magnitude of the frequency bin to the spectral mean and to a calculated factor of the spectral mean indicates that transient noise is present, suppressing the transient noise in the frequency bin, wherein the calculated factor of the spectral mean is a fixed spectral weighting that is configured to de-emphasize frequency bins of the plurality of frequency bins corresponding to frequencies at which the voice data is transmitted, wherein suppressing the transient noise includes adjusting the magnitude of the frequency bin to a new value between the spectral mean and the current value of the magnitude of the frequency bin; andresponsive to determining that the estimated voice probability for the segment is less than the threshold probability, suppress the transient noise contained in the segment of the audio signal while not reducing distortion of the voice data, including:calculating a spectral mean for the audio segment over a plurality of frequency bins of the audio segment, andfor each frequency bin of the plurality of frequency bins of the audio segment, if a comparison of a magnitude of the frequency bin to the spectral mean indicates that transient noise is present, suppress the transient noise in the frequency bin, wherein suppressing the transient noise includes adjusting the magnitude of the frequency bin to a new value between the spectral mean and the current value of the magnitude of the frequency bin,wherein the transient noise is at least one of feedback noise, fan noise, and button-clicking noise due to mechanical connection between an audio capture device and a keyboard or trackpad of the teleconferencing computing device.</p></layer>
<layer id = "layer676"><p><b>US9620137B2:Determining between scalar and vector quantization in higher order ambisonic coefficients</b><br><b>Independant Claims</b><br>1) A method of decoding a bitstream indicative of a plurality of higher-order ambisonic (HOA) coefficients representative of a soundfield, the method comprising: obtaining, by an audio decoding device, the bitstream, wherein the bitstream includes a syntax element identifying whether the vector quantization or the scalar quantization was performed; performing, by the audio decoding device and based on the syntax element identifying whether the vector quantization or the scalar quantization was performed, either vector dequantization or scalar dequantization with respect to a spatial component defined in a spherical harmonic domain; reconstructing, by the audio decoding device, the plurality of HOA coefficients based on the dequantized spatial component; rendering, by the audio decoding device, one or more loudspeaker feeds based on the reconstructed plurality of HOA coefficients; and reproducing, by one or more loudspeakers coupled to the audio decoding device, the soundfield based on the one or more loudspeaker feeds.<br>10) A device configured to decode a bitstream indicative of a plurality of higher-order ambisonic (HOA) coefficients representative of a soundfield, the device comprising: a memory configured to store the bitstream that includes a syntax element that identifies whether the vector quantization or the scalar quantization was performed; and one or more processors coupled to the memory, and configured to:perform, based on the syntax element that identifies whether the vector quantization or the scalar quantization was performed, either vector dequantization or scalar dequantization with respect to a spatial component defined in a spherical harmonic domain;reconstruct the plurality of HOA coefficients based on the dequantized spatial component; andrender one or more loudspeaker feeds based on the reconstructed plurality of HOA coefficients; and one or more loudspeakers coupled to the processor, and configured to reproduce the soundfield based on the one or more loudspeaker feeds.<br>19) A method of encoding audio data indicative of a plurality of higher-order ambisonic (HOA) coefficients representative of a soundfield, the method comprising: capturing, by a microphone coupled to an audio encoding device, the audio data; and determining, by the audio encoding device, whether to perform vector quantization or scalar quantization with respect to a spatial component decomposed from the plurality of HOA coefficients; performing, by the audio encoding device and so as to generate a bitstream including an encoded version of the audio data, either the vector quantization or the scalar quantization with respect to the spatial component based on the determination; and specifying, by the audio encoding device and in the bitstream, a syntax element indicating whether the vector quantization or the scalar quantization was performed.</p></layer>
<layer id = "layer677"><p><b>US9524720B2:Systems and methods of blind bandwidth extension</b><br><b>Independant Claims</b><br>1) A method comprising: determining, based on multiple quantized low-band parameters and a set of low-band parameters of an audio signal, a first set of high-band parameters and a second set of high-band parameters, wherein a number of the multiple quantized low-band parameters is changed from frame to frame of the audio signal; and predicting a set of high-band parameters based on a weighted combination of the first set of high-band parameters and the second set of high-band parameters.<br>13) An apparatus comprising: a processor; and a memory storing instructions executable by the processor to perform operations comprising: determining, based on multiple quantized low-band parameters and a set of low-band parameters of an audio signal, a first set of high-band parameters and a second set of high-band parameters, wherein a number of the multiple quantized low-band parameters is changed from frame to frame of the audio signal; and predicting a set of high-band parameters based on a weighted combination of the first set of high-band parameters and the second set of high-band parameters.<br>24) A non-transitory computer-readable medium comprising instructions that, when executed by a processor, cause the processor to: determine, based on multiple quantized low-band parameters and a set of low-band parameters of an audio signal, a first set of high-band parameters and a second set of high-band parameters, wherein a number of the multiple quantized low-band parameters is changed from frame to frame of the audio signal; and predict a set of high-band parameters based on a weighted combination of the first set of high-band parameters and the second set of high-band parameters.<br>28) An apparatus comprising: means for determining, based on multiple quantized low-band parameters and a set of low-band parameters of an audio signal, a first set of high-band parameters and a second set of high-band parameters, wherein a number of the multiple quantized low-band parameters is changed from frame to frame of the audio signal; and means for predicting a set of high-band parameters based on a weighted combination of the first set of high-band parameters and the second set of high-band parameters.</p></layer>
<layer id = "layer678"><p><b>US10163447B2:High-band signal modeling</b><br><b>Independant Claims</b><br>35) A non-transitory computer-readable medium comprising instructions that, when executed by a processor at a speech decoder, cause the processor to: generate a harmonically extended signal based on a low-band excitation signal, wherein the low-band excitation signal is generated by a linear prediction based decoder based on parameters received from a speech encoder; generate a group of high-band excitation sub-bands based, at least in part, on the harmonically extended signal; and adjust, at a dedicated parameter adjuster, the group of high-band excitation sub-bands based on adjustment parameters received from the speech encoder, wherein a transmission bandwidth of a bit stream is reduced compared to transmission of an encoded version of high-frequency sub-bands of an encoder-side audio signal, and wherein the adjustment parameters comprise:a first adjustment parameter based on a comparison of an energy level of a first high-frequency sub-band in a group of high-frequency sub-bands to an energy level associated with a residual signal of a first high-frequency sub-band in a second group of high-frequency; anda second adjustment parameter for a second high-frequency sub-band in the group of high-frequency sub-bands; and reconstruct the high-frequency sub-bands of the encoder-side audio signal based on the adjusted group of high-band excitation sub-bands.<br>33) An apparatus comprising: means for generating a harmonically extended signal based on a low-band excitation signal, wherein the low-band excitation signal is generated by a linear prediction based decoder based on parameters received from a speech encoder; means for generating a group of high-band excitation sub-bands based, at least in part, on the harmonically extended signal; means for adjusting the group of high-band excitation sub-bands based on adjustment parameters received from the speech encoder, wherein a transmission bandwidth of a bit stream is reduced compared to transmission of an encoded version of high-frequency sub-bands of an encoder-side audio signal, and wherein the adjustment parameters comprise:a first adjustment parameter based on a comparison of an energy level of a first high-frequency sub-band in a group of high-frequency sub-bands to an energy level associated with a residual signal of a first high-frequency sub-band in a second group of high-frequency; anda second adjustment parameter for a second high-frequency sub-band in the group of high-frequency sub-bands; and means for reconstructing the high-frequency sub-bands of the encoder-side audio signal based on the adjusted group of high-band excitation sub-bands.<br>31) An apparatus comprising: a non-linear transformation generator configured to generate a harmonically extended signal based on a low-band excitation signal, wherein the low-band excitation signal is generated by a linear prediction based decoder based on parameters received from a speech encoder; a second filter configured to generate a group of high-band excitation sub-bands based, at least in part, on the harmonically extended signal; dedicated parameter adjusters configured to adjust the group of high-band excitation sub-bands based on adjustment parameters received from the speech encoder, wherein a transmission bandwidth of a bit stream is reduced compared to transmission of an encoded version of high-frequency sub-bands of an encoder-side audio signal, and wherein the adjustment parameters comprise:a first adjustment parameter based on a comparison of an energy level of a first high-frequency sub-band in a group of high-frequency sub-bands to an energy level associated with a residual signal of a first high-frequency sub-band in a second group of high-frequency; anda second adjustment parameter for a second high-frequency sub-band in the group of high-frequency sub-bands; and a reconstruction unit configured to reconstruct the high-frequency sub-bands of the encoder-side audio signal based on the adjusted group of high-band excitation sub-bands.<br>29) A method comprising: generating, at a speech decoder, a harmonically extended signal based on a low-band excitation signal, wherein the low-band excitation signal is generated by a linear prediction based decoder based on parameters received from a speech encoder; generating a group of high-band excitation sub-bands based, at least in part, on the harmonically extended signal; adjusting, at a dedicated parameter adjuster, the group of high-band excitation sub-bands based on adjustment parameters received from the speech encoder, wherein a transmission bandwidth of a bit stream is reduced compared to transmission of an encoded version of high-frequency sub-bands of an encoder-side audio signal, and wherein the adjustment parameters comprise:a first adjustment parameter based on a comparison of an energy level of a first high-frequency sub-band in a group of high-frequency sub-bands to an energy level associated with a residual signal of a first high-frequency sub-band in a second group of high-frequency; anda second adjustment parameter for a second high-frequency sub-band in the group of high-frequency sub-bands; and reconstructing the high-frequency sub-bands of the encoder-side audio signal based on the adjusted group of high-band excitation sub-bands.<br>24) An apparatus for reducing a transmission bandwidth of a bit stream, the apparatus comprising: means for filtering an audio signal into a group of low-frequency sub-bands within a low-band frequency range and a first group of high-frequency sub-bands within a high-band frequency range; means for generating a first residual signal of a first high-frequency sub-band in the first group of high-frequency sub-bands; means for generating a harmonically extended signal based on the group of low-frequency sub-bands and a non-linear processing function; means for generating a second group of high-frequency sub-bands based, at least in part, on the harmonically extended signal, wherein the second group of high-frequency sub-bands corresponds to the first group of high-frequency sub-bands; means for determining a first adjustment parameter based on a comparison of an energy level associated with the first residual signal to an energy level of a first high-frequency sub-band in the second group of high-frequency sub-bands; means for determining a second adjustment parameter for a second high-frequency sub-band in the second group of high-frequency sub-bands based on a metric of a second high-frequency sub-band in the first group of high-frequency sub-bands; and means for transmitting the first adjustment parameter and the second adjustment parameter to a speech decoder as part of the bit stream, the first adjustment parameter and the second adjustment parameter usable by the speech decoder to reconstruct the first group of high-frequency sub-bands, wherein the transmission bandwidth of the bit stream is reduced compared to transmission of an encoded version of the first group of high-frequency sub-bands.<br>19) A non-transitory computer-readable medium comprising instructions for reducing a transmission bandwidth of a bit stream, wherein the instructions, when executed by a processor at a speech encoder, cause the processor to: filter an audio signal into a group of low-frequency sub-bands within a low-band frequency range and a first group of high-frequency sub-bands within a high-band frequency range; generate a first residual signal of a first sub-band in the first group of high-frequency sub-bands; generate a harmonically extended signal based on the group of low-frequency sub-bands and a non-linear processing function; generate a second group of high-frequency sub-bands based, at least in part, on the harmonically extended signal, wherein the second group of high-frequency sub-bands corresponds to the first group of high-frequency sub-bands; determine, at a dedicated parameter estimator, a first adjustment parameter based on a comparison of an energy level associated with the first residual signal to an energy level of a first high-frequency sub-band in the second group of high-frequency sub-bands; determine a second adjustment parameter for a second high-frequency sub-band in the second group of high-frequency sub-bands based on a metric of a second high-frequency sub-band in the first group of high-frequency sub-bands; and initiate transmission of the first adjustment parameter and the second adjustment parameter to a speech decoder as part of the bit stream, wherein the first adjustment parameter and the second adjustment parameter are usable by the speech decoder to reconstruct the first group of high-frequency sub-bands, and wherein the transmission bandwidth of the bit stream is reduced compared to transmission of an encoded version of the first group of high-frequency sub-bands.<br>10) An apparatus for reducing a transmission bandwidth of a bit stream, the apparatus comprising: a first filter configured to filter an audio signal into a group of low-frequency sub-bands within a low-band frequency range and a first group of high-frequency sub-bands within a high-band frequency range; a parameter estimator configured to generate a first residual signal of a first high-frequency sub-band in the first group of high-frequency sub-bands; a non-linear transformation generator configured to generate a harmonically extended signal based on the group of low-frequency sub-bands and a non-linear processing function; a second filter configured to generate a second group of high-frequency sub-bands based, at least in part, on the harmonically extended signal, wherein the second group of high-frequency sub-bands corresponds to the first group of high-frequency sub-bands; dedicated parameter estimators configured to:determine a first adjustment parameter based on a comparison of an energy level associated with the first residual signal to an energy level of a first high-frequency sub-band in the second group of high-frequency sub-bands; anddetermine a second adjustment parameter for a second high-frequency sub-band in the second group of high-frequency sub-bands based on a metric of a second high-frequency sub-band in the first group of high-frequency sub-bands; and a transmitter to transmit the first adjustment parameter and the second adjustment parameter to a speech decoder as part of the bit stream, the first adjustment parameter and the second adjustment parameter usable by the speech decoder to reconstruct the first group of high-frequency sub-bands, wherein the transmission bandwidth of the bit stream is reduced compared to transmission of an encoded version of the first group of high-frequency sub-bands.<br>1) A method of reducing a transmission bandwidth of a bit stream, the method comprising: filtering, at a speech encoder, an audio signal into a group of low-frequency sub-bands within a low-band frequency range and a first group of high-frequency sub-bands within a high-band frequency range; generating a first residual signal of a first high-frequency sub-band in the first group of high-frequency sub-bands; generating a harmonically extended signal based on the group of low-frequency sub-bands and a non-linear processing function; generating a second group of high-frequency sub-bands based, at least in part, on the harmonically extended signal, wherein the second group of high-frequency sub-bands corresponds to the first group of high-frequency sub-bands; determining, at a dedicated parameter estimator, a first adjustment parameter based on a comparison of an energy level associated with the first residual signal to an energy level of a first high-frequency sub-band in the second group of high-frequency sub-bands; determining a second adjustment parameter for a second high-frequency sub-band in the second group of high-frequency sub-bands based on a metric of a second high-frequency sub-band in the first group of high-frequency sub-bands; and transmitting the first adjustment parameter and the second adjustment parameter to a speech decoder as part of the bit stream, the first adjustment parameter and the second adjustment parameter usable by the speech decoder to reconstruct the first group of high-frequency sub-bands, wherein the transmission bandwidth of the bit stream is reduced compared to transmission of an encoded version of the first group of high-frequency sub-bands.</p></layer>
<layer id = "layer679"><p><b>US20180336912A1:Method And Device For Spectral Expansion For An Audio Signal</b><br><b>Independant Claims</b><br>19) A nontransitory computer readable medium containing instructions, the execution of the instructions by a processor of a computer system causing the processor to perform operations comprising: generating a mapping matrix based on an analysis of a reference wideband signal and a reference narrowband signal, wherein the mapping matrix is generated based on using a dB domain for performing a linear prediction; generating a resynthesized noise signal by processing a random noise signal with the mapping matrix and an energy envelope analysis of an input narrowband audio signal; and generating an output audio signal by summing a high-pass filtered version of the resynthesized noise signal with the input narrowband audio signal.<br>11) A method, comprising: generating, by utilizing a processor, a mapping matrix based on an analysis of a reference wideband signal and a reference narrowband signal, wherein the mapping matrix is generated without using a linear predictive coefficient (LPC) method, wherein the mapping matrix is generated based on using a dB domain for performing a linear prediction; generating a resynthesized noise signal by processing a random noise signal with the mapping matrix and an energy envelope analysis of an input narrowband audio signal; and generating an output audio signal by summing a high-pass filtered version of the resynthesized noise signal with the input narrowband audio signal.<br>1) A system, comprising: a processor that performs operations comprising: generating a mapping matrix based on an analysis of a reference wideband signal and a reference narrowband signal, wherein the mapping matrix is generated without using a linear predictive coefficient (LPC) method, wherein the mapping matrix is generated based on using a dB domain for performing a linear prediction; generating a resynthesized noise signal by processing a random noise signal with the mapping matrix and an energy envelope analysis of an input narrowband audio signal; and generating an output audio signal by summing a high-pass filtered version of the resynthesized noise signal with the input narrowband audio signal.</p></layer>
<layer id = "layer680"><p><b>US9754600B2:Reuse of index of huffman codebook for coding vectors</b><br><b>Independant Claims</b><br>1) A device for processing a bitstream, the device comprising: one or more processors configured to:obtain the bitstream, the bitstream comprising a compressed version of a spatial component of a sound field, the spatial component of the sound field being represented by a vector in a spherical harmonics domain, wherein a value of a syntax element for a current frame is indicative of an index that determines a particular Huffman codebook, the bitstream further including an indicator,the indicator having a particular value indicating the bitstream does not include the value of the syntax element for the current frame and the value of the syntax element for the current frame is equal to a value of the syntax element for a previous frame;use the particular Huffman codebook to code data associated with the vector; and a memory coupled to the one or more processors, the memory configured to store the bitstream.<br>11) A method of processing a bitstream, the method comprising: obtaining the bitstream, the bitstream comprising a compressed version of a spatial component of a sound field, the spatial component of the sound field being represented by a vector in a spherical harmonics domain, wherein a value of a syntax element for a current frame is indicative of an index that determines a particular Huffman codebook, the bitstream further including an indicator,the indicator having a particular value indicating the bitstream does not include the value of the syntax element for the current frame and the value of the syntax element for the current frame is equal to a value of the syntax element for a previous frame; using the particular Huffman codebook to code data associated with the vector; and storing the bitstream.<br>21) A device for processing a bitstream, the device comprising: means for obtaining the bitstream, the bitstream comprising a compressed version of a spatial component of a sound field, the spatial component of the sound field being represented by a vector in a spherical harmonics domain, wherein a value of a syntax element for a current frame is indicative of an index that determines a particular Huffman codebook, the bitstream further including an indicator,the indicator having a particular value indicating the bitstream does not include the value of the syntax element for the current frame and the value of the syntax element for the current frame is equal to a value of the syntax element for a previous frame; and means for using the particular Huffman codebook to code data associated with the vector; and means for storing the bitstream.<br>26) A non-transitory computer-readable storage medium having instructions stored thereon that, when executed, configure a device to: obtain a bitstream, the bitstream comprising a compressed version of a spatial component of a sound field, the spatial component of the sound field being represented by a vector in a spherical harmonics domain, wherein a value of a syntax element for a current frame is indicative of an index that determines a particular Huffman codebook, the bitstream further including an indicator,the indicator having a particular value indicating the bitstream does not include the value of the syntax element for the current frame and the value of the syntax element for the current frame is equal to a value of the syntax element for a previous frame; use the particular Huffman codebook to code data associated with the vector; and store the bitstream.</p></layer>
<layer id = "layer681"><p><b>US20180338210A1:Method And Device For Recognition And Arbitration Of An Input Connection</b><br><b>Independant Claims</b><br>20) A controller, comprising: a processing unit communicatively coupled to one or more multimedia connections comprising tip, ring, ring, sleeve (TRRS) audio, universal serial bus, a proprietary serial protocol, or a combination thereof, wherein the processing unit perform operations comprising: determining an audio configuration of an audio device by way of current and load sensing through an audio jack of the device; and assigning, upon detection of a connector type of an audio connector of the audio device, data lines to or from the audio device to pins utilized for a TRRS line connection in accordance with the connector type, wherein the audio jack is communicatively coupled to the processing unit using the TRRS line connection.<br>14) A method, comprising: detecting, by utilizing a processing unit of a device coupled to one or more multimedia connections comprising tip, ring, ring, sleeve (TRRS) audio, universal serial bus, a proprietary serial protocol, or a combination thereof, an audio configuration of an audio device by way of current and load sensing through an audio jack of the device; and independently assigning, by utilizing the processing unit and upon detection of a connector type of an audio connector of the audio device, data lines to or from the audio device to pins utilized for a TRRS line connection in accordance with the connector type, wherein the audio jack is communicatively coupled to the processing unit using the TRRS line connection.<br>1) A device, comprising: a processing unit communicatively coupled to one or more multimedia connections comprising tip, ring, ring, sleeve (TRRS) audio, universal serial bus, a proprietary serial protocol, or a combination thereof, wherein the processing unit perform operations comprising: detecting an audio configuration of an audio device by way of current and load sensing through an audio jack of the device; and independently assigning, upon detection of a connector type of an audio connector of the audio device, data lines to or from the audio device to pins utilized for a TRRS line connection in accordance with the connector type, wherein the audio jack is communicatively coupled to the processing unit using the TRRS line connection.</p></layer>
<layer id = "layer682"><p><b>US20170084282A1:METHOD FOR PROCESSING SPEECH/AUDIO SIGNAL AND APPARATUS</b><br><b>Independant Claims</b><br>16) An apparatus for reconstructing a noise component of a speech/audio signal, comprising:a unit for receiving a bitstream;a bitstream processing unit, configured decode the bitstream, to obtain a speech/audio signal;a signal determining unit, configured to determine a first speech/audio signal according to the speech/audio signal obtained by the bitstream processing unit, wherein the first speech/audio signal includes a noise component needs;a first determining unit, configured to determine a symbol of each sample value in the first speech/audio signal determined by the signal determining unit and an amplitude value of each sample value in the first speech/audio signal determined by the signal determining unit;a second determining unit, configured to determine an adaptive normalization length;a third determining unit, configured to determine an adjusted amplitude value of each sample value according to the adaptive normalization length determined by the second determining unit and the amplitude value that is of each sample value and is determined by the first determining unit;a unit for reconstructing the noise component of the first speech/audio signal; anda fourth determining unit, configured to determine a second speech/audio signal according to the symbol that is of each sample value and is determined by the first determining unit and the adjusted amplitude value that is of each sample value and is determined by the third determining unit, wherein the second speech/audio signal is a signal obtained after the noise component of the first speech/audio signal is reconstructed.<br>1) A method for processing a speech/audio signal, wherein the method comprises:receiving a bitstream;decoding the bitstream to obtain a speech/audio signal;determining a first speech/audio signal according to the speech/audio signal, wherein the first speech/audio signal includes a noise component;determining a symbol of each sample value in the first speech/audio signal and an amplitude value of each sample value in the first speech/audio signal;determining an adaptive normalization length;determining an adjusted amplitude value of each sample value according to the adaptive normalization length and the amplitude value of each sample value;reconstructing the noise component of the first speech/audio signal; anddetermining a second speech/audio signal according to the symbol of each sample value and the adjusted amplitude value of each sample value.</p></layer>
<layer id = "layer683"><p><b>US10149047B2:Multi-aural MMSE analysis techniques for clarifying audio signals</b><br><b>Independant Claims</b><br>3) A method for clarifying an audio signal comprising: The method of claim 2, wherein determining the noise estimate includes comparing the plurality of frequency bands of the primary audio signal with the corresponding plurality of frequency bands of the reference audio signal.<br>16) An electronic device configured to receive audio signals, comprising: a primary audio channel for receiving a primary audio signal; a reference audio channel for receiving a reference audio signal; a processor programmed to: receive the primary audio signal from the primary audio channel and the reference audio signal from the reference audio channel; process the reference audio signal to provide a noise estimate of an unknown noise component; generate a minimum mean squared error analysis that accounts for the noise estimate of the unknown noise component; subject a plurality of frequency bands of the primary audio signal to the minimum mean squared error analysis; compare a result of the minimum mean squared analysis of each frequency band of the plurality of frequency bands of the primary audio signal to a result of the minimum mean squared analysis of a corresponding frequency band of the plurality of frequency bands of the reference audio signal to provide a frequency band comparison; assign a confidence interval as a measure of statistical likelihood of dominance of an unknown target component relative to the unknown noise component for each frequency band of the plurality of frequency bands of the primary audio signal based on the frequency band comparison that corresponds to that frequency band; adjust an output power of the frequency band based on the confidence interval to provide a modified output frequency band; and combine the modified output frequency bands for each frequency band of the plurality of frequency bands of the primary audio signal to provide a clarified output audio signal substantially reduced in the unknown noise component; and cause an output element to output the clarified output audio signal; and wherein the output element is in communication with the processor.<br>15) A method for clarifying an audio signal comprising: receiving a primary audio signal and a reference audio signal, each audio signal including a plurality of frequency bands, an unknown target component, and an unknown noise component; subjecting the primary audio signal to an adaptive time domain filter to provide a filtered audio signal; determining a noise estimate of the unknown noise component using the reference audio signal; tailoring a minimum mean squared error analysis based on the noise estimate; and subjecting each frequency band of the plurality of frequency bands of the filtered audio signal to the minimum mean squared error analysis; assigning a confidence interval as a measure of statistical likelihood of dominance of the unknown target component in to each frequency band of the plurality of frequency bands of the filtered audio signal based on a result of the minimum mean squared analyses; modifying an audio output level of each frequency band of the filtered audio signal based on the confidence interval of that frequency band to provide a modified output frequency band; and combining the modified output frequency bands for each frequency band of the plurality of frequency bands of the filtered audio signal to provide a clarified output audio signal substantially reduced in the unknown noise component.<br>1) A method for clarifying an audio signal comprising: receiving a primary audio signal and a reference audio signal, each audio signal including a plurality of frequency bands, an unknown target component, and an unknown noise component; determining a noise estimate of the unknown noise component from the reference audio signal; incorporating the noise estimate into a minimum mean squared error analysis; subjecting each frequency band of the plurality of frequency bands of the primary audio signal to the minimum mean squared error analysis; assigning a confidence interval as a measure of statistical likelihood of dominance of the unknown target component in each frequency band of the plurality of frequency bands based on a result of the minimum mean squared analysis; modifying an audio output level of each frequency band of the primary audio signal based on the confidence interval of that frequency band to provide a modified output frequency band; and combining the modified output frequency bands for each frequency band of the plurality of frequency bands of the primary audio signal to provide a clarified output audio signal substantially reduced in the unknown noise component.</p></layer>
<layer id = "layer684"><p><b>US10311885B2:Method and apparatus for recovering lost frames</b><br><b>Independant Claims</b><br>9) An audio signal decoding apparatus, comprising:a processor, and a storage medium storing programming instructions for execution by the processor,wherein the programming instructions, when executed by the processor, cause the decoding apparatus to perform a process of recovering lost frames in an audio signal,wherein the process comprises:receiving and decoding a bit stream to obtain the audio signal, wherein the audio signal is transmitted in consecutive frames, and at least one frame of the audio signal is lost;obtaining an initial high-frequency band signal of a current lost frame of the audio signal, wherein the initial high-frequency band signal is obtained according to a global gain, a subframe gain, and an encoding type of a previous frame of the current lost frame;calculating a ratio R, wherein the ratio R is a ratio of a high frequency excitation energy of the previous frame to a high frequency excitation energy of the current lost frame, wherein the high frequency excitation energy of the current lost frame is obtained according to a low-frequency band signal energy of the current lost frame;obtaining a global gain of the current lost frame according to the ratio R and the global gain of the previous frame;obtaining a high-frequency band signal of the current lost frame according to the initial high-frequency band signal of the current lost frame and the global gain of the current lost frame;reconstructing the current lost frame according to the high-frequency band signal of the current lost frame; andoutputting the audio signal including the reconstructed current lost frame.<br>1) A method for recovering lost frames in an audio signal, performed by an audio signal decoder, comprising:receiving and decoding a bit stream to obtain the audio signal, wherein the audio signal is transmitted in consecutive frames, and at least one frame of the audio signal is lost;obtaining an initial high-frequency band signal of a current lost frame of the audio signal, wherein the initial high-frequency band signal is obtained according to a global gain, a subframe gain, and an encoding type of a previous frame of the current lost frame;calculating a ratio R, wherein the ratio R is a ratio of a high frequency excitation energy of the previous frame to a high frequency excitation energy of the current lost frame, wherein the high frequency excitation energy of the current lost frame is obtained according to a low-frequency band signal energy of the current lost frame;obtaining a global gain of the current lost frame according to the ratio R and the global gain of the previous frame;obtaining a high-frequency band signal of the current lost frame according to the initial high-frequency band signal of the current lost frame and the global gain of the current lost frame;reconstructing the current lost frame according to the high-frequency band signal of the current lost frame; andoutputting the audio signal including the reconstructed current lost frame.</p></layer>
<layer id = "layer685"><p><b>US9361899B2:System and method for compressed domain estimation of the signal to noise ratio of a coded speech signal</b><br><b>Independant Claims</b><br>1) A method comprising: receiving, at a computing device, a speech signal having a bitstream and a signal-to-noise ratio (“SNR”) associated therewith; and estimating the SNR directly from the bitstream or using a partial decoder that is configured to extract one or more parameters, the parameters including at least one of a fixed codebook gain, an adaptive codebook gain, a pitch lag, and a line spectral frequency (“LSF”) coefficient.<br>17) A system comprising: one or more computing devices configured to receive a speech signal having a bitstream and a signal-to-noise ratio (“SNR”) associated therewith, the one or more computing devices being further configured to estimate the SNR directly from the bitstream or using a partial decoder that is configured to extract one or more parameters, the parameters including at least one of a fixed codebook gain, an adaptive codebook gain, a pitch lag, and a line spectral frequency (“LSF”) coefficient.</p></layer>
<layer id = "layer686"><p><b>US9245538B1:Bandwidth enhancement of speech signals assisted by noise reduction</b><br><b>Independant Claims</b><br>1) A method for expanding a bandwidth of an acoustic signal, the method comprising: reducing a noise component in an acoustic signal to produce a noise-reduced signal and noise-reduction parameters, the acoustic signal representing at least one captured sound and having the noise component and a speech component, the speech component having spectral values within a first bandwidth, the noise-reduction parameters indicating characteristics of the speech component and the noise component of the acoustic signal; forming an expanded signal segment from the noise-reduced signal based at least in part on the noise-reduction parameters, so as to expand a bandwidth of the speech component and limit expansion of a bandwidth of the reduced noise component, the expanded signal segment being bandwidth expanded and having spectral values within a second bandwidth outside the first bandwidth, the spectral values of the expanded signal segment based on the spectral values of the speech component and further based on an energy level of the noise component; and forming an expanded acoustic signal based on the noise-reduced signal and the expanded signal segment.<br>17) A system for expanding a spectral bandwidth of an acoustic signal, the system comprising: a noise reduction module stored in a memory coupled to a processor, the noise reduction module executable by the processor to determine an energy level of a noise component in an acoustic signal having the noise component and a speech component, the speech component having spectral values within a first bandwidth, and to reduce the noise component in the acoustic signal to produce a noise-reduced signal and noise-reduction parameters, the noise-reduction parameters indicating characteristics of the speech component and the noise component of the acoustic signal; and a bandwidth expansion module stored in the memory coupled to the processor, the bandwidth expansion module executable by the processor to: form an expanded signal segment from the noise-reduced signal based at least in part on the noise-reduction parameters, so as to expand a bandwidth of the speech component and limit expansion of a bandwidth of the reduced noise component, the expanded signal segment being bandwidth expanded and having spectral values within a second bandwidth outside the first bandwidth, the spectral values of the expanded signal segment based on the spectral values of the speech component and further based on the determined energy level of the noise component, and form an expanded acoustic signal based on the noise-reduced signal and the expanded signal segment.<br>9) A non-transitory computer readable storage medium having embodied thereon a program, the program being executable by a processor to perform a method for expanding a spectral bandwidth of an acoustic signal, the method comprising: reducing a noise component in an acoustic signal to produce a noise-reduced signal and noise-reduction parameters, the acoustic signal representing at least one captured sound and having the noise component and a speech component, the speech component having spectral values within a first bandwidth, the noise-reduction parameters indicating characteristics of the speech component and the noise component of the acoustic signal; forming an expanded signal segment from the noise-reduced signal based at least in part on the noise-reduction parameters, so as to expand a bandwidth of the speech component and limit expansion of a bandwidth of the reduced noise component, the expanded signal segment being bandwidth expanded and having spectral values within a second bandwidth outside the first bandwidth, the spectral values of the expanded signal segment based on the spectral values of the speech component and further based on an energy level of the noise component; and forming an expanded acoustic signal based on the noise-reduced signal and the expanded signal segment.</p></layer>
<layer id = "layer687"><p><b>US9799330B2:Multi-sourced noise suppression</b><br><b>Independant Claims</b><br>1) A method for multi-sourced noise suppression, the method comprising: assigning weights to audio streams, the audio streams being provided substantially synchronously by a plurality of audio devices, the weights depending on quality of the audio streams, wherein the assigning weights includes generating an acoustic activity map by locating, identifying and mapping target sounds and noise sources in at least one of a single room and multi-room environment, so as to create a multidimensional acoustic view of the environment; based on the weights, performing noise suppression processing on the audio streams to generate a cleaned voice signal; providing the cleaned voice signal from the noise suppression processing to at least one remote device for further processing; and based on the acoustic activity map, selecting an optimal one of the plurality of audio devices to communicate with the user.<br>15) A system for multi-sourced audio processing, the system comprising: a processor; and a memory communicatively coupled with the processor, the memory storing instructions, which, when executed by the processor, perform a method comprising:assigning weights to audio streams, the audio streams being provided substantially synchronously by a plurality of audio devices, the weights depending on quality of the audio streams;based on the weights, performing noise suppression processing on the audio streams to generate a cleaned voice signal, andproviding the cleaned voice signal from the noise suppression processing to a remote device for further processing, wherein each of the audio devices includes at least one microphone and wherein the plurality of audio devices are physically separate from each other but connected in a dynamic network of connected devices, such that the audio devices are connected as part of an Internet of Things environment.<br>17) A non-transitory computer-readable storage medium having embodied thereon instructions, which, when executed by at least one processor, perform steps of a method, the method comprising: assigning weights to audio streams, the audio streams being provided substantially synchronously by a plurality of audio devices, the weights depending on quality of the audio streams, wherein the assigning weights includes generating an acoustic activity map by locating, identifying and mapping target sounds and noise sources in at least one of a single room and multi-room environment, so as to create a multidimensional acoustic view of the environment; based on the weights, performing noise suppression processing on the audio streams to generate a cleaned voice signal; providing the cleaned voice signal from the noise suppression processing to at least one remote device for further processing; and based on the acoustic activity map, selecting an optimal one of the plurality of audio devices to communicate with the user.</p></layer>
<layer id = "layer688"><p><b>US9978388B2:Systems and methods for restoration of speech components</b><br><b>Independant Claims</b><br>1) A method for restoring speech components of an audio signal, the method comprising: receiving an audio signal after it has been processed for noise suppression; determining distorted frequency regions and undistorted frequency regions in the received audio signal that has been processed for noise suppression, the distorted frequency regions including regions of the audio signal in which speech distortion is present due to the noise suppression processing; and performing one or more iterations using a model to generate predictions of a restored version of the audio signal, the model being configured to modify the audio signal so as to restore the speech components in the distorted frequency regions.<br>11) A system for restoring speech components of an audio signal, the system comprising: at least one processor; and a memory communicatively coupled with the at least one processor, the memory storing instructions, which when executed by the at least one processor performs a method comprising:receiving an audio signal after it has been processed for noise suppression;determining distorted frequency regions and undistorted frequency regions in the received audio signal that has been processed for noise suppression, the distorted frequency regions including regions of the audio signal in which speech distortion is present due to the noise suppression processing; andperforming one or more iterations using a model to generate predictions of a restored version of the audio signal, the model being configured to modify the audio signal so as to restore the speech components in the distorted frequency regions.<br>20) A non-transitory computer-readable storage medium having embodied thereon instructions, which when executed by at least one processor, perform steps of a method, the method comprising: receiving an audio signal after it has been processed for noise suppression; determining distorted frequency regions and undistorted frequency regions in the received audio signal that has been processed for noise suppression, the distorted frequency regions including regions of the audio signal in which speech distortion is present due to the noise suppression processing; and performing one or more iterations using a model to refine predictions of the audio signal at the distorted frequency regions, the model being configured to modify the audio signal so as to restore speech components in the distorted frequency regions.</p></layer>
<layer id = "layer689"><p><b>US9837089B2:High-band signal generation</b><br><b>Independant Claims</b><br>1) A device for signal processing comprising: a receiver configured to receive a parameter associated with a bandwidth-extended audio stream; and a high-band excitation signal generator configured to:determine a value of the parameter; andin response to the parameter having a first value:select filter information associated with the bandwidth-extended audio stream;determine filter coefficients based on the filter information; andgenerate a high-band excitation signal based on the filter information, wherein the high-band excitation signal is generated based on application of a filter having the filter coefficients to a first high-band excitation signal.<br>17) A signal processing method comprising: determining, at a device, a value of a parameter associated with a bandwidth-extended audio stream; and in response to the parameter having a first value:selecting filter information associated with the bandwidth-extended audio stream;determining filter coefficients based on the filter information; andgenerating, at the device, a high-band excitation signal based on the filter information, wherein the high-band excitation signal is generated based on application of a filter having the filter coefficients to a first high-band excitation signal.<br>25) A non-transitory computer-readable medium including instructions that, when executed by a processor, cause the processor to perform operations comprising: receiving a parameter associated with a bandwidth-extended audio stream; determining a value of the parameter; and in response to the parameter having a first value:selecting filter information associated with the bandwidth-extended audio stream;determining filter coefficients based on the filter information; andgenerating a high-band excitation signal based on the filter information, wherein the high-band excitation signal is generated based on application of a filter having the filter coefficients to a first high-band excitation signal.<br>27) An apparatus comprising: means for receiving a parameter associated with a bandwidth-extended audio stream; and means for generating a high-band excitation signal configured to:determine a value of the parameter; andin response to the parameter having a first value:select filter information associated with the bandwidth-extended audio stream;determine filter coefficients based on the filter information; andgenerate a high-band excitation signal based on the filter information, wherein the high-band excitation signal is generated based on application of a filter having the filter coefficients to a first high-band excitation signal.</p></layer>
<layer id = "layer690"><p><b>US9922668B2:Estimating fractional chirp rate with multiple frequency representations</b><br><b>Independant Claims</b><br>1) A computer-implemented method for automatic speaker recognition, the method comprising: obtaining a first portion of a speech signal; computing a first frequency representation from the first portion of the speech signal using a first fractional chirp rate; computing a first score using an auto-correlation of the first frequency representation; computing a second frequency representation from the first portion of the speech signal using a second fractional chirp rate; computing a second score using an auto-correlation of the second frequency representation; comparing the first score and the second score; determining a first estimated fractional chirp rate of the first portion of the speech signal corresponding to a highest score of the first score and the second score; determining a first estimated pitch of the first portion of the speech signal using the first estimated fractional chirp rate; obtaining a second portion of the speech signal, the second portion of the speech signal being at least partially non-overlapping with the first portion of the speech signal; computing a third frequency representation from the second portion of the speech signal using a third fractional chirp rate; computing a third score using an auto-correlation of the third frequency representation; computing a fourth frequency representation from the second portion of the speech signal using a fourth fractional chirp rate; computing a fourth score using an auto-correlation of the fourth frequency representation; comparing the third score and the fourth score; determining a second estimated fractional chirp rate of the second portion of the speech signal corresponding to a highest score of the third score and the fourth score; determining a second estimated pitch of the second portion of the speech signal using the second estimated fractional chirp rate; computing a sequence of pitch estimates, the sequence of pitch estimates comprising the first estimated pitch and the second estimated pitch; and applying the sequence of pitch estimates to recognize a speaker as a source of the speech signal.<br>12) One or more non-transitory computer-readable media comprising computer executable instructions that, when executed, cause at least one processor to perform actions comprising: obtaining a first portion of a speech signal; computing a first frequency representation from the first portion of the speech signal using a first fractional chirp rate; computing a first score using an auto-correlation of the first frequency representation; computing a second frequency representation from the first portion of the speech signal using a second fractional chirp rate; computing a second score using an auto-correlation of the second frequency representation; comparing the first score and the second score; determining a first estimated fractional chirp rate of the first portion of the speech signal corresponding to a highest score of the first score and the second score; determining a first estimated pitch of the first portion of the speech signal using the first estimated fractional chirp rate; obtaining a second portion of the speech signal, the second portion of the speech signal being at least partially non-overlapping with the first portion of the speech signal; computing a third frequency representation from the second portion of the speech signal using a third fractional chirp rate; computing a third score using an auto-correlation of the third frequency representation; computing a fourth frequency representation from the second portion of the speech signal using a fourth fractional chirp rate; computing a fourth score using an auto-correlation of the fourth frequency representation; comparing the third score and the fourth score; determining a second estimated fractional chirp rate of the second portion of the speech signal corresponding to a highest score of the third score and the fourth score; determining a second estimated pitch of the second portion of the speech signal using the second estimated fractional chirp rate; computing a sequence of pitch estimates, the sequence of pitch estimates comprising the first estimated pitch and the second estimated pitch; and applying the sequence of pitch estimates to recognize a speaker to perform signal reconstruction on the speech signal.<br>8) A system for automatic speech recognition, the system comprising one or more computing devices comprising at least one processor and at least one memory, the one or more computing devices configured to: obtain a first portion of a speech signal; compute a first frequency representation from the first portion of the speech signal using a first fractional chirp rate; compute a first score using an auto-correlation of the first frequency representation; compute a second frequency representation from the first portion of the speech signal using a second fractional chirp rate; compute a second score using an autocorrelation of the second frequency representation; compare the first score and the second score; determine a first estimated fractional chirp rate of the first portion of the speech signal corresponding to a highest score of the first score and the second score; determine a first estimated pitch of the first portion of the speech signal using the first estimated fractional chirp rate; obtain a second portion of the speech signal, the second portion of the speech signal being at least partially non-overlapping with the first portion of the speech signal; compute a third frequency representation from the second portion of the speech signal using a third fractional chirp rate; compute a third score using an auto-correlation of the third frequency representation; compute a fourth frequency representation from the second portion of the speech signal using a fourth fractional chirp rate; compute a fourth score using an auto-correlation of the fourth frequency representation; compare the third score and the fourth score; determine a second estimated fractional chirp rate of the second portion of the speech signal corresponding to a highest score of the third score and the fourth score; determine a second estimated pitch of the second portion of the speech signal using the second estimated fractional chirp rate; compute a sequence of pitch estimates, the sequence of pitch estimates comprising the first estimated pitch and the second estimated pitch; apply the sequence of pitch estimates to perform automatic speech recognition on the speech signal.</p></layer>
<layer id = "layer691"><p><b>US9870785B2:Determining features of harmonic signals</b><br><b>Independant Claims</b><br>1) A computer-implemented method for automatic speaker recognition, the method comprising: obtaining a first portion of a speech signal; computing, using one or more processors, a first estimated fractional chirp rate from the first portion of the speech signal; computing, using the one or more processors, a first frequency representation from the first portion of the speech signal using the first estimated fractional chirp rate; computing, using the one or more processors, a first pitch estimate from the first portion of the speech signal using a plurality of peak-to-peak distances in the first frequency representation; computing, using the one or more processors, a second pitch estimate from the first portion of the speech signal using the first pitch estimate and a correlation between a first frequency portion of a second frequency representation of the first portion of the speech signal, and a second frequency portion of the second frequency representation; obtaining a second portion of the speech signal; computing, using the one or more processors, a second estimated fractional chirp rate from the second portion of the speech signal; computing, using the one or more processors, a third frequency representation from the second portion of the speech signal using the second estimated fractional chirp rate; computing, using the one or more processors, a third pitch estimate from the second portion of the speech signal using a plurality of peak-to-peak distances in the third frequency representation; computing, using the one or more processors, a fourth pitch estimate from the second portion of the speech signal using the third pitch estimate and a correlation between a first frequency portion of a fourth frequency representation of the second portion of the speech signal, and a second frequency portion of the fourth frequency representation; generating a sequence of pitch estimates, the sequence of pitch estimates comprising the second pitch estimate and the fourth pitch estimate; applying the sequence of pitch estimates to recognize a speaker as a source of the speech signal.<br>12) A system for automatic speaker recognition, the system comprising one or more computing devices comprising at least one processor and at least one memory, the one or more computing devices configured to: obtain a first portion of a speech signal; compute a first estimated fractional chirp rate from the first portion of the speech signal; compute a first frequency representation from the first portion of the speech signal using the first estimated fractional chirp rate; compute a first pitch estimate from the first portion of the speech signal using a plurality of peak-to-peak distances in the first frequency representation; compute a second pitch estimate from the first portion of the speech signal using the first pitch estimate and a correlation between a first frequency portion of a second frequency representation of the first portion of the speech signal, and a second frequency portion of the second frequency representation; obtain a second portion of the speech signal; compute a second estimated fractional chirp rate from the second portion of the speech signal; compute a third frequency representation from the second portion of the speech signal using the second estimated fractional chirp rate; compute a third pitch estimate from the second portion of the speech signal using a plurality of peak-to-peak distances in the third frequency representation; compute a fourth pitch estimate from the second portion of the speech signal using the third pitch estimate and a correlation between a first frequency portion of a fourth frequency representation of the second portion of the speech signal, and a second frequency portion of the fourth frequency representation; generate a sequence of pitch estimates, the sequence of pitch estimates comprising the second pitch estimate and the fourth pitch estimate; and apply the sequence of pitch estimates to recognize a speaker as a source of the speech signal.<br>18) One or more non-transitory computer-readable media comprising computer executable instructions that, when executed, cause at least one processor to perform actions comprising: obtaining a first portion of a speech signal; computing a first estimated fractional chirp rate from the first portion of the speech signal; computing a first frequency representation from the first portion of the speech signal using the first estimated fractional chirp rate; computing a first pitch estimate from the first portion of the speech signal using a plurality of peak-to-peak distances in the first frequency representation; computing a second pitch estimate from the first portion of the speech signal using the first pitch estimate and a correlation between a first frequency portion of a second frequency representation of the first portion of the speech signal, and a second frequency portion of the second frequency representation; obtaining a second portion of the speech signal; computing a second estimated fractional chirp rate from the second portion of the speech signal; computing a third frequency representation from the second portion of the speech signal using the second estimated fractional chirp rate; computing a third pitch estimate from the second portion of the speech signal using a plurality of peak-to-peak distances in the third frequency representation; computing a fourth pitch estimate from the second portion of the speech signal using the third pitch estimate and a correlation between a first frequency portion of a fourth frequency representation of the second portion of the speech signal, and a second frequency portion of the fourth frequency representation; generating a sequence of pitch estimates, the sequence of pitch estimates comprising the second pitch estimate and the fourth pitch estimate; applying the sequence of pitch estimates to recognize a speaker as a source of the speech signal.</p></layer>
<layer id = "layer692"><p><b>US9842611B2:Estimating pitch using peak-to-peak distances</b><br><b>Independant Claims</b><br>1) A computer-implemented method for automatic speaker recognition, the method comprising: obtaining a first portion of a speech signal; computing, using one or more processing devices, a first frequency representation of the first portion of the speech signal; obtaining a first threshold; identifying a first plurality of peaks in the first frequency representation using the first threshold by identifying values of the first frequency representation larger than the first threshold; computing, using the one or more processing devices, a first plurality of peak-to-peak distances using locations in frequency of the first plurality of peaks; obtaining a second threshold; identifying a second plurality of peaks in the first frequency representation using the second threshold by identifying values of the first frequency representation larger than the second threshold; computing, using the one or more processing devices, a second plurality of peak-to-peak distances using locations in frequency of the second plurality of peaks; computing, using the one or more processing devices, a first pitch estimate of the first portion of the speech signal using the first plurality of peak-to-peak distances and the second plurality of peak-to-peak distances; obtaining a second portion of the speech signal; computing, using the one or more processing devices, a second frequency representation of the second portion of the speech signal; identifying a third plurality of peaks in the second frequency representation; computing, using the one or more processing devices, a third plurality of peak-to-peak distances using locations in frequency of the third plurality of peaks; computing, using the one or more processing devices, a second pitch estimate of the second portion of the speech signal using the third plurality of peak-to-peak distances; generating, using the one or more processing devices, a sequence of pitch estimates, the sequence of pitch estimates comprising the first pitch estimate and the second pitch estimate; and applying the sequence of pitch estimates to recognize a speaker as a source of the speech signal.<br>15) One or more non-transitory computer-readable media comprising computer executable instructions that, when executed, cause at least one processor to perform actions comprising: obtaining a first portion of a speech signal; computing a first frequency representation of the first portion of the speech signal; obtaining a first threshold; identifying a first plurality of peaks in the first frequency representation using the first threshold by identifying values of the first frequency representation larger than the first threshold; computing a first plurality of peak-to-peak distances using locations in frequency of the first plurality of peaks; obtaining a second threshold; identifying a second plurality of peaks in the first frequency representation using the second threshold by identifying values of the first frequency representation larger than the second threshold; computing a second plurality of peak-to-peak distances using locations in frequency of the second plurality of peaks; computing a first pitch estimate of the first portion of the speech signal using the first plurality of peak-to-peak distances and the second plurality of peak-to-peak distances; obtaining a second portion of the speech signal; computing a second frequency representation of the second portion of the speech signal; identifying a third plurality of peaks in the second frequency representation; computing a third plurality of peak-to-peak distances using locations in frequency of the third plurality of peaks; computing a second pitch estimate of the second portion of the speech signal using the third plurality of peak-to-peak distances; generating a sequence of pitch estimates, the sequence of pitch estimates comprising the first pitch estimate and the second pitch estimate; and applying the sequence of pitch estimates to recognize a speaker as a source of the speech signal.<br>8) A system for automatic speech recognition, the system comprising one or more computing devices comprising at least one processor and at least one memory, the one or more computing devices configured to: obtain a first portion of a speech signal; compute a first frequency representation of the first portion of the speech signal; obtain a first threshold; identify a first plurality of peaks in the first frequency representation using the first threshold by identifying values of the first frequency representation larger than the first threshold; compute a first plurality of peak-to-peak distances using locations in frequency of the first plurality of peaks; obtain a second threshold; identify a second plurality of peaks in the first frequency representation using the second threshold by identifying values of the first frequency representation larger than the second threshold; compute a second plurality of peak-to-peak distances using locations in frequency of the second plurality of peaks; compute a first pitch estimate of the first portion of the speech signal using the first plurality of peak-to-peak distances and the second plurality of peak-to-peak distances; obtain a second portion of the speech signal; compute a second frequency representation of the second portion of the speech signal; identify a third plurality of peaks in the second frequency representation; compute a third plurality of peak-to-peak distances using locations in frequency of the third plurality of peaks; compute a second pitch estimate of the second portion of the speech signal using the third plurality of peak-to-peak distances; generate a sequence of pitch estimates, the sequence of pitch estimates comprising the first pitch estimate and the second pitch estimate; and apply the sequence of pitch estimates to perform automatic speech recognition on the speech signal.</p></layer>
<layer id = "layer693"><p><b>US10186276B2:Adaptive noise suppression for super wideband music</b><br><b>Independant Claims</b><br>18) A method used in voice and data communications comprising:classifying primary input audio data, by a classifier, from a primary microphone and output a primary microphone classification of the primary input audio data;classifying secondary input audio data, by the classifier, from a secondary microphone and output a secondary microphone classification of the secondary input audio data;obtaining a proximity signal that determines whether the device's proximity to the user's face;obtaining an audio context, with a control unit, of the primary input audio data and the secondary input audio data, wherein the control unit combines the proximity signal and the primary microphone classification and the secondary microphone classification output by the classifier prior to application of noise suppression to the primary input audio data and the secondary input audio data, wherein the input audio data includes speech signals, music signals, and noise signals, and the audio context indicating a valid speech context or a valid music context;applying, with a noise suppression unit, the variable level of noise suppression to the primary input audio data and the secondary input audio data, wherein the variable level of noise suppression includes a first level of noise suppression when the speech signals are louder than the music signals, and a second level of noise suppression that is lower than the first level of the noise suppression to leave music signals undistorted, in the primary input audio data and secondary input audio data, when the music signals are louder than the speech signals, and the variable noise suppression is applied to the primary input audio data and the secondary input audio data prior to bandwidth compression, by an audio encoder coupled to the noise suppression unit, to generate a noise suppressed version of the primary input audio data and the secondary input audio data;bandwidth compressing, with the audio encoder, the noise suppressed version of the primary input audio data and the secondary input audio data, based on the audio context, to generate at least one audio encoder packet; andtransmitting the at least one audio encoder packet from a source device to a destination device. classifying primary input audio data, by a classifier, from a primary microphone and output a primary microphone classification of the primary input audio data; classifying secondary input audio data, by the classifier, from a secondary microphone and output a secondary microphone classification of the secondary input audio data; obtaining a proximity signal that determines whether the device's proximity to the user's face; obtaining an audio context, with a control unit, of the primary input audio data and the secondary input audio data, wherein the control unit combines the proximity signal and the primary microphone classification and the secondary microphone classification output by the classifier prior to application of noise suppression to the primary input audio data and the secondary input audio data, wherein the input audio data includes speech signals, music signals, and noise signals, and the audio context indicating a valid speech context or a valid music context; applying, with a noise suppression unit, the variable level of noise suppression to the primary input audio data and the secondary input audio data, wherein the variable level of noise suppression includes a first level of noise suppression when the speech signals are louder than the music signals, and a second level of noise suppression that is lower than the first level of the noise suppression to leave music signals undistorted, in the primary input audio data and secondary input audio data, when the music signals are louder than the speech signals, and the variable noise suppression is applied to the primary input audio data and the secondary input audio data prior to bandwidth compression, by an audio encoder coupled to the noise suppression unit, to generate a noise suppressed version of the primary input audio data and the secondary input audio data; bandwidth compressing, with the audio encoder, the noise suppressed version of the primary input audio data and the secondary input audio data, based on the audio context, to generate at least one audio encoder packet; and transmitting the at least one audio encoder packet from a source device to a destination device.<br>14) An apparatus configured to perform noise suppression comprising:means for classifying primary input audio data, by a classifier, from a primary microphone and means for classifying primary input audio data, by a classifier, from a primary microphone and means for classifying secondary input audio data, by the classifier, from a secondary means for obtain a proximity signal that determines the device's relative position to a user; means for determining an audio context, with a control unit, of the primary input audio data and the secondary input audio data, wherein the control unit combines the proximity signal and the primary microphone classification and the secondary microphone classification output by the classifier, prior to application of a variable level of noise suppression to the primary input audio data and the secondary input audio data, wherein the primary input audio data and the secondary input audio data includes speech signals, music signals, and noise signals, and the audio context indicating a valid speech context or a valid music context; means for applying, with a noise suppression unit, the variable level of noise suppression to the primary input audio data and the secondary input audio data, wherein the variable level of the noise suppression includes a first level of noise suppression when the speech signals are louder than the music signals, and a second level of noise suppression that is lower than the first level of the noise suppression to leave music signals undistorted, in the primary input audio data and the secondary input audio data, when the music signals are louder than the speech signals, and the variable noise suppression is applied to the primary input audio data and the secondary input audio data prior to bandwidth compression, by an audio encoder coupled to the noise suppression unit, to generate a noise suppressed version of the primary input audio data and the secondary input audio data; means for bandwidth compressing the noise suppressed version of the primary input audio data and the secondary input audio data, based on the primary microphone classification and the secondary microphone classification output by the classifier, to generate at least one audio encoder packet; and means for transmitting the at least one audio encoder packet.<br>1) A device configured to provide voice and data communications, the device comprising:one or more processors configured to:classify primary input audio data, by a classifier, from a primary microphone and output a primary microphone classification of the primary input audio data;classify secondary input audio data, by the classifier, from a secondary microphone and output a secondary microphone classification of the secondary input audio data;obtain a proximity signal that determines the device's relative position to a user;obtain an audio context, with a control unit, of the primary input audio data and the secondary input audio data, wherein the control unit combines the proximity signal, the primary microphone classification, and the secondary microphone classification output by the classifier, prior to application of a variable level of noise suppression to the primary input audio data and the secondary input audio data, wherein the primary input audio data and secondary input audio data includes speech signals, music signals, and noise signals and the audio context indicating a valid speech context or a valid music context;apply, with a noise suppression unit, the variable level of noise suppression to the primary input audio data and the secondary input audio data, wherein the variable level of the noise suppression unit includes a first level of noise suppression when the speech signals are louder than the music signals, and a second level of noise suppression that is lower than the first level of the noise suppression to leave music signals undistorted in the primary input audio data and the secondary input audio data when the music signals are louder than the speech signals, and the variable noise suppression is applied to the primary input audio data and the secondary input audio data prior to bandwidth compression, by an audio encoder coupled to the noise suppression unit, to generate a noise suppressed version of the primary input audio data and the secondary input audio data; andbandwidth compress, with the audio encoder, the noise suppressed version of the primary input audio data and the secondary input audio data to generate at least one audio encoder packet;a memory, electrically coupled to the one or more processors, configured to store the at least one audio encoder packet; anda transmitter configured to transmit the at least one audio encoder packet. one or more processors configured to:classify primary input audio data, by a classifier, from a primary microphone and output a primary microphone classification of the primary input audio data;classify secondary input audio data, by the classifier, from a secondary microphone and output a secondary microphone classification of the secondary input audio data;obtain a proximity signal that determines the device's relative position to a user;obtain an audio context, with a control unit, of the primary input audio data and the secondary input audio data, wherein the control unit combines the proximity signal, the primary microphone classification, and the secondary microphone classification output by the classifier, prior to application of a variable level of noise suppression to the primary input audio data and the secondary input audio data, wherein the primary input audio data and secondary input audio data includes speech signals, music signals, and noise signals and the audio context indicating a valid speech context or a valid music context;apply, with a noise suppression unit, the variable level of noise suppression to the primary input audio data and the secondary input audio data, wherein the variable level of the noise suppression unit includes a first level of noise suppression when the speech signals are louder than the music signals, and a second level of noise suppression that is lower than the first level of the noise suppression to leave music signals undistorted in the primary input audio data and the secondary input audio data when the music signals are louder than the speech signals, and the variable noise suppression is applied to the primary input audio data and the secondary input audio data prior to bandwidth compression, by an audio encoder coupled to the noise suppression unit, to generate a noise suppressed version of the primary input audio data and the secondary input audio data; andbandwidth compress, with the audio encoder, the noise suppressed version of the primary input audio data and the secondary input audio data to generate at least one audio encoder packet; a memory, electrically coupled to the one or more processors, configured to store the at least one audio encoder packet; and a transmitter configured to transmit the at least one audio encoder packet.</p></layer>
<layer id = "layer694"><p><b>US9437212B1:Systems and methods for suppressing noise in an audio signal for subbands in a frequency domain based on a closed-form solution</b><br><b>Independant Claims</b><br>1) A method for reducing noise from an input signal to generate a noise-reduced output signal, the method comprising: receiving an input signal; transforming the input signal from a time domain to a plurality of subbands in a frequency domain, wherein each subband of the plurality of subbands includes a speech component and a noise component; for each of the subbands, estimating an amplitude of the speech component based on a of minimization of a normalized mean square error, wherein the normalized mean squared error is based on a mean squared error represented by E[(A−Â)|Y], where Â is an estimate of the amplitude of the speech component, A represents an actual value of the amplitude of the speech component, Y is the amplitude of the subband, and E is an expected value operator; and filtering the plurality of subbands in the frequency domain based on the estimated amplitudes of the speech components to generate the noise-reduced output signal.<br>11) A system for reducing noise from an input signal to generate a noise-reduced output signal, the system comprising: a time-to-frequency transformation device configured to transform an input signal from a time domain to a plurality of subbands in the frequency domain, wherein each subband of the plurality of subbands includes a speech component and a noise component; a filter coupled to the time-to-frequency device, the filter being configured to: for each of the subbands, estimate an amplitude of the speech component based on a minimization of a normalized mean square error, wherein the normalized mean squared error is based on a mean squared error represented by E[(A−Â)|Y], where Â is an estimate of the amplitude of the speech component, A represents an actual value of the amplitude of the speech component, Y is the amplitude of the subband, and E is an expected value operator, and filter the plurality of subbands in the frequency domain based on the estimated amplitudes of the speech components to generate the noise-reduced output signal; and a frequency-to-time transformation device configured to transform the noise-reduced output signal from the frequency domain to the time domain.</p></layer>
<layer id = "layer695"><p><b>US9558755B1:Noise suppression assisted automatic speech recognition</b><br><b>Independant Claims</b><br>1) A method for processing an audio signal, comprising: generating sub-band signals from a received primary acoustic signal and a received secondary acoustic signal; determining two or more features for the sub-band signals, the two or more features including a speech energy level for the sub-band noise level and at least one of the following: inter-microphone level differences, inter-microphone time differences, and inter-microphone phase differences between the primary acoustic signal and the secondary acoustic signal; suppressing a noise component in the primary acoustic signal based on the two or more features, the suppressing configured to clean the primary acoustic signal to create a cleaned speech signal optimized for accurate speech recognition processing by an automatic speech recognition processing module, the suppressing comprising: applying a gain to a sub-band of the primary acoustic signal to provide a noise suppressed signal, the applying comprising: determining a speech to noise ratio (SNR) for the sub-band of the primary acoustic signal; accessing the gain, based on the frequency of the sub-band and the determined SNR for the sub-band, from a datastore, the datastore including a plurality of pre-stored gains configured to create cleaned speech signals optimized for accurate speech recognition processing by the automatic speech recognition processing module, each pre-stored gain in the plurality of pre-stored gains associated with a corresponding frequency and an SNR value; and applying the accessed gain to the sub-band frequency; and providing the cleaned speech signal and corresponding noise suppression information to the automatic speech recognition processing module, the noise suppression information based on the two or more features and including a voice activity detection signal.<br>9) A non-transitory computer readable storage medium having embodied thereon a program, the program being executable by a processor to perform a method for reducing noise in an audio signal, the method comprising: generating sub-band signals from a received primary acoustic signal and a received secondary acoustic signal; determining two or more features for a sub-band signal, the two or more features including a speech energy level for the sub-band noise level and at least one of the following: inter-microphone level differences, inter-microphone time differences, and inter-microphone phase differences between the primary acoustic signal and the secondary acoustic signal; suppressing a noise component in the primary acoustic signal based on the two or more features, the suppressing configured to clean the primary acoustic signal to create a cleaned speech signal optimized for accurate speech recognition processing by an automatic speech recognition processing module, the suppressing comprising: applying a gain to a sub-band of the primary acoustic signal to provide a noise suppressed signal, the applying comprising: determining a speech to noise ratio (SNR) for the sub-band of the primary acoustic signal; accessing the gain, based on the frequency of the sub-band and the determined SNR for the sub-band, from a datastore, the datastore including a plurality of pre-stored gains configured to create cleaned speech signals optimized for accurate speech recognition processing by the automatic speech recognition processing module, each pre-stored gain in the plurality of pre-stored gains associated with a corresponding frequency and an SNR value; and applying the accessed gain to the sub-band frequency; and providing the cleaned speech signal and corresponding noise suppression information to the automatic speech recognition processing module, the noise suppression information based on the two or more features and including a speech to noise ratio for each of the sub-band signals and a voice activity detection signal.</p></layer>
<layer id = "layer696"><p><b>US9640194B1:Noise suppression for speech processing based on machine-learning mask estimation</b><br><b>Independant Claims</b><br>1) A method for noise suppression, comprising: receiving, by a first processor communicatively coupled with a first memory, first noisy speech, the first noisy speech obtained using two or more microphones; extracting, by the first processor, one or more first cues from the first noisy speech, the one or more first cues including cues associated with noise suppression and automatic speech processing; and creating clean automatic speech processing features using a mapping and the extracted one or more first cues, the clean automatic speech processing features being for use in automatic speech processing and the mapping being provided by a process including:receiving, by a second processor communicatively coupled with a second memory, clean speech and noise;producing, by the second processor, second noisy speech using the clean speech and the noise;extracting, by the second processor, one or more second cues from the second noisy speech, the one or more second cues including cues associated with noise suppression and noisy automatic speech processing;extracting clean automatic speech processing cues from the clean speech; andgenerating, by the second processor, the mapping from the one or more second cues to the clean automatic speech processing cues, the generating including at least one machine-learning technique.<br>10) A system for noise suppression, comprising: a first frequency analysis module, executed by at least one processor, that is configured to receive first noisy speech, the first noisy speech being each obtained using at least two microphones; a second frequency analysis module, executed by the at least one processor, that is configured to receive clean speech and noise; a combination module, executed by the at least one processor, that is configured to produce second noisy speech using the clean speech and the noise; a first cue extraction module, executed by the at least one processor, that is configured to extract one or more first cues from the first noisy speech, the one or more first cues including cues associated with noise suppression and automatic speech processing; a second cue extraction module, executed by the at least one processor, that is configured to extract one or more second cues from the second noisy speech, the one or more second cues including cues associated with noise suppression and noisy automatic speech processing; a third cue extraction module, executed by the at least one processor, that is configured to extract clean automatic speech processing cues from the clean speech; and a learning module, executed by the at least one processor, that is configured to generate a mapping from the one or more second cues associated with the noise suppression cues and the noisy automatic speech processing cues to the clean automatic speech processing cues, the generating including at least one machine-learning technique; and a modification module, executed by the at least one processor, that is configured to create clean automatic speech processing features using the mapping and the extracted one or more first cues, the clean automatic speech processing features being for use in automatic speech processing.</p></layer>
<layer id = "layer697"><p><b>US10257611B2:Stereo separation and directional suppression with omni-directional microphones</b><br><b>Independant Claims</b><br>11) A system for providing a multi-channel audio signal, the system comprising:at least one processor; anda memory communicatively coupled with the at least one processor, the memory storing instructions, which when executed by the at least one processor, perform a method comprising:receiving at least a first audio signal and a second audio signal, the first audio signal representing sound captured by a first microphone associated with a first location and the second audio signal representing sound captured by a second microphone associated with a second location, the first microphone and the second microphone comprising omni-directional microphones of a device;generating a first channel signal of the multi-channel audio signal by forming, based on the first audio signal and the second audio signal, a first beam at the first location;generating a second channel signal of the multi-channel audio signal by forming, based on the first audio signal and the second audio signal, a second beam at the second location,wherein generating the first and second channel signals further includes suppressing sound captured by the first and second microphones associated with a sound source located in a determined direction relative to the device; andprocessing the first and second audio signals to determine the determined direction associated with the sound source.<br>1) A method for providing a multi-channel audio signal, the method comprising:receiving at least a first audio signal and a second audio signal, the first audio signal representing sound captured by a first microphone associated with a first location and the second audio signal representing sound captured by a second microphone associated with a second location, the first microphone and the second microphone comprising omni-directional microphones of a device;generating a first channel signal of the multi-channel audio signal by forming, based on the first audio signal and the second audio signal, a first beam at the first location;generating a second channel signal of the multi-channel audio signal by forming, based on the first audio signal and the second audio signal, a second beam at the second location,wherein generating the first and second channel signals further includes suppressing sound captured by the first and second microphones associated with a sound source located in a determined direction relative to the device; andprocessing the first and second audio signals to determine the determined direction associated with the sound source.</p></layer>
<layer id = "layer698"><p><b>US9270722B2:Method for concatenating frames in communication system</b><br><b>Independant Claims</b><br>1) A system for concatenating a first frame of samples and a subsequent second frame of samples in a digitized audio signal in a receiver, the system comprising: one or more processor; and one or more computer-readable memories, coupled to the one or more processors, comprising instructions executable by the one or more processors to configure the system to: generate concealment samples from the subsequent second frame of samples of the digitized audio signal; place the concealment samples in the signal such that the second frame follows the concealment samples; initialize a parametric all pass filter in the receiver based on said concealment samples, thereby initializing filter coefficients of the parametric all pass filter; and concurrently apply the parametric all pass filter to at least part of samples in at least two consecutive frames, so as to minimize a discontinuity at a boundary between the first and second frames of samples.<br>15) A receiver device for concatenating a first frame of samples and a subsequent second frame of samples in a digitized audio signal comprising: a processor; one or more memories, coupled to the processor, comprising instructions executable by the processor to perform operations comprising: receiving the signal comprising the first frame of samples and the subsequent second frame of samples; generating concealment samples from the subsequent second frame of samples of the digitized audio signal; placing the concealment samples in the signal such that the second frame follows the concealment samples; initializing a parametric all pass filter in the receiver based on said concealment samples, thereby initializing filter coefficients of the parametric all pass filter; and concurrently applying the parametric all pass filter to at least part of samples in at least two consecutive frames, so as to minimize a discontinuity at a boundary between the first and second frames of samples.<br>18) A method for concatenating a first frame of samples and a subsequent second frame of samples in a digitized audio signal in a receiver, the method comprising: generating concealment samples from the subsequent second frame of samples of the digitized audio signal; placing the concealment samples in the signal such that the second frame follows the concealment samples; initializing a parametric all pass filter in the receiver based on said concealment samples, thereby initializing filter coefficients of the parametric all pass filter; and concurrently applying the parametric all pass filter to at least part of samples in at least two consecutive frames, so as to minimize a discontinuity at a boundary between the first and second frames of samples.</p></layer>
<layer id = "layer699"><p><b>USRE47180E1:Apparatus and method for generating a bandwidth extended signal</b><br><b>Independant Claims</b><br>26) A non-transitory storage medium having stored thereon a computer program with a program code for performing the method for generating a bandwidth extended signal from an input signal, when the computer program runs on a computer or microcontroller, the method comprising: generating a first patch based on the input signal and generating a second patch based on the input signal, wherein a spectral density of the second patch is higher than a spectral density of the first patch; and combining the first patch and the second patch for extending the bandwidth of the input signal; wherein the method comprises generating one of the first patch and the second patch using a harmonic patching algorithm and wherein the method comprises generating the other of the first patch and the second patch using a non-linear distortion, so that the other of the first patch and the second patch comprises frequencies that are not integer multiples of frequencies of the first band of the input signal, or wherein the method comprises generating one of the first patch and the second patch using a harmonic patching algorithm and wherein the patch generator is configured to generate the other of the first patch and the second patch using a non-linear distortion to obtain further harmonics, so that energy is distributed between lines obtained by the harmonic patching algorithm.<br>25) A method for generating a bandwidth extended signal from an input signal, the method comprising: generating a first patch based on the input signal and generating a second patch based on the input signal, wherein a spectral density of the second patch is higher than a spectral density of the first patch; and combining the first patch and the second patch for extending the bandwidth of the input signal; wherein the method comprises generating one of the first patch and the second patch using a harmonic patching algorithm and wherein the method comprises generating the other of the first patch and the second patch using a non-linear distortion, so that the other of the first patch and the second patch comprises frequencies that are not integer multiples of frequencies of the first band of the input signal, or wherein the method comprises generating one of the first patch and the second patch using a harmonic patching algorithm and wherein the patch generator is configured to generate the other of the first patch and the second patch using a non-linear distortion to obtain further harmonics, so that energy is distributed between lines obtained by the harmonic patching algorithm.<br>24) The apparatus according to claim 18, wherein the apparatus is configured to generate the bandwidth extended signal by performing a weighted addition of the second patch, the first patch and a first band of the input signal.<br>23) The apparatus according to claim 18, wherein the apparatus is configured to generate the bandwidth extended signal by performing a weighted addition of the second patch and the first patch.<br>22) The apparatus according to claim 18, wherein the patch generator is configured to generate the second patch so that gaps in a spectrum of the first patch are filled by the second patch.<br>21) The apparatus according to claim 20, wherein the spectral envelope criterion is determined based on a spectral envelope of an original signal.<br>20) The apparatus according to claim 18, wherein the apparatus is configured to scale the first patch and the second patch before or after generation to fulfill a spectral envelope criterion.<br>19) The apparatus according to claim 18, wherein the patch generator is configured to generate the first patch so that the first patch comprises gaps in comparison to a low frequency band of the input signal, and wherein the patch generator is configured to generate the second patch so that the second patch comprises only a few gaps or no gaps in comparison to the low frequency band of the input signal.<br>18) An apparatus for generating a bandwidth extended signal from an input signal, the apparatus comprising: a patch generator configured to generate a first patch based on the input signal and configured to generate a second patch based on the input signal, wherein a spectral density of the second patch is higher than a spectral density of the first patch; and a combiner configured to combine the first patch and the second patch for extending the bandwidth of the input signal, wherein the patch generator is configured to generate one of the first patch and the second patch using a harmonic patching algorithm and wherein the patch generator is configured to generate the other of the first patch and the second patch using a non-linear distortion, so that the other of the first patch and the second patch comprises frequencies that are not integer multiples of frequencies of the first band of the input signal, or wherein the patch generator is configured to generate one of the first patch and the second patch using a harmonic patching algorithm and wherein the patch generator is configured to generate the other of the first patch and the second patch using a non-linear distortion to obtain further harmonics, so that energy is distributed between lines obtained by the harmonic patching algorithm.<br>17) A non-transitory storage medium having stored thereon a computer program with a program code for performing the method for providing a bandwidth reduced signal based on an input signal, the method comprising: determining a spectral envelope data based on a high frequency band of the input signal; generating patch scaling control data for scaling the bandwidth reduced signal at a decoder or for scaling a first patch and a second patch by the decoder, so that a bandwidth extended signal generated by the decoder fulfills a spectral envelope criterion, wherein the spectral envelope criterion is based on the spectral envelope data, wherein the first patch is generated from a first band of the bandwidth reduced signal according to a first patching algorithm and a second patch is generated from the first band of the bandwidth reduced signal according to a second patching algorithm, wherein a spectral density of the second patch generated according to the second patching algorithm is higher than a spectral density of the first patch generated according to the first patching algorithm; combining a low frequency band of the input signal, the spectral envelope data and the patch scaling control data to acquire the bandwidth reduced signal; providing the bandwidth reduced signal for a transmission or storage, when the computer program runs on a computer or a microcontroller.<br>16) A non-transitory storage medium having stored thereon a computer program with a program code for performing the method for generating a bandwidth extended signal from an input signal, wherein the input signal is represented, for a first band by a first resolution data, and for a second band by a second resolution data, the second resolution being lower than the first resolution, the method comprising: generating a first patch from the first band of the input signal according to a first patching algorithm; generating a second patch from the first band of the input signal according to a second patching algorithm, wherein a spectral density of the second patch generated according to the second patching algorithm is higher than a spectral density of the first patch generated according to the first patching algorithm; scaling the input signal according to the first patching algorithm and according to the second patching algorithm or scaling the first patch and the second patch, so that the bandwidth extended signal fulfills the spectral envelope criterion or scaling only one of the first and second patches to obtain a scaled patch, and then combining the scaled patch and a non-scaled patch from the first and second patches to obtain combined patches, and then scaling the combined patches before combining the combined patches with the first band of the input signal; and combining the first patch, the second patch or the combined patches and the first band of the input signal to acquire the bandwidth extended signal, when the computer program runs on a computer or a microcontroller.<br>15) A method for providing a bandwidth reduced signal based on an input signal, comprising: determining a spectral envelope data based on a high frequency band of the input signal; generating patch scaling control data for scaling the bandwidth reduced signal at a decoder or for scaling a first patch and a second patch by the decoder, so that a bandwidth extended signal generated by the decoder fulfills a spectral envelope criterion, wherein the spectral envelope criterion is based on the spectral envelope data, wherein the first patch is generated from a first band of the bandwidth reduced signal according to a first patching algorithm and a second patch is generated from the first band of the bandwidth reduced signal according to a second patching algorithm, wherein a spectral density of the second patch generated according to the second patching algorithm is higher than a spectral density of the first patch generated according to the first patching algorithm; combining a low frequency band of the input signal, the spectral envelope data and the patch scaling control data to acquire the bandwidth reduced signal; providing the bandwidth reduced signal for a transmission or storage.<br>14) A method for generating a bandwidth extended signal from an input signal, wherein the input signal is represented, for a first band by a first resolution data, and for a second band by a second resolution data, the second resolution being lower than the first resolution, the method comprising: generating a first patch from the first band of the input signal according to a first patching algorithm; generating a second patch from the first band of the input signal according to a second patching algorithm, wherein a spectral density of the second patch generated according to the second patching algorithm is higher than a spectral density of the first patch generated according to the first patching algorithm; scaling the input signal according to the first patching algorithm and according to the second patching algorithm or scaling the first patch and the second patch, so that the bandwidth extended signal fulfills the spectral envelope criterion or scaling only one of the first and second patches to obtain a scaled patch, and then combining the scaled patch and a non-scaled patch from the first and second patches to obtain combined patches, and then scaling the combined patches before combining the combined patches with the first band of the input signal; and combining the first patch, the second patch or the combined patches and the first band of the input signal to acquire the bandwidth extended signal.<br>11) An apparatus for providing a bandwidth reduced signal based on an input signal, comprising: a spectral envelope data determiner configured to determine spectral envelope data based on a high-frequency band of the input signal; a patch scaling control data generator configured to generate patch scaling control data for scaling the bandwidth reduced signal at a decoder or for scaling a first patch and a second patch by the decoder, so that a bandwidth extended signal generated by the decoder fulfills a spectral envelope criterion, wherein the spectral envelope criterion is based on the spectral envelope data wherein the first patch is generated from a first band of the bandwidth reduced signal according to a first patching algorithm and the second patch is generated from the first band of the bandwidth reduced signal according to a second patching algorithm, wherein a spectral density of the second patch generated according to the second patching algorithm is higher than a spectral density of the first patch generated according to the first patching algorithm; an output interface configured to combine a low frequency band of the input signal, the spectral envelope data and the patch scaling control data to acquire the bandwidth reduced signal and configured to provide the bandwidth reduced signal for transmission or storage.<br>1) An apparatus for generating a bandwidth extended signal from an input signal, wherein the input signal is represented, for a first band by a first resolution data, and for a second band by a second resolution data, the second resolution being lower than the first resolution, the apparatus comprising: a patch generator configured to generate a first patch from the first band of the input signal according to a first patching algorithm and configured to generate a second patch from the first band of the input signal according to a second patching algorithm, wherein a spectral density of the second patch generated according to the second patching algorithm is higher than a spectral density of the first patch generated according to the first patching algorithm; and a combiner configured to combine the first patch, the second patch and the first band of the input signal to acquire the bandwidth extended signal, wherein the apparatus for generating a bandwidth extended signal is configured to scale the input signal according to the first patching algorithm and according to the second patching algorithm or to scale the first patch and the second patch, or to scale only one of the first and second patches to obtain a scaled patch, to then combine the scaled patch and a non-scaled patch from the first and second patches to obtain combined patches, and to then scale the combined patches before combining the combined patches with the first band of the input signal, so that the bandwidth extended signal fulfills a spectral envelope criterion.</p></layer>   </body><script>function showText() { var re = new RegExp(document.getElementById("search_text").value, "i"); var j=0; for (i = 1; i < 700; i++) {   var myLayer = "layer" + i;   if (re.test(document.getElementById(myLayer).innerHTML)){    showElement(myLayer);    j++;   }else{    hideElement(myLayer);   } } document.getElementById('result_count_i').value = j;}function hideElement(elementId) { document.getElementById(elementId).style.display = 'none';}function showElement(elementId) { document.getElementById(elementId).style.display = 'block';}</script></html>
